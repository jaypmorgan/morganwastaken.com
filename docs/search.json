[
  {
    "objectID": "posts.html",
    "href": "posts.html",
    "title": "Blog Posts",
    "section": "",
    "text": "How I utilise the word utilise\n\n\n\n\n\n\nJay Paul Morgan\n\n\nMay 8, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nOn Scientific Ethics\n\n\n\n\n\n\nJay Paul Morgan\n\n\nApr 21, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nDomain-informed graph neural networks: a quantum chemistry case study\n\n\n\n\n\n\nJay Paul Morgan\n\n\nJun 27, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nMCH2023 - A retrospective\n\n\n\n\n\n\nJay Paul Morgan\n\n\nApr 21, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nMachine Learning and Computer Vision in Heliophysics\n\n\n\n\n\n\nJay Paul Morgan\n\n\nMar 19, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nDisplaying remote images in Org-mode\n\n\n\n\n\n\nJay Paul Morgan\n\n\nMar 18, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nUsing a remote Python process in Org-mode files\n\n\n\n\n\n\nJay Paul Morgan\n\n\nDec 15, 2022\n\n\n\n\n\n\n\n\n\n\n\n\nXTAI 2022 - Adaptive Neighbourhoods for the Discovery of Adversarial Examples\n\n\n\n\n\n\nJay Paul Morgan\n\n\nOct 12, 2022\n\n\n\n\n\n\n\n\n\n\n\n\nBritish Colloquium for Theoretical Computer Science (BCTCS) 2021\n\n\n\n\n\n\nJay Paul Morgan\n\n\nMar 29, 2021\n\n\n\n\n\n\n\n\n\n\n\n\nMakefile: Towards Reproducible Research-based Programming\n\n\n\n\n\n\nJay Paul Morgan\n\n\nMar 5, 2020\n\n\n\n\n\n\n\n\n\n\n\n\nFuzzy Logic Membership Functions\n\n\n\n\n\n\nJay Paul Morgan\n\n\nJun 27, 2019\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-8.html",
    "href": "teaching/2023-2024/Programming Level-up/lecture-8.html",
    "title": "All about Git",
    "section": "",
    "text": "If we’re just programming by ourselves we often just make the changes to the program as we need and move on. But what if we’re not the only person making changes? For example, there are thousands of developers contributing to large open-source projects like the Linux kernel, Deep Learning frameworks such as Pytorch or Tensorflow, and programming languages such as Python. How do we manage the changes from all of these thousands of independent developers while keeping track of what’s changed?\nThis is (one of) the role of version control systems, often abbreviated to VCS. A version control system is an additional layer of software over our programming code that allows us to ‘checkpoint’ the program code at a specific point in time. Moreover, it can help ‘merge’ changes from different developers, so that the changes made by one developer does not un-intentionally overwrite the changes made by a different developer.\nGit, developed by Linus Torvalds in 2005, is one such version control system that is the most ubiquitous at the time of writing. It has surpassed many existing version control systems, and while many new ones have been proposed, none have been successful (yet) at unmounting Git from it’s throne as the leader of VCSs.\nIn this lecture, we’ll learn how to setup and use git in our projects."
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-8.html#creating-checking-out-branches",
    "href": "teaching/2023-2024/Programming Level-up/lecture-8.html#creating-checking-out-branches",
    "title": "All about Git",
    "section": "Creating & Checking out Branches",
    "text": "Creating & Checking out Branches\nTo create a new branch use the branch sub-command, specifying the name of the new branch:\nmy-new-project % git branch develop\nmy-new-project % git branch\n  develop\n* main\nHere, we’ve created a new branch develop, and listed all of the existing branches using git branch.\nThe asterisk (*) next to the branch name tells us what branch we’re currently on.\nTo change branches we can checkout a new branch:\nmy-new-project % git checkout develop\nSwitched to branch 'develop'\nmy-new-project % git branch\n* develop\n  main\nOur project now looks like:\n\n\n\n\n\ngitGraph\n    commit\n    commit\n    branch develop\n    checkout develop\n\n\n\n\n\n\nGit will tell us when it’s changing branches as you see in the above command.\nNow that we’re on the new branch, we can start to make some changes, stage, and commit them:\nmy-new-project % git status\nOn branch develop\nChanges not staged for commit:\n  (use \"git add &lt;file&gt;...\" to update what will be committed)\n  (use \"git restore &lt;file&gt;...\" to discard changes in working directory)\n    modified:   src/main.cpp\n\nno changes added to commit (use \"git add\" and/or \"git commit -a\")\nmy-new-project % git add src/main.cpp  \nmy-new-project % git commit -m 'Add new feature'\n[develop a59f1a7] Add new feature\n 1 file changed, 1 insertion(+)\nNow our project looks like:\n\n\n\n\n\ngitGraph\n    commit\n    commit\n    branch develop\n    checkout develop\n    commit"
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-8.html#merging-branches",
    "href": "teaching/2023-2024/Programming Level-up/lecture-8.html#merging-branches",
    "title": "All about Git",
    "section": "Merging Branches",
    "text": "Merging Branches\nOur ‘feature’ is complete, and we have a working state of the program, so we’ll want to merge this new feature back into the main branch.\nFirst, we’ll checkout the main branch\nmy-new-project % git checkout main\nSwitched to branch 'main'\nAnd now, we’ll merge the develop branch into the main branch using the merge sub-command:\nmy-new-project % git merge develop\nUpdating 1a5d58e..a59f1a7\nFast-forward\n src/main.cpp | 1 +\n 1 file changed, 1 insertion(+)\nOur project now looks like:\n\n\n\n\n\ngitGraph\n    commit\n    commit\n    branch develop\n    checkout develop\n    commit\n    checkout main\n    merge develop"
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-8.html#merge-conflicts",
    "href": "teaching/2023-2024/Programming Level-up/lecture-8.html#merge-conflicts",
    "title": "All about Git",
    "section": "Merge Conflicts",
    "text": "Merge Conflicts\nSometimes, though, the branches cannot automatically be merged together. This can happen when the branches being merged have edited the same piece of text. Which edits does Git keep when merging? It’s a piece of software, not a mind-reader! It can’t know the answer to this question so we have to tell Git what to keep and what to throw away to complete the merging process.\nSo, let’s imagine we’re trying to merge two branches that have edited the same text. I’ve created this scenario by editing the title of the README file in two branches and tried to merge them. At this point this happened:\nmy-new-project % git merge develop\nAuto-merging README.md\nCONFLICT (content): Merge conflict in README.md\nAutomatic merge failed; fix conflicts and then commit the result.\nGit is telling me: “I can’t automatically merge these two branches because they’ve edited the same thing. Tell me what to keep and then we can carry on.”\nSo we’ll do just that, if we open up the README.md file mentioned in the merge conflict message, we’ll see:\n&lt;&lt;&lt;&lt;&lt;&lt;&lt; HEAD \n# Deep Learning \n======= \n# C++ Examples of Deep Learning \n&gt;&gt;&gt;&gt;&gt;&gt;&gt; develop \nEverything between &lt;&lt;&lt;&lt;&lt;&lt;&lt; HEAD and ======= is what’s currently in the commit. While between ======= and &gt;&gt;&gt;&gt;&gt;&gt;&gt; develop is the content trying to be merged.\nLet’s say that we prefer what is in the develop branch, then we’ll remove (just by deleting in your text editor of choice) everything from &lt;&lt;&lt;&lt;&lt;&lt;&lt; HEAD to ======= and then remove &gt;&gt;&gt;&gt;&gt;&gt;&gt; develop so that our file now looks like this:\n# C++ Examples of Deep Learning \nIn essence we’ve extracted the parts of the file we wanted to keep in the process of merging, and removed the parts we didn’t want, in addition to removing the &lt;&lt;&lt;&lt;&lt;, ===== delimiters.\nNow we can save this file and commit the changes, thus completing the merge conflicts.\nmy-new-project % git status\nOn branch main\nYou have unmerged paths.\n  (fix conflicts and run \"git commit\")\n  (use \"git merge --abort\" to abort the merge)\n\nUnmerged paths:\n  (use \"git add &lt;file&gt;...\" to mark resolution)\n    both modified:   README.md\n\nno changes added to commit (use \"git add\" and/or \"git commit -a\")\nmy-new-project % git commit -a -m 'Resolve conflicts'\n[main c8efca4] Resolve conflicts\nOur git history will now look something like:\n\n\n\n\n\ngitGraph\n    commit\n    commit\n    branch develop\n    checkout develop\n    commit\n    checkout main\n    merge develop\n    commit\n    checkout develop\n    commit\n    checkout main\n    merge develop"
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-8-reveal.html#creating-checking-out-branches",
    "href": "teaching/2023-2024/Programming Level-up/lecture-8-reveal.html#creating-checking-out-branches",
    "title": "All about Git",
    "section": "Creating & Checking out Branches",
    "text": "Creating & Checking out Branches\nTo create a new branch use the branch sub-command, specifying the name of the new branch:\nmy-new-project % git branch develop\nmy-new-project % git branch\n  develop\n* main\nHere, we’ve created a new branch develop, and listed all of the existing branches using git branch.\nThe asterisk (*) next to the branch name tells us what branch we’re currently on.\nTo change branches we can checkout a new branch:\nmy-new-project % git checkout develop\nSwitched to branch 'develop'\nmy-new-project % git branch\n* develop\n  main\nOur project now looks like:\n\n\n\n\n\ngitGraph\n    commit\n    commit\n    branch develop\n    checkout develop\n\n\n\n\n\n\nGit will tell us when it’s changing branches as you see in the above command.\nNow that we’re on the new branch, we can start to make some changes, stage, and commit them:\nmy-new-project % git status\nOn branch develop\nChanges not staged for commit:\n  (use \"git add &lt;file&gt;...\" to update what will be committed)\n  (use \"git restore &lt;file&gt;...\" to discard changes in working directory)\n    modified:   src/main.cpp\n\nno changes added to commit (use \"git add\" and/or \"git commit -a\")\nmy-new-project % git add src/main.cpp  \nmy-new-project % git commit -m 'Add new feature'\n[develop a59f1a7] Add new feature\n 1 file changed, 1 insertion(+)\nNow our project looks like:\n\n\n\n\n\ngitGraph\n    commit\n    commit\n    branch develop\n    checkout develop\n    commit"
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-8-reveal.html#merging-branches",
    "href": "teaching/2023-2024/Programming Level-up/lecture-8-reveal.html#merging-branches",
    "title": "All about Git",
    "section": "Merging Branches",
    "text": "Merging Branches\nOur ‘feature’ is complete, and we have a working state of the program, so we’ll want to merge this new feature back into the main branch.\nFirst, we’ll checkout the main branch\nmy-new-project % git checkout main\nSwitched to branch 'main'\nAnd now, we’ll merge the develop branch into the main branch using the merge sub-command:\nmy-new-project % git merge develop\nUpdating 1a5d58e..a59f1a7\nFast-forward\n src/main.cpp | 1 +\n 1 file changed, 1 insertion(+)\nOur project now looks like:\n\n\n\n\n\ngitGraph\n    commit\n    commit\n    branch develop\n    checkout develop\n    commit\n    checkout main\n    merge develop"
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-8-reveal.html#merge-conflicts",
    "href": "teaching/2023-2024/Programming Level-up/lecture-8-reveal.html#merge-conflicts",
    "title": "All about Git",
    "section": "Merge Conflicts",
    "text": "Merge Conflicts\nSometimes, though, the branches cannot automatically be merged together. This can happen when the branches being merged have edited the same piece of text. Which edits does Git keep when merging? It’s a piece of software, not a mind-reader! It can’t know the answer to this question so we have to tell Git what to keep and what to throw away to complete the merging process.\nSo, let’s imagine we’re trying to merge two branches that have edited the same text. I’ve created this scenario by editing the title of the README file in two branches and tried to merge them. At this point this happened:\nmy-new-project % git merge develop\nAuto-merging README.md\nCONFLICT (content): Merge conflict in README.md\nAutomatic merge failed; fix conflicts and then commit the result.\nGit is telling me: “I can’t automatically merge these two branches because they’ve edited the same thing. Tell me what to keep and then we can carry on.”\nSo we’ll do just that, if we open up the README.md file mentioned in the merge conflict message, we’ll see:\n&lt;&lt;&lt;&lt;&lt;&lt;&lt; HEAD \n# Deep Learning \n======= \n# C++ Examples of Deep Learning \n&gt;&gt;&gt;&gt;&gt;&gt;&gt; develop \nEverything between &lt;&lt;&lt;&lt;&lt;&lt;&lt; HEAD and ======= is what’s currently in the commit. While between ======= and &gt;&gt;&gt;&gt;&gt;&gt;&gt; develop is the content trying to be merged.\nLet’s say that we prefer what is in the develop branch, then we’ll remove (just by deleting in your text editor of choice) everything from &lt;&lt;&lt;&lt;&lt;&lt;&lt; HEAD to ======= and then remove &gt;&gt;&gt;&gt;&gt;&gt;&gt; develop so that our file now looks like this:\n# C++ Examples of Deep Learning \nIn essence we’ve extracted the parts of the file we wanted to keep in the process of merging, and removed the parts we didn’t want, in addition to removing the &lt;&lt;&lt;&lt;&lt;, ===== delimiters.\nNow we can save this file and commit the changes, thus completing the merge conflicts.\nmy-new-project % git status\nOn branch main\nYou have unmerged paths.\n  (fix conflicts and run \"git commit\")\n  (use \"git merge --abort\" to abort the merge)\n\nUnmerged paths:\n  (use \"git add &lt;file&gt;...\" to mark resolution)\n    both modified:   README.md\n\nno changes added to commit (use \"git add\" and/or \"git commit -a\")\nmy-new-project % git commit -a -m 'Resolve conflicts'\n[main c8efca4] Resolve conflicts\nOur git history will now look something like:\n\n\n\n\n\ngitGraph\n    commit\n    commit\n    branch develop\n    checkout develop\n    commit\n    checkout main\n    merge develop\n    commit\n    checkout develop\n    commit\n    checkout main\n    merge develop"
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-1.html#a-first-program",
    "href": "teaching/2023-2024/Programming Level-up/lecture-1.html#a-first-program",
    "title": "Python Introduction",
    "section": "A first program",
    "text": "A first program\nWe’re going to start with the ‘Hello, World’ program that prints Hello, World! to the screen. In python this is as simple as writing:\n    print(\"Hello, World!\")   # this prints: Hello, World!\nResults: \n# =&gt; Hello, World!\nNOTE anything following a # is a comment and is completely ignored by the computer. It is there for you to document your code for others, and most importantly, for yourself."
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-1.html#running-this-program",
    "href": "teaching/2023-2024/Programming Level-up/lecture-1.html#running-this-program",
    "title": "Python Introduction",
    "section": "Running this program",
    "text": "Running this program\nBefore we can run this program, we need to save it somewhere. For this, will create a new file, insert this text, and save it as &lt;filename&gt;.py, where &lt;filename&gt; is what we want to call the script. This name doesn’t matter for its execution.\nOnce we have created the script, we can run it from the command line. We will get into the command line in a later lecture, but right now all you need to know is:\n    python3 &lt;filename&gt;.py"
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-1.html#an-alternative-method-of-running-python",
    "href": "teaching/2023-2024/Programming Level-up/lecture-1.html#an-alternative-method-of-running-python",
    "title": "Python Introduction",
    "section": "An alternative method of running python",
    "text": "An alternative method of running python\nYou may notice that if you don’t give python a filename to run, you will enter something called the REPL.\n    Python 3.9.5 (default, Jun  4 2021, 12:28:51) \n    [GCC 7.5.0] :: Anaconda, Inc. on linux\n    Type \"help\", \"copyright\", \"credits\" or \"license\" for more information.\n    &gt;&gt;&gt; \nREPL stands for READ, EXECUTE, PRINT, LOOP."
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-1.html#variables",
    "href": "teaching/2023-2024/Programming Level-up/lecture-1.html#variables",
    "title": "Python Introduction",
    "section": "Variables",
    "text": "Variables\nA variable is a symbol associated with a value. This value can differ widely, and we will take a look at different types of values/data later.\nNeverthless, variables are useful for referring to values and storing to the results of a computation.\n    x = 1\n    y = 2\n    z = x + y\n    print(z)   # prints: 3\n    \n    # variables can be /overwritten/\n    z = \"hello, world\"\n    print(z)   # prints: hello, world\nResults: \n# =&gt; 3\n# =&gt; hello, world"
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-1.html#primitive-data-types",
    "href": "teaching/2023-2024/Programming Level-up/lecture-1.html#primitive-data-types",
    "title": "Python Introduction",
    "section": "Primitive data types",
    "text": "Primitive data types\nPrimitive data types are the most fundamental parts of programming, they cannot be broken down.\n    \"Hello\" # string\n    1       # integer\n    1.0     # float\n    True    # Boolean (or bool for short)\nWe can get the type of some data by using the type(...) function. For example,\n    print(type(5))\n    print(type(5.0))\n    \n    x = \"all cats meow\"\n    \n    print(type(x))\nResults: \n# =&gt; &lt;class 'int'&gt;\n# =&gt; &lt;class 'float'&gt;\n# =&gt; &lt;class 'str'&gt;"
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-1.html#basic-math-with-primitives",
    "href": "teaching/2023-2024/Programming Level-up/lecture-1.html#basic-math-with-primitives",
    "title": "Python Introduction",
    "section": "Basic Math with primitives",
    "text": "Basic Math with primitives\nUsing these primitive data types, we can do some basic math operations!\n    print(1 + 2)    # Addtion\n    print(1 - 2)    # Subtraction\n    print(1 * 2)    # Multiplication\n    print(1 / 2)    # Division\n    print(2 ** 2)   # Exponent\n    print(3 % 2)    # Modulo operator\nResults: \n# =&gt; 3\n# =&gt; -1\n# =&gt; 2\n# =&gt; 0.5\n# =&gt; 4\n# =&gt; 1\nSometimes types get converted to the same type:\n    print(1.0 + 2)  # float + integer = float\nResults: \n# =&gt; 3.0\nEven more interesting is with Booleans!\n    True + True\nResults: \n# =&gt; 2"
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-1.html#bodmas-in-python",
    "href": "teaching/2023-2024/Programming Level-up/lecture-1.html#bodmas-in-python",
    "title": "Python Introduction",
    "section": "BODMAS in Python",
    "text": "BODMAS in Python\nLike in mathematics, certain math operator take precedence over others.\n\nB - Brackets\nO - Orders (roots, exponents)\nD - division\nM - multiplication\nA - addition\nS - subtraction.\n\nTo make the context clear as to what operations to perform first, use brackets.\n    (5 / 5) + 1\n    5 / (5 + 1)\nResults: \n# =&gt; 2.0\n# =&gt; 0.8333333333333334"
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-1.html#basic-math-quick-exercise",
    "href": "teaching/2023-2024/Programming Level-up/lecture-1.html#basic-math-quick-exercise",
    "title": "Python Introduction",
    "section": "Basic Math – Quick exercise",
    "text": "Basic Math – Quick exercise\nWrite the following equation in python:\n\\((5 + 2) \\times (\\frac{10}{2} + 10)^2\\)\nRemember to use parentheses ( ) to ensure that operations take precedence over others.\nYour answer should come out as: 1575.0"
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-1.html#formatting-strings",
    "href": "teaching/2023-2024/Programming Level-up/lecture-1.html#formatting-strings",
    "title": "Python Introduction",
    "section": "Formatting strings",
    "text": "Formatting strings\nIn many previous examples when we’ve printed strings, we’ve done something like:\n    age = 35\n    \n    print(\"The value of age is\", age)\nResults: \n# =&gt; The value of age is 35\nWhile this works in this small context, it can get pretty cumbersome if we have many variables we want to print, and we also want to change how they are displayed when they are printed.\nWe’re going to take a look now at much better ways of printing."
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-1.html#better-ways-of-printing-strings--",
    "href": "teaching/2023-2024/Programming Level-up/lecture-1.html#better-ways-of-printing-strings--",
    "title": "Python Introduction",
    "section": "Better ways of printing strings - %",
    "text": "Better ways of printing strings - %\nThe first method is using %. When we print, we first construct a string with special delimiters, such as %s that denotes a string, and %d that denotes a number. This is telling Python where we want the values to be placed in the string.\nOnce we’ve created the string, we need to specify the data, which we do with % (...). Like, for example:\n    age = 35\n    name = \"John\"\n    \n    print(\"%d years old\" % age)  # no tuple for one variable\n    print(\"%s is %d years old\" % (name, age)) \nResults: \n# =&gt; 35 years old\n# =&gt; John is 35 years old\nHere we are specifying the a string %s and number %d, and then giving the variables that correspond with that data type.\nThe special delimiters correspond with a data type. Here are some of the most common:\n\n%s – For strings\n%d – For numbers\n%f – For floating point numbers.\n\nThere are others such as %x that prints the hexadecimal representation, but these are less common. You can find the full list at: https://docs.python.org/3/library/stdtypes.html#old-string-formatting\nWhen using these delimiters, we can add modifiers to how they format and display the value. Take a very common example, where we have a floating point value, and, when printing it, we only want to print to 3 decimal places. To accomplish this, we again use %f but add a .3 to between the % and f. In this example, we are printing π to 3 decimal places.\n    print(\"Pi to 3 digits is: %.3f\" % 3.1415926535)\nResults: \n# =&gt; Pi to 3 digits is: 3.142\nIn the previous example, we used .3 to specify 3 decimal places. If we put a number before the decimal, like 10.3 we are telling Python make this float occupy 10 spaces and this float should have 3 decimal places printed. When it gets printed, you will notice that it shifts to the right, it gets padded by space. If we use a negative number in front of the decimal place, we are telling python to shift it to the left.\n    print(\"Pi to 3 digits is: %10.3f\" % 3.1415926535)\n    print(\"Pi to 3 digits is: %-10.3f\" % 3.1415926535)\nResults: \n# =&gt; Pi to 3 digits is:      3.142\n# =&gt; Pi to 3 digits is: 3.142\nThe final method of formatting strings is a newcomer within the language, it is the so-called f-string. Where a f character is prefixed to the beginning of the string you’re creating. f-string’s allow you to use Python syntax within the string (again delimited by {}.\nTake this for example where we are referencing the variables name and age directly.\n    name = \"Jane\"\n    age = 35\n\n    print(f\"{name} is {age} years old\")\nResults: \n# =&gt; Jane is 35 years old\nf-string’s allow you to execute Python code within the string. Here we are accessing the value from the dictionary by specifying the key within the string itself! It certainly makes it a lot easier, especially if we only need to access the values for the string itself.\n    contact_info = {\"name\": \"Jane\", \"age\": 35}\n    \n    print(f\"{contact_info['name']} is {contact_info['age']} years old\")\nResults: \n# =&gt; Jane is 35 years old\nhttps://pyformat.info/\nWe can still format the values when using f-string. The method is similar to those using the %f specifiers.\n    pi = 3.1415926535\n    print(f\"Pi is {pi:.3f} to 3 decimal places\")\nResults: \n# =&gt; Pi is 3.142 to 3 decimal places\nMany more examples can be found at: https://zetcode.com/python/fstring/"
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-1.html#splitting-strings",
    "href": "teaching/2023-2024/Programming Level-up/lecture-1.html#splitting-strings",
    "title": "Python Introduction",
    "section": "Splitting strings",
    "text": "Splitting strings\nApart from formatting, there are plenty more operations we can perform on strings. We are going to highlight some of the most common here.\nThe first we’re going to look at is splitting a string by a delimiter character using the .split() method. If we don’t pass any argument to the .split() method, then by default, it will split by spaces. However, we can change this by specifying the delimiter.\n    my_string = \"This is a sentence, where each word is separated by a space\"\n    \n    print(my_string.split())\n    print(my_string.split(\",\"))\nResults: \n# =&gt; ['This', 'is', 'a', 'sentence,', 'where', 'each', 'word', 'is', 'separated', 'by', 'a', 'space']\n# =&gt; ['This is a sentence', ' where each word is separated by a space']"
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-1.html#joining-strings-together",
    "href": "teaching/2023-2024/Programming Level-up/lecture-1.html#joining-strings-together",
    "title": "Python Introduction",
    "section": "Joining strings together",
    "text": "Joining strings together\nAs .split() splits a single string into a list, .join() joins a list of strings into a single string. To use .join(), we first create a string of the delimiter we want to use to join the list of strings by. In this example we’re going to use \"-\". Then we call the .join() method, passing the list as an argument.\nThe result is a single string using the delimiter to separate the items of the list.\n    x = ['This', 'is', 'a', 'sentence,', 'where', 'each', 'word', 'is', 'separated', 'by', 'a', 'space']\n    \n    print(\"-\".join(x))\nResults: \n# =&gt; This-is-a-sentence,-where-each-word-is-separated-by-a-space"
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-1.html#changing-cases",
    "href": "teaching/2023-2024/Programming Level-up/lecture-1.html#changing-cases",
    "title": "Python Introduction",
    "section": "Changing cases",
    "text": "Changing cases\nOther common operations on strings involve change the case. For example:\n\nMake the entire string uppercase or lowercase\nMaking the string title case (every where starts with a capital letter).\nStripping the string by removing any empty spaces either side of the string.\n\nNote we can chain many methods together by doing .method_1().method_2(), but only if they return string. If they return None, then chaining will not work.\n    x = \"    this String Can change case\"\n    \n    print(x.upper())\n    print(x.lower())\n    print(x.title())\n    print(x.strip())\n    print(x.strip().title())\nResults: \n# =&gt;     THIS STRING CAN CHANGE CASE\n# =&gt;     this string can change case\n# =&gt;     This String Can Change Case\n# =&gt; this String Can change case\n# =&gt; This String Can Change Case"
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-1.html#replacing-parts-of-a-string",
    "href": "teaching/2023-2024/Programming Level-up/lecture-1.html#replacing-parts-of-a-string",
    "title": "Python Introduction",
    "section": "Replacing parts of a string",
    "text": "Replacing parts of a string\nTo replace a substring, we use the .replace() method. The first argument is the old string you want to replace. The second argument is what you want to replace it with.\n    x = \"This is a string that contains some text\"\n    \n    print(x.replace(\"contains some\", \"definitely contains some\"))\nResults: \n# =&gt; This is a string that definitely contains some text"
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-1.html#container-data-typesdata-structures",
    "href": "teaching/2023-2024/Programming Level-up/lecture-1.html#container-data-typesdata-structures",
    "title": "Python Introduction",
    "section": "Container data types/Data structures",
    "text": "Container data types/Data structures\nContainer data types or data structures, as the name suggests, are used to contain other things. Types of containers are:\n\nLists\nDictionaries\nTuples\nSets\n\n    [1, \"hello\", 2]                 # list\n    {\"my-key\": 2, \"your-key\": 1}    # dictionary (or dict)\n    (1, 2)                          # tuple\n    set(1, 2)                       # set\nWe’ll take a look at each of these different container types and explore why we might want to use each of them."
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-1.html#an-aside-on-terminology",
    "href": "teaching/2023-2024/Programming Level-up/lecture-1.html#an-aside-on-terminology",
    "title": "Python Introduction",
    "section": "An aside on Terminology",
    "text": "An aside on Terminology\nTo make our explanations clearer and reduce confusion, each of the different symbols have unique names.\nI will use this terminology consistently throughout the course, and it is common to see the same use outside the course.\n\n[ ] brackets (square brackets).\n{ } braces (curly braces).\n( ) parentheses."
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-1.html#lists",
    "href": "teaching/2023-2024/Programming Level-up/lecture-1.html#lists",
    "title": "Python Introduction",
    "section": "Lists",
    "text": "Lists\nA hetreogenious container. This means that it can store any type of data.\n    x = [1, \"hello\", 2]\nElements can be accessed using indexing [ ] notation. For example:\n    print(x[0])    # this will get the first element (i.e. 1)\n    print(x[1])    # the second element (i.e. \"hello\")\n    print(x[2])    # the third element (i.e. 2)\nResults: \n# =&gt; 1\n# =&gt; hello\n# =&gt; 2\nnotice how the first element is the 0-th item in the list/ we say that python is 0-indexed."
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-1.html#slices",
    "href": "teaching/2023-2024/Programming Level-up/lecture-1.html#slices",
    "title": "Python Introduction",
    "section": "Slices",
    "text": "Slices\nIf we wanted to access an element from a data structure, such as a list, we would use the [ ] accessor, specifying the index of the element we wish to retrieve (remember that indexes start at zero!). But what if we ranted to access many elements at once? Well to accomplish that, we have a slice or a range of indexes (not to be confused with the range function). A slice is defined as:\nstart_index:end_index\nwhere the end_index is non inclusive – it doesn’t get included in the result. Here is an example where we have a list of 6 numbers from 0 to 5, and we slice the list from index 0 to 3. Notice how the 3rd index is not included.\n    x = [0, 1, 2, 3, 4, 5]\n    print(x[0:3])\nResults: \n# =&gt; [0, 1, 2]"
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-1.html#ranges",
    "href": "teaching/2023-2024/Programming Level-up/lecture-1.html#ranges",
    "title": "Python Introduction",
    "section": "Ranges",
    "text": "Ranges\nWhen we use start_index:end_index, the slice increments by 1 from start_index to end_index. If we wanted to increment by a different amount we can use the slicing form:\nstart_index:end_index:step\nHere is an example where we step the indexes by 2:\n    x = list(range(100))\n    print(x[10:15:2])\nResults: \n# =&gt; [10, 12, 14]"
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-1.html#reverse",
    "href": "teaching/2023-2024/Programming Level-up/lecture-1.html#reverse",
    "title": "Python Introduction",
    "section": "Reverse",
    "text": "Reverse\nOne strange fact about the step is that if we specify a negative number for the step, Python will work backwards, and effectively reverse the list.\n    x = list(range(5))\n    \n    print(x[::-1])\nResults: \n# =&gt; [4, 3, 2, 1, 0]\nIn a previous example, I created a slice like 0:3. This was a little wasteful as we can write slightly less code. If we write :end_index, Python assumes and creates a slice from the first index (0) to the end_index. If we write start_index:, Python assumes and creates a slice from start_index to the end of the list.\n    x = list(range(100))\n    \n    print(x[:10])\n    print(x[90:])\nResults: \n# =&gt; [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n# =&gt; [90, 91, 92, 93, 94, 95, 96, 97, 98, 99]"
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-1.html#indexing-backwards",
    "href": "teaching/2023-2024/Programming Level-up/lecture-1.html#indexing-backwards",
    "title": "Python Introduction",
    "section": "Indexing backwards",
    "text": "Indexing backwards\nFinally, we also work backwards from the end of list. If we use a negative number, such as -1, we are telling Python, take the elements from the end of the list. -1 is the final index, and numbers lower than -1 work further backwards through the list.\n    x = list(range(100))\n    \n    print(x[-1])\n    print(x[-2])\nResults: \n# =&gt; 99\n# =&gt; 98\nSlicing with negative indexes, also works. Here we are creating a slice from the end of the list - 10, to the last (but not including) index.\n    x = list(range(100))\n    \n    print(x[-10:-1])\nResults: \n# =&gt; [90, 91, 92, 93, 94, 95, 96, 97, 98]"
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-1.html#adding-data-to-a-list",
    "href": "teaching/2023-2024/Programming Level-up/lecture-1.html#adding-data-to-a-list",
    "title": "Python Introduction",
    "section": "Adding data to a list",
    "text": "Adding data to a list\nIf we want to add items to the end of the list, we use the append function:\n    my_list = []\n    \n    my_list.append(\"all\")\n    my_list.append(\"dogs\")\n    my_list.append(\"bark\")\n    \n    print(my_list)\nResults: \n# =&gt; ['all', 'dogs', 'bark']"
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-1.html#dictionaries",
    "href": "teaching/2023-2024/Programming Level-up/lecture-1.html#dictionaries",
    "title": "Python Introduction",
    "section": "Dictionaries",
    "text": "Dictionaries\nDictionaries are a little different from lists as each ‘element’ consists of a key-pair value. Let’s have a look at some examples where the dictionaries contains one element:\n    my_dictionary = {\"key\": \"value\"}\n    my_other_dict = {\"age\": 25}\nTo access the value, we get it using [key] notation:\n    my_other_dict[\"age\"]\nResults: \n# =&gt; 25\nNOTE keys are unique, i.e:\n    my_dictionary = {\"age\": 25, \"age\": 15}\n    my_dictionary[\"age\"]\nResults: \n# =&gt; 15\nThe key in the dictionary doesn’t necessarily need to be a string. For example, in this case, we have created two key-pair elements, where the keys to both are tuples of numbers.\n    my_dictionary = {(1, 2): \"square\", (3, 4): \"circle\"}\n    \n    print(my_dictionary[(1, 2)])\nResults: \n# =&gt; square\n\nadding data\nIf we want to add data to a dictionary, we simply perform the accessor method with a key that is not in the dictionary:\n    my_dict = {}\n    \n    my_dict[\"name\"] = \"James\"\n    my_dict[\"age\"] = 35\n    \n    print(my_dict)\nResults: \n# =&gt; {'name': 'James', 'age': 35}\n\n\nQuick Exercise\n\nCreate a dictionary for the following address, and assign it a variable name called address:\n\n\n\n\n\n\n\n\n\nKey\n\n\nValue\n\n\n\n\n\n\nnumber\n\n\n22\n\n\n\n\nstreet\n\n\nBakers Street\n\n\n\n\ncity\n\n\nLondon\n\n\n\n\n\nPrint out the address’s street name using the [ ] accessor with the correct key."
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-1.html#tuples",
    "href": "teaching/2023-2024/Programming Level-up/lecture-1.html#tuples",
    "title": "Python Introduction",
    "section": "Tuples",
    "text": "Tuples\n    my_tuple = (1, 56, -2)\nLike lists, elements of the tuple can be accessed by their position in the list, starting with the 0-th element:\n    print(my_tuple[0])  # =&gt; 1\n    print(my_tuple[1])  # =&gt; 56\n    print(my_tuple[2])  # =&gt; -2\nResults: \n# =&gt; 1\n# =&gt; 56\n# =&gt; -2\nUnlike lists, tuples cannot be changed after they’ve been created. We say they are immutable. So this will not work:\n    my_tuple[2] = \"dogs\"  # creates an Error\nResults: \n# =&gt; Traceback (most recent call last):\n  File \"&lt;stdin&gt;\", line 1, in &lt;module&gt;\n  File \"/tmp/pyKdIIcx\", line 18, in &lt;module&gt;\n  File \"&lt;string&gt;\", line 1, in &lt;module&gt;\nTypeError: 'tuple' object does not support item assignment"
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-1.html#sets",
    "href": "teaching/2023-2024/Programming Level-up/lecture-1.html#sets",
    "title": "Python Introduction",
    "section": "Sets",
    "text": "Sets\nSets in Python are like tuples, but contain only unique elements.\nYou can use the set( ) function (more on functions later!), supplying a list, to create a set:\n    my_set = set([1, 2, 2, 2, 3, 4])\n    my_set\nResults: \n# =&gt; {1, 2, 3, 4}\nNotice how there is only one ‘2’ in the resulting set, duplicate elements are removed.\n\nadding data\nIf we want to add data to a set, we use the .add() method. The element used as an argument to this function will only be added to the set if it is not already in the set.\n    my_set = set([])\n    \n    my_set.add(1)\n    my_set.add(2)\n    my_set.add(1)\n    \n    print(my_set)\nResults: \n# =&gt; {1, 2}"
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-1.html#if-statement",
    "href": "teaching/2023-2024/Programming Level-up/lecture-1.html#if-statement",
    "title": "Python Introduction",
    "section": "If statement",
    "text": "If statement\nIf statements allow for branching paths of execution. In other words, we can execute some statements if some conditions holds (or does not hold).\nThe structure of a simple if statement is:\nif &lt;condition&gt;:\n    &lt;body&gt;\n    x = 2\n    y = \"stop\"\n    \n    if x &lt; 5:\n        print(\"X is less than five\")\n    if y == \"go\":\n        print(\"All systems go!!\")\nResults: \n# =&gt; X is less than five\nIn the previous example, the first print statement was only executed if the x &lt; 5 evaluates to True, but in python, we can add another branch if the condition evaluates to False. This branch is denoted by the else keyword.\n    x = 10\n    \n    if x &lt; 5:\n        print(\"X is less than five\")\n    else:\n        print(\"X is greater than or equal to five\")\nResults: \n# =&gt; X is greater than or equal to five"
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-1.html#does-it-contain-a-substring",
    "href": "teaching/2023-2024/Programming Level-up/lecture-1.html#does-it-contain-a-substring",
    "title": "Python Introduction",
    "section": "does it contain a substring?",
    "text": "does it contain a substring?\nWe can check if a string exists within another string using the in keyword. This returns a Boolean value, so we can use it as a condition to an if statement.\n    x = \"This is a string that contains some text\"\n    \n    if \"text\" in x:\n        print(\"It exists\")\nResults: \n# =&gt; It exists"
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-1.html#if-statement-quick-exercise",
    "href": "teaching/2023-2024/Programming Level-up/lecture-1.html#if-statement-quick-exercise",
    "title": "Python Introduction",
    "section": "If statement – Quick Exercise",
    "text": "If statement – Quick Exercise\n\nCreate a variable called age and assign the value of this variable 35.\nCreate and if statement that prints the square of age if the value of age is more than 24.\nThis if statement should have an else condition, that prints age divided by 2.\nWhat is the printed value?"
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-1.html#multiple-paths",
    "href": "teaching/2023-2024/Programming Level-up/lecture-1.html#multiple-paths",
    "title": "Python Introduction",
    "section": "Multiple paths",
    "text": "Multiple paths\nIf we wanted to add multiple potential paths, we can add more using the elif &lt;condition&gt; keywords.\nNote: The conditions are checked from top to bottom, only executing the else if none evaluate to True. The first condition that evaluates to True is executed, the rest are skipped.\nx = 15\n\nif x &lt; 5:\n    print(\"X is less than five\")\nelif x &gt; 10:\n    print(\"X is greater than ten\")\nelse:\n    print(\"X is between five and ten\")\n\nResults: \n# =&gt; X is greater than ten"
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-1.html#inline-if-statements",
    "href": "teaching/2023-2024/Programming Level-up/lecture-1.html#inline-if-statements",
    "title": "Python Introduction",
    "section": "Inline if-statements",
    "text": "Inline if-statements\nSometimes, we might want to conditionally set a variable a value. For this, we can use an inline if statement. The form of an inline if statement is:\n&lt;value-if-true&gt; if &lt;condition&gt; else &lt;value-if-false&gt;\nx = 10\n\ny = 5 if x &gt; 5 else 2\n\nprint(x + y)\n\nResults: \n# =&gt; 15"
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-1.html#boolean-logic",
    "href": "teaching/2023-2024/Programming Level-up/lecture-1.html#boolean-logic",
    "title": "Python Introduction",
    "section": "Boolean Logic",
    "text": "Boolean Logic\nAs we’ve seen, if statements are checking for conditions to evaluate to True or False. In python we use various comparison operators to check for conditions that evaluate to Booleans.\n\nComparison operators\n\n&lt; less than\n&lt;= less than or equal to\n&gt; greater than\n&gt;= greater than or equal to\n== is equal to\nnot negation\n\nIf we want to check for multiple conditions, we can use conjunctives or disjunctive operators to combine the Boolean formulas.\nConjunctives/Disjunctives\n\nand all boolean expressions must evaluate to true\nor only one expression needs to be true\n\n\n\nNot\nUsing not you can invert the Boolean result of the expression.\nprint(not True)\n\nResults: \n# =&gt; False\n\nx = 10\n\nif not x == 11:\n    print(\"X is not 11\")\n\nResults: \n# =&gt; X is not 11\n\n\nAnd\nLet’s take an example using the and keyword. and here is checking that x is above or equal to 10 and y is exactly 5. If either of the conditions is False, python will execute the else path (if there is one, of course!).\nx = 10\ny = 5\n\nif x &gt;= 10 and y == 5:\n    z = x + y\nelse:\n    z = x * y\n\nprint(z)\n\nResults: \n# =&gt; 15\n\n\nOr\nHere we see the use of the or keyword. If any of the conditions evaluates to True then the whole condition evaluates to True.\nx = 10\ny = 5\n\nif x &lt; 5 or y == 5:\n    print(\"We got here!\")\nelse:\n    print(\"We got here instead...\")\n\nResults: \n# =&gt; We got here!\nNote: or is short-circuiting. This means that if tests the conditions left-to-right, and when it finds something that is True it stops evaluating the rest of the conditions.\nx = 10\n\nif x &lt; 20 or print(\"We got to this condition\"):\n    print(\"The value of x is\", x) \n\nResults: \n# =&gt; The value of x is 10\n\n\nCombining And and Or\nIf your Boolean logic refers to a single variable, you can combine the logic without the and and or. But its not always common.\nFor example,\nx = 7\n\nif x &lt; 10 and x &gt; 4:\n    print(\"X is between 5 and 10\")\nCan be the same as:\nx = 7\n\nif 5 &lt; x &lt; 10:\n    print(\"X is between 5 and 10\")\n\nResults: \n# =&gt; X is between 5 and 10"
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-1.html#for-loop",
    "href": "teaching/2023-2024/Programming Level-up/lecture-1.html#for-loop",
    "title": "Python Introduction",
    "section": "For loop",
    "text": "For loop\nLooping or iteration allows us to perform a series of actions multiple times. We are going to start with the more useful for loop in python. The syntax of a for loop is:\nfor &lt;variable_name&gt; in &lt;iterable&gt;:\n    &lt;body&gt;\n\nfor i in range(3):\n    print(i)\n\nResults: \n# =&gt; 0\n# =&gt; 1\n# =&gt; 2"
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-1.html#break",
    "href": "teaching/2023-2024/Programming Level-up/lecture-1.html#break",
    "title": "Python Introduction",
    "section": "break",
    "text": "break\nThe previous example loops over the body a fix number of times. But what if we wanted to stop looping early? Well, we can use the break keyword. This keyword will exit the body of the loop.\nfor i in range(10):\n    if i &gt; 5:\n        break\n    print(i)\n\nResults: \n# =&gt; 0\n# =&gt; 1\n# =&gt; 2\n# =&gt; 3\n# =&gt; 4\n# =&gt; 5"
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-1.html#continue",
    "href": "teaching/2023-2024/Programming Level-up/lecture-1.html#continue",
    "title": "Python Introduction",
    "section": "continue",
    "text": "continue\nA different keyword you might want to use is continue. Continue allows you to move/skip onto the next iteration without executing the entire body of the for loop.\nfor i in range(10):\n    if i % 2 == 0:\n        continue\n    print(i)\n\nResults: \n# =&gt; 1\n# =&gt; 3\n# =&gt; 5\n# =&gt; 7\n# =&gt; 9"
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-1.html#ranges-1",
    "href": "teaching/2023-2024/Programming Level-up/lecture-1.html#ranges-1",
    "title": "Python Introduction",
    "section": "ranges",
    "text": "ranges\nInstead of using continue like in the previous slide, the range function provides us with some options:\nrange(start, stop, step)\nIn this example, we are starting our iteration at 10, ending at 15, but stepping the counter 2 steps.\nfor i in range(10, 15, 2):\n    print(i)\n\nResults: \n# =&gt; 10\n# =&gt; 12\n# =&gt; 14"
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-1.html#loop-over-collections",
    "href": "teaching/2023-2024/Programming Level-up/lecture-1.html#loop-over-collections",
    "title": "Python Introduction",
    "section": "Loop over collections",
    "text": "Loop over collections\nFor loops allow us to iterate over a collection, taking one element at a time. Take for example, a list, and for every item in the list we print its square.\nmy_list = [1, 5, 2, 3, 5.5]\n\nfor el in my_list:\n    print(el**2)\n\nResults: \n# =&gt; 1\n# =&gt; 25\n# =&gt; 4\n# =&gt; 9\n# =&gt; 30.25\nThis kind of looping can work for tuples and sets, but as we have seen, dictionaries are a little different. Every ‘element’ in a dictionary consists of a key and a value. Therefore when we iterate over items in a dictionary, we can assign the key and value to different variables in the loop.\nNote the use of the .items() after the dictionary. We will explore this later.\nmy_dict = {\"name\": \"jane\", \"age\": 35, \"loc\": \"France\"}\n\nfor el_key, el_val in my_dict.items():\n    print(\"Key is:\", el_key, \" value is: \", el_val)\n\nResults: \n# =&gt; Key is: name  and the value is:  jane\n# =&gt; Key is: age  and the value is:  35\n# =&gt; Key is: location  and the value is:  France\nWe could also loop over the keys in the dictionary using the .keys() method instead of .items().\nmy_dict = {\"name\": \"jane\", \"age\": 35, \"loc\": \"France\"}\n\nfor the_key in my_dict.keys():\n    print(the_key)\n\nResults: \n# =&gt; name\n# =&gt; age\n# =&gt; loc\nOr, the values using .values().\nmy_dict = {\"name\": \"jane\", \"age\": 35, \"loc\": \"France\"}\n\nfor the_value in my_dict.values():\n    print(the_value)\n\nResults: \n# =&gt; jane\n# =&gt; 35\n# =&gt; France"
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-1.html#list-comprehensions",
    "href": "teaching/2023-2024/Programming Level-up/lecture-1.html#list-comprehensions",
    "title": "Python Introduction",
    "section": "List comprehensions",
    "text": "List comprehensions\nWe have seen previously how for loops work. Knowing the syntax of a for loop and wanting to populate a list with some data, we might be tempted to write:\nx = []\nfor i in range(3):\n    x.append(i)\n\nprint(x)\n\nResults: \n# =&gt; [0, 1, 2]\nWhile this is perfectly valid Python code, Python itself provides ‘List comprehensions’ to make this process easier.\nx = [i for i in range(3)]\nThe syntax of a list comprehensions is:\n[ &lt;variable&gt; for &lt;variable&gt; in &lt;iterable&gt; ]\nWe can also perform similar actions with a dictionary\n[ &lt;key&gt;, &lt;value&gt; for &lt;key&gt;, &lt;value&gt; in &lt;dictionary.items()&gt; ]\n\nusing if’s\nPerhaps we only want to optionally perform an action within the list comprehension? Python allows us to do this with the inline if statement we’ve seen in the previous lecture.\nx = [i if i &lt; 5 else -1 for i in range(7)]\nprint(x)\n\nResults: \n# =&gt; [0, 1, 2, 3, 4, -1, -1]\nWe add the inline &lt;var&gt; if &lt;condition&gt; else &lt;other-var&gt; before the for loop part of the comprehension.\nThere is another type of if statement in a list comprehension, this occurs when we don’t have an else.\nx = [i for i in range(7) if i &lt; 3]\nprint(x)\n\nResults: \n# =&gt; [0, 1, 2]\nIn this example, we’re only ‘adding’ to the list if the condition (\\(i &lt; 3\\)) is true, else the element is not included in the resulting list.\n\n\nmultiple for’s\nIf we like, we can also use nested for loops by simply adding another for loop into the comprehension.\nx = [(i, j) for i in range(2) for j in range(2)]\n\nprint(x)\n\nResults: \n# =&gt; [(0, 0), (0, 1), (1, 0), (1, 1)]\nIn this example, we’re creating a tuple for each element, effectively each combination of 1 and 0."
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-1.html#list-comprehensions-with-dictionary",
    "href": "teaching/2023-2024/Programming Level-up/lecture-1.html#list-comprehensions-with-dictionary",
    "title": "Python Introduction",
    "section": "List comprehensions with dictionary",
    "text": "List comprehensions with dictionary\nPython doesn’t restrict us to list comprehensions, but we can do a similar operation to create a dictionary.\nx = [2, 5, 6]\ny = {idx: val for idx, val in enumerate(x)}\nprint(y)\n\nResults: \n# =&gt; {0: 2, 1: 5, 2: 6}\nHere, every item in x has been associated with its numerical index as a key thanks to the enumerate function that returns both the index and value at iteration in the for loop."
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-1.html#for-loop-quick-exercise",
    "href": "teaching/2023-2024/Programming Level-up/lecture-1.html#for-loop-quick-exercise",
    "title": "Python Introduction",
    "section": "For loop – Quick Exercise",
    "text": "For loop – Quick Exercise\n\nCreate a list of elements:\n\n2\n“NA”\n24\n5\n\nUse a for loop to iterate over this list.\nIn the body of the for loop, compute \\(2x + 1\\), where \\(x\\) is the current element of the list.\nStore the result of this computation in a new variable \\(y\\), and then print y.\n\nNote You cannot compute \\(2x + 1\\) of “NA”, therefore you will to use an if statement to skip onto the next iteration if it encounters this. Hint try: type(...) =!= str"
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-1.html#while-loop",
    "href": "teaching/2023-2024/Programming Level-up/lecture-1.html#while-loop",
    "title": "Python Introduction",
    "section": "While loop",
    "text": "While loop\nA while loop is another looping concept like for but it can loop for an arbitrary amount of times. A while loop looks to see if the condition is True, and if it is, it will execute the body.\nThe syntax of the while loop is:\nwhile &lt;condition&gt;:\n    &lt;body&gt;\n\ni = 0\n\nwhile i &lt; 3:\n    print(i)\n    i = i + 1\n\nResults: \n# =&gt; 0\n# =&gt; 1\n# =&gt; 2\n\nx = 0\ny = 1\nHere is another example:\nwhile x + y &lt; 10:\n    print(\"X is,\", x, \"and y is\", y)\n    x = x + 1\n    y = y * 2\n\nprint(\"X ended as\", x, \", while y is\", y)\n\nResults: \n# =&gt; X is, 0 and y is 1\n# =&gt; X is, 1 and y is 2\n# =&gt; X is, 2 and y is 4\n# =&gt; X ended as 3 , while y is 8"
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-1.html#example-usage-of-a-function",
    "href": "teaching/2023-2024/Programming Level-up/lecture-1.html#example-usage-of-a-function",
    "title": "Python Introduction",
    "section": "Example usage of a function",
    "text": "Example usage of a function\nLet’s make a function that takes two numbers and adds them together:\ndef my_addition(a, b):\n    result = a + b\n    return result\n\nx = 2\ny = 3\nz = my_addition(2, 3)  # return 5 and stores in z\nprint(z)\n\nResults: \n# =&gt; 5"
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-1.html#quick-exercise-1",
    "href": "teaching/2023-2024/Programming Level-up/lecture-1.html#quick-exercise-1",
    "title": "Python Introduction",
    "section": "Quick exercise",
    "text": "Quick exercise\n\nCreate a function called my_square. This function should take one argument (you can call this argument what you like).\nThe body of the function should compute and return the square of the argument.\nCall this function with 5.556.\nStore the result of calling this function, and print it.\nWhat is the result?"
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-1.html#re-usability-with-functions",
    "href": "teaching/2023-2024/Programming Level-up/lecture-1.html#re-usability-with-functions",
    "title": "Python Introduction",
    "section": "Re-usability with Functions",
    "text": "Re-usability with Functions\nFunctions are better illustrated through some examples, so let’s see some!\nname_1 = \"john\"\nname_2 = \"mary\"\nname_3 = \"michael\"\n\nprint(\"Hello \" + name_1 + \", how are you?\")\nprint(\"Hello \" + name_2 + \", how are you?\")\nprint(\"Hello \" + name_3 + \", how are you?\")\nThe above is pretty wasteful. Why? Because we are performing the exact same operation multiple times, with only the variable changed.\nBy abstracting the actions we want to perform into a function, we can ultimately reduce the amount of code we write. Be a lazy programmer!\nname_1 = \"john\"\nname_2 = \"mary\"\nname_3 = \"michael\"\n\ndef say_hello(name):\n    print(\"Hello \" + name + \", how are you?\")\n\nsay_hello(name_1)\nsay_hello(name_2)\nsay_hello(name_3)\nIn this example, we’ve used the function as defined with the def pattern to write the print statement once. Then, we’ve called the function with each variable as its argument."
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-1.html#named-parameters",
    "href": "teaching/2023-2024/Programming Level-up/lecture-1.html#named-parameters",
    "title": "Python Introduction",
    "section": "Named parameters",
    "text": "Named parameters\nWe’ve seen in previous examples that, when we create a function, we give each of the arguments (if there are any) a name.\nWhen calling this function, we can specify these same names such as:\ndef say_hello(name):\n    print(\"Hello,\", name)\n\nsay_hello(\"Micheal\")\nsay_hello(name=\"Micheal\")\n\nResults: \n# =&gt; Hello, Micheal\n# =&gt; Hello, Micheal\nBy specifying the name of the parameter we’re using with the called function, we can change the order\ndef say_greeting(greeting, name):\n    print(greeting, name, \"I hope you're having a good day\")\n\nsay_greeting(name=\"John\", greeting=\"Hi\")\n\nResults: \n# =&gt; Hi John I hope you're having a good day"
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-1.html#optionaldefaultpositional-arguments",
    "href": "teaching/2023-2024/Programming Level-up/lecture-1.html#optionaldefaultpositional-arguments",
    "title": "Python Introduction",
    "section": "Optional/Default/Positional arguments",
    "text": "Optional/Default/Positional arguments\nWhen we call a function with arguments without naming them, we are supplying them by position.\ndef say_greeting(greeting, name):\n    print(greeting, name, \"I hope you're having a good day\")\n\nsay_greeting(#first position, #section position)\nThe first position gets mapped to variable name of greeting inside the body of the say_greeting function, while the second position gets mapped to name.\nSometimes when creating a function we may want to use default arguments, these are arguments that are used if the call to the function does not specify what their value should be. For example.\ndef say_greeting(name, greeting=\"Hello\"):\n    print(greeting, name, \"I hope you're having a good day\")\n\nsay_greeting(\"John\")\nsay_greeting(\"John\", \"Hi\")  # supply greeting as positional argument\n\nResults: \n# =&gt; Hello John I hope you're having a good day\n# =&gt; Hi John I hope you're having a good day\nNote if you supply a default argument in the function definition, all arguments after this default argument must also supply a default argument.\nSo, this won’t work:\ndef say_greeting(name=\"Jane\", greeting):\n    print(greeting, name, \"I hope you're having a good day\")\n\nsay_greeting(\"John\", \"Hi\")"
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-1.html#recap-on-arguments",
    "href": "teaching/2023-2024/Programming Level-up/lecture-1.html#recap-on-arguments",
    "title": "Python Introduction",
    "section": "Recap on arguments",
    "text": "Recap on arguments\n# defining the function\n\ndef say_greeting(name, greeting)  # no default arguments\ndef say_greeting(name, greeting=\"Hello\")  # greeting is a default argument\ndef say_greeting(name=\"Jane\", greeting=\"Hello\")  # both arguments have a default\n\n# calling the functions\n\nsay_greeting(\"John\", \"Hi\")  # both arguments are provided by position\nsay_greeting(name=\"John\", greeting=\"Hi\")  # arguments are supplied by name\nsay_greeting(greeting=\"Hi\", name=\"John\")  # the position of named arguments do not matter"
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-1.html#function-doc-strings",
    "href": "teaching/2023-2024/Programming Level-up/lecture-1.html#function-doc-strings",
    "title": "Python Introduction",
    "section": "Function doc-strings",
    "text": "Function doc-strings\nTo make it clear for a human to quickly understand what a function is doing, you can add an optional doc-string. This is a string that is added directly after the initial definition of the function:\ndef my_function(x, y):\n    \"\"\"I am a docstring!!!\"\"\"\n    return x + y\nSome common use cases for docstrings are explaining what the parameters are that it expects, and what it returns.\nIf your explanation is a little longer than a line, a multiline docstring can be created as long as you’re using \"\"\" three quotation marks either side of the string\ndef my_function(x, y):\n    \"\"\"\n    This is my realllly long docstring\n    that explains how the function works. But sometimes\n    its best not to explain the obvious\n    \"\"\"\n    return x + y"
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-1.html#understanding-scope",
    "href": "teaching/2023-2024/Programming Level-up/lecture-1.html#understanding-scope",
    "title": "Python Introduction",
    "section": "Understanding scope",
    "text": "Understanding scope\nIn this example we have two scopes which can be easily seen by the indentation. The first is the global scope. The second scope is the scope of the function. The scope of the function can reference variables in the larger scope. But once the function scope exits, we can no longer reference the variables from the function.\nx = 10\n\ndef compute_addition(y):\n    return x + y\n\nprint(compute_addition(10))\nprint(x)\nprint(y)  # does not work\n\nResults: \n# =&gt; 20\n# =&gt; 10\nEven though we can reference the global scope variable from the scope of the function, we can’t modify it like this:\nx = 10\n\ndef compute_addition_2(y):\n    x = x + 5  # error local variable referenced before assignment\n    return x + y\n\nprint(compute_addition_2(10))\nIf we really wanted to reference a variable in a global scope and modify its value, we could use the global keyword. Doing this makes the function output something different every time it is called. This can make it difficult to debug incorrect programs.\nx = 10\n\ndef compute_addition_2(y):\n    global x\n    x = x + 5\n    return x + y\n\nprint(compute_addition_2(10))\nprint(x)\nprint(compute_addition_2(10))\n\nResults: \n# =&gt; 25\n# =&gt; 15\n# =&gt; 30\nIn almost all cases, avoid using global variables. Instead pass the variables as parameters. This can reduce a source of potential errors and ensure that if a function is called multiple times, the output can be more consistent and expected.\nx = 10\n\ndef compute_addition_3(x, y):\n    x = x + 5\n    return x + y\n\nprint(compute_addition_3(x, 10))\nprint(x)\nprint(compute_addition_3(x, 10))\n\nResults: \n# =&gt; 25\n# =&gt; 10\n# =&gt; 25"
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-1.html#library-system",
    "href": "teaching/2023-2024/Programming Level-up/lecture-1.html#library-system",
    "title": "Python Introduction",
    "section": "Library system",
    "text": "Library system"
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-1.html#use-what-youve-learnt",
    "href": "teaching/2023-2024/Programming Level-up/lecture-1.html#use-what-youve-learnt",
    "title": "Python Introduction",
    "section": "Use what you’ve learnt!",
    "text": "Use what you’ve learnt!\nWe’re going to create a library system to help locate and lookup information about books. For example, we want to know the author of book called ‘Moby Dick’.\nTo create this system, we are going to do it in stages. First, we will want to create our database of books:\n\n\n\n\n\n\n\n\n\nTitle\n\n\nAuthor\n\n\nRelease Date\n\n\n\n\n\n\nMoby Dick\n\n\nHerman Melville\n\n\n1851\n\n\n\n\nA Study in Scarlet\n\n\nSir Arthur Conan Doyle\n\n\n1887\n\n\n\n\nFrankenstein\n\n\nMary Shelley\n\n\n1818\n\n\n\n\nHitchhikers Guide to the Galaxy\n\n\nDouglas Adams\n\n\n1879\n\n\n\n\nOur database is going to be a list of dictionaries. Where each dictionary is a row from this table. For example, one of the dictionaries will have the key “title” and a value “Moby Dick”.\nCreate this database and call it db."
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-1.html#locating-books",
    "href": "teaching/2023-2024/Programming Level-up/lecture-1.html#locating-books",
    "title": "Python Introduction",
    "section": "Locating Books",
    "text": "Locating Books\n\nCreate a function called locate_by_title that takes the database to look through, and the title to look up as arguments.\nThis function should check each dictionary, and if the title is the same as what was searched for, it should return the whole dictionary.\nTest this function by calling the locate_by_title function with db and \"Frankenstein\". You should get {\"title\": \"Frankenstein\", \"author\": ...}.\n\nNote you should include docstrings to describe the arguments to the function, and what it will return."
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-1.html#selecting-a-subset",
    "href": "teaching/2023-2024/Programming Level-up/lecture-1.html#selecting-a-subset",
    "title": "Python Introduction",
    "section": "Selecting a subset",
    "text": "Selecting a subset\nNow that we can find books by the title name, we also want to find all books that were released after a certain data.\n\nCreate a function called books_released_after that takes two arguments: the database to look through, and the year.\nThis function should look through the database, if it finds a book that was released after the year, it should add it to a list of books that is returned from this function.\nTest this function by calling books_released_after with db and 1850. This function call should return a list containing three dictionaries. The first entry should be ‘Moby Dick’ and the section should be ‘A Study in Scarlet’, etc."
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-1.html#updating-our-database",
    "href": "teaching/2023-2024/Programming Level-up/lecture-1.html#updating-our-database",
    "title": "Python Introduction",
    "section": "Updating our database",
    "text": "Updating our database\nOh no! ‘Hitchhikers Guide to the Galaxy’ was released in 1979 not 1879, there must have been a typo. Let’s create a function to update this.\n\nCreate a function called update, that takes 5 arguments: 1) the database to update, 2) the key of the value we want to update 3) the value we want to update it to 4) the key we want to check to find out if we have the correct book and 5) the value of the key to check if we have the correct book.\nupdate(db,\n       key=\"release year\",\n       value=1979,\n       where_key=\"title\",\n       where_value=\"Hitchhikers Guide to the Galaxy\")"
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-1.html#extended-exercise",
    "href": "teaching/2023-2024/Programming Level-up/lecture-1.html#extended-exercise",
    "title": "Python Introduction",
    "section": "Extended exercise",
    "text": "Extended exercise\n\nIn the previous steps we created functions locate_by_title and books_released_after. These two functions are similar in a way that they are selecting a subset of our database (just by different criteria).\nFor this harder exercise, can we create a single function called query that allows us to do both locate_by_title and books_released_after.\nAn example call to this query function may look like:\nresults = query(db,\n                where_key=\"title\",\n                where_value=\"Moby Dick\",\n                where_qualifier=\"exactly\")\nwhere_qualifier should accept strings like \"exactly\", \"greater than\", and \"less       than\"."
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-1-reveal.html#a-first-program",
    "href": "teaching/2023-2024/Programming Level-up/lecture-1-reveal.html#a-first-program",
    "title": "Python Introduction",
    "section": "A first program",
    "text": "A first program\nWe’re going to start with the ‘Hello, World’ program that prints Hello, World! to the screen. In python this is as simple as writing:\n    print(\"Hello, World!\")   # this prints: Hello, World!\nResults: \n# =&gt; Hello, World!\nNOTE anything following a # is a comment and is completely ignored by the computer. It is there for you to document your code for others, and most importantly, for yourself."
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-1-reveal.html#running-this-program",
    "href": "teaching/2023-2024/Programming Level-up/lecture-1-reveal.html#running-this-program",
    "title": "Python Introduction",
    "section": "Running this program",
    "text": "Running this program\nBefore we can run this program, we need to save it somewhere. For this, will create a new file, insert this text, and save it as &lt;filename&gt;.py, where &lt;filename&gt; is what we want to call the script. This name doesn’t matter for its execution.\nOnce we have created the script, we can run it from the command line. We will get into the command line in a later lecture, but right now all you need to know is:\n    python3 &lt;filename&gt;.py"
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-1-reveal.html#an-alternative-method-of-running-python",
    "href": "teaching/2023-2024/Programming Level-up/lecture-1-reveal.html#an-alternative-method-of-running-python",
    "title": "Python Introduction",
    "section": "An alternative method of running python",
    "text": "An alternative method of running python\nYou may notice that if you don’t give python a filename to run, you will enter something called the REPL.\n    Python 3.9.5 (default, Jun  4 2021, 12:28:51) \n    [GCC 7.5.0] :: Anaconda, Inc. on linux\n    Type \"help\", \"copyright\", \"credits\" or \"license\" for more information.\n    &gt;&gt;&gt; \nREPL stands for READ, EXECUTE, PRINT, LOOP."
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-1-reveal.html#variables",
    "href": "teaching/2023-2024/Programming Level-up/lecture-1-reveal.html#variables",
    "title": "Python Introduction",
    "section": "Variables",
    "text": "Variables\nA variable is a symbol associated with a value. This value can differ widely, and we will take a look at different types of values/data later.\nNeverthless, variables are useful for referring to values and storing to the results of a computation.\n    x = 1\n    y = 2\n    z = x + y\n    print(z)   # prints: 3\n    \n    # variables can be /overwritten/\n    z = \"hello, world\"\n    print(z)   # prints: hello, world\nResults: \n# =&gt; 3\n# =&gt; hello, world"
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-1-reveal.html#primitive-data-types",
    "href": "teaching/2023-2024/Programming Level-up/lecture-1-reveal.html#primitive-data-types",
    "title": "Python Introduction",
    "section": "Primitive data types",
    "text": "Primitive data types\nPrimitive data types are the most fundamental parts of programming, they cannot be broken down.\n    \"Hello\" # string\n    1       # integer\n    1.0     # float\n    True    # Boolean (or bool for short)\nWe can get the type of some data by using the type(...) function. For example,\n    print(type(5))\n    print(type(5.0))\n    \n    x = \"all cats meow\"\n    \n    print(type(x))\nResults: \n# =&gt; &lt;class 'int'&gt;\n# =&gt; &lt;class 'float'&gt;\n# =&gt; &lt;class 'str'&gt;"
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-1-reveal.html#basic-math-with-primitives",
    "href": "teaching/2023-2024/Programming Level-up/lecture-1-reveal.html#basic-math-with-primitives",
    "title": "Python Introduction",
    "section": "Basic Math with primitives",
    "text": "Basic Math with primitives\nUsing these primitive data types, we can do some basic math operations!\n    print(1 + 2)    # Addtion\n    print(1 - 2)    # Subtraction\n    print(1 * 2)    # Multiplication\n    print(1 / 2)    # Division\n    print(2 ** 2)   # Exponent\n    print(3 % 2)    # Modulo operator\nResults: \n# =&gt; 3\n# =&gt; -1\n# =&gt; 2\n# =&gt; 0.5\n# =&gt; 4\n# =&gt; 1\nSometimes types get converted to the same type:\n    print(1.0 + 2)  # float + integer = float\nResults: \n# =&gt; 3.0\nEven more interesting is with Booleans!\n    True + True\nResults: \n# =&gt; 2"
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-1-reveal.html#bodmas-in-python",
    "href": "teaching/2023-2024/Programming Level-up/lecture-1-reveal.html#bodmas-in-python",
    "title": "Python Introduction",
    "section": "BODMAS in Python",
    "text": "BODMAS in Python\nLike in mathematics, certain math operator take precedence over others.\n\nB - Brackets\nO - Orders (roots, exponents)\nD - division\nM - multiplication\nA - addition\nS - subtraction.\n\nTo make the context clear as to what operations to perform first, use brackets.\n    (5 / 5) + 1\n    5 / (5 + 1)\nResults: \n# =&gt; 2.0\n# =&gt; 0.8333333333333334"
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-1-reveal.html#basic-math-quick-exercise",
    "href": "teaching/2023-2024/Programming Level-up/lecture-1-reveal.html#basic-math-quick-exercise",
    "title": "Python Introduction",
    "section": "Basic Math – Quick exercise",
    "text": "Basic Math – Quick exercise\nWrite the following equation in python:\n\\((5 + 2) \\times (\\frac{10}{2} + 10)^2\\)\nRemember to use parentheses ( ) to ensure that operations take precedence over others.\nYour answer should come out as: 1575.0"
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-1-reveal.html#formatting-strings",
    "href": "teaching/2023-2024/Programming Level-up/lecture-1-reveal.html#formatting-strings",
    "title": "Python Introduction",
    "section": "Formatting strings",
    "text": "Formatting strings\nIn many previous examples when we’ve printed strings, we’ve done something like:\n    age = 35\n    \n    print(\"The value of age is\", age)\nResults: \n# =&gt; The value of age is 35\nWhile this works in this small context, it can get pretty cumbersome if we have many variables we want to print, and we also want to change how they are displayed when they are printed.\nWe’re going to take a look now at much better ways of printing."
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-1-reveal.html#better-ways-of-printing-strings--",
    "href": "teaching/2023-2024/Programming Level-up/lecture-1-reveal.html#better-ways-of-printing-strings--",
    "title": "Python Introduction",
    "section": "Better ways of printing strings - %",
    "text": "Better ways of printing strings - %\nThe first method is using %. When we print, we first construct a string with special delimiters, such as %s that denotes a string, and %d that denotes a number. This is telling Python where we want the values to be placed in the string.\nOnce we’ve created the string, we need to specify the data, which we do with % (...). Like, for example:\n    age = 35\n    name = \"John\"\n    \n    print(\"%d years old\" % age)  # no tuple for one variable\n    print(\"%s is %d years old\" % (name, age)) \nResults: \n# =&gt; 35 years old\n# =&gt; John is 35 years old\nHere we are specifying the a string %s and number %d, and then giving the variables that correspond with that data type.\nThe special delimiters correspond with a data type. Here are some of the most common:\n\n%s – For strings\n%d – For numbers\n%f – For floating point numbers.\n\nThere are others such as %x that prints the hexadecimal representation, but these are less common. You can find the full list at: https://docs.python.org/3/library/stdtypes.html#old-string-formatting\nWhen using these delimiters, we can add modifiers to how they format and display the value. Take a very common example, where we have a floating point value, and, when printing it, we only want to print to 3 decimal places. To accomplish this, we again use %f but add a .3 to between the % and f. In this example, we are printing π to 3 decimal places.\n    print(\"Pi to 3 digits is: %.3f\" % 3.1415926535)\nResults: \n# =&gt; Pi to 3 digits is: 3.142\nIn the previous example, we used .3 to specify 3 decimal places. If we put a number before the decimal, like 10.3 we are telling Python make this float occupy 10 spaces and this float should have 3 decimal places printed. When it gets printed, you will notice that it shifts to the right, it gets padded by space. If we use a negative number in front of the decimal place, we are telling python to shift it to the left.\n    print(\"Pi to 3 digits is: %10.3f\" % 3.1415926535)\n    print(\"Pi to 3 digits is: %-10.3f\" % 3.1415926535)\nResults: \n# =&gt; Pi to 3 digits is:      3.142\n# =&gt; Pi to 3 digits is: 3.142\nThe final method of formatting strings is a newcomer within the language, it is the so-called f-string. Where a f character is prefixed to the beginning of the string you’re creating. f-string’s allow you to use Python syntax within the string (again delimited by {}.\nTake this for example where we are referencing the variables name and age directly.\n    name = \"Jane\"\n    age = 35\n\n    print(f\"{name} is {age} years old\")\nResults: \n# =&gt; Jane is 35 years old\nf-string’s allow you to execute Python code within the string. Here we are accessing the value from the dictionary by specifying the key within the string itself! It certainly makes it a lot easier, especially if we only need to access the values for the string itself.\n    contact_info = {\"name\": \"Jane\", \"age\": 35}\n    \n    print(f\"{contact_info['name']} is {contact_info['age']} years old\")\nResults: \n# =&gt; Jane is 35 years old\nhttps://pyformat.info/\nWe can still format the values when using f-string. The method is similar to those using the %f specifiers.\n    pi = 3.1415926535\n    print(f\"Pi is {pi:.3f} to 3 decimal places\")\nResults: \n# =&gt; Pi is 3.142 to 3 decimal places\nMany more examples can be found at: https://zetcode.com/python/fstring/"
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-1-reveal.html#splitting-strings",
    "href": "teaching/2023-2024/Programming Level-up/lecture-1-reveal.html#splitting-strings",
    "title": "Python Introduction",
    "section": "Splitting strings",
    "text": "Splitting strings\nApart from formatting, there are plenty more operations we can perform on strings. We are going to highlight some of the most common here.\nThe first we’re going to look at is splitting a string by a delimiter character using the .split() method. If we don’t pass any argument to the .split() method, then by default, it will split by spaces. However, we can change this by specifying the delimiter.\n    my_string = \"This is a sentence, where each word is separated by a space\"\n    \n    print(my_string.split())\n    print(my_string.split(\",\"))\nResults: \n# =&gt; ['This', 'is', 'a', 'sentence,', 'where', 'each', 'word', 'is', 'separated', 'by', 'a', 'space']\n# =&gt; ['This is a sentence', ' where each word is separated by a space']"
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-1-reveal.html#joining-strings-together",
    "href": "teaching/2023-2024/Programming Level-up/lecture-1-reveal.html#joining-strings-together",
    "title": "Python Introduction",
    "section": "Joining strings together",
    "text": "Joining strings together\nAs .split() splits a single string into a list, .join() joins a list of strings into a single string. To use .join(), we first create a string of the delimiter we want to use to join the list of strings by. In this example we’re going to use \"-\". Then we call the .join() method, passing the list as an argument.\nThe result is a single string using the delimiter to separate the items of the list.\n    x = ['This', 'is', 'a', 'sentence,', 'where', 'each', 'word', 'is', 'separated', 'by', 'a', 'space']\n    \n    print(\"-\".join(x))\nResults: \n# =&gt; This-is-a-sentence,-where-each-word-is-separated-by-a-space"
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-1-reveal.html#changing-cases",
    "href": "teaching/2023-2024/Programming Level-up/lecture-1-reveal.html#changing-cases",
    "title": "Python Introduction",
    "section": "Changing cases",
    "text": "Changing cases\nOther common operations on strings involve change the case. For example:\n\nMake the entire string uppercase or lowercase\nMaking the string title case (every where starts with a capital letter).\nStripping the string by removing any empty spaces either side of the string.\n\nNote we can chain many methods together by doing .method_1().method_2(), but only if they return string. If they return None, then chaining will not work.\n    x = \"    this String Can change case\"\n    \n    print(x.upper())\n    print(x.lower())\n    print(x.title())\n    print(x.strip())\n    print(x.strip().title())\nResults: \n# =&gt;     THIS STRING CAN CHANGE CASE\n# =&gt;     this string can change case\n# =&gt;     This String Can Change Case\n# =&gt; this String Can change case\n# =&gt; This String Can Change Case"
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-1-reveal.html#replacing-parts-of-a-string",
    "href": "teaching/2023-2024/Programming Level-up/lecture-1-reveal.html#replacing-parts-of-a-string",
    "title": "Python Introduction",
    "section": "Replacing parts of a string",
    "text": "Replacing parts of a string\nTo replace a substring, we use the .replace() method. The first argument is the old string you want to replace. The second argument is what you want to replace it with.\n    x = \"This is a string that contains some text\"\n    \n    print(x.replace(\"contains some\", \"definitely contains some\"))\nResults: \n# =&gt; This is a string that definitely contains some text"
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-1-reveal.html#container-data-typesdata-structures",
    "href": "teaching/2023-2024/Programming Level-up/lecture-1-reveal.html#container-data-typesdata-structures",
    "title": "Python Introduction",
    "section": "Container data types/Data structures",
    "text": "Container data types/Data structures\nContainer data types or data structures, as the name suggests, are used to contain other things. Types of containers are:\n\nLists\nDictionaries\nTuples\nSets\n\n    [1, \"hello\", 2]                 # list\n    {\"my-key\": 2, \"your-key\": 1}    # dictionary (or dict)\n    (1, 2)                          # tuple\n    set(1, 2)                       # set\nWe’ll take a look at each of these different container types and explore why we might want to use each of them."
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-1-reveal.html#an-aside-on-terminology",
    "href": "teaching/2023-2024/Programming Level-up/lecture-1-reveal.html#an-aside-on-terminology",
    "title": "Python Introduction",
    "section": "An aside on Terminology",
    "text": "An aside on Terminology\nTo make our explanations clearer and reduce confusion, each of the different symbols have unique names.\nI will use this terminology consistently throughout the course, and it is common to see the same use outside the course.\n\n[ ] brackets (square brackets).\n{ } braces (curly braces).\n( ) parentheses."
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-1-reveal.html#lists",
    "href": "teaching/2023-2024/Programming Level-up/lecture-1-reveal.html#lists",
    "title": "Python Introduction",
    "section": "Lists",
    "text": "Lists\nA hetreogenious container. This means that it can store any type of data.\n    x = [1, \"hello\", 2]\nElements can be accessed using indexing [ ] notation. For example:\n    print(x[0])    # this will get the first element (i.e. 1)\n    print(x[1])    # the second element (i.e. \"hello\")\n    print(x[2])    # the third element (i.e. 2)\nResults: \n# =&gt; 1\n# =&gt; hello\n# =&gt; 2\nnotice how the first element is the 0-th item in the list/ we say that python is 0-indexed."
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-1-reveal.html#slices",
    "href": "teaching/2023-2024/Programming Level-up/lecture-1-reveal.html#slices",
    "title": "Python Introduction",
    "section": "Slices",
    "text": "Slices\nIf we wanted to access an element from a data structure, such as a list, we would use the [ ] accessor, specifying the index of the element we wish to retrieve (remember that indexes start at zero!). But what if we ranted to access many elements at once? Well to accomplish that, we have a slice or a range of indexes (not to be confused with the range function). A slice is defined as:\nstart_index:end_index\nwhere the end_index is non inclusive – it doesn’t get included in the result. Here is an example where we have a list of 6 numbers from 0 to 5, and we slice the list from index 0 to 3. Notice how the 3rd index is not included.\n    x = [0, 1, 2, 3, 4, 5]\n    print(x[0:3])\nResults: \n# =&gt; [0, 1, 2]"
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-1-reveal.html#ranges",
    "href": "teaching/2023-2024/Programming Level-up/lecture-1-reveal.html#ranges",
    "title": "Python Introduction",
    "section": "Ranges",
    "text": "Ranges\nWhen we use start_index:end_index, the slice increments by 1 from start_index to end_index. If we wanted to increment by a different amount we can use the slicing form:\nstart_index:end_index:step\nHere is an example where we step the indexes by 2:\n    x = list(range(100))\n    print(x[10:15:2])\nResults: \n# =&gt; [10, 12, 14]"
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-1-reveal.html#reverse",
    "href": "teaching/2023-2024/Programming Level-up/lecture-1-reveal.html#reverse",
    "title": "Python Introduction",
    "section": "Reverse",
    "text": "Reverse\nOne strange fact about the step is that if we specify a negative number for the step, Python will work backwards, and effectively reverse the list.\n    x = list(range(5))\n    \n    print(x[::-1])\nResults: \n# =&gt; [4, 3, 2, 1, 0]\nIn a previous example, I created a slice like 0:3. This was a little wasteful as we can write slightly less code. If we write :end_index, Python assumes and creates a slice from the first index (0) to the end_index. If we write start_index:, Python assumes and creates a slice from start_index to the end of the list.\n    x = list(range(100))\n    \n    print(x[:10])\n    print(x[90:])\nResults: \n# =&gt; [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n# =&gt; [90, 91, 92, 93, 94, 95, 96, 97, 98, 99]"
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-1-reveal.html#indexing-backwards",
    "href": "teaching/2023-2024/Programming Level-up/lecture-1-reveal.html#indexing-backwards",
    "title": "Python Introduction",
    "section": "Indexing backwards",
    "text": "Indexing backwards\nFinally, we also work backwards from the end of list. If we use a negative number, such as -1, we are telling Python, take the elements from the end of the list. -1 is the final index, and numbers lower than -1 work further backwards through the list.\n    x = list(range(100))\n    \n    print(x[-1])\n    print(x[-2])\nResults: \n# =&gt; 99\n# =&gt; 98\nSlicing with negative indexes, also works. Here we are creating a slice from the end of the list - 10, to the last (but not including) index.\n    x = list(range(100))\n    \n    print(x[-10:-1])\nResults: \n# =&gt; [90, 91, 92, 93, 94, 95, 96, 97, 98]"
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-1-reveal.html#adding-data-to-a-list",
    "href": "teaching/2023-2024/Programming Level-up/lecture-1-reveal.html#adding-data-to-a-list",
    "title": "Python Introduction",
    "section": "Adding data to a list",
    "text": "Adding data to a list\nIf we want to add items to the end of the list, we use the append function:\n    my_list = []\n    \n    my_list.append(\"all\")\n    my_list.append(\"dogs\")\n    my_list.append(\"bark\")\n    \n    print(my_list)\nResults: \n# =&gt; ['all', 'dogs', 'bark']"
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-1-reveal.html#dictionaries",
    "href": "teaching/2023-2024/Programming Level-up/lecture-1-reveal.html#dictionaries",
    "title": "Python Introduction",
    "section": "Dictionaries",
    "text": "Dictionaries\nDictionaries are a little different from lists as each ‘element’ consists of a key-pair value. Let’s have a look at some examples where the dictionaries contains one element:\n    my_dictionary = {\"key\": \"value\"}\n    my_other_dict = {\"age\": 25}\nTo access the value, we get it using [key] notation:\n    my_other_dict[\"age\"]\nResults: \n# =&gt; 25\nNOTE keys are unique, i.e:\n    my_dictionary = {\"age\": 25, \"age\": 15}\n    my_dictionary[\"age\"]\nResults: \n# =&gt; 15\nThe key in the dictionary doesn’t necessarily need to be a string. For example, in this case, we have created two key-pair elements, where the keys to both are tuples of numbers.\n    my_dictionary = {(1, 2): \"square\", (3, 4): \"circle\"}\n    \n    print(my_dictionary[(1, 2)])\nResults: \n# =&gt; square\nadding data\nIf we want to add data to a dictionary, we simply perform the accessor method with a key that is not in the dictionary:\n    my_dict = {}\n    \n    my_dict[\"name\"] = \"James\"\n    my_dict[\"age\"] = 35\n    \n    print(my_dict)\nResults: \n# =&gt; {'name': 'James', 'age': 35}\nQuick Exercise\n\nCreate a dictionary for the following address, and assign it a variable name called address:\n\n\n\n\n\n\n\n\n\nKey\n\n\nValue\n\n\n\n\n\n\nnumber\n\n\n22\n\n\n\n\nstreet\n\n\nBakers Street\n\n\n\n\ncity\n\n\nLondon\n\n\n\n\n\nPrint out the address’s street name using the [ ] accessor with the correct key."
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-1-reveal.html#tuples",
    "href": "teaching/2023-2024/Programming Level-up/lecture-1-reveal.html#tuples",
    "title": "Python Introduction",
    "section": "Tuples",
    "text": "Tuples\n    my_tuple = (1, 56, -2)\nLike lists, elements of the tuple can be accessed by their position in the list, starting with the 0-th element:\n    print(my_tuple[0])  # =&gt; 1\n    print(my_tuple[1])  # =&gt; 56\n    print(my_tuple[2])  # =&gt; -2\nResults: \n# =&gt; 1\n# =&gt; 56\n# =&gt; -2\nUnlike lists, tuples cannot be changed after they’ve been created. We say they are immutable. So this will not work:\n    my_tuple[2] = \"dogs\"  # creates an Error\nResults: \n# =&gt; Traceback (most recent call last):\n  File \"&lt;stdin&gt;\", line 1, in &lt;module&gt;\n  File \"/tmp/pyKdIIcx\", line 18, in &lt;module&gt;\n  File \"&lt;string&gt;\", line 1, in &lt;module&gt;\nTypeError: 'tuple' object does not support item assignment"
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-1-reveal.html#sets",
    "href": "teaching/2023-2024/Programming Level-up/lecture-1-reveal.html#sets",
    "title": "Python Introduction",
    "section": "Sets",
    "text": "Sets\nSets in Python are like tuples, but contain only unique elements.\nYou can use the set( ) function (more on functions later!), supplying a list, to create a set:\n    my_set = set([1, 2, 2, 2, 3, 4])\n    my_set\nResults: \n# =&gt; {1, 2, 3, 4}\nNotice how there is only one ‘2’ in the resulting set, duplicate elements are removed.\nadding data\nIf we want to add data to a set, we use the .add() method. The element used as an argument to this function will only be added to the set if it is not already in the set.\n    my_set = set([])\n    \n    my_set.add(1)\n    my_set.add(2)\n    my_set.add(1)\n    \n    print(my_set)\nResults: \n# =&gt; {1, 2}"
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-1-reveal.html#if-statement",
    "href": "teaching/2023-2024/Programming Level-up/lecture-1-reveal.html#if-statement",
    "title": "Python Introduction",
    "section": "If statement",
    "text": "If statement\nIf statements allow for branching paths of execution. In other words, we can execute some statements if some conditions holds (or does not hold).\nThe structure of a simple if statement is:\nif &lt;condition&gt;:\n    &lt;body&gt;\n    x = 2\n    y = \"stop\"\n    \n    if x &lt; 5:\n        print(\"X is less than five\")\n    if y == \"go\":\n        print(\"All systems go!!\")\nResults: \n# =&gt; X is less than five\nIn the previous example, the first print statement was only executed if the x &lt; 5 evaluates to True, but in python, we can add another branch if the condition evaluates to False. This branch is denoted by the else keyword.\n    x = 10\n    \n    if x &lt; 5:\n        print(\"X is less than five\")\n    else:\n        print(\"X is greater than or equal to five\")\nResults: \n# =&gt; X is greater than or equal to five"
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-1-reveal.html#does-it-contain-a-substring",
    "href": "teaching/2023-2024/Programming Level-up/lecture-1-reveal.html#does-it-contain-a-substring",
    "title": "Python Introduction",
    "section": "does it contain a substring?",
    "text": "does it contain a substring?\nWe can check if a string exists within another string using the in keyword. This returns a Boolean value, so we can use it as a condition to an if statement.\n    x = \"This is a string that contains some text\"\n    \n    if \"text\" in x:\n        print(\"It exists\")\nResults: \n# =&gt; It exists"
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-1-reveal.html#if-statement-quick-exercise",
    "href": "teaching/2023-2024/Programming Level-up/lecture-1-reveal.html#if-statement-quick-exercise",
    "title": "Python Introduction",
    "section": "If statement – Quick Exercise",
    "text": "If statement – Quick Exercise\n\nCreate a variable called age and assign the value of this variable 35.\nCreate and if statement that prints the square of age if the value of age is more than 24.\nThis if statement should have an else condition, that prints age divided by 2.\nWhat is the printed value?"
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-1-reveal.html#multiple-paths",
    "href": "teaching/2023-2024/Programming Level-up/lecture-1-reveal.html#multiple-paths",
    "title": "Python Introduction",
    "section": "Multiple paths",
    "text": "Multiple paths\nIf we wanted to add multiple potential paths, we can add more using the elif &lt;condition&gt; keywords.\nNote: The conditions are checked from top to bottom, only executing the else if none evaluate to True. The first condition that evaluates to True is executed, the rest are skipped.\nx = 15\n\nif x &lt; 5:\n    print(\"X is less than five\")\nelif x &gt; 10:\n    print(\"X is greater than ten\")\nelse:\n    print(\"X is between five and ten\")\n\nResults: \n# =&gt; X is greater than ten"
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-1-reveal.html#inline-if-statements",
    "href": "teaching/2023-2024/Programming Level-up/lecture-1-reveal.html#inline-if-statements",
    "title": "Python Introduction",
    "section": "Inline if-statements",
    "text": "Inline if-statements\nSometimes, we might want to conditionally set a variable a value. For this, we can use an inline if statement. The form of an inline if statement is:\n&lt;value-if-true&gt; if &lt;condition&gt; else &lt;value-if-false&gt;\nx = 10\n\ny = 5 if x &gt; 5 else 2\n\nprint(x + y)\n\nResults: \n# =&gt; 15"
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-1-reveal.html#boolean-logic",
    "href": "teaching/2023-2024/Programming Level-up/lecture-1-reveal.html#boolean-logic",
    "title": "Python Introduction",
    "section": "Boolean Logic",
    "text": "Boolean Logic\nAs we’ve seen, if statements are checking for conditions to evaluate to True or False. In python we use various comparison operators to check for conditions that evaluate to Booleans.\nComparison operators\n\n&lt; less than\n&lt;= less than or equal to\n&gt; greater than\n&gt;= greater than or equal to\n== is equal to\nnot negation\n\nIf we want to check for multiple conditions, we can use conjunctives or disjunctive operators to combine the Boolean formulas.\nConjunctives/Disjunctives\n\nand all boolean expressions must evaluate to true\nor only one expression needs to be true\n\nNot\nUsing not you can invert the Boolean result of the expression.\nprint(not True)\n\nResults: \n# =&gt; False\n\nx = 10\n\nif not x == 11:\n    print(\"X is not 11\")\n\nResults: \n# =&gt; X is not 11\nAnd\nLet’s take an example using the and keyword. and here is checking that x is above or equal to 10 and y is exactly 5. If either of the conditions is False, python will execute the else path (if there is one, of course!).\nx = 10\ny = 5\n\nif x &gt;= 10 and y == 5:\n    z = x + y\nelse:\n    z = x * y\n\nprint(z)\n\nResults: \n# =&gt; 15\nOr\nHere we see the use of the or keyword. If any of the conditions evaluates to True then the whole condition evaluates to True.\nx = 10\ny = 5\n\nif x &lt; 5 or y == 5:\n    print(\"We got here!\")\nelse:\n    print(\"We got here instead...\")\n\nResults: \n# =&gt; We got here!\nNote: or is short-circuiting. This means that if tests the conditions left-to-right, and when it finds something that is True it stops evaluating the rest of the conditions.\nx = 10\n\nif x &lt; 20 or print(\"We got to this condition\"):\n    print(\"The value of x is\", x) \n\nResults: \n# =&gt; The value of x is 10\nCombining And and Or\nIf your Boolean logic refers to a single variable, you can combine the logic without the and and or. But its not always common.\nFor example,\nx = 7\n\nif x &lt; 10 and x &gt; 4:\n    print(\"X is between 5 and 10\")\nCan be the same as:\nx = 7\n\nif 5 &lt; x &lt; 10:\n    print(\"X is between 5 and 10\")\n\nResults: \n# =&gt; X is between 5 and 10"
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-1-reveal.html#for-loop",
    "href": "teaching/2023-2024/Programming Level-up/lecture-1-reveal.html#for-loop",
    "title": "Python Introduction",
    "section": "For loop",
    "text": "For loop\nLooping or iteration allows us to perform a series of actions multiple times. We are going to start with the more useful for loop in python. The syntax of a for loop is:\nfor &lt;variable_name&gt; in &lt;iterable&gt;:\n    &lt;body&gt;\n\nfor i in range(3):\n    print(i)\n\nResults: \n# =&gt; 0\n# =&gt; 1\n# =&gt; 2"
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-1-reveal.html#break",
    "href": "teaching/2023-2024/Programming Level-up/lecture-1-reveal.html#break",
    "title": "Python Introduction",
    "section": "break",
    "text": "break\nThe previous example loops over the body a fix number of times. But what if we wanted to stop looping early? Well, we can use the break keyword. This keyword will exit the body of the loop.\nfor i in range(10):\n    if i &gt; 5:\n        break\n    print(i)\n\nResults: \n# =&gt; 0\n# =&gt; 1\n# =&gt; 2\n# =&gt; 3\n# =&gt; 4\n# =&gt; 5"
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-1-reveal.html#continue",
    "href": "teaching/2023-2024/Programming Level-up/lecture-1-reveal.html#continue",
    "title": "Python Introduction",
    "section": "continue",
    "text": "continue\nA different keyword you might want to use is continue. Continue allows you to move/skip onto the next iteration without executing the entire body of the for loop.\nfor i in range(10):\n    if i % 2 == 0:\n        continue\n    print(i)\n\nResults: \n# =&gt; 1\n# =&gt; 3\n# =&gt; 5\n# =&gt; 7\n# =&gt; 9"
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-1-reveal.html#ranges-1",
    "href": "teaching/2023-2024/Programming Level-up/lecture-1-reveal.html#ranges-1",
    "title": "Python Introduction",
    "section": "ranges",
    "text": "ranges\nInstead of using continue like in the previous slide, the range function provides us with some options:\nrange(start, stop, step)\nIn this example, we are starting our iteration at 10, ending at 15, but stepping the counter 2 steps.\nfor i in range(10, 15, 2):\n    print(i)\n\nResults: \n# =&gt; 10\n# =&gt; 12\n# =&gt; 14"
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-1-reveal.html#loop-over-collections",
    "href": "teaching/2023-2024/Programming Level-up/lecture-1-reveal.html#loop-over-collections",
    "title": "Python Introduction",
    "section": "Loop over collections",
    "text": "Loop over collections\nFor loops allow us to iterate over a collection, taking one element at a time. Take for example, a list, and for every item in the list we print its square.\nmy_list = [1, 5, 2, 3, 5.5]\n\nfor el in my_list:\n    print(el**2)\n\nResults: \n# =&gt; 1\n# =&gt; 25\n# =&gt; 4\n# =&gt; 9\n# =&gt; 30.25\nThis kind of looping can work for tuples and sets, but as we have seen, dictionaries are a little different. Every ‘element’ in a dictionary consists of a key and a value. Therefore when we iterate over items in a dictionary, we can assign the key and value to different variables in the loop.\nNote the use of the .items() after the dictionary. We will explore this later.\nmy_dict = {\"name\": \"jane\", \"age\": 35, \"loc\": \"France\"}\n\nfor el_key, el_val in my_dict.items():\n    print(\"Key is:\", el_key, \" value is: \", el_val)\n\nResults: \n# =&gt; Key is: name  and the value is:  jane\n# =&gt; Key is: age  and the value is:  35\n# =&gt; Key is: location  and the value is:  France\nWe could also loop over the keys in the dictionary using the .keys() method instead of .items().\nmy_dict = {\"name\": \"jane\", \"age\": 35, \"loc\": \"France\"}\n\nfor the_key in my_dict.keys():\n    print(the_key)\n\nResults: \n# =&gt; name\n# =&gt; age\n# =&gt; loc\nOr, the values using .values().\nmy_dict = {\"name\": \"jane\", \"age\": 35, \"loc\": \"France\"}\n\nfor the_value in my_dict.values():\n    print(the_value)\n\nResults: \n# =&gt; jane\n# =&gt; 35\n# =&gt; France"
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-1-reveal.html#list-comprehensions",
    "href": "teaching/2023-2024/Programming Level-up/lecture-1-reveal.html#list-comprehensions",
    "title": "Python Introduction",
    "section": "List comprehensions",
    "text": "List comprehensions\nWe have seen previously how for loops work. Knowing the syntax of a for loop and wanting to populate a list with some data, we might be tempted to write:\nx = []\nfor i in range(3):\n    x.append(i)\n\nprint(x)\n\nResults: \n# =&gt; [0, 1, 2]\nWhile this is perfectly valid Python code, Python itself provides ‘List comprehensions’ to make this process easier.\nx = [i for i in range(3)]\nThe syntax of a list comprehensions is:\n[ &lt;variable&gt; for &lt;variable&gt; in &lt;iterable&gt; ]\nWe can also perform similar actions with a dictionary\n[ &lt;key&gt;, &lt;value&gt; for &lt;key&gt;, &lt;value&gt; in &lt;dictionary.items()&gt; ]\nusing if’s\nPerhaps we only want to optionally perform an action within the list comprehension? Python allows us to do this with the inline if statement we’ve seen in the previous lecture.\nx = [i if i &lt; 5 else -1 for i in range(7)]\nprint(x)\n\nResults: \n# =&gt; [0, 1, 2, 3, 4, -1, -1]\nWe add the inline &lt;var&gt; if &lt;condition&gt; else &lt;other-var&gt; before the for loop part of the comprehension.\nThere is another type of if statement in a list comprehension, this occurs when we don’t have an else.\nx = [i for i in range(7) if i &lt; 3]\nprint(x)\n\nResults: \n# =&gt; [0, 1, 2]\nIn this example, we’re only ‘adding’ to the list if the condition (\\(i &lt; 3\\)) is true, else the element is not included in the resulting list.\nmultiple for’s\nIf we like, we can also use nested for loops by simply adding another for loop into the comprehension.\nx = [(i, j) for i in range(2) for j in range(2)]\n\nprint(x)\n\nResults: \n# =&gt; [(0, 0), (0, 1), (1, 0), (1, 1)]\nIn this example, we’re creating a tuple for each element, effectively each combination of 1 and 0."
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-1-reveal.html#list-comprehensions-with-dictionary",
    "href": "teaching/2023-2024/Programming Level-up/lecture-1-reveal.html#list-comprehensions-with-dictionary",
    "title": "Python Introduction",
    "section": "List comprehensions with dictionary",
    "text": "List comprehensions with dictionary\nPython doesn’t restrict us to list comprehensions, but we can do a similar operation to create a dictionary.\nx = [2, 5, 6]\ny = {idx: val for idx, val in enumerate(x)}\nprint(y)\n\nResults: \n# =&gt; {0: 2, 1: 5, 2: 6}\nHere, every item in x has been associated with its numerical index as a key thanks to the enumerate function that returns both the index and value at iteration in the for loop."
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-1-reveal.html#for-loop-quick-exercise",
    "href": "teaching/2023-2024/Programming Level-up/lecture-1-reveal.html#for-loop-quick-exercise",
    "title": "Python Introduction",
    "section": "For loop – Quick Exercise",
    "text": "For loop – Quick Exercise\n\nCreate a list of elements:\n\n2\n“NA”\n24\n5\n\nUse a for loop to iterate over this list.\nIn the body of the for loop, compute \\(2x + 1\\), where \\(x\\) is the current element of the list.\nStore the result of this computation in a new variable \\(y\\), and then print y.\n\nNote You cannot compute \\(2x + 1\\) of “NA”, therefore you will to use an if statement to skip onto the next iteration if it encounters this. Hint try: type(...) =!= str"
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-1-reveal.html#while-loop",
    "href": "teaching/2023-2024/Programming Level-up/lecture-1-reveal.html#while-loop",
    "title": "Python Introduction",
    "section": "While loop",
    "text": "While loop\nA while loop is another looping concept like for but it can loop for an arbitrary amount of times. A while loop looks to see if the condition is True, and if it is, it will execute the body.\nThe syntax of the while loop is:\nwhile &lt;condition&gt;:\n    &lt;body&gt;\n\ni = 0\n\nwhile i &lt; 3:\n    print(i)\n    i = i + 1\n\nResults: \n# =&gt; 0\n# =&gt; 1\n# =&gt; 2\n\nx = 0\ny = 1\nHere is another example:\nwhile x + y &lt; 10:\n    print(\"X is,\", x, \"and y is\", y)\n    x = x + 1\n    y = y * 2\n\nprint(\"X ended as\", x, \", while y is\", y)\n\nResults: \n# =&gt; X is, 0 and y is 1\n# =&gt; X is, 1 and y is 2\n# =&gt; X is, 2 and y is 4\n# =&gt; X ended as 3 , while y is 8"
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-1-reveal.html#example-usage-of-a-function",
    "href": "teaching/2023-2024/Programming Level-up/lecture-1-reveal.html#example-usage-of-a-function",
    "title": "Python Introduction",
    "section": "Example usage of a function",
    "text": "Example usage of a function\nLet’s make a function that takes two numbers and adds them together:\ndef my_addition(a, b):\n    result = a + b\n    return result\n\nx = 2\ny = 3\nz = my_addition(2, 3)  # return 5 and stores in z\nprint(z)\n\nResults: \n# =&gt; 5"
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-1-reveal.html#quick-exercise-1",
    "href": "teaching/2023-2024/Programming Level-up/lecture-1-reveal.html#quick-exercise-1",
    "title": "Python Introduction",
    "section": "Quick exercise",
    "text": "Quick exercise\n\nCreate a function called my_square. This function should take one argument (you can call this argument what you like).\nThe body of the function should compute and return the square of the argument.\nCall this function with 5.556.\nStore the result of calling this function, and print it.\nWhat is the result?"
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-1-reveal.html#re-usability-with-functions",
    "href": "teaching/2023-2024/Programming Level-up/lecture-1-reveal.html#re-usability-with-functions",
    "title": "Python Introduction",
    "section": "Re-usability with Functions",
    "text": "Re-usability with Functions\nFunctions are better illustrated through some examples, so let’s see some!\nname_1 = \"john\"\nname_2 = \"mary\"\nname_3 = \"michael\"\n\nprint(\"Hello \" + name_1 + \", how are you?\")\nprint(\"Hello \" + name_2 + \", how are you?\")\nprint(\"Hello \" + name_3 + \", how are you?\")\nThe above is pretty wasteful. Why? Because we are performing the exact same operation multiple times, with only the variable changed.\nBy abstracting the actions we want to perform into a function, we can ultimately reduce the amount of code we write. Be a lazy programmer!\nname_1 = \"john\"\nname_2 = \"mary\"\nname_3 = \"michael\"\n\ndef say_hello(name):\n    print(\"Hello \" + name + \", how are you?\")\n\nsay_hello(name_1)\nsay_hello(name_2)\nsay_hello(name_3)\nIn this example, we’ve used the function as defined with the def pattern to write the print statement once. Then, we’ve called the function with each variable as its argument."
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-1-reveal.html#named-parameters",
    "href": "teaching/2023-2024/Programming Level-up/lecture-1-reveal.html#named-parameters",
    "title": "Python Introduction",
    "section": "Named parameters",
    "text": "Named parameters\nWe’ve seen in previous examples that, when we create a function, we give each of the arguments (if there are any) a name.\nWhen calling this function, we can specify these same names such as:\ndef say_hello(name):\n    print(\"Hello,\", name)\n\nsay_hello(\"Micheal\")\nsay_hello(name=\"Micheal\")\n\nResults: \n# =&gt; Hello, Micheal\n# =&gt; Hello, Micheal\nBy specifying the name of the parameter we’re using with the called function, we can change the order\ndef say_greeting(greeting, name):\n    print(greeting, name, \"I hope you're having a good day\")\n\nsay_greeting(name=\"John\", greeting=\"Hi\")\n\nResults: \n# =&gt; Hi John I hope you're having a good day"
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-1-reveal.html#optionaldefaultpositional-arguments",
    "href": "teaching/2023-2024/Programming Level-up/lecture-1-reveal.html#optionaldefaultpositional-arguments",
    "title": "Python Introduction",
    "section": "Optional/Default/Positional arguments",
    "text": "Optional/Default/Positional arguments\nWhen we call a function with arguments without naming them, we are supplying them by position.\ndef say_greeting(greeting, name):\n    print(greeting, name, \"I hope you're having a good day\")\n\nsay_greeting(#first position, #section position)\nThe first position gets mapped to variable name of greeting inside the body of the say_greeting function, while the second position gets mapped to name.\nSometimes when creating a function we may want to use default arguments, these are arguments that are used if the call to the function does not specify what their value should be. For example.\ndef say_greeting(name, greeting=\"Hello\"):\n    print(greeting, name, \"I hope you're having a good day\")\n\nsay_greeting(\"John\")\nsay_greeting(\"John\", \"Hi\")  # supply greeting as positional argument\n\nResults: \n# =&gt; Hello John I hope you're having a good day\n# =&gt; Hi John I hope you're having a good day\nNote if you supply a default argument in the function definition, all arguments after this default argument must also supply a default argument.\nSo, this won’t work:\ndef say_greeting(name=\"Jane\", greeting):\n    print(greeting, name, \"I hope you're having a good day\")\n\nsay_greeting(\"John\", \"Hi\")"
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-1-reveal.html#recap-on-arguments",
    "href": "teaching/2023-2024/Programming Level-up/lecture-1-reveal.html#recap-on-arguments",
    "title": "Python Introduction",
    "section": "Recap on arguments",
    "text": "Recap on arguments\n# defining the function\n\ndef say_greeting(name, greeting)  # no default arguments\ndef say_greeting(name, greeting=\"Hello\")  # greeting is a default argument\ndef say_greeting(name=\"Jane\", greeting=\"Hello\")  # both arguments have a default\n\n# calling the functions\n\nsay_greeting(\"John\", \"Hi\")  # both arguments are provided by position\nsay_greeting(name=\"John\", greeting=\"Hi\")  # arguments are supplied by name\nsay_greeting(greeting=\"Hi\", name=\"John\")  # the position of named arguments do not matter"
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-1-reveal.html#function-doc-strings",
    "href": "teaching/2023-2024/Programming Level-up/lecture-1-reveal.html#function-doc-strings",
    "title": "Python Introduction",
    "section": "Function doc-strings",
    "text": "Function doc-strings\nTo make it clear for a human to quickly understand what a function is doing, you can add an optional doc-string. This is a string that is added directly after the initial definition of the function:\ndef my_function(x, y):\n    \"\"\"I am a docstring!!!\"\"\"\n    return x + y\nSome common use cases for docstrings are explaining what the parameters are that it expects, and what it returns.\nIf your explanation is a little longer than a line, a multiline docstring can be created as long as you’re using \"\"\" three quotation marks either side of the string\ndef my_function(x, y):\n    \"\"\"\n    This is my realllly long docstring\n    that explains how the function works. But sometimes\n    its best not to explain the obvious\n    \"\"\"\n    return x + y"
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-1-reveal.html#understanding-scope",
    "href": "teaching/2023-2024/Programming Level-up/lecture-1-reveal.html#understanding-scope",
    "title": "Python Introduction",
    "section": "Understanding scope",
    "text": "Understanding scope\nIn this example we have two scopes which can be easily seen by the indentation. The first is the global scope. The second scope is the scope of the function. The scope of the function can reference variables in the larger scope. But once the function scope exits, we can no longer reference the variables from the function.\nx = 10\n\ndef compute_addition(y):\n    return x + y\n\nprint(compute_addition(10))\nprint(x)\nprint(y)  # does not work\n\nResults: \n# =&gt; 20\n# =&gt; 10\nEven though we can reference the global scope variable from the scope of the function, we can’t modify it like this:\nx = 10\n\ndef compute_addition_2(y):\n    x = x + 5  # error local variable referenced before assignment\n    return x + y\n\nprint(compute_addition_2(10))\nIf we really wanted to reference a variable in a global scope and modify its value, we could use the global keyword. Doing this makes the function output something different every time it is called. This can make it difficult to debug incorrect programs.\nx = 10\n\ndef compute_addition_2(y):\n    global x\n    x = x + 5\n    return x + y\n\nprint(compute_addition_2(10))\nprint(x)\nprint(compute_addition_2(10))\n\nResults: \n# =&gt; 25\n# =&gt; 15\n# =&gt; 30\nIn almost all cases, avoid using global variables. Instead pass the variables as parameters. This can reduce a source of potential errors and ensure that if a function is called multiple times, the output can be more consistent and expected.\nx = 10\n\ndef compute_addition_3(x, y):\n    x = x + 5\n    return x + y\n\nprint(compute_addition_3(x, 10))\nprint(x)\nprint(compute_addition_3(x, 10))\n\nResults: \n# =&gt; 25\n# =&gt; 10\n# =&gt; 25"
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-1-reveal.html#library-system",
    "href": "teaching/2023-2024/Programming Level-up/lecture-1-reveal.html#library-system",
    "title": "Python Introduction",
    "section": "Library system",
    "text": "Library system"
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-1-reveal.html#use-what-youve-learnt",
    "href": "teaching/2023-2024/Programming Level-up/lecture-1-reveal.html#use-what-youve-learnt",
    "title": "Python Introduction",
    "section": "Use what you’ve learnt!",
    "text": "Use what you’ve learnt!\nWe’re going to create a library system to help locate and lookup information about books. For example, we want to know the author of book called ‘Moby Dick’.\nTo create this system, we are going to do it in stages. First, we will want to create our database of books:\n\n\n\n\n\n\n\n\n\nTitle\n\n\nAuthor\n\n\nRelease Date\n\n\n\n\n\n\nMoby Dick\n\n\nHerman Melville\n\n\n1851\n\n\n\n\nA Study in Scarlet\n\n\nSir Arthur Conan Doyle\n\n\n1887\n\n\n\n\nFrankenstein\n\n\nMary Shelley\n\n\n1818\n\n\n\n\nHitchhikers Guide to the Galaxy\n\n\nDouglas Adams\n\n\n1879\n\n\n\n\nOur database is going to be a list of dictionaries. Where each dictionary is a row from this table. For example, one of the dictionaries will have the key “title” and a value “Moby Dick”.\nCreate this database and call it db."
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-1-reveal.html#locating-books",
    "href": "teaching/2023-2024/Programming Level-up/lecture-1-reveal.html#locating-books",
    "title": "Python Introduction",
    "section": "Locating Books",
    "text": "Locating Books\n\nCreate a function called locate_by_title that takes the database to look through, and the title to look up as arguments.\nThis function should check each dictionary, and if the title is the same as what was searched for, it should return the whole dictionary.\nTest this function by calling the locate_by_title function with db and \"Frankenstein\". You should get {\"title\": \"Frankenstein\", \"author\": ...}.\n\nNote you should include docstrings to describe the arguments to the function, and what it will return."
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-1-reveal.html#selecting-a-subset",
    "href": "teaching/2023-2024/Programming Level-up/lecture-1-reveal.html#selecting-a-subset",
    "title": "Python Introduction",
    "section": "Selecting a subset",
    "text": "Selecting a subset\nNow that we can find books by the title name, we also want to find all books that were released after a certain data.\n\nCreate a function called books_released_after that takes two arguments: the database to look through, and the year.\nThis function should look through the database, if it finds a book that was released after the year, it should add it to a list of books that is returned from this function.\nTest this function by calling books_released_after with db and 1850. This function call should return a list containing three dictionaries. The first entry should be ‘Moby Dick’ and the section should be ‘A Study in Scarlet’, etc."
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-1-reveal.html#updating-our-database",
    "href": "teaching/2023-2024/Programming Level-up/lecture-1-reveal.html#updating-our-database",
    "title": "Python Introduction",
    "section": "Updating our database",
    "text": "Updating our database\nOh no! ‘Hitchhikers Guide to the Galaxy’ was released in 1979 not 1879, there must have been a typo. Let’s create a function to update this.\n\nCreate a function called update, that takes 5 arguments: 1) the database to update, 2) the key of the value we want to update 3) the value we want to update it to 4) the key we want to check to find out if we have the correct book and 5) the value of the key to check if we have the correct book.\nupdate(db,\n       key=\"release year\",\n       value=1979,\n       where_key=\"title\",\n       where_value=\"Hitchhikers Guide to the Galaxy\")"
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-1-reveal.html#extended-exercise",
    "href": "teaching/2023-2024/Programming Level-up/lecture-1-reveal.html#extended-exercise",
    "title": "Python Introduction",
    "section": "Extended exercise",
    "text": "Extended exercise\n\nIn the previous steps we created functions locate_by_title and books_released_after. These two functions are similar in a way that they are selecting a subset of our database (just by different criteria).\nFor this harder exercise, can we create a single function called query that allows us to do both locate_by_title and books_released_after.\nAn example call to this query function may look like:\nresults = query(db,\n                where_key=\"title\",\n                where_value=\"Moby Dick\",\n                where_qualifier=\"exactly\")\nwhere_qualifier should accept strings like \"exactly\", \"greater than\", and \"less       than\"."
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-2.html",
    "href": "teaching/2023-2024/Programming Level-up/lecture-2.html",
    "title": "Errors & Object Oriented Programming",
    "section": "",
    "text": "When programming, its good to be defensive and handle errors gracefully. For example, if you’re creating a program, that as part of its process, reads from a file, its possible that this file may not exist at the point the program tries to read it. If it doesn’t exist, the program will crash giving an error such as: FileNotfoundError.\nPerhaps this file is non-essential to the operation of the program, and we can continue without the file. In these cases, we will want to appropriately catch the error to prevent it from stopping Python.\n\n\nTry-catches are keywords that introduce a scope where the statements are executed, and if an error (of a certain type IndexError in this example) occurs, different statements could be executed.\nIn this example, we are trying to access an element in a list using an index larger than the length of the list. This will produce an IndexError. Instead of exiting Python with an error, however, we can catch the error, and print a string.\n    x = [1, 2, 3]\n    \n    try:\n        print(x[3])\n    except IndexError:\n        print(\"Couldn't access element\")\nResults: \n# =&gt; Couldn't access element\n\n\n\nIf we wanted to include the original error message in the print statement, we can use the form:\n    except &lt;error&gt; as &lt;variable&gt;\nThis provides us with an variable containing the original error that we can use later on in the try-catch form.\n    x = [1, 2, 3]\n    \n    try:\n        print(x[3])\n    except IndexError as e:\n        print(f\"Couldn't access elements at index beacuse: {e}\")\nResults: \n# =&gt; Couldn't access elements at index beacuse: list index out of range\n\n\n\nThere are numerous types of errors that could occur in a Python. Here are just some of the most common.\n\nIndexError – Raised when a sequence subscript is out of range.\nValueError – Raised when an operation or function receives an argument that has the right type but an inappropriate value\nAssertionError – Raised when an assert statement fails.\nFileNotFoundError – Raised when a file or directory is requested but doesn’t exist.\n\nThe full list of exceptions in Python 3 can be found at: https://docs.python.org/3/library/exceptions.html\n\n\n\nOne of the previous errors (AssertionError) occurs when an assert statement fails. Assert is a keyword provided to test some condition and raise an error if the condition is false. It typically requires less code than an if-statement that raises an error, so they might be useful for checking the inputs to functions, for example:\n    def my_divide(a, b):\n        assert b != 0\n        return a / b\n    \n    my_divide(1, 2)\n    my_divide(1, 0)\nHere we are checking that the divisor is not a 0, in which case division is not defined."
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-2.html#try-catch",
    "href": "teaching/2023-2024/Programming Level-up/lecture-2.html#try-catch",
    "title": "Errors & Object Oriented Programming",
    "section": "",
    "text": "Try-catches are keywords that introduce a scope where the statements are executed, and if an error (of a certain type IndexError in this example) occurs, different statements could be executed.\nIn this example, we are trying to access an element in a list using an index larger than the length of the list. This will produce an IndexError. Instead of exiting Python with an error, however, we can catch the error, and print a string.\n    x = [1, 2, 3]\n    \n    try:\n        print(x[3])\n    except IndexError:\n        print(\"Couldn't access element\")\nResults: \n# =&gt; Couldn't access element"
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-2.html#capturing-messages",
    "href": "teaching/2023-2024/Programming Level-up/lecture-2.html#capturing-messages",
    "title": "Errors & Object Oriented Programming",
    "section": "",
    "text": "If we wanted to include the original error message in the print statement, we can use the form:\n    except &lt;error&gt; as &lt;variable&gt;\nThis provides us with an variable containing the original error that we can use later on in the try-catch form.\n    x = [1, 2, 3]\n    \n    try:\n        print(x[3])\n    except IndexError as e:\n        print(f\"Couldn't access elements at index beacuse: {e}\")\nResults: \n# =&gt; Couldn't access elements at index beacuse: list index out of range"
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-2.html#types-of-exceptions",
    "href": "teaching/2023-2024/Programming Level-up/lecture-2.html#types-of-exceptions",
    "title": "Errors & Object Oriented Programming",
    "section": "",
    "text": "There are numerous types of errors that could occur in a Python. Here are just some of the most common.\n\nIndexError – Raised when a sequence subscript is out of range.\nValueError – Raised when an operation or function receives an argument that has the right type but an inappropriate value\nAssertionError – Raised when an assert statement fails.\nFileNotFoundError – Raised when a file or directory is requested but doesn’t exist.\n\nThe full list of exceptions in Python 3 can be found at: https://docs.python.org/3/library/exceptions.html"
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-2.html#assertions",
    "href": "teaching/2023-2024/Programming Level-up/lecture-2.html#assertions",
    "title": "Errors & Object Oriented Programming",
    "section": "",
    "text": "One of the previous errors (AssertionError) occurs when an assert statement fails. Assert is a keyword provided to test some condition and raise an error if the condition is false. It typically requires less code than an if-statement that raises an error, so they might be useful for checking the inputs to functions, for example:\n    def my_divide(a, b):\n        assert b != 0\n        return a / b\n    \n    my_divide(1, 2)\n    my_divide(1, 0)\nHere we are checking that the divisor is not a 0, in which case division is not defined."
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-2.html#introduction-to-classes",
    "href": "teaching/2023-2024/Programming Level-up/lecture-2.html#introduction-to-classes",
    "title": "Errors & Object Oriented Programming",
    "section": "Introduction to classes",
    "text": "Introduction to classes\nA class is some representation (can be abstract) of an object. Classes can be used to create some kind of structure that can be manipulated and changed, just like the ways you’ve seen with lists, dictionaries, etc.\nClasses allow us to perform Object-oriented Programming (OOP), where we represent concepts by classes.\nBut to properly understand how classes work, and why we would want to use them, we should take a look at some examples."
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-2.html#basic-syntax",
    "href": "teaching/2023-2024/Programming Level-up/lecture-2.html#basic-syntax",
    "title": "Errors & Object Oriented Programming",
    "section": "Basic syntax",
    "text": "Basic syntax\nWe’re going to start off with the very basic syntax, and build up some more complex classes.\nTo create a class, we use the class keyword, and give our new class a name. This introduces a new scope in Python, the scope of the class.\nTypically, the first thing we shall see in the class is the __init__ function.\n    class &lt;name_of_class&gt;:\n        def __init__(self, args*):\n            &lt;body&gt;"
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-2.html#init-method",
    "href": "teaching/2023-2024/Programming Level-up/lecture-2.html#init-method",
    "title": "Errors & Object Oriented Programming",
    "section": "Init method",
    "text": "Init method\nThe __init__ function is a function that gets called automatically as soon as a class is made. This init function can take many arguments, but must always start with a self.\nIn this example, we are creating a class that represents an x, y coordinate. We’ve called this class Coordinate, and we’ve defined our init function to take an x and y values when the class is being created.\nNote its more typical to use titlecase when specifying the class name. So when reading code its easy to see when you’re creating a class versus calling a function. You should use this style.\n    class Coordinate:\n        def __init__(self, x, y):\n            self.x = x\n            self.y = y"
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-2.html#instantiating",
    "href": "teaching/2023-2024/Programming Level-up/lecture-2.html#instantiating",
    "title": "Errors & Object Oriented Programming",
    "section": "Instantiating",
    "text": "Instantiating\nTo create an instance of this class, call the name of the class as you would a function, and pass any parameters you’ve defined in the init function.\nIn this example, we are creating a new vector using Vector(...) and we’re passing the x and y coordinate.\n    class Vector:\n        def __init__(self, x, y):\n            self.x = x\n            self.y = y\n    \n    \n    point_1 = Vector(5, 2)"
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-2.html#class-variables",
    "href": "teaching/2023-2024/Programming Level-up/lecture-2.html#class-variables",
    "title": "Errors & Object Oriented Programming",
    "section": "Class variables",
    "text": "Class variables\nIn the previous example, we’ve been creating a class variables by using self.&lt;variable_name&gt;. This is telling Python this class should have a variable of this name.\nIt allows then to reference the variable when working with the class.\n    class Vector:\n        def __init__(self, x, y):\n            self.x = x\n            self.y = y\n            self.length = self.x + self.y\n    \n    point_1 = Vector(5, 2)\n    print(point_1.x)\n    print(point_1.y)\n    print(point_1.length)\nResults: \n# =&gt; 5\n# =&gt; 2\n# =&gt; 7"
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-2.html#class-methods",
    "href": "teaching/2023-2024/Programming Level-up/lecture-2.html#class-methods",
    "title": "Errors & Object Oriented Programming",
    "section": "Class Methods",
    "text": "Class Methods\nA class can have many methods associated with it. To create a new method, we create a function within the scope of the class, remember that the first parameter of the function should be self.\nEven in these functions, we can refer to our self.x and self.y within this new function.\nYou’ll notice that to call this function, we using the .length() method similar to how we’ve worked with strings/lists/etc. This is because in Python, everything is an object!\n    class Vector:\n        def __init__(self, x, y):\n            self.x = x\n            self.y = y\n    \n        def length(self):\n            return self.x + self.y\n    \n    \n    my_point = Vector(2, 5)\n    print(my_point.length())\nResults: \n# =&gt; 7"
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-2.html#dunder-methods",
    "href": "teaching/2023-2024/Programming Level-up/lecture-2.html#dunder-methods",
    "title": "Errors & Object Oriented Programming",
    "section": "dunder-methods",
    "text": "dunder-methods\nWhile we could, for example, create a function called .print(), sometimes we would like to use the in built functions like print(). When creating a class, there is a set of dunder-methods (double-under to reference the two ‘__’ characters either side of the function name).\nOne of these dunder-methods is __repr__, which allows us to specify how the object looks when its printed.\n    class OldVector:\n        def __init__(self, x, y):\n            self.x = x\n            self.y = y\n    \n    print(OldVector(2, 5))\n    \n    class Vector:\n        def __init__(self, x, y):\n            self.x = x\n            self.y = y\n    \n        def __repr__(self):\n            return f\"Vector({self.x}, {self.y})\"\n    \n    print(Vector(2, 5))\nResults: \n# =&gt; &lt;__main__.OldVector object at 0x7f658721e250&gt;\n# =&gt; Vector(2, 5)\nThere are many more dunder-methods you should know when creating classes. We shall go through:\n\n__len__ – specify how the length of the class should be computed.\n__getitem__ – how to index over the class\n__call__ – how to use the class like a function\n__iter__ – what to do when iteration starts\n__next__ – what to do at the next step of the iteration"
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-2.html#len__",
    "href": "teaching/2023-2024/Programming Level-up/lecture-2.html#len__",
    "title": "Errors & Object Oriented Programming",
    "section": "__len__",
    "text": "__len__\nThe __len__ function allows us to specify how the len() function acts on the class. Take this hypothetical dataset. We create a __len__ function that returns the length of the unique elements in the dataset.\n    class Dataset:\n        def __init__(self, data):\n            self.data = data\n    \n        def __len__(self):\n            \"\"\"Return the length of unique elements\"\"\"\n            return len(set(self.data))\n    \n    data = Dataset([1, 2, 3, 3, 3, 5, 1])\n    print(len(data))\nResults: \n# =&gt; 4"
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-2.html#getitem__",
    "href": "teaching/2023-2024/Programming Level-up/lecture-2.html#getitem__",
    "title": "Errors & Object Oriented Programming",
    "section": "__getitem__",
    "text": "__getitem__\nNext __getitem__ allows us to index over a class. This new function must include self and a variable to pass the index. Here I’ve used idx. In this function I am simply indexing on the on the classes self.data.\n    class Dataset:\n        def __init__(self, data):\n            self.data = data\n    \n        def __getitem__(self, idx):\n            return self.data[idx]\n    \n    data = Dataset([1, 2, 3, 3, 3, 5, 1])\n    print(data[2])\nResults: \n# =&gt; 3"
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-2.html#call__",
    "href": "teaching/2023-2024/Programming Level-up/lecture-2.html#call__",
    "title": "Errors & Object Oriented Programming",
    "section": "__call__",
    "text": "__call__\nIn a small number of cases, it is nice to use the class just like a function. This is what __call__ allows us to do. In this function we specify what should happen when class is ‘called’ like a function. In this simple example, we are creating a function that prints the type of food being used as a parameter to the function.\n    class Jaguar:\n        def __call__(self, food):\n            print(f\"The jaguar eats the {food}.\")\n    \n    food = \"apple\"\n    animal = Jaguar()\n    \n    animal(food)\nResults: \n# =&gt; The jaguar eats the apple."
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-2.html#iter__-and-__next__",
    "href": "teaching/2023-2024/Programming Level-up/lecture-2.html#iter__-and-__next__",
    "title": "Errors & Object Oriented Programming",
    "section": "__iter__ and __next__",
    "text": "__iter__ and __next__\n__iter__ and __next__ allow us to make our class iterable, i.e. we can use it in a for loop for example.\nThe __iter__ function should define what happens when we start the iteration, and __next__ defines what happens at every step of the iteration.\nLet’s take a look at an example where we have an iterable set of prime numbers.\n    class Primes:\n        def __init__(self):\n            self.primes = [2, 3, 5, 7, 11]\n    \n        def __iter__(self):\n            self.idx = 0\n            return self\n    \n        def __len__(self):\n            return len(self.primes)\n    \n        def __next__(self):\n            if self.idx &lt; len(self):\n                item = self.primes[self.idx]\n                self.idx += 1\n                return item\n            else:\n                raise StopIteration\nAnd now we can iterate over this class\n    prime_numbers = Primes()\n    \n    for prime_number in prime_numbers:\n        print(prime_number)\nResults: \n# =&gt; 2\n# =&gt; 3\n# =&gt; 5\n# =&gt; 7\n# =&gt; 11"
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-2.html#inheritance",
    "href": "teaching/2023-2024/Programming Level-up/lecture-2.html#inheritance",
    "title": "Errors & Object Oriented Programming",
    "section": "Inheritance",
    "text": "Inheritance\nOne special thing about OOP is that its normally designed to provide inheritance – this is true in Python. Inheritance is where you have a base class, and other classes inherit from this base class. This means that the class that inherits from the base class has access to the same methods and class variables. In some cases, it can override some of these features.\nLet’s take a look an example.\n    class Animal:\n        def growl(self):\n            print(\"The animal growls\")\n    \n        def walk(self):\n            raise NotImplementError\nHere we have created a simple class called Animal, that has two functions, one of which will raise an error if its called.\nWe can inherit from this Animal class by placing our base class in () after the new class name.\nHere we are creating two classes, Tiger and Duck. Both of these new classes inherit from Animal. Also, both of these classes are overriding the walk functions. But they are not creating a growl method themselves.\n    class Tiger(Animal):\n        def walk(self):\n            print(\"The Tiger walks through the jungle\")\n    \n    class Duck(Animal):\n        def walk(self):\n            print(\"The Duck walks through the jungle\")\nLook at what happens when we create instances of these classes, and call the functions. First we see that the correct method has been called. I.e. for the duck class, the correct walk method was called.\n    first_animal = Tiger()\n    second_animal = Duck()\n    \n    first_animal.walk()\n    second_animal.walk()\nResults: \n# =&gt; The Tiger walks through the jungle\n# =&gt; The Duck walks through the jungle\nBut what happens if we call the .growl() method?\n    first_animal.growl()\n    second_animal.growl()\nResults: \n# =&gt; The animal growls\n# =&gt; The animal growls\nWe see that it still works. Even though both Duck and Tiger didn’t create a .growl() method, it inherited it from the base class Animal. This works for class methods and class variables."
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-2.html#adding-data",
    "href": "teaching/2023-2024/Programming Level-up/lecture-2.html#adding-data",
    "title": "Errors & Object Oriented Programming",
    "section": "Adding data",
    "text": "Adding data\nWe will want to include a function to add data to our database.\nCreate a class method called add, that takes three arguments (in addition to self of course), the title, the author, and the release date.\nThis add function adds the new book entry to the end of data. Populate this database with the following information.\n\n\n\n\n\n\n\n\n\nTitle\n\n\nAuthor\n\n\nRelease Date\n\n\n\n\n\n\nMoby Dick\n\n\nHerman Melville\n\n\n1851\n\n\n\n\nA Study in Scarlet\n\n\nSir Arthur Conan Doyle\n\n\n1887\n\n\n\n\nFrankenstein\n\n\nMary Shelley\n\n\n1818\n\n\n\n\nHitchhikers Guide to the Galaxy\n\n\nDouglas Adams\n\n\n1879"
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-2.html#locating-a-book",
    "href": "teaching/2023-2024/Programming Level-up/lecture-2.html#locating-a-book",
    "title": "Errors & Object Oriented Programming",
    "section": "Locating a book",
    "text": "Locating a book\nCreate a class method called locate by title that takes the title of the book to look up, and returns the dictionary of all books that have this title. Unlike last time, we don’t need to pass the data as an argument, as its contained within the class."
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-2.html#updating-our-database",
    "href": "teaching/2023-2024/Programming Level-up/lecture-2.html#updating-our-database",
    "title": "Errors & Object Oriented Programming",
    "section": "Updating our database",
    "text": "Updating our database\nCreate a class method called update that takes 4 arguments:, 1) the key of the value we want to update 2) the value we want to update it to 3) the key we want to check to find out if we have the correct book and 4) the value of the key to check if we have the correct book.\n    db.update(key=\"release_date\", value=1979, where_key=\"title\",\n              where_value=\"Hitchhikers Guide to the Galaxy\")\nUse this to fix the release data of the Hitchhiker’s book."
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-2.html#printed-representation",
    "href": "teaching/2023-2024/Programming Level-up/lecture-2.html#printed-representation",
    "title": "Errors & Object Oriented Programming",
    "section": "Printed representation",
    "text": "Printed representation\nUsing the __str__ dunder-method (this is similar to __repr__ as we saw before), create a function that prints out a formatted representation of the entire database as a string. Some of the output should look like:\nLibrary System\n--------------\n\nEntry 1:\n- Name: Moby Dick\n- Author: Herman Melville\n- Release Date: 1851\n..."
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-2.html#extending-our-oop-usage",
    "href": "teaching/2023-2024/Programming Level-up/lecture-2.html#extending-our-oop-usage",
    "title": "Errors & Object Oriented Programming",
    "section": "Extending our OOP usage",
    "text": "Extending our OOP usage\nSo far we’ve used a list of dictionaries. One issue with this is that there is no constraints on the keys we can use. This will certainly create problems if certain keys are missing.\nInstead of using dictionaries. We can create another class called Book that will take three arguments when it is initialised: name, author, and release_date. The init function should initialise three class variables to save this information.\nModify the database to, instead of working with a list of dictionaries, work with a list of Book objects."
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-2.html#printed-representation-challenge.",
    "href": "teaching/2023-2024/Programming Level-up/lecture-2.html#printed-representation-challenge.",
    "title": "Errors & Object Oriented Programming",
    "section": "Printed representation – challenge.",
    "text": "Printed representation – challenge.\nImprove upon the printed representation of the last exercise but instead of bulleted lists, use formatted tables using f-string formatting (https://zetcode.com/python/fstring/).\nThe output should look like this:\nLibrary System\n--------------\n\n| Name           | Author           | Release Data |\n|----------------|------------------|--------------|\n| Moby Dick      | Herman Melville  |         1851 |\n...\nNotice how Release date is right justified, while Name and Author are left justified."
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-2-reveal.html#try-catch",
    "href": "teaching/2023-2024/Programming Level-up/lecture-2-reveal.html#try-catch",
    "title": "Errors & Object Oriented Programming",
    "section": "Try-catch",
    "text": "Try-catch\nTry-catches are keywords that introduce a scope where the statements are executed, and if an error (of a certain type IndexError in this example) occurs, different statements could be executed.\nIn this example, we are trying to access an element in a list using an index larger than the length of the list. This will produce an IndexError. Instead of exiting Python with an error, however, we can catch the error, and print a string.\n    x = [1, 2, 3]\n    \n    try:\n        print(x[3])\n    except IndexError:\n        print(\"Couldn't access element\")\nResults: \n# =&gt; Couldn't access element"
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-2-reveal.html#capturing-messages",
    "href": "teaching/2023-2024/Programming Level-up/lecture-2-reveal.html#capturing-messages",
    "title": "Errors & Object Oriented Programming",
    "section": "Capturing messages",
    "text": "Capturing messages\nIf we wanted to include the original error message in the print statement, we can use the form:\n    except &lt;error&gt; as &lt;variable&gt;\nThis provides us with an variable containing the original error that we can use later on in the try-catch form.\n    x = [1, 2, 3]\n    \n    try:\n        print(x[3])\n    except IndexError as e:\n        print(f\"Couldn't access elements at index beacuse: {e}\")\nResults: \n# =&gt; Couldn't access elements at index beacuse: list index out of range"
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-2-reveal.html#types-of-exceptions",
    "href": "teaching/2023-2024/Programming Level-up/lecture-2-reveal.html#types-of-exceptions",
    "title": "Errors & Object Oriented Programming",
    "section": "Types of exceptions",
    "text": "Types of exceptions\nThere are numerous types of errors that could occur in a Python. Here are just some of the most common.\n\nIndexError – Raised when a sequence subscript is out of range.\nValueError – Raised when an operation or function receives an argument that has the right type but an inappropriate value\nAssertionError – Raised when an assert statement fails.\nFileNotFoundError – Raised when a file or directory is requested but doesn’t exist.\n\nThe full list of exceptions in Python 3 can be found at: https://docs.python.org/3/library/exceptions.html"
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-2-reveal.html#assertions",
    "href": "teaching/2023-2024/Programming Level-up/lecture-2-reveal.html#assertions",
    "title": "Errors & Object Oriented Programming",
    "section": "Assertions",
    "text": "Assertions\nOne of the previous errors (AssertionError) occurs when an assert statement fails. Assert is a keyword provided to test some condition and raise an error if the condition is false. It typically requires less code than an if-statement that raises an error, so they might be useful for checking the inputs to functions, for example:\n    def my_divide(a, b):\n        assert b != 0\n        return a / b\n    \n    my_divide(1, 2)\n    my_divide(1, 0)\nHere we are checking that the divisor is not a 0, in which case division is not defined."
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-2-reveal.html#introduction-to-classes",
    "href": "teaching/2023-2024/Programming Level-up/lecture-2-reveal.html#introduction-to-classes",
    "title": "Errors & Object Oriented Programming",
    "section": "Introduction to classes",
    "text": "Introduction to classes\nA class is some representation (can be abstract) of an object. Classes can be used to create some kind of structure that can be manipulated and changed, just like the ways you’ve seen with lists, dictionaries, etc.\nClasses allow us to perform Object-oriented Programming (OOP), where we represent concepts by classes.\nBut to properly understand how classes work, and why we would want to use them, we should take a look at some examples."
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-2-reveal.html#basic-syntax",
    "href": "teaching/2023-2024/Programming Level-up/lecture-2-reveal.html#basic-syntax",
    "title": "Errors & Object Oriented Programming",
    "section": "Basic syntax",
    "text": "Basic syntax\nWe’re going to start off with the very basic syntax, and build up some more complex classes.\nTo create a class, we use the class keyword, and give our new class a name. This introduces a new scope in Python, the scope of the class.\nTypically, the first thing we shall see in the class is the __init__ function.\n    class &lt;name_of_class&gt;:\n        def __init__(self, args*):\n            &lt;body&gt;"
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-2-reveal.html#init-method",
    "href": "teaching/2023-2024/Programming Level-up/lecture-2-reveal.html#init-method",
    "title": "Errors & Object Oriented Programming",
    "section": "Init method",
    "text": "Init method\nThe __init__ function is a function that gets called automatically as soon as a class is made. This init function can take many arguments, but must always start with a self.\nIn this example, we are creating a class that represents an x, y coordinate. We’ve called this class Coordinate, and we’ve defined our init function to take an x and y values when the class is being created.\nNote its more typical to use titlecase when specifying the class name. So when reading code its easy to see when you’re creating a class versus calling a function. You should use this style.\n    class Coordinate:\n        def __init__(self, x, y):\n            self.x = x\n            self.y = y"
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-2-reveal.html#instantiating",
    "href": "teaching/2023-2024/Programming Level-up/lecture-2-reveal.html#instantiating",
    "title": "Errors & Object Oriented Programming",
    "section": "Instantiating",
    "text": "Instantiating\nTo create an instance of this class, call the name of the class as you would a function, and pass any parameters you’ve defined in the init function.\nIn this example, we are creating a new vector using Vector(...) and we’re passing the x and y coordinate.\n    class Vector:\n        def __init__(self, x, y):\n            self.x = x\n            self.y = y\n    \n    \n    point_1 = Vector(5, 2)"
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-2-reveal.html#class-variables",
    "href": "teaching/2023-2024/Programming Level-up/lecture-2-reveal.html#class-variables",
    "title": "Errors & Object Oriented Programming",
    "section": "Class variables",
    "text": "Class variables\nIn the previous example, we’ve been creating a class variables by using self.&lt;variable_name&gt;. This is telling Python this class should have a variable of this name.\nIt allows then to reference the variable when working with the class.\n    class Vector:\n        def __init__(self, x, y):\n            self.x = x\n            self.y = y\n            self.length = self.x + self.y\n    \n    point_1 = Vector(5, 2)\n    print(point_1.x)\n    print(point_1.y)\n    print(point_1.length)\nResults: \n# =&gt; 5\n# =&gt; 2\n# =&gt; 7"
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-2-reveal.html#class-methods",
    "href": "teaching/2023-2024/Programming Level-up/lecture-2-reveal.html#class-methods",
    "title": "Errors & Object Oriented Programming",
    "section": "Class Methods",
    "text": "Class Methods\nA class can have many methods associated with it. To create a new method, we create a function within the scope of the class, remember that the first parameter of the function should be self.\nEven in these functions, we can refer to our self.x and self.y within this new function.\nYou’ll notice that to call this function, we using the .length() method similar to how we’ve worked with strings/lists/etc. This is because in Python, everything is an object!\n    class Vector:\n        def __init__(self, x, y):\n            self.x = x\n            self.y = y\n    \n        def length(self):\n            return self.x + self.y\n    \n    \n    my_point = Vector(2, 5)\n    print(my_point.length())\nResults: \n# =&gt; 7"
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-2-reveal.html#dunder-methods",
    "href": "teaching/2023-2024/Programming Level-up/lecture-2-reveal.html#dunder-methods",
    "title": "Errors & Object Oriented Programming",
    "section": "dunder-methods",
    "text": "dunder-methods\nWhile we could, for example, create a function called .print(), sometimes we would like to use the in built functions like print(). When creating a class, there is a set of dunder-methods (double-under to reference the two ‘__’ characters either side of the function name).\nOne of these dunder-methods is __repr__, which allows us to specify how the object looks when its printed.\n    class OldVector:\n        def __init__(self, x, y):\n            self.x = x\n            self.y = y\n    \n    print(OldVector(2, 5))\n    \n    class Vector:\n        def __init__(self, x, y):\n            self.x = x\n            self.y = y\n    \n        def __repr__(self):\n            return f\"Vector({self.x}, {self.y})\"\n    \n    print(Vector(2, 5))\nResults: \n# =&gt; &lt;__main__.OldVector object at 0x7f658721e250&gt;\n# =&gt; Vector(2, 5)\nThere are many more dunder-methods you should know when creating classes. We shall go through:\n\n__len__ – specify how the length of the class should be computed.\n__getitem__ – how to index over the class\n__call__ – how to use the class like a function\n__iter__ – what to do when iteration starts\n__next__ – what to do at the next step of the iteration"
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-2-reveal.html#len__",
    "href": "teaching/2023-2024/Programming Level-up/lecture-2-reveal.html#len__",
    "title": "Errors & Object Oriented Programming",
    "section": "__len__",
    "text": "__len__\nThe __len__ function allows us to specify how the len() function acts on the class. Take this hypothetical dataset. We create a __len__ function that returns the length of the unique elements in the dataset.\n    class Dataset:\n        def __init__(self, data):\n            self.data = data\n    \n        def __len__(self):\n            \"\"\"Return the length of unique elements\"\"\"\n            return len(set(self.data))\n    \n    data = Dataset([1, 2, 3, 3, 3, 5, 1])\n    print(len(data))\nResults: \n# =&gt; 4"
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-2-reveal.html#getitem__",
    "href": "teaching/2023-2024/Programming Level-up/lecture-2-reveal.html#getitem__",
    "title": "Errors & Object Oriented Programming",
    "section": "__getitem__",
    "text": "__getitem__\nNext __getitem__ allows us to index over a class. This new function must include self and a variable to pass the index. Here I’ve used idx. In this function I am simply indexing on the on the classes self.data.\n    class Dataset:\n        def __init__(self, data):\n            self.data = data\n    \n        def __getitem__(self, idx):\n            return self.data[idx]\n    \n    data = Dataset([1, 2, 3, 3, 3, 5, 1])\n    print(data[2])\nResults: \n# =&gt; 3"
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-2-reveal.html#call__",
    "href": "teaching/2023-2024/Programming Level-up/lecture-2-reveal.html#call__",
    "title": "Errors & Object Oriented Programming",
    "section": "__call__",
    "text": "__call__\nIn a small number of cases, it is nice to use the class just like a function. This is what __call__ allows us to do. In this function we specify what should happen when class is ‘called’ like a function. In this simple example, we are creating a function that prints the type of food being used as a parameter to the function.\n    class Jaguar:\n        def __call__(self, food):\n            print(f\"The jaguar eats the {food}.\")\n    \n    food = \"apple\"\n    animal = Jaguar()\n    \n    animal(food)\nResults: \n# =&gt; The jaguar eats the apple."
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-2-reveal.html#iter__-and-__next__",
    "href": "teaching/2023-2024/Programming Level-up/lecture-2-reveal.html#iter__-and-__next__",
    "title": "Errors & Object Oriented Programming",
    "section": "__iter__ and __next__",
    "text": "__iter__ and __next__\n__iter__ and __next__ allow us to make our class iterable, i.e. we can use it in a for loop for example.\nThe __iter__ function should define what happens when we start the iteration, and __next__ defines what happens at every step of the iteration.\nLet’s take a look at an example where we have an iterable set of prime numbers.\n    class Primes:\n        def __init__(self):\n            self.primes = [2, 3, 5, 7, 11]\n    \n        def __iter__(self):\n            self.idx = 0\n            return self\n    \n        def __len__(self):\n            return len(self.primes)\n    \n        def __next__(self):\n            if self.idx &lt; len(self):\n                item = self.primes[self.idx]\n                self.idx += 1\n                return item\n            else:\n                raise StopIteration\nAnd now we can iterate over this class\n    prime_numbers = Primes()\n    \n    for prime_number in prime_numbers:\n        print(prime_number)\nResults: \n# =&gt; 2\n# =&gt; 3\n# =&gt; 5\n# =&gt; 7\n# =&gt; 11"
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-2-reveal.html#inheritance",
    "href": "teaching/2023-2024/Programming Level-up/lecture-2-reveal.html#inheritance",
    "title": "Errors & Object Oriented Programming",
    "section": "Inheritance",
    "text": "Inheritance\nOne special thing about OOP is that its normally designed to provide inheritance – this is true in Python. Inheritance is where you have a base class, and other classes inherit from this base class. This means that the class that inherits from the base class has access to the same methods and class variables. In some cases, it can override some of these features.\nLet’s take a look an example.\n    class Animal:\n        def growl(self):\n            print(\"The animal growls\")\n    \n        def walk(self):\n            raise NotImplementError\nHere we have created a simple class called Animal, that has two functions, one of which will raise an error if its called.\nWe can inherit from this Animal class by placing our base class in () after the new class name.\nHere we are creating two classes, Tiger and Duck. Both of these new classes inherit from Animal. Also, both of these classes are overriding the walk functions. But they are not creating a growl method themselves.\n    class Tiger(Animal):\n        def walk(self):\n            print(\"The Tiger walks through the jungle\")\n    \n    class Duck(Animal):\n        def walk(self):\n            print(\"The Duck walks through the jungle\")\nLook at what happens when we create instances of these classes, and call the functions. First we see that the correct method has been called. I.e. for the duck class, the correct walk method was called.\n    first_animal = Tiger()\n    second_animal = Duck()\n    \n    first_animal.walk()\n    second_animal.walk()\nResults: \n# =&gt; The Tiger walks through the jungle\n# =&gt; The Duck walks through the jungle\nBut what happens if we call the .growl() method?\n    first_animal.growl()\n    second_animal.growl()\nResults: \n# =&gt; The animal growls\n# =&gt; The animal growls\nWe see that it still works. Even though both Duck and Tiger didn’t create a .growl() method, it inherited it from the base class Animal. This works for class methods and class variables."
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-2-reveal.html#adding-data",
    "href": "teaching/2023-2024/Programming Level-up/lecture-2-reveal.html#adding-data",
    "title": "Errors & Object Oriented Programming",
    "section": "Adding data",
    "text": "Adding data\nWe will want to include a function to add data to our database.\nCreate a class method called add, that takes three arguments (in addition to self of course), the title, the author, and the release date.\nThis add function adds the new book entry to the end of data. Populate this database with the following information.\n\n\n\n\n\n\n\n\n\nTitle\n\n\nAuthor\n\n\nRelease Date\n\n\n\n\n\n\nMoby Dick\n\n\nHerman Melville\n\n\n1851\n\n\n\n\nA Study in Scarlet\n\n\nSir Arthur Conan Doyle\n\n\n1887\n\n\n\n\nFrankenstein\n\n\nMary Shelley\n\n\n1818\n\n\n\n\nHitchhikers Guide to the Galaxy\n\n\nDouglas Adams\n\n\n1879"
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-2-reveal.html#locating-a-book",
    "href": "teaching/2023-2024/Programming Level-up/lecture-2-reveal.html#locating-a-book",
    "title": "Errors & Object Oriented Programming",
    "section": "Locating a book",
    "text": "Locating a book\nCreate a class method called locate by title that takes the title of the book to look up, and returns the dictionary of all books that have this title. Unlike last time, we don’t need to pass the data as an argument, as its contained within the class."
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-2-reveal.html#updating-our-database",
    "href": "teaching/2023-2024/Programming Level-up/lecture-2-reveal.html#updating-our-database",
    "title": "Errors & Object Oriented Programming",
    "section": "Updating our database",
    "text": "Updating our database\nCreate a class method called update that takes 4 arguments:, 1) the key of the value we want to update 2) the value we want to update it to 3) the key we want to check to find out if we have the correct book and 4) the value of the key to check if we have the correct book.\n    db.update(key=\"release_date\", value=1979, where_key=\"title\",\n              where_value=\"Hitchhikers Guide to the Galaxy\")\nUse this to fix the release data of the Hitchhiker’s book."
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-2-reveal.html#printed-representation",
    "href": "teaching/2023-2024/Programming Level-up/lecture-2-reveal.html#printed-representation",
    "title": "Errors & Object Oriented Programming",
    "section": "Printed representation",
    "text": "Printed representation\nUsing the __str__ dunder-method (this is similar to __repr__ as we saw before), create a function that prints out a formatted representation of the entire database as a string. Some of the output should look like:\nLibrary System\n--------------\n\nEntry 1:\n- Name: Moby Dick\n- Author: Herman Melville\n- Release Date: 1851\n..."
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-2-reveal.html#extending-our-oop-usage",
    "href": "teaching/2023-2024/Programming Level-up/lecture-2-reveal.html#extending-our-oop-usage",
    "title": "Errors & Object Oriented Programming",
    "section": "Extending our OOP usage",
    "text": "Extending our OOP usage\nSo far we’ve used a list of dictionaries. One issue with this is that there is no constraints on the keys we can use. This will certainly create problems if certain keys are missing.\nInstead of using dictionaries. We can create another class called Book that will take three arguments when it is initialised: name, author, and release_date. The init function should initialise three class variables to save this information.\nModify the database to, instead of working with a list of dictionaries, work with a list of Book objects."
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-2-reveal.html#printed-representation-challenge.",
    "href": "teaching/2023-2024/Programming Level-up/lecture-2-reveal.html#printed-representation-challenge.",
    "title": "Errors & Object Oriented Programming",
    "section": "Printed representation – challenge.",
    "text": "Printed representation – challenge.\nImprove upon the printed representation of the last exercise but instead of bulleted lists, use formatted tables using f-string formatting (https://zetcode.com/python/fstring/).\nThe output should look like this:\nLibrary System\n--------------\n\n| Name           | Author           | Release Data |\n|----------------|------------------|--------------|\n| Moby Dick      | Herman Melville  |         1851 |\n...\nNotice how Release date is right justified, while Name and Author are left justified."
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-7.html",
    "href": "teaching/2023-2024/Programming Level-up/lecture-7.html",
    "title": "Linux & Supercomputer",
    "section": "",
    "text": "Linux is a popular operating system (OS) like Windows, or MacOS.\nUnlike these other two OSs, Linux is open source, which means the source code is freely available to look at and modify.\nAs its open source, its very possible for anyone to build their own version of Linux or build on top of Linux to create their own Distribution of Linux.\n\n\n\n\nA distribution can be considered like a flavour or version of Linux. There are many popular flavours that attempt to meet different needs from different users. For example:\n\nUbuntu – typically the first Linux experience people will have. Attempts to be very user friendly.\nFedora – stable and secure distribution while also providing up-to-date packages.\nArch Linux – strong focus on customisability rather than user friendliness with bleeding edge packages.\n\n\n\n\n\nWhile we have said that Linux is open source, there are many other traits that make it stand out from other operating systems:\n\nComplete control of how the system operates.\nThe level of flexibility and automation that you can get from using the Linux command line.\n\nWhile there are many other traits, these two are going to be what we’re going to focus on."
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-7.html#what-is-linux",
    "href": "teaching/2023-2024/Programming Level-up/lecture-7.html#what-is-linux",
    "title": "Linux & Supercomputer",
    "section": "",
    "text": "Linux is a popular operating system (OS) like Windows, or MacOS.\nUnlike these other two OSs, Linux is open source, which means the source code is freely available to look at and modify.\nAs its open source, its very possible for anyone to build their own version of Linux or build on top of Linux to create their own Distribution of Linux."
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-7.html#whats-a-distribution",
    "href": "teaching/2023-2024/Programming Level-up/lecture-7.html#whats-a-distribution",
    "title": "Linux & Supercomputer",
    "section": "",
    "text": "A distribution can be considered like a flavour or version of Linux. There are many popular flavours that attempt to meet different needs from different users. For example:\n\nUbuntu – typically the first Linux experience people will have. Attempts to be very user friendly.\nFedora – stable and secure distribution while also providing up-to-date packages.\nArch Linux – strong focus on customisability rather than user friendliness with bleeding edge packages."
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-7.html#defining-traits-of-linux",
    "href": "teaching/2023-2024/Programming Level-up/lecture-7.html#defining-traits-of-linux",
    "title": "Linux & Supercomputer",
    "section": "",
    "text": "While we have said that Linux is open source, there are many other traits that make it stand out from other operating systems:\n\nComplete control of how the system operates.\nThe level of flexibility and automation that you can get from using the Linux command line.\n\nWhile there are many other traits, these two are going to be what we’re going to focus on."
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-7.html#whats-a-command",
    "href": "teaching/2023-2024/Programming Level-up/lecture-7.html#whats-a-command",
    "title": "Linux & Supercomputer",
    "section": "What’s a command?",
    "text": "What’s a command?\nWhile many recent versions of Linux makes things more accessible via GUIs, they will never be a substitute for using the command line. We’re going to learn how to control the system via the command line, via a shell. A shell, like the Python REPL we’ve already seen, is waits for you to input commands, executes the command, and prints the output if there is output to print.\nA Linux command is a call to a program optionally followed by some arguments. For example, if we want list out the files and folders in the directory, we would use the ls (list) command:\nls\nThe ls command comes with a number of optional flags and arguments that we can add onto the call. When calling a command a flag is something that begins with a - , for example -l tells ls to list the directory in a list format.\nls -l\nWe have supplied the -l flag. There are many other flags for ls, like for example, the human readable file systems with -h or show hidden files (files that start with a period) with -a.\nWhen we’re using multiple flags we could write\nls -l -h -a\nOr:\nls -lha\nSometimes commands take optional positional arguments. Going back to our list directory command, where, by default, it will list the current directory. But instead we can tell the command to list a particular directory by supplying the path as an argument\nls images/ -lha\n# or ls -lha images/ works too\nHow do I know how to use a command? Well that’s where another command comes in. It’s called man (short for manual). If you pass another command to the man command, the documentation will be shown in the terminal, e.g.:\nman ls  # display the documentation for ls\nThe documentation should list all the different flags and arguments, describe what they mean, and sometimes give example or most common usage of a command.\nWhen the ‘man page’ is display, you can scroll up and down the page using your arrow keys, and page-up and page-down. When you’re done reading, just hit the ‘q’ character\nI am going to go through some of the most common commands just to make sure that you’re familiar with the typical usage."
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-7.html#cd",
    "href": "teaching/2023-2024/Programming Level-up/lecture-7.html#cd",
    "title": "Linux & Supercomputer",
    "section": "cd",
    "text": "cd\nWe’ve already seen ls to list a directory. The command to move to a directory is cd (change directory), that takes an argument of filepath to move to:\ncd ~ # tilde is short-hand for the 'home directory'\ncd ~/Documents/My\\ Files  # go to Documents and then to \"My Files\"\ncd   # no argument, by default goes to the home directory"
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-7.html#mkdir",
    "href": "teaching/2023-2024/Programming Level-up/lecture-7.html#mkdir",
    "title": "Linux & Supercomputer",
    "section": "mkdir",
    "text": "mkdir\nSticking with the them of directories, to make a new directory we use mkdir, whose argument takes the name of the directory we want to create:\nmkdir my_new_directory\nYou can create a many level nested directory structure all at once using the -p (parents) flag, that tells mkdir if the parent directory of the target directory doesn’t exist, create it.\nmkdir photos/2020/01/05  # won't work unless photos/2020/01 exist\nmkdir -p photos/2020/01/05  # this will work"
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-7.html#cp",
    "href": "teaching/2023-2024/Programming Level-up/lecture-7.html#cp",
    "title": "Linux & Supercomputer",
    "section": "cp",
    "text": "cp\nTo copy a file or directory, we can use the cp command. Here we are copying a file, where the first argument is the filepath of the file you want to copy and the second argument is the filepath where the copy should be placed.\ncp my_old_file my_new_file\nBy default (without a flag), cp will not work with directories, for that you have to use the -r (recursive) flag\ncp -r data/ data-backup"
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-7.html#mv",
    "href": "teaching/2023-2024/Programming Level-up/lecture-7.html#mv",
    "title": "Linux & Supercomputer",
    "section": "mv",
    "text": "mv\nThe syntax of moving a file is similar to that of cp:\nmv old_file new_file\nExcept that it works for both files and directories without any flags. mv can also be used to rename files, that’s all renaming is: moving a file to the same directory under a different name."
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-7.html#rm",
    "href": "teaching/2023-2024/Programming Level-up/lecture-7.html#rm",
    "title": "Linux & Supercomputer",
    "section": "rm",
    "text": "rm\nTo remove a file us rm:\nrm file_to_delete\nIf you want to delete a directory, use the -r (recursive) flag:\nrm -r directory_to_delete/"
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-7.html#cat",
    "href": "teaching/2023-2024/Programming Level-up/lecture-7.html#cat",
    "title": "Linux & Supercomputer",
    "section": "cat",
    "text": "cat\ncat stands for concatenate, i.e. concatenating the contents of two or more files:\ncat file1 file2\nThe result is that the concatenation of these two files will be printed to the screen. If you wanted to put the result into its own file you would redirect the output using &gt;\ncat file1 file2 &gt; newfile\nSince cat reads the file and prints it to screen it is a very handy way to view the contents of a file, even if it was not intended for that."
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-7.html#pwd",
    "href": "teaching/2023-2024/Programming Level-up/lecture-7.html#pwd",
    "title": "Linux & Supercomputer",
    "section": "pwd",
    "text": "pwd\nSometimes you may get lost when moving directories. pwd prints the current working directory from the root directory, i.e. the path that is printed is an absolute path.\npwd"
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-7.html#find",
    "href": "teaching/2023-2024/Programming Level-up/lecture-7.html#find",
    "title": "Linux & Supercomputer",
    "section": "find",
    "text": "find\nIf we want to list all files of a certain type, we can use the wildcard * that we’ve seen before:\nls *.jpg # list all files that end with .jpg\nHowever, this will only list for the current directory. Perhaps the better way to find files will be using the find command:\nfind . -type f -name *.jpg\nThe first argument is the directory to start the search, then we define the type f being files, and then specify the name. Find will recursively search through directories and sub-directories to find all files that match that name."
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-7.html#grep",
    "href": "teaching/2023-2024/Programming Level-up/lecture-7.html#grep",
    "title": "Linux & Supercomputer",
    "section": "grep",
    "text": "grep\nHow about if we want to find files that have a certain contents? For that we can use grep. Grep will read a file and print (by default) the lines that contains your pattern. i.e.:\ngrep 'Linux' lecture.org\nThis will print the lines that contain the word Linux in lecture.org. If we just want the matched value, we use the -o flag.\ngrep -o '[0-9]' lecture.org\nThis prints all occurrences of numbers in lecture.org"
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-7.html#lessheadtail",
    "href": "teaching/2023-2024/Programming Level-up/lecture-7.html#lessheadtail",
    "title": "Linux & Supercomputer",
    "section": "less/head/tail",
    "text": "less/head/tail\nIf a file is very long, we may not want to read the file using cat, as it will have to print the entire file. Instead we could use less, which will allow us to navigate through the file, using arrow keys to move and q to quit.\nless filename\nIf we just want to view the first few lines, or the last few lines of a file we can use head/tail, respectively:\nhead filename\ntail -n 20 filename  # last 20 lines\ntail -F filename # constantly read the file"
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-7.html#wc",
    "href": "teaching/2023-2024/Programming Level-up/lecture-7.html#wc",
    "title": "Linux & Supercomputer",
    "section": "wc",
    "text": "wc\nOften times we just want to count the number of something. For example, if we want to count the number of files/folders in the directory we can do:\nls -l | wc -l\nWe’re first printing all files and folders in a list format (one per line), then passing (piping_) the result to wc, which with the -l line flag, is counting the number of lines. Therefore we get a count of the number of files and folders. Here is another example where we’re counting how many times the word bash appears in these lecture notes:\ngrep -o 'bash' lecture.org | wc -l"
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-7.html#piping",
    "href": "teaching/2023-2024/Programming Level-up/lecture-7.html#piping",
    "title": "Linux & Supercomputer",
    "section": "piping",
    "text": "piping\nThe purpose of piping is to pass data around between commands. We have just seen how we can pass the output of, say, the ls command to the input of wc. This allows use to construct very sophisticated pipelines to do some quite complex things from the combination of very simple commands.\nfind . -name '*.txt' -type f -print0 | xargs -0 grep \"something\""
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-7.html#overview",
    "href": "teaching/2023-2024/Programming Level-up/lecture-7.html#overview",
    "title": "Linux & Supercomputer",
    "section": "Overview",
    "text": "Overview\nIn summary we have seen the following commands:\n\nls - List a directory\ncd - Change/move to a directory\nmkdir - Make a new directory\ncat - Concatenate files\ncp - Copy a file/directory\nmv - Move files/folders\nrm - Remove files and folders\npwd - Display the current absolute path\nfind - Find files\ngrep - Find occurrences of a pattern in a file\nless/head/tail - Read a file\nwc - Count"
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-7.html#your-very-first-bash-script",
    "href": "teaching/2023-2024/Programming Level-up/lecture-7.html#your-very-first-bash-script",
    "title": "Linux & Supercomputer",
    "section": "Your Very first bash script",
    "text": "Your Very first bash script\nLet’s start with the classic ‘Hello, World’ example. We’ll create a new file called ‘hello.sh’ and enter the following:\n#!/bin/bash\n\necho \"Hello, World!\"\nFirst thing to notice is that the first line contains what we call a ‘shebang’ or ‘hashbang’. It tells Linux which shell interpreter will be used to run the script, in this case: /bin/bash\nThe next (non-empty) line in the file is echo 'Hello, World'. This is exactly the same as the other commands we’ve just seen.\nNow that we’ve created and saved our bash script, we will want to run it. We have two alternative methods to run this script:\nbash hello.sh  # run the script via bash\nThe second, requires that we have executable privileges for the script:\nchmod +x hello.sh  # add executable 'x' privileges\n./hello.sh  # execute it"
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-7.html#variables",
    "href": "teaching/2023-2024/Programming Level-up/lecture-7.html#variables",
    "title": "Linux & Supercomputer",
    "section": "Variables",
    "text": "Variables\nThe variables we create in our bash scripts are very much the same as the environment variables we’ve seen before. Take for example:\n#!/bin/bash\nAGE=\"35\"\nPERSON_NAME=\"Jane\"\necho \"$PERSON_NAME is $AGE years old\"\nWe create a variable AGE with the = assignment operator. Note we don’t put spaces either side of the equals sign in bash. To refer to the variable, we use $AGE, using the $ dollar sign."
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-7.html#interpolation-in-bash-strings",
    "href": "teaching/2023-2024/Programming Level-up/lecture-7.html#interpolation-in-bash-strings",
    "title": "Linux & Supercomputer",
    "section": "Interpolation in bash strings",
    "text": "Interpolation in bash strings\nYou would have noticed in the previous example that we included the variable directly into the string we’re echoing out. This is something similar to what we’ve seen with f-strings in Python.\nWhen we use double quotes: \"...\" in bash, the variable will be integrated into the resulting string. We can even call bash functions from directly inside the string:\necho \"I am logging in as: $(who)\""
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-7.html#bash-strings-the-sharp-edges",
    "href": "teaching/2023-2024/Programming Level-up/lecture-7.html#bash-strings-the-sharp-edges",
    "title": "Linux & Supercomputer",
    "section": "Bash strings – the sharp edges",
    "text": "Bash strings – the sharp edges\nYou might be tempted to use a variable when generating a path:\nTRAIN_PROCESS=\"training\"\nTEST_PROCESS=\"testing\"\n\ntouch \"./data/$TRAIN_PROCESS_error.txt\"\ntouch \"./data/$TEST_PROCESS_error.txt\nBut this will create an error as underscores can be part of the variable name, so bash will be looking for a variable named: $TRAIN_PROCESS_error which has never been created. To get around this, we can wrap our variable in curly braces:\ntouch \"./data/${TRAIN_PROCESS}_error.txt\""
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-7.html#stopping-interpolation-in-bash-strings",
    "href": "teaching/2023-2024/Programming Level-up/lecture-7.html#stopping-interpolation-in-bash-strings",
    "title": "Linux & Supercomputer",
    "section": "Stopping interpolation in bash strings",
    "text": "Stopping interpolation in bash strings\nWe can also use single quotes for strings in bash. When we use these strings, the string itself is not interpreted, and thus it will ignore any variables or bash commands:\necho 'I am logging in as: $(who)'"
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-7.html#inputoutput",
    "href": "teaching/2023-2024/Programming Level-up/lecture-7.html#inputoutput",
    "title": "Linux & Supercomputer",
    "section": "Input/Output",
    "text": "Input/Output\nIf we want to read the input from keyboard into a variable, we use the read command:\n#!/bin/bash\n\necho \"Enter your name:\"\nread NAME\n\necho \"Hello, $NAME\"\nread in this context will read in the input and create the variable with that value. As we’ve already seen, we can then output this value to the console using the echo command."
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-7.html#booleans",
    "href": "teaching/2023-2024/Programming Level-up/lecture-7.html#booleans",
    "title": "Linux & Supercomputer",
    "section": "Booleans",
    "text": "Booleans\nTechnically, bash does not have built in data types for true and false, but Linux has the commands true and false which we could use in place. The implementation of how these commands work is not important.\nFILE_EXISTS=true\n\nif [ \"$FILE_EXISTS\" = true ]; then\necho \"The file exists!\"\nfi"
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-7.html#conditionals",
    "href": "teaching/2023-2024/Programming Level-up/lecture-7.html#conditionals",
    "title": "Linux & Supercomputer",
    "section": "Conditionals",
    "text": "Conditionals\nWhen we’re creating if expressions, we use the following syntax:\nif &lt;&lt;conditional&gt;&gt;; then\n   # do something\nelse\n   # do something else\nfi\nWe can also use elif\nif &lt;&lt;conditional&gt;&gt;; then\n   # do something\nelif &lt;&lt;conditional&gt;&gt;; then\n   # do something else\nelse\n   # something else entirely\nfi\nWriting condition expressions can be a little more cumbersome than in Python. These can be many pain points for new bash programmers, take for example:\nFILE_EXISTS=false\n\nif [ $FILE_EXISTS ]; then\necho \"The file exists!\"\nfi\nThis is because we have used the [...] single bracket syntax for the test. But there are others:\n\nNo brackets: we could omit the brackets in which case it would run the false command not print the statement.\nSingle paranthesis (...) creates a sub-shell.\nDouble paranthesis ((...)) for arithmetic operation\nSingle square bracket [...] calls test\nDouble square bracket [[...]]\n\nWhat if we write:\nVAR_1=\"Mr Foo Bar\"\nVAR_2=\"Mr Foo Bar\"\nif [ $VAR_1 = $VAR_2 ]; then\necho \"They are the same\"\nfi\nWe would get an error because test expands the arguments into:\nMr Foo Bar = Mr Foo Bar\nWith the spaces included. To prevent this from happening, we have to wrap the variables in quotation marks.\nVAR_1=\"Mr Foo Bar\"\nVAR_2=\"Mr Foo Bar\"\nif [ \"$VAR_1\" = \"$VAR_2\" ]; then\necho \"They are the same\"\nfi\nIf we use [[ in if statement, then we can do more sophisticated things like pattern matching:\nFILENAME=\"testing.png\"\nif [[ \"$FILENAME\" = *.png ]]; then\necho \"Its a png file\"\nfi"
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-7.html#loops",
    "href": "teaching/2023-2024/Programming Level-up/lecture-7.html#loops",
    "title": "Linux & Supercomputer",
    "section": "Loops",
    "text": "Loops\nLike in Python, we can iterate in bash\nfor i in {1..10}; do\necho $i\ndone\nThis iterates with i starting at 1 upto 10 (inclusive). Or we could do:\nfor (( i=1; i &lt;= 10; i++ )); do\necho $i\ndone\nWe can also iterate over a list of files/folders in a directory:\nfor FILE in ./images/*; do\necho $FILE\ndone\nUsing the while form, we can continue looping until our conditional is false. For example, we could loop testing our internet connection, until its been established:\nwhile ! ping -c 1 google.com; do\necho \"No internet yet\"\nsleep 1\ndone\n\necho \"Internet is available!\""
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-7.html#functions",
    "href": "teaching/2023-2024/Programming Level-up/lecture-7.html#functions",
    "title": "Linux & Supercomputer",
    "section": "Functions",
    "text": "Functions\nTo create a function, we use the following syntax:\nfunction_name() {\n# do something\n}\nAnd to call the function, you just need to use the function name:\nfunction_name # this called function name\nHere is another example:\nsay_hello() {\necho \"Hello, $1\"\n}\n\nsay_hello \"Jane\"\nNotice that we didn’t need to include any argument list. We just used $1 for the first argument passed to the function.\nsay_hello() {\necho \"$1, $2\"\n}\n\nsay_hello \"Hi\" \"Jane\"\nReturning values is ‘interesting’ as, coming from other languages, you think could do something like this:\nsay_hello() {\nreturn \"hello\"\n}\nRESULT=\"$(say_hello)\"\necho $RESULT\nThis didn’t work like we expected, the value wasn’t returned and assigned to RESULT. So how do we return a value?\nsay_hello() {\necho \"Hello\"\n}\nRESULT=\"$(say_hello)\"\necho \"This is before the printing of result\"\necho $RESULT"
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-7.html#how-to-login",
    "href": "teaching/2023-2024/Programming Level-up/lecture-7.html#how-to-login",
    "title": "Linux & Supercomputer",
    "section": "How to login",
    "text": "How to login\nssh &lt;&lt;username&gt;&gt;@sms-ext.lis-lab.fr\nTyping this command can become tiresome very quickly, especially after sending data back and forth. But we can make it a lot easier by updating our ~/.ssh/config file to include something like:\nHost cluster\n HostName sms-ext.lis-lab.fr\n User &lt;&lt;username&gt;&gt;\nThen to login to the cluster, we just need to type:\nssh cluster\nAnd we should be prompted for our password."
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-7.html#how-to-login-1",
    "href": "teaching/2023-2024/Programming Level-up/lecture-7.html#how-to-login-1",
    "title": "Linux & Supercomputer",
    "section": "How to login",
    "text": "How to login\nIf you trust the machine your on, you can remove password authentication and move to key-based authentication:\nssh-copy-id cluster\nWhen we next login to the server, we shouldn’t be prompted for a password."
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-7.html#how-to-copy-files-to-and-from-the-cluster",
    "href": "teaching/2023-2024/Programming Level-up/lecture-7.html#how-to-copy-files-to-and-from-the-cluster",
    "title": "Linux & Supercomputer",
    "section": "How to copy files to and from the cluster",
    "text": "How to copy files to and from the cluster\nWe have a number of options for transferring files to and from the cluster. Firstly, let’s look at the command scp. It takes two arguments, the first argument is the file you want to send, the second argument is the destination of the sent file.\nscp &lt;&lt;origin&gt;&gt; &lt;&lt;destination&gt;&gt;\nSimilar to commands like cp, scp by default only works for files, not folders. To send folders/directories, we use the -r flag just like cp.\nscp -r &lt;&lt;origin_folder&gt;&gt; &lt;&lt;destination_folder&gt;&gt;"
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-7.html#copying-files-rsync",
    "href": "teaching/2023-2024/Programming Level-up/lecture-7.html#copying-files-rsync",
    "title": "Linux & Supercomputer",
    "section": "Copying files – rsync",
    "text": "Copying files – rsync\nOne of the downsides about scp is that it will copy every file you give it. Even if the file at the destination is exactly the same. What if we only want to copy files that need to be copied, i.e. that are outdated, thus saving time? For that, we can use rsync. Rsync will copy files from one source to a destination only if the destination needs to be updated. This can save a lot of time by skipping files that already exist at the destination:\nrsync &lt;&lt;source&gt;&gt; &lt;&lt;destination&gt;&gt;"
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-7.html#the-login--and-compute-nodes",
    "href": "teaching/2023-2024/Programming Level-up/lecture-7.html#the-login--and-compute-nodes",
    "title": "Linux & Supercomputer",
    "section": "The Login- and Compute Nodes",
    "text": "The Login- and Compute Nodes\nWhen you login to the cluster, you are logging into the login node. Note that no computation should be run on this node. If you want to run scripts, you will have to submit a job to the compute nodes.\nOn the login node there is a system installed called ‘SLURM’. SLURM is a job scheduler program that receives your requests for executing scripts, it will queue them and assign them to available compute nodes.\nWe will take a look at how to request and manage jobs using the various commands that SLURM provides."
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-7.html#how-to-launch-a-job-srun",
    "href": "teaching/2023-2024/Programming Level-up/lecture-7.html#how-to-launch-a-job-srun",
    "title": "Linux & Supercomputer",
    "section": "How to launch a job – srun",
    "text": "How to launch a job – srun\nThe first command we will look at it is srun. This command will run request a job for execution in ‘real-time’. By real-time, we mean that the shell will wait until the job has been submitted.\nsrun &lt;&lt;compute node options&gt;&gt; &lt;&lt;command to run&gt;&gt;\nLet’s take a look at an example where we want to run an interactive bash shell on the compute shell (similar to ssh’ing into the compute node).\nsrun --time=00:10:00 --pty bash -l\nThis will request a job on any available compute node for 10 minutes. When a node becomes available, bash will execute, dropping you into the shell. You will notice that the shell prompt has changed from sms to the name of the node."
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-7.html#salloc",
    "href": "teaching/2023-2024/Programming Level-up/lecture-7.html#salloc",
    "title": "Linux & Supercomputer",
    "section": "salloc",
    "text": "salloc\nThere is another method we can use to create an interactive job. We could use the salloc command to allocate resources for a task. After the resources have been allocated and our job is ready, we can ssh into the node with the allocated resources.\nsalloc --time=10:00:00 &\nssh &lt;name&gt;"
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-7.html#options",
    "href": "teaching/2023-2024/Programming Level-up/lecture-7.html#options",
    "title": "Linux & Supercomputer",
    "section": "options",
    "text": "options\nIn the previous command, we used the --time option to specify how long the job will run for. But there are other options we can use to be more specific about the jobs we want to run.\n--cpus-per-task can be used to request more than one CPU to be allocated. This is especially helpful when we have a multithreaded process we want to run.\n--mem specifies how much memory should be allocated to the job. For example: --mem=16G tells SLURM to allocate 16 GB of memory."
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-7.html#gpu-allocation",
    "href": "teaching/2023-2024/Programming Level-up/lecture-7.html#gpu-allocation",
    "title": "Linux & Supercomputer",
    "section": "GPU allocation",
    "text": "GPU allocation\nIf we need to use a GPU, we need to use a few options. Firstly, we can specify that our job is on a compute node with GPU. There will usually be a group of nodes in a ‘GPU’ group or partition, and thus we can specify to use one of these partitions:\nsrun --time=00:10:00 --partiton=gpu --pty bash -l\nBut you will notice that you still do not have access to a GPU. You’re running on the GPU node, but you haven’t actually requested a GPU be allocated to your job. For that you will use --gres:\nsrun --time=00:10:00 --partition=gpu --gres=gpu:1 --pty bash -l\nHere we are requesting one GPU, but if we use --gres:gpu:2 we are requesting 2 GPUs etc.\nThere are many different types of GPUs available, some older than others. If you wanted to allocate a job with a specific type of GPU you can use the --constraint flag:\nsrun --time=00:10:00 \\\n --partition=gpu \\\n --gres=gpu:1 \\\n --constraint='cuda61' \\\n --pty bash -l\nThis command requests that our job run on the GPU partition, with 1 GPU allocated that has the capability of running CUDA compute 61.\nOr we can specify the type of GPU in the gres option:\nsrun --time=00:10:00 \\\n --partition=gpu \\\n --gres=gpu:2080:1 \\\n --pty bash -l"
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-7.html#learning-more-about-nodes",
    "href": "teaching/2023-2024/Programming Level-up/lecture-7.html#learning-more-about-nodes",
    "title": "Linux & Supercomputer",
    "section": "Learning more about nodes",
    "text": "Learning more about nodes\nTo understand what each compute node has we can use the scontrol command.\nscontrol show nodes\nWill list out all nodes and all capabilities of each node. Or just one node:\nscontrol show node lisnode2"
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-7.html#sbatch",
    "href": "teaching/2023-2024/Programming Level-up/lecture-7.html#sbatch",
    "title": "Linux & Supercomputer",
    "section": "sbatch",
    "text": "sbatch\nIt can be quite inconvenient to launch an interactive job to run some compute, and wait for the job to be allocated. If, instead, you have a long running experiment that you want to run without any intervention from you, you can use sbatch.\nSbatch will require us to write a small bash script that specifies how to run a job and what to do once its allocated.\n#!/bin/bash\n\n#SBATCH --time=00:01:00\n#SBATCH --job-name=my_new_job\n#SBATCH --output=my_new_job.out\n#SBATCH --error=my_new_job.err\n\necho $HOSTNAME\nAnd run it:\nsbatch my_job.sh\nNotice that instead of supplying options to sbatch, we can instead record them directly into the script using the #SBATCH. SLURM will examine this file, looking for lines starting with this comment, and infer that the rest of the line contains the options.\nThere are a few other options we’ve included that are very useful when running non-interactive jobs. Firstly, we’ve given the job a name (my_new_job). This is so we can different between many jobs that we might run at the same time. To list out the jobs we currently have running we use squeue.\nsqueue\nBy default, squeue will list all of the active jobs, even other peoples. To specify only your jobs user the --user option:\nsqueue --user=jay.morgan\nThe other two options, --output and --error specify where the printed output and printed errors will be stored. Since the job is being run on a different node, by a non-interactive process, if you didn’t include these lines, you wouldn’t be able to see what was being printed by echo or by any other process such as print in Python."
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-7.html#squeue",
    "href": "teaching/2023-2024/Programming Level-up/lecture-7.html#squeue",
    "title": "Linux & Supercomputer",
    "section": "squeue",
    "text": "squeue\nWhen we list the jobs using squeue it will give us multiple columns of information, such as:\n\nJOBID – the referable id of the job.\nPARTITION – the partition on which the job has been requested for.\nNAME – the name of the job.\nUSER – the user who submitted the job.\nST – the status, is the job currently running, waiting, or exiting?\nTIME – how long the job has been running for.\nNODES – how many nodes have been allocated to the job."
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-7.html#scontrol",
    "href": "teaching/2023-2024/Programming Level-up/lecture-7.html#scontrol",
    "title": "Linux & Supercomputer",
    "section": "scontrol",
    "text": "scontrol\nscontrol allows us to modify an existing job. For example, let us say that we have a job which we need to extend the time limit. Given that we know the job id (we could use squeue to find this), we can ask SLURM to update the time limit using:\nscontrol update jobid=&lt;job_id&gt; TimeLimit=&lt;new_timelimit&gt;"
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-7.html#scancel",
    "href": "teaching/2023-2024/Programming Level-up/lecture-7.html#scancel",
    "title": "Linux & Supercomputer",
    "section": "scancel",
    "text": "scancel\nLet’s say that we’ve submitted a job, but we’ve noticed that there was an error in the code, and want to stop the job. For that, we use scancel and specify the id of the job we wish to cancel:\nscancel 158590\nAfter running this command, we should see, using squeue, that either the job is finishing, or that its disappeared from our list (meaning that its completely stopped)."
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-7.html#sacct",
    "href": "teaching/2023-2024/Programming Level-up/lecture-7.html#sacct",
    "title": "Linux & Supercomputer",
    "section": "sacct",
    "text": "sacct\nIf our job has finished, or exited and is no longer in squeue, we can use sacct to get a history of the jobs.\nsacct will list all of your jobs within some default window of time. If we want to change this window we can use the --starttime and --endtime options.\nValid time formats are:\n\nHH:MM[:SS][AM|PM]\nMMDD[YY][-HH:MM[:SS]]\nMM.DD[.YY][-HH:MM[:SS]]\nMM/DD[/YY][-HH:MM[:SS]]\nYYYY-MM-DD[THH:MM[:SS]]\ntoday, midnight, noon, fika (3 PM), teatime (4 PM)\nnow[{+|-}count[seconds(default)|minutes|hours|days|weeks]]"
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-7.html#job-task-arrays-motivation",
    "href": "teaching/2023-2024/Programming Level-up/lecture-7.html#job-task-arrays-motivation",
    "title": "Linux & Supercomputer",
    "section": "Job Task Arrays – motivation",
    "text": "Job Task Arrays – motivation\nTask arrays allow you to submit many jobs of the same type. Why might this be useful? Suppose you have a list of files that take a long time to process:\n\nfile_0.txt\nfile_1.txt\nfile_2.txt\n\nOr you have some computation script, such as deep learning training script, that takes uses a hyperparameter which can be tuned to achieve different performance results:\npython train.py --learning-rate 0.001\nInstead of a creating a sbatch script for each value of hyperparameter, or sequentially enumerating the values, you can use a job task array to spawn multiple jobs with slightly different values."
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-7.html#job-task-arrays-how-to",
    "href": "teaching/2023-2024/Programming Level-up/lecture-7.html#job-task-arrays-how-to",
    "title": "Linux & Supercomputer",
    "section": "Job Task Arrays – how to",
    "text": "Job Task Arrays – how to\nFirst, we will look at how to actually submit an array of tasks. To create an task array, you will need to add the --array options to your sbatch script:\n#!/bin/bash\n\n#SBATCH --job-name=my_task_array\n#SBATCH --array=1-5\n\n...\nHere we are creating an array of tasks numbered from 1-5. When you submit this script, you will see five tasks submitted to the queue.\nNow that we know how to create an array of tasks, we will want to do something useful with it. When you create an array, each individual task will have a unique variable called SLURM_ARRAY_TASK_ID. So for example, if we launch an array of 5 tasks, the first task will have the value 1. Why is this useful? Well, we can use this variable to alter the program slightly. Take for example our list of files we need to process:\n#!/bin/bash\n#SBATCH --job-name=my_task_array\n#SBATCH --array=0-4\n#SBATCH --time=00:10:00\n\nFILENAME=\"file_${SLURM_ARRAY_TASK_ID}.txt\"\npython process.py $FILENAME\nThis will create a new bash variable called FILENAME by concatenating file_ the current task’s (i.e. 0, for the first task, 1 for the second task, etc) and .txt.\nIf we run the previous example, we will see that we have five jobs named exactly the same thing my_task_array. This is okay, but we can be a little bit more clear as to which task is running, i.e. which task is processing which file?\nWe can use some special variables in our bash script to make this more clear. These are %A that is the main job id, and %a that is the task array id.\n#!/bin/bash\n\n#SBATCH --error=my_task_array.%A_%a.out\n#SBATCH --output=my_task_array.%A_%a.out\n...\nNow, every task in our array will have a slightly different name because of the %a and therefore we will be able to determine which job is processing which file.\nLet’s move on to the second example, where we have a Deep Learning training program and we want to try different parameters. In this case, we can again use a task array.\n#!/bin/bash\n\n#SBATCH --array=1-10\nWe could either pass the SLURM_ARRAY_TASK_ID as a command line argument to the script:\npython training.py --learning-rate $SLURM_ARRAY_TASK_ID\nBut in this case, we could have to properly calculate the correct learning rate from the SLURM_ARRAY_TASK_ID value (remember that in my sbatch script I set --array=1-5). But bash only performs integer arithmetic, therefore we will need to calculate the correct learning rate in something else.\nInstead of passing the learning rate via a command line argument. We can get the value directly from our python script and calculate the value.\nimport os\n\ntask_id = int(os.environ[\"SLURM_ARRAY_TASK_ID\"])\nlearning_rate = task_id / 100\nHere we are using the builtin os module in Python, getting the environment variable from the dictionary environ and parsing the value as an integer. Then we can calculate the appropriate learning rate using this value. So for example, if SLURM_ARRAY_TASK_ID is set to 1. Our learning rate would be 0.01 for this task.\nIf you’re creating a job task array, you may want to create hundreds of jobs. And of course, you don’t want to use up the entire cluster leaving no resources for anybody else! Therefore, you will only want a maximum number of tasks to run at any one time.\n#!/bin/bash\n\n#SBATCH --array=1-100%5\nThis will create a job task array of 100 jobs numbered from 1 to 100. But we have added an additional argument %5 which means that only 5 jobs can run at any one time for this task array. If you have five tasks running, the other 95 tasks will wait.\nIf, at any point, you want to change how many jobs can run simultaineously, you can update this ‘throttle’ value using scontrol:\nscontrol update ArrayTaskThrottle=&lt;count&gt; JobId=&lt;jobID&gt;\nSo if we’ve already launched a job task array with the job id of 50602 that has a throttle value of 5 (only 5 tasks will run at once), we can change it to 10 using:\nscontrol update ArrayTaskThrottle=10 JobId=50602"
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-7.html#a-guided-walk-through-environment",
    "href": "teaching/2023-2024/Programming Level-up/lecture-7.html#a-guided-walk-through-environment",
    "title": "Linux & Supercomputer",
    "section": "A guided walk through – environment",
    "text": "A guided walk through – environment\nIn this section we’re going to give an example walk through of working with the HPC cluster. In this example, we’re going to write our scripts locally, including the slurm submission script, and when they’re ready, we’ll send them to the cluster to perform the actual computation.\nLet’s imagine we’re starting a new project, and are programming our scripts in Python. Now is a good time to create a new conda environment to install our packages we’re going to use for our research. We’ll create this environment with (replacing &lt;env-name&gt; with whatever we want to call this environment):\nconda create --name &lt;env-name&gt;\nand then activate it:\nconda activate &lt;env-name&gt;\nconda install python=3.9"
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-7.html#writing-our-scripts",
    "href": "teaching/2023-2024/Programming Level-up/lecture-7.html#writing-our-scripts",
    "title": "Linux & Supercomputer",
    "section": "Writing our scripts",
    "text": "Writing our scripts\nLet us also image we’ve just wrote the following script to create a lorenz attractor: lorenz.py\nThe specific implementation of this script is not particularly important for this walk through. Just know that we’re importing a few packages such as numpy and matplotlib. Then, we’re performing some computation, and saving the results to analyse later. As this script uses external libraries, we need to install them:\nconda install numpy matplotlib"
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-7.html#writing-our-job-submission-script",
    "href": "teaching/2023-2024/Programming Level-up/lecture-7.html#writing-our-job-submission-script",
    "title": "Linux & Supercomputer",
    "section": "Writing our job submission script",
    "text": "Writing our job submission script\nSince we want our calculations to be performed on the cluster, we will need to also write a job submission script (let’s call this submit-job.sh) in bash to pass to SLURM.\n#!/bin/bash\n\n#SBATCH --job-name=lorenz_attractor\n#SBATCH --output=lorenz_attractor.log\n#SBATCH --error=lorenz_attractor.log\n#SBATCH --time=00:10:00\n\npython lorenz.py"
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-7.html#replicating-our-environment-on-the-cluster",
    "href": "teaching/2023-2024/Programming Level-up/lecture-7.html#replicating-our-environment-on-the-cluster",
    "title": "Linux & Supercomputer",
    "section": "Replicating our environment on the cluster",
    "text": "Replicating our environment on the cluster\nAs we’ve installed external packages in our local development environment, we will want to ensure that when we run the calculations on the cluster, it will be using the same versions of packages. Conda makes this a lot easier. First, we export our environment to a recipe file:\nconda env export --no-builds &gt; environment.yml"
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-7.html#sending-our-scripts-to-the-cluster",
    "href": "teaching/2023-2024/Programming Level-up/lecture-7.html#sending-our-scripts-to-the-cluster",
    "title": "Linux & Supercomputer",
    "section": "Sending our scripts to the cluster",
    "text": "Sending our scripts to the cluster\nAll of our scripts are ready! We can now transfer them from our personal computer, to the cluster. The files we need to transfer are:\n\nlorenz.py\nenvironment.yml\nsubmit-job.sh\n\nWhile we can send a folder (and the containing files), let’s send them one at a time:\nscp lorenz.py &lt;hostname&gt;:&lt;destination-path&gt;\nscp environment.yml &lt;hostname&gt;:&lt;destination-path&gt;\nscp submit-job.sh &lt;hostname&gt;:&lt;destination-path&gt;\nwhere &lt;hostname&gt; is the hostname/IP address that you’ve used to connect to the login node on the cluster before. &lt;destination-path&gt; is the path to where you want to save the files."
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-7.html#logging-into-the-cluster",
    "href": "teaching/2023-2024/Programming Level-up/lecture-7.html#logging-into-the-cluster",
    "title": "Linux & Supercomputer",
    "section": "Logging into the cluster",
    "text": "Logging into the cluster\nNow that our files are on the cluster, we can login:\nssh &lt;username&gt;@&lt;hostname&gt;\nAt which point, we’ve logged into the login node, and then we need to change directory to where we saved the files:\ncd &lt;destination-path&gt;"
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-7.html#re-creating-our-development-environment",
    "href": "teaching/2023-2024/Programming Level-up/lecture-7.html#re-creating-our-development-environment",
    "title": "Linux & Supercomputer",
    "section": "Re-creating our development environment",
    "text": "Re-creating our development environment\nNow that we’re in the same folder as our scripts, we’re almost ready to submit our job. First, we need to recreate our development environment from our environment.yml file.\nconda env create -f environment.yml\nAnd activate our newly created environment:\nconda activate &lt;env-name&gt;"
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-7.html#submitting-our-job",
    "href": "teaching/2023-2024/Programming Level-up/lecture-7.html#submitting-our-job",
    "title": "Linux & Supercomputer",
    "section": "Submitting our job",
    "text": "Submitting our job\nNow we can submit our job:\nsbatch submit-job.sh\nWe can check the progress of our job with squeue, or its already completed, look at the job history with sacct."
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-7.html#downloading-the-results",
    "href": "teaching/2023-2024/Programming Level-up/lecture-7.html#downloading-the-results",
    "title": "Linux & Supercomputer",
    "section": "Downloading the results",
    "text": "Downloading the results\nIf our job runs successfully, a data.pkl file will be created. Back on our local computers, we will need to run the following to download it:\nscp &lt;hostname&gt;:&lt;destination-path&gt;/data.pkl ./\nThis will download the file into the current directory."
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-7.html#analysing-the-results",
    "href": "teaching/2023-2024/Programming Level-up/lecture-7.html#analysing-the-results",
    "title": "Linux & Supercomputer",
    "section": "Analysing the results",
    "text": "Analysing the results\nWith the data.pkl file downloaded, we can visualise the results using plot_lorenz.py: https://pageperso.lis-lab.fr/jay.morgan/resources/2021-programming-level-up/lectures/week-5/plot-lorenz.py\nIf everything has been run correctly, you should see a plot of the lorenz attractor."
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-7.html#useful-features-x11-forwarding",
    "href": "teaching/2023-2024/Programming Level-up/lecture-7.html#useful-features-x11-forwarding",
    "title": "Linux & Supercomputer",
    "section": "Useful features – X11 Forwarding",
    "text": "Useful features – X11 Forwarding\nIf we’re performing analysis interactively using the cluster, we’ll often want to visualise the results, using matplotlib for example. To see our plots display like they would on our local machine when we call plt.plot or plt.show(), we will need to ensure that we’re using something called X11 Forwarding. To enable X11 Forwarding, we use the -X option when ssh‘ing into the cluster and compute nodes (i.e. it will need to be enabled on every ’hop’ so to speak).\nssh -X &lt;&lt;remote-host&gt;&gt;\nIf want to enable it by default, we can enable it in our ssh config file:\nHost cluster\n HostName sms-ext.lis-lab.fr\n FowardX11 yes\n User &lt;&lt;username&gt;&gt;\nAfter setting up X11 Forwarding correctly, and when logged into the remote host, we should be able to echo a variable called $DISPLAY.\necho $DISPLAY\nIf $DISPLAY has a value, we know that X11 Forwarding has been setup correctly, and we’re ready to do some plotting!"
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-7.html#useful-features-jupyter-notebooks",
    "href": "teaching/2023-2024/Programming Level-up/lecture-7.html#useful-features-jupyter-notebooks",
    "title": "Linux & Supercomputer",
    "section": "Useful features – Jupyter Notebooks",
    "text": "Useful features – Jupyter Notebooks\nWe’ve talked about how good jupyter notebooks are for performing analysis and exploration. But often times, we will need a lot of compute resources (more than our local computers can handle) to do this analysis. This is where using jupyter notebook on the supercomputers comes in handy. However, it is not as simple as starting the jupyter notebook server and opening up your web browser. First, we will need to setup a ‘reverse ssh tunnel’.\nIn a nut-shell, a reverse ssh tunnel allows you to redirect data on a remote port to a local port.\nTherefore, we can, using a reverse ssh tunnel, start a jupyter notebook on the supercomputer and access it using the web browser on our local computer!\nTo begin, we can create an interactive job on the cluster:\nsrun --time=01:00:00 --pty bash -l\nAnd start our jupyter notebook, specifying a port that will not be in use:\njupyter notebook --port 30333\nWith our notebook server now started on the 30333 port, we will want to create an ssh tunnel from our local computer, to the cluster’s login node, and then a tunnel from the login node to the specific compute node where the job is running:\nssh -L 30333:localhost:30333 &lt;&lt;cluster-login-node&gt;&gt; ssh -L 30333:localhost:30333 &lt;&lt;cluster-compute-node&gt;&gt;\nIf everything goes well, we should now be able to open up our web browser, navigate to localhost:30333 and see our jupyter notebooks."
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-7-reveal.html#what-is-linux",
    "href": "teaching/2023-2024/Programming Level-up/lecture-7-reveal.html#what-is-linux",
    "title": "Linux & Supercomputer",
    "section": "What is Linux?",
    "text": "What is Linux?\n\nLinux is a popular operating system (OS) like Windows, or MacOS.\nUnlike these other two OSs, Linux is open source, which means the source code is freely available to look at and modify.\nAs its open source, its very possible for anyone to build their own version of Linux or build on top of Linux to create their own Distribution of Linux."
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-7-reveal.html#whats-a-distribution",
    "href": "teaching/2023-2024/Programming Level-up/lecture-7-reveal.html#whats-a-distribution",
    "title": "Linux & Supercomputer",
    "section": "What’s a Distribution?",
    "text": "What’s a Distribution?\nA distribution can be considered like a flavour or version of Linux. There are many popular flavours that attempt to meet different needs from different users. For example:\n\nUbuntu – typically the first Linux experience people will have. Attempts to be very user friendly.\nFedora – stable and secure distribution while also providing up-to-date packages.\nArch Linux – strong focus on customisability rather than user friendliness with bleeding edge packages."
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-7-reveal.html#defining-traits-of-linux",
    "href": "teaching/2023-2024/Programming Level-up/lecture-7-reveal.html#defining-traits-of-linux",
    "title": "Linux & Supercomputer",
    "section": "Defining Traits of Linux",
    "text": "Defining Traits of Linux\nWhile we have said that Linux is open source, there are many other traits that make it stand out from other operating systems:\n\nComplete control of how the system operates.\nThe level of flexibility and automation that you can get from using the Linux command line.\n\nWhile there are many other traits, these two are going to be what we’re going to focus on."
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-7-reveal.html#whats-a-command",
    "href": "teaching/2023-2024/Programming Level-up/lecture-7-reveal.html#whats-a-command",
    "title": "Linux & Supercomputer",
    "section": "What’s a command?",
    "text": "What’s a command?\nWhile many recent versions of Linux makes things more accessible via GUIs, they will never be a substitute for using the command line. We’re going to learn how to control the system via the command line, via a shell. A shell, like the Python REPL we’ve already seen, is waits for you to input commands, executes the command, and prints the output if there is output to print.\nA Linux command is a call to a program optionally followed by some arguments. For example, if we want list out the files and folders in the directory, we would use the ls (list) command:\nls\nThe ls command comes with a number of optional flags and arguments that we can add onto the call. When calling a command a flag is something that begins with a - , for example -l tells ls to list the directory in a list format.\nls -l\nWe have supplied the -l flag. There are many other flags for ls, like for example, the human readable file systems with -h or show hidden files (files that start with a period) with -a.\nWhen we’re using multiple flags we could write\nls -l -h -a\nOr:\nls -lha\nSometimes commands take optional positional arguments. Going back to our list directory command, where, by default, it will list the current directory. But instead we can tell the command to list a particular directory by supplying the path as an argument\nls images/ -lha\n# or ls -lha images/ works too\nHow do I know how to use a command? Well that’s where another command comes in. It’s called man (short for manual). If you pass another command to the man command, the documentation will be shown in the terminal, e.g.:\nman ls  # display the documentation for ls\nThe documentation should list all the different flags and arguments, describe what they mean, and sometimes give example or most common usage of a command.\nWhen the ‘man page’ is display, you can scroll up and down the page using your arrow keys, and page-up and page-down. When you’re done reading, just hit the ‘q’ character\nI am going to go through some of the most common commands just to make sure that you’re familiar with the typical usage."
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-7-reveal.html#cd",
    "href": "teaching/2023-2024/Programming Level-up/lecture-7-reveal.html#cd",
    "title": "Linux & Supercomputer",
    "section": "cd",
    "text": "cd\nWe’ve already seen ls to list a directory. The command to move to a directory is cd (change directory), that takes an argument of filepath to move to:\ncd ~ # tilde is short-hand for the 'home directory'\ncd ~/Documents/My\\ Files  # go to Documents and then to \"My Files\"\ncd   # no argument, by default goes to the home directory"
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-7-reveal.html#mkdir",
    "href": "teaching/2023-2024/Programming Level-up/lecture-7-reveal.html#mkdir",
    "title": "Linux & Supercomputer",
    "section": "mkdir",
    "text": "mkdir\nSticking with the them of directories, to make a new directory we use mkdir, whose argument takes the name of the directory we want to create:\nmkdir my_new_directory\nYou can create a many level nested directory structure all at once using the -p (parents) flag, that tells mkdir if the parent directory of the target directory doesn’t exist, create it.\nmkdir photos/2020/01/05  # won't work unless photos/2020/01 exist\nmkdir -p photos/2020/01/05  # this will work"
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-7-reveal.html#cp",
    "href": "teaching/2023-2024/Programming Level-up/lecture-7-reveal.html#cp",
    "title": "Linux & Supercomputer",
    "section": "cp",
    "text": "cp\nTo copy a file or directory, we can use the cp command. Here we are copying a file, where the first argument is the filepath of the file you want to copy and the second argument is the filepath where the copy should be placed.\ncp my_old_file my_new_file\nBy default (without a flag), cp will not work with directories, for that you have to use the -r (recursive) flag\ncp -r data/ data-backup"
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-7-reveal.html#mv",
    "href": "teaching/2023-2024/Programming Level-up/lecture-7-reveal.html#mv",
    "title": "Linux & Supercomputer",
    "section": "mv",
    "text": "mv\nThe syntax of moving a file is similar to that of cp:\nmv old_file new_file\nExcept that it works for both files and directories without any flags. mv can also be used to rename files, that’s all renaming is: moving a file to the same directory under a different name."
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-7-reveal.html#rm",
    "href": "teaching/2023-2024/Programming Level-up/lecture-7-reveal.html#rm",
    "title": "Linux & Supercomputer",
    "section": "rm",
    "text": "rm\nTo remove a file us rm:\nrm file_to_delete\nIf you want to delete a directory, use the -r (recursive) flag:\nrm -r directory_to_delete/"
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-7-reveal.html#cat",
    "href": "teaching/2023-2024/Programming Level-up/lecture-7-reveal.html#cat",
    "title": "Linux & Supercomputer",
    "section": "cat",
    "text": "cat\ncat stands for concatenate, i.e. concatenating the contents of two or more files:\ncat file1 file2\nThe result is that the concatenation of these two files will be printed to the screen. If you wanted to put the result into its own file you would redirect the output using &gt;\ncat file1 file2 &gt; newfile\nSince cat reads the file and prints it to screen it is a very handy way to view the contents of a file, even if it was not intended for that."
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-7-reveal.html#pwd",
    "href": "teaching/2023-2024/Programming Level-up/lecture-7-reveal.html#pwd",
    "title": "Linux & Supercomputer",
    "section": "pwd",
    "text": "pwd\nSometimes you may get lost when moving directories. pwd prints the current working directory from the root directory, i.e. the path that is printed is an absolute path.\npwd"
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-7-reveal.html#find",
    "href": "teaching/2023-2024/Programming Level-up/lecture-7-reveal.html#find",
    "title": "Linux & Supercomputer",
    "section": "find",
    "text": "find\nIf we want to list all files of a certain type, we can use the wildcard * that we’ve seen before:\nls *.jpg # list all files that end with .jpg\nHowever, this will only list for the current directory. Perhaps the better way to find files will be using the find command:\nfind . -type f -name *.jpg\nThe first argument is the directory to start the search, then we define the type f being files, and then specify the name. Find will recursively search through directories and sub-directories to find all files that match that name."
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-7-reveal.html#grep",
    "href": "teaching/2023-2024/Programming Level-up/lecture-7-reveal.html#grep",
    "title": "Linux & Supercomputer",
    "section": "grep",
    "text": "grep\nHow about if we want to find files that have a certain contents? For that we can use grep. Grep will read a file and print (by default) the lines that contains your pattern. i.e.:\ngrep 'Linux' lecture.org\nThis will print the lines that contain the word Linux in lecture.org. If we just want the matched value, we use the -o flag.\ngrep -o '[0-9]' lecture.org\nThis prints all occurrences of numbers in lecture.org"
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-7-reveal.html#lessheadtail",
    "href": "teaching/2023-2024/Programming Level-up/lecture-7-reveal.html#lessheadtail",
    "title": "Linux & Supercomputer",
    "section": "less/head/tail",
    "text": "less/head/tail\nIf a file is very long, we may not want to read the file using cat, as it will have to print the entire file. Instead we could use less, which will allow us to navigate through the file, using arrow keys to move and q to quit.\nless filename\nIf we just want to view the first few lines, or the last few lines of a file we can use head/tail, respectively:\nhead filename\ntail -n 20 filename  # last 20 lines\ntail -F filename # constantly read the file"
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-7-reveal.html#wc",
    "href": "teaching/2023-2024/Programming Level-up/lecture-7-reveal.html#wc",
    "title": "Linux & Supercomputer",
    "section": "wc",
    "text": "wc\nOften times we just want to count the number of something. For example, if we want to count the number of files/folders in the directory we can do:\nls -l | wc -l\nWe’re first printing all files and folders in a list format (one per line), then passing (piping_) the result to wc, which with the -l line flag, is counting the number of lines. Therefore we get a count of the number of files and folders. Here is another example where we’re counting how many times the word bash appears in these lecture notes:\ngrep -o 'bash' lecture.org | wc -l"
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-7-reveal.html#piping",
    "href": "teaching/2023-2024/Programming Level-up/lecture-7-reveal.html#piping",
    "title": "Linux & Supercomputer",
    "section": "piping",
    "text": "piping\nThe purpose of piping is to pass data around between commands. We have just seen how we can pass the output of, say, the ls command to the input of wc. This allows use to construct very sophisticated pipelines to do some quite complex things from the combination of very simple commands.\nfind . -name '*.txt' -type f -print0 | xargs -0 grep \"something\""
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-7-reveal.html#overview",
    "href": "teaching/2023-2024/Programming Level-up/lecture-7-reveal.html#overview",
    "title": "Linux & Supercomputer",
    "section": "Overview",
    "text": "Overview\nIn summary we have seen the following commands:\n\nls - List a directory\ncd - Change/move to a directory\nmkdir - Make a new directory\ncat - Concatenate files\ncp - Copy a file/directory\nmv - Move files/folders\nrm - Remove files and folders\npwd - Display the current absolute path\nfind - Find files\ngrep - Find occurrences of a pattern in a file\nless/head/tail - Read a file\nwc - Count"
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-7-reveal.html#your-very-first-bash-script",
    "href": "teaching/2023-2024/Programming Level-up/lecture-7-reveal.html#your-very-first-bash-script",
    "title": "Linux & Supercomputer",
    "section": "Your Very first bash script",
    "text": "Your Very first bash script\nLet’s start with the classic ‘Hello, World’ example. We’ll create a new file called ‘hello.sh’ and enter the following:\n#!/bin/bash\n\necho \"Hello, World!\"\nFirst thing to notice is that the first line contains what we call a ‘shebang’ or ‘hashbang’. It tells Linux which shell interpreter will be used to run the script, in this case: /bin/bash\nThe next (non-empty) line in the file is echo 'Hello, World'. This is exactly the same as the other commands we’ve just seen.\nNow that we’ve created and saved our bash script, we will want to run it. We have two alternative methods to run this script:\nbash hello.sh  # run the script via bash\nThe second, requires that we have executable privileges for the script:\nchmod +x hello.sh  # add executable 'x' privileges\n./hello.sh  # execute it"
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-7-reveal.html#variables",
    "href": "teaching/2023-2024/Programming Level-up/lecture-7-reveal.html#variables",
    "title": "Linux & Supercomputer",
    "section": "Variables",
    "text": "Variables\nThe variables we create in our bash scripts are very much the same as the environment variables we’ve seen before. Take for example:\n#!/bin/bash\nAGE=\"35\"\nPERSON_NAME=\"Jane\"\necho \"$PERSON_NAME is $AGE years old\"\nWe create a variable AGE with the = assignment operator. Note we don’t put spaces either side of the equals sign in bash. To refer to the variable, we use $AGE, using the $ dollar sign."
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-7-reveal.html#interpolation-in-bash-strings",
    "href": "teaching/2023-2024/Programming Level-up/lecture-7-reveal.html#interpolation-in-bash-strings",
    "title": "Linux & Supercomputer",
    "section": "Interpolation in bash strings",
    "text": "Interpolation in bash strings\nYou would have noticed in the previous example that we included the variable directly into the string we’re echoing out. This is something similar to what we’ve seen with f-strings in Python.\nWhen we use double quotes: \"...\" in bash, the variable will be integrated into the resulting string. We can even call bash functions from directly inside the string:\necho \"I am logging in as: $(who)\""
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-7-reveal.html#bash-strings-the-sharp-edges",
    "href": "teaching/2023-2024/Programming Level-up/lecture-7-reveal.html#bash-strings-the-sharp-edges",
    "title": "Linux & Supercomputer",
    "section": "Bash strings – the sharp edges",
    "text": "Bash strings – the sharp edges\nYou might be tempted to use a variable when generating a path:\nTRAIN_PROCESS=\"training\"\nTEST_PROCESS=\"testing\"\n\ntouch \"./data/$TRAIN_PROCESS_error.txt\"\ntouch \"./data/$TEST_PROCESS_error.txt\nBut this will create an error as underscores can be part of the variable name, so bash will be looking for a variable named: $TRAIN_PROCESS_error which has never been created. To get around this, we can wrap our variable in curly braces:\ntouch \"./data/${TRAIN_PROCESS}_error.txt\""
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-7-reveal.html#stopping-interpolation-in-bash-strings",
    "href": "teaching/2023-2024/Programming Level-up/lecture-7-reveal.html#stopping-interpolation-in-bash-strings",
    "title": "Linux & Supercomputer",
    "section": "Stopping interpolation in bash strings",
    "text": "Stopping interpolation in bash strings\nWe can also use single quotes for strings in bash. When we use these strings, the string itself is not interpreted, and thus it will ignore any variables or bash commands:\necho 'I am logging in as: $(who)'"
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-7-reveal.html#inputoutput",
    "href": "teaching/2023-2024/Programming Level-up/lecture-7-reveal.html#inputoutput",
    "title": "Linux & Supercomputer",
    "section": "Input/Output",
    "text": "Input/Output\nIf we want to read the input from keyboard into a variable, we use the read command:\n#!/bin/bash\n\necho \"Enter your name:\"\nread NAME\n\necho \"Hello, $NAME\"\nread in this context will read in the input and create the variable with that value. As we’ve already seen, we can then output this value to the console using the echo command."
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-7-reveal.html#booleans",
    "href": "teaching/2023-2024/Programming Level-up/lecture-7-reveal.html#booleans",
    "title": "Linux & Supercomputer",
    "section": "Booleans",
    "text": "Booleans\nTechnically, bash does not have built in data types for true and false, but Linux has the commands true and false which we could use in place. The implementation of how these commands work is not important.\nFILE_EXISTS=true\n\nif [ \"$FILE_EXISTS\" = true ]; then\necho \"The file exists!\"\nfi"
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-7-reveal.html#conditionals",
    "href": "teaching/2023-2024/Programming Level-up/lecture-7-reveal.html#conditionals",
    "title": "Linux & Supercomputer",
    "section": "Conditionals",
    "text": "Conditionals\nWhen we’re creating if expressions, we use the following syntax:\nif &lt;&lt;conditional&gt;&gt;; then\n   # do something\nelse\n   # do something else\nfi\nWe can also use elif\nif &lt;&lt;conditional&gt;&gt;; then\n   # do something\nelif &lt;&lt;conditional&gt;&gt;; then\n   # do something else\nelse\n   # something else entirely\nfi\nWriting condition expressions can be a little more cumbersome than in Python. These can be many pain points for new bash programmers, take for example:\nFILE_EXISTS=false\n\nif [ $FILE_EXISTS ]; then\necho \"The file exists!\"\nfi\nThis is because we have used the [...] single bracket syntax for the test. But there are others:\n\nNo brackets: we could omit the brackets in which case it would run the false command not print the statement.\nSingle paranthesis (...) creates a sub-shell.\nDouble paranthesis ((...)) for arithmetic operation\nSingle square bracket [...] calls test\nDouble square bracket [[...]]\n\nWhat if we write:\nVAR_1=\"Mr Foo Bar\"\nVAR_2=\"Mr Foo Bar\"\nif [ $VAR_1 = $VAR_2 ]; then\necho \"They are the same\"\nfi\nWe would get an error because test expands the arguments into:\nMr Foo Bar = Mr Foo Bar\nWith the spaces included. To prevent this from happening, we have to wrap the variables in quotation marks.\nVAR_1=\"Mr Foo Bar\"\nVAR_2=\"Mr Foo Bar\"\nif [ \"$VAR_1\" = \"$VAR_2\" ]; then\necho \"They are the same\"\nfi\nIf we use [[ in if statement, then we can do more sophisticated things like pattern matching:\nFILENAME=\"testing.png\"\nif [[ \"$FILENAME\" = *.png ]]; then\necho \"Its a png file\"\nfi"
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-7-reveal.html#loops",
    "href": "teaching/2023-2024/Programming Level-up/lecture-7-reveal.html#loops",
    "title": "Linux & Supercomputer",
    "section": "Loops",
    "text": "Loops\nLike in Python, we can iterate in bash\nfor i in {1..10}; do\necho $i\ndone\nThis iterates with i starting at 1 upto 10 (inclusive). Or we could do:\nfor (( i=1; i &lt;= 10; i++ )); do\necho $i\ndone\nWe can also iterate over a list of files/folders in a directory:\nfor FILE in ./images/*; do\necho $FILE\ndone\nUsing the while form, we can continue looping until our conditional is false. For example, we could loop testing our internet connection, until its been established:\nwhile ! ping -c 1 google.com; do\necho \"No internet yet\"\nsleep 1\ndone\n\necho \"Internet is available!\""
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-7-reveal.html#functions",
    "href": "teaching/2023-2024/Programming Level-up/lecture-7-reveal.html#functions",
    "title": "Linux & Supercomputer",
    "section": "Functions",
    "text": "Functions\nTo create a function, we use the following syntax:\nfunction_name() {\n# do something\n}\nAnd to call the function, you just need to use the function name:\nfunction_name # this called function name\nHere is another example:\nsay_hello() {\necho \"Hello, $1\"\n}\n\nsay_hello \"Jane\"\nNotice that we didn’t need to include any argument list. We just used $1 for the first argument passed to the function.\nsay_hello() {\necho \"$1, $2\"\n}\n\nsay_hello \"Hi\" \"Jane\"\nReturning values is ‘interesting’ as, coming from other languages, you think could do something like this:\nsay_hello() {\nreturn \"hello\"\n}\nRESULT=\"$(say_hello)\"\necho $RESULT\nThis didn’t work like we expected, the value wasn’t returned and assigned to RESULT. So how do we return a value?\nsay_hello() {\necho \"Hello\"\n}\nRESULT=\"$(say_hello)\"\necho \"This is before the printing of result\"\necho $RESULT"
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-7-reveal.html#how-to-login",
    "href": "teaching/2023-2024/Programming Level-up/lecture-7-reveal.html#how-to-login",
    "title": "Linux & Supercomputer",
    "section": "How to login",
    "text": "How to login\nssh &lt;&lt;username&gt;&gt;@sms-ext.lis-lab.fr\nTyping this command can become tiresome very quickly, especially after sending data back and forth. But we can make it a lot easier by updating our ~/.ssh/config file to include something like:\nHost cluster\n HostName sms-ext.lis-lab.fr\n User &lt;&lt;username&gt;&gt;\nThen to login to the cluster, we just need to type:\nssh cluster\nAnd we should be prompted for our password."
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-7-reveal.html#how-to-login-1",
    "href": "teaching/2023-2024/Programming Level-up/lecture-7-reveal.html#how-to-login-1",
    "title": "Linux & Supercomputer",
    "section": "How to login",
    "text": "How to login\nIf you trust the machine your on, you can remove password authentication and move to key-based authentication:\nssh-copy-id cluster\nWhen we next login to the server, we shouldn’t be prompted for a password."
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-7-reveal.html#how-to-copy-files-to-and-from-the-cluster",
    "href": "teaching/2023-2024/Programming Level-up/lecture-7-reveal.html#how-to-copy-files-to-and-from-the-cluster",
    "title": "Linux & Supercomputer",
    "section": "How to copy files to and from the cluster",
    "text": "How to copy files to and from the cluster\nWe have a number of options for transferring files to and from the cluster. Firstly, let’s look at the command scp. It takes two arguments, the first argument is the file you want to send, the second argument is the destination of the sent file.\nscp &lt;&lt;origin&gt;&gt; &lt;&lt;destination&gt;&gt;\nSimilar to commands like cp, scp by default only works for files, not folders. To send folders/directories, we use the -r flag just like cp.\nscp -r &lt;&lt;origin_folder&gt;&gt; &lt;&lt;destination_folder&gt;&gt;"
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-7-reveal.html#copying-files-rsync",
    "href": "teaching/2023-2024/Programming Level-up/lecture-7-reveal.html#copying-files-rsync",
    "title": "Linux & Supercomputer",
    "section": "Copying files – rsync",
    "text": "Copying files – rsync\nOne of the downsides about scp is that it will copy every file you give it. Even if the file at the destination is exactly the same. What if we only want to copy files that need to be copied, i.e. that are outdated, thus saving time? For that, we can use rsync. Rsync will copy files from one source to a destination only if the destination needs to be updated. This can save a lot of time by skipping files that already exist at the destination:\nrsync &lt;&lt;source&gt;&gt; &lt;&lt;destination&gt;&gt;"
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-7-reveal.html#the-login--and-compute-nodes",
    "href": "teaching/2023-2024/Programming Level-up/lecture-7-reveal.html#the-login--and-compute-nodes",
    "title": "Linux & Supercomputer",
    "section": "The Login- and Compute Nodes",
    "text": "The Login- and Compute Nodes\nWhen you login to the cluster, you are logging into the login node. Note that no computation should be run on this node. If you want to run scripts, you will have to submit a job to the compute nodes.\nOn the login node there is a system installed called ‘SLURM’. SLURM is a job scheduler program that receives your requests for executing scripts, it will queue them and assign them to available compute nodes.\nWe will take a look at how to request and manage jobs using the various commands that SLURM provides."
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-7-reveal.html#how-to-launch-a-job-srun",
    "href": "teaching/2023-2024/Programming Level-up/lecture-7-reveal.html#how-to-launch-a-job-srun",
    "title": "Linux & Supercomputer",
    "section": "How to launch a job – srun",
    "text": "How to launch a job – srun\nThe first command we will look at it is srun. This command will run request a job for execution in ‘real-time’. By real-time, we mean that the shell will wait until the job has been submitted.\nsrun &lt;&lt;compute node options&gt;&gt; &lt;&lt;command to run&gt;&gt;\nLet’s take a look at an example where we want to run an interactive bash shell on the compute shell (similar to ssh’ing into the compute node).\nsrun --time=00:10:00 --pty bash -l\nThis will request a job on any available compute node for 10 minutes. When a node becomes available, bash will execute, dropping you into the shell. You will notice that the shell prompt has changed from sms to the name of the node."
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-7-reveal.html#salloc",
    "href": "teaching/2023-2024/Programming Level-up/lecture-7-reveal.html#salloc",
    "title": "Linux & Supercomputer",
    "section": "salloc",
    "text": "salloc\nThere is another method we can use to create an interactive job. We could use the salloc command to allocate resources for a task. After the resources have been allocated and our job is ready, we can ssh into the node with the allocated resources.\nsalloc --time=10:00:00 &\nssh &lt;name&gt;"
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-7-reveal.html#options",
    "href": "teaching/2023-2024/Programming Level-up/lecture-7-reveal.html#options",
    "title": "Linux & Supercomputer",
    "section": "options",
    "text": "options\nIn the previous command, we used the --time option to specify how long the job will run for. But there are other options we can use to be more specific about the jobs we want to run.\n--cpus-per-task can be used to request more than one CPU to be allocated. This is especially helpful when we have a multithreaded process we want to run.\n--mem specifies how much memory should be allocated to the job. For example: --mem=16G tells SLURM to allocate 16 GB of memory."
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-7-reveal.html#gpu-allocation",
    "href": "teaching/2023-2024/Programming Level-up/lecture-7-reveal.html#gpu-allocation",
    "title": "Linux & Supercomputer",
    "section": "GPU allocation",
    "text": "GPU allocation\nIf we need to use a GPU, we need to use a few options. Firstly, we can specify that our job is on a compute node with GPU. There will usually be a group of nodes in a ‘GPU’ group or partition, and thus we can specify to use one of these partitions:\nsrun --time=00:10:00 --partiton=gpu --pty bash -l\nBut you will notice that you still do not have access to a GPU. You’re running on the GPU node, but you haven’t actually requested a GPU be allocated to your job. For that you will use --gres:\nsrun --time=00:10:00 --partition=gpu --gres=gpu:1 --pty bash -l\nHere we are requesting one GPU, but if we use --gres:gpu:2 we are requesting 2 GPUs etc.\nThere are many different types of GPUs available, some older than others. If you wanted to allocate a job with a specific type of GPU you can use the --constraint flag:\nsrun --time=00:10:00 \\\n --partition=gpu \\\n --gres=gpu:1 \\\n --constraint='cuda61' \\\n --pty bash -l\nThis command requests that our job run on the GPU partition, with 1 GPU allocated that has the capability of running CUDA compute 61.\nOr we can specify the type of GPU in the gres option:\nsrun --time=00:10:00 \\\n --partition=gpu \\\n --gres=gpu:2080:1 \\\n --pty bash -l"
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-7-reveal.html#learning-more-about-nodes",
    "href": "teaching/2023-2024/Programming Level-up/lecture-7-reveal.html#learning-more-about-nodes",
    "title": "Linux & Supercomputer",
    "section": "Learning more about nodes",
    "text": "Learning more about nodes\nTo understand what each compute node has we can use the scontrol command.\nscontrol show nodes\nWill list out all nodes and all capabilities of each node. Or just one node:\nscontrol show node lisnode2"
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-7-reveal.html#sbatch",
    "href": "teaching/2023-2024/Programming Level-up/lecture-7-reveal.html#sbatch",
    "title": "Linux & Supercomputer",
    "section": "sbatch",
    "text": "sbatch\nIt can be quite inconvenient to launch an interactive job to run some compute, and wait for the job to be allocated. If, instead, you have a long running experiment that you want to run without any intervention from you, you can use sbatch.\nSbatch will require us to write a small bash script that specifies how to run a job and what to do once its allocated.\n#!/bin/bash\n\n#SBATCH --time=00:01:00\n#SBATCH --job-name=my_new_job\n#SBATCH --output=my_new_job.out\n#SBATCH --error=my_new_job.err\n\necho $HOSTNAME\nAnd run it:\nsbatch my_job.sh\nNotice that instead of supplying options to sbatch, we can instead record them directly into the script using the #SBATCH. SLURM will examine this file, looking for lines starting with this comment, and infer that the rest of the line contains the options.\nThere are a few other options we’ve included that are very useful when running non-interactive jobs. Firstly, we’ve given the job a name (my_new_job). This is so we can different between many jobs that we might run at the same time. To list out the jobs we currently have running we use squeue.\nsqueue\nBy default, squeue will list all of the active jobs, even other peoples. To specify only your jobs user the --user option:\nsqueue --user=jay.morgan\nThe other two options, --output and --error specify where the printed output and printed errors will be stored. Since the job is being run on a different node, by a non-interactive process, if you didn’t include these lines, you wouldn’t be able to see what was being printed by echo or by any other process such as print in Python."
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-7-reveal.html#squeue",
    "href": "teaching/2023-2024/Programming Level-up/lecture-7-reveal.html#squeue",
    "title": "Linux & Supercomputer",
    "section": "squeue",
    "text": "squeue\nWhen we list the jobs using squeue it will give us multiple columns of information, such as:\n\nJOBID – the referable id of the job.\nPARTITION – the partition on which the job has been requested for.\nNAME – the name of the job.\nUSER – the user who submitted the job.\nST – the status, is the job currently running, waiting, or exiting?\nTIME – how long the job has been running for.\nNODES – how many nodes have been allocated to the job."
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-7-reveal.html#scontrol",
    "href": "teaching/2023-2024/Programming Level-up/lecture-7-reveal.html#scontrol",
    "title": "Linux & Supercomputer",
    "section": "scontrol",
    "text": "scontrol\nscontrol allows us to modify an existing job. For example, let us say that we have a job which we need to extend the time limit. Given that we know the job id (we could use squeue to find this), we can ask SLURM to update the time limit using:\nscontrol update jobid=&lt;job_id&gt; TimeLimit=&lt;new_timelimit&gt;"
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-7-reveal.html#scancel",
    "href": "teaching/2023-2024/Programming Level-up/lecture-7-reveal.html#scancel",
    "title": "Linux & Supercomputer",
    "section": "scancel",
    "text": "scancel\nLet’s say that we’ve submitted a job, but we’ve noticed that there was an error in the code, and want to stop the job. For that, we use scancel and specify the id of the job we wish to cancel:\nscancel 158590\nAfter running this command, we should see, using squeue, that either the job is finishing, or that its disappeared from our list (meaning that its completely stopped)."
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-7-reveal.html#sacct",
    "href": "teaching/2023-2024/Programming Level-up/lecture-7-reveal.html#sacct",
    "title": "Linux & Supercomputer",
    "section": "sacct",
    "text": "sacct\nIf our job has finished, or exited and is no longer in squeue, we can use sacct to get a history of the jobs.\nsacct will list all of your jobs within some default window of time. If we want to change this window we can use the --starttime and --endtime options.\nValid time formats are:\n\nHH:MM[:SS][AM|PM]\nMMDD[YY][-HH:MM[:SS]]\nMM.DD[.YY][-HH:MM[:SS]]\nMM/DD[/YY][-HH:MM[:SS]]\nYYYY-MM-DD[THH:MM[:SS]]\ntoday, midnight, noon, fika (3 PM), teatime (4 PM)\nnow[{+|-}count[seconds(default)|minutes|hours|days|weeks]]"
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-7-reveal.html#job-task-arrays-motivation",
    "href": "teaching/2023-2024/Programming Level-up/lecture-7-reveal.html#job-task-arrays-motivation",
    "title": "Linux & Supercomputer",
    "section": "Job Task Arrays – motivation",
    "text": "Job Task Arrays – motivation\nTask arrays allow you to submit many jobs of the same type. Why might this be useful? Suppose you have a list of files that take a long time to process:\n\nfile_0.txt\nfile_1.txt\nfile_2.txt\n\nOr you have some computation script, such as deep learning training script, that takes uses a hyperparameter which can be tuned to achieve different performance results:\npython train.py --learning-rate 0.001\nInstead of a creating a sbatch script for each value of hyperparameter, or sequentially enumerating the values, you can use a job task array to spawn multiple jobs with slightly different values."
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-7-reveal.html#job-task-arrays-how-to",
    "href": "teaching/2023-2024/Programming Level-up/lecture-7-reveal.html#job-task-arrays-how-to",
    "title": "Linux & Supercomputer",
    "section": "Job Task Arrays – how to",
    "text": "Job Task Arrays – how to\nFirst, we will look at how to actually submit an array of tasks. To create an task array, you will need to add the --array options to your sbatch script:\n#!/bin/bash\n\n#SBATCH --job-name=my_task_array\n#SBATCH --array=1-5\n\n...\nHere we are creating an array of tasks numbered from 1-5. When you submit this script, you will see five tasks submitted to the queue.\nNow that we know how to create an array of tasks, we will want to do something useful with it. When you create an array, each individual task will have a unique variable called SLURM_ARRAY_TASK_ID. So for example, if we launch an array of 5 tasks, the first task will have the value 1. Why is this useful? Well, we can use this variable to alter the program slightly. Take for example our list of files we need to process:\n#!/bin/bash\n#SBATCH --job-name=my_task_array\n#SBATCH --array=0-4\n#SBATCH --time=00:10:00\n\nFILENAME=\"file_${SLURM_ARRAY_TASK_ID}.txt\"\npython process.py $FILENAME\nThis will create a new bash variable called FILENAME by concatenating file_ the current task’s (i.e. 0, for the first task, 1 for the second task, etc) and .txt.\nIf we run the previous example, we will see that we have five jobs named exactly the same thing my_task_array. This is okay, but we can be a little bit more clear as to which task is running, i.e. which task is processing which file?\nWe can use some special variables in our bash script to make this more clear. These are %A that is the main job id, and %a that is the task array id.\n#!/bin/bash\n\n#SBATCH --error=my_task_array.%A_%a.out\n#SBATCH --output=my_task_array.%A_%a.out\n...\nNow, every task in our array will have a slightly different name because of the %a and therefore we will be able to determine which job is processing which file.\nLet’s move on to the second example, where we have a Deep Learning training program and we want to try different parameters. In this case, we can again use a task array.\n#!/bin/bash\n\n#SBATCH --array=1-10\nWe could either pass the SLURM_ARRAY_TASK_ID as a command line argument to the script:\npython training.py --learning-rate $SLURM_ARRAY_TASK_ID\nBut in this case, we could have to properly calculate the correct learning rate from the SLURM_ARRAY_TASK_ID value (remember that in my sbatch script I set --array=1-5). But bash only performs integer arithmetic, therefore we will need to calculate the correct learning rate in something else.\nInstead of passing the learning rate via a command line argument. We can get the value directly from our python script and calculate the value.\nimport os\n\ntask_id = int(os.environ[\"SLURM_ARRAY_TASK_ID\"])\nlearning_rate = task_id / 100\nHere we are using the builtin os module in Python, getting the environment variable from the dictionary environ and parsing the value as an integer. Then we can calculate the appropriate learning rate using this value. So for example, if SLURM_ARRAY_TASK_ID is set to 1. Our learning rate would be 0.01 for this task.\nIf you’re creating a job task array, you may want to create hundreds of jobs. And of course, you don’t want to use up the entire cluster leaving no resources for anybody else! Therefore, you will only want a maximum number of tasks to run at any one time.\n#!/bin/bash\n\n#SBATCH --array=1-100%5\nThis will create a job task array of 100 jobs numbered from 1 to 100. But we have added an additional argument %5 which means that only 5 jobs can run at any one time for this task array. If you have five tasks running, the other 95 tasks will wait.\nIf, at any point, you want to change how many jobs can run simultaineously, you can update this ‘throttle’ value using scontrol:\nscontrol update ArrayTaskThrottle=&lt;count&gt; JobId=&lt;jobID&gt;\nSo if we’ve already launched a job task array with the job id of 50602 that has a throttle value of 5 (only 5 tasks will run at once), we can change it to 10 using:\nscontrol update ArrayTaskThrottle=10 JobId=50602"
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-7-reveal.html#a-guided-walk-through-environment",
    "href": "teaching/2023-2024/Programming Level-up/lecture-7-reveal.html#a-guided-walk-through-environment",
    "title": "Linux & Supercomputer",
    "section": "A guided walk through – environment",
    "text": "A guided walk through – environment\nIn this section we’re going to give an example walk through of working with the HPC cluster. In this example, we’re going to write our scripts locally, including the slurm submission script, and when they’re ready, we’ll send them to the cluster to perform the actual computation.\nLet’s imagine we’re starting a new project, and are programming our scripts in Python. Now is a good time to create a new conda environment to install our packages we’re going to use for our research. We’ll create this environment with (replacing &lt;env-name&gt; with whatever we want to call this environment):\nconda create --name &lt;env-name&gt;\nand then activate it:\nconda activate &lt;env-name&gt;\nconda install python=3.9"
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-7-reveal.html#writing-our-scripts",
    "href": "teaching/2023-2024/Programming Level-up/lecture-7-reveal.html#writing-our-scripts",
    "title": "Linux & Supercomputer",
    "section": "Writing our scripts",
    "text": "Writing our scripts\nLet us also image we’ve just wrote the following script to create a lorenz attractor: lorenz.py\nThe specific implementation of this script is not particularly important for this walk through. Just know that we’re importing a few packages such as numpy and matplotlib. Then, we’re performing some computation, and saving the results to analyse later. As this script uses external libraries, we need to install them:\nconda install numpy matplotlib"
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-7-reveal.html#writing-our-job-submission-script",
    "href": "teaching/2023-2024/Programming Level-up/lecture-7-reveal.html#writing-our-job-submission-script",
    "title": "Linux & Supercomputer",
    "section": "Writing our job submission script",
    "text": "Writing our job submission script\nSince we want our calculations to be performed on the cluster, we will need to also write a job submission script (let’s call this submit-job.sh) in bash to pass to SLURM.\n#!/bin/bash\n\n#SBATCH --job-name=lorenz_attractor\n#SBATCH --output=lorenz_attractor.log\n#SBATCH --error=lorenz_attractor.log\n#SBATCH --time=00:10:00\n\npython lorenz.py"
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-7-reveal.html#replicating-our-environment-on-the-cluster",
    "href": "teaching/2023-2024/Programming Level-up/lecture-7-reveal.html#replicating-our-environment-on-the-cluster",
    "title": "Linux & Supercomputer",
    "section": "Replicating our environment on the cluster",
    "text": "Replicating our environment on the cluster\nAs we’ve installed external packages in our local development environment, we will want to ensure that when we run the calculations on the cluster, it will be using the same versions of packages. Conda makes this a lot easier. First, we export our environment to a recipe file:\nconda env export --no-builds &gt; environment.yml"
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-7-reveal.html#sending-our-scripts-to-the-cluster",
    "href": "teaching/2023-2024/Programming Level-up/lecture-7-reveal.html#sending-our-scripts-to-the-cluster",
    "title": "Linux & Supercomputer",
    "section": "Sending our scripts to the cluster",
    "text": "Sending our scripts to the cluster\nAll of our scripts are ready! We can now transfer them from our personal computer, to the cluster. The files we need to transfer are:\n\nlorenz.py\nenvironment.yml\nsubmit-job.sh\n\nWhile we can send a folder (and the containing files), let’s send them one at a time:\nscp lorenz.py &lt;hostname&gt;:&lt;destination-path&gt;\nscp environment.yml &lt;hostname&gt;:&lt;destination-path&gt;\nscp submit-job.sh &lt;hostname&gt;:&lt;destination-path&gt;\nwhere &lt;hostname&gt; is the hostname/IP address that you’ve used to connect to the login node on the cluster before. &lt;destination-path&gt; is the path to where you want to save the files."
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-7-reveal.html#logging-into-the-cluster",
    "href": "teaching/2023-2024/Programming Level-up/lecture-7-reveal.html#logging-into-the-cluster",
    "title": "Linux & Supercomputer",
    "section": "Logging into the cluster",
    "text": "Logging into the cluster\nNow that our files are on the cluster, we can login:\nssh &lt;username&gt;@&lt;hostname&gt;\nAt which point, we’ve logged into the login node, and then we need to change directory to where we saved the files:\ncd &lt;destination-path&gt;"
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-7-reveal.html#re-creating-our-development-environment",
    "href": "teaching/2023-2024/Programming Level-up/lecture-7-reveal.html#re-creating-our-development-environment",
    "title": "Linux & Supercomputer",
    "section": "Re-creating our development environment",
    "text": "Re-creating our development environment\nNow that we’re in the same folder as our scripts, we’re almost ready to submit our job. First, we need to recreate our development environment from our environment.yml file.\nconda env create -f environment.yml\nAnd activate our newly created environment:\nconda activate &lt;env-name&gt;"
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-7-reveal.html#submitting-our-job",
    "href": "teaching/2023-2024/Programming Level-up/lecture-7-reveal.html#submitting-our-job",
    "title": "Linux & Supercomputer",
    "section": "Submitting our job",
    "text": "Submitting our job\nNow we can submit our job:\nsbatch submit-job.sh\nWe can check the progress of our job with squeue, or its already completed, look at the job history with sacct."
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-7-reveal.html#downloading-the-results",
    "href": "teaching/2023-2024/Programming Level-up/lecture-7-reveal.html#downloading-the-results",
    "title": "Linux & Supercomputer",
    "section": "Downloading the results",
    "text": "Downloading the results\nIf our job runs successfully, a data.pkl file will be created. Back on our local computers, we will need to run the following to download it:\nscp &lt;hostname&gt;:&lt;destination-path&gt;/data.pkl ./\nThis will download the file into the current directory."
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-7-reveal.html#analysing-the-results",
    "href": "teaching/2023-2024/Programming Level-up/lecture-7-reveal.html#analysing-the-results",
    "title": "Linux & Supercomputer",
    "section": "Analysing the results",
    "text": "Analysing the results\nWith the data.pkl file downloaded, we can visualise the results using plot_lorenz.py: https://pageperso.lis-lab.fr/jay.morgan/resources/2021-programming-level-up/lectures/week-5/plot-lorenz.py\nIf everything has been run correctly, you should see a plot of the lorenz attractor."
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-7-reveal.html#useful-features-x11-forwarding",
    "href": "teaching/2023-2024/Programming Level-up/lecture-7-reveal.html#useful-features-x11-forwarding",
    "title": "Linux & Supercomputer",
    "section": "Useful features – X11 Forwarding",
    "text": "Useful features – X11 Forwarding\nIf we’re performing analysis interactively using the cluster, we’ll often want to visualise the results, using matplotlib for example. To see our plots display like they would on our local machine when we call plt.plot or plt.show(), we will need to ensure that we’re using something called X11 Forwarding. To enable X11 Forwarding, we use the -X option when ssh‘ing into the cluster and compute nodes (i.e. it will need to be enabled on every ’hop’ so to speak).\nssh -X &lt;&lt;remote-host&gt;&gt;\nIf want to enable it by default, we can enable it in our ssh config file:\nHost cluster\n HostName sms-ext.lis-lab.fr\n FowardX11 yes\n User &lt;&lt;username&gt;&gt;\nAfter setting up X11 Forwarding correctly, and when logged into the remote host, we should be able to echo a variable called $DISPLAY.\necho $DISPLAY\nIf $DISPLAY has a value, we know that X11 Forwarding has been setup correctly, and we’re ready to do some plotting!"
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-7-reveal.html#useful-features-jupyter-notebooks",
    "href": "teaching/2023-2024/Programming Level-up/lecture-7-reveal.html#useful-features-jupyter-notebooks",
    "title": "Linux & Supercomputer",
    "section": "Useful features – Jupyter Notebooks",
    "text": "Useful features – Jupyter Notebooks\nWe’ve talked about how good jupyter notebooks are for performing analysis and exploration. But often times, we will need a lot of compute resources (more than our local computers can handle) to do this analysis. This is where using jupyter notebook on the supercomputers comes in handy. However, it is not as simple as starting the jupyter notebook server and opening up your web browser. First, we will need to setup a ‘reverse ssh tunnel’.\nIn a nut-shell, a reverse ssh tunnel allows you to redirect data on a remote port to a local port.\nTherefore, we can, using a reverse ssh tunnel, start a jupyter notebook on the supercomputer and access it using the web browser on our local computer!\nTo begin, we can create an interactive job on the cluster:\nsrun --time=01:00:00 --pty bash -l\nAnd start our jupyter notebook, specifying a port that will not be in use:\njupyter notebook --port 30333\nWith our notebook server now started on the 30333 port, we will want to create an ssh tunnel from our local computer, to the cluster’s login node, and then a tunnel from the login node to the specific compute node where the job is running:\nssh -L 30333:localhost:30333 &lt;&lt;cluster-login-node&gt;&gt; ssh -L 30333:localhost:30333 &lt;&lt;cluster-compute-node&gt;&gt;\nIf everything goes well, we should now be able to open up our web browser, navigate to localhost:30333 and see our jupyter notebooks."
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-4.html",
    "href": "teaching/2023-2024/Programming Level-up/lecture-4.html",
    "title": "Introduction to Numpy",
    "section": "",
    "text": "NumPy (https://numpy.org/) is one of the fundamental Python libraries for scientific computing. In essence, its aim is to make vector and array processing in Python much more efficient. Therefore, it would be your go-to for (numerical) data processing.\nNumerical data processing with NumPy can, most often that not, be magnitudes faster than what you can write in Python, even if the operations are the same. This is because NumPy is partly written in C.\nFor example, if we want to compute the matrix multiplication of two arrays:\nA = [[1, 4], [9, 5]]  # 2 dimensional 'matrices' A and B\nB = [[1, 2], [3, 4]]\nC = [[0, 0], [0, 0]]  # our result 'pre-allocated' with zeros\n\nfor i in range(len(A)):\n    for j in range(len(B)):\n        for k in range(len(B)):\n            C[i][j] += A[i][k] * B[k][j]\nThe previous example is quite un-weidly. We have to manually loop through the matrices and apply the computation for each element. This can be very slow in Python. NumPy provides a much cleaner and quicker interface:\nimport numpy as np\nA = np.array([[1, 4], [9, 5]])\nB = np.array([[1, 2], [3, 4]])\nC = A @ B  # or np.matmul(A, B)\nprint(C)\nResults: \n# =&gt; [[13 18]\n# =&gt;  [24 38]]\n\n\n\nBefore we can use NumPy, we must first install it if its not already. NumPy can easily be installed with one of your package managers of choice. For example, if you want to install via conda:\nconda install numpy\nor with pip:\npip install numpy\n\n\n\nAs we’ve seen previously, we use np.array to create a numpy array from a Python data type\nA = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\nprint(A)\nResults: \n# =&gt; [[1 2 3]\n# =&gt;  [4 5 6]\n# =&gt;  [7 8 9]]\nWe’ve created a 3x3 matrix of integers. Note that, out-of-the-box, NumPy doesn’t support ragged arrays (matrices that are not rectangular), so this will not work as you expect:\nA = np.array([[1], [1, 2]])\n\n\n\nA numpy array has various attributes that are useful for our numerical computing. Some of these include:\nA = np.array([[1, 4], [9, 5]])\n\nprint(A.shape)  # the shape of the array\nprint(A.size)   # number of elements\nprint(A.ndim)   # number of dimensions\nprint(A.nbytes) # storage used\nprint(A.dtype)  # data type of elements\nResults: \n# =&gt; (2, 2)\n# =&gt; 4\n# =&gt; 2\n# =&gt; 32\n# =&gt; int64\n\n\n\nIn the previous example, the elements in the array we int64. But normally, we will see float64. However, there are many other available data types, where each of the different data types affects how much memory is used to represent the data.\n\nint (8, 16, 32, 64)\nuint (unsigned integers)\nbool\nfloat (8, 16, 32, 64)\ncomplex\n\nhttps://numpy.org/doc/stable/user/basics.types.html https://numpy.org/doc/stable/reference/arrays.dtypes.html\n\n\n\nWhen creating a NumPy array, NumPy will select what it thinks to be the most appropriate data type. However, we can tell NumPy explicitly what the data type should be with the dtype argument.\nA = np.array([[1, 2], [9, 5]], dtype=np.int8)\nprint(A)\nprint(A.dtype)\n\nA = np.array([[1, 2], [9, 5]], dtype=np.float)\nprint(A)\nprint(A.dtype)\nResults: \n# =&gt; [[1 2]\n# =&gt;  [9 5]]\n# =&gt; int8\n# =&gt; [[1. 2.]\n# =&gt;  [9. 5.]]\n# =&gt; float64\n\n\n\nIn some cases, we wish to change the data type of arrays after its creation. For this we use the .astype() method. This method takes a single argument: the data type you wish to change the array to.\nA = np.array([1, 2, 3, 4])\nprint(A.dtype)\nint64\n\n\n\nWe could change it to a float64 array:\nA = A.astype(float)\nprint(A.dtype)\nfloat64\n\n\n\nOr float32:\nA = A.astype(np.float32)\nprint(A.dtype)\nfloat32\n\n\n\nNumPy also provides us with a number of different functions to create arrays. Instead of doing this:\nA = np.array([[0, 0], [0, 0]])\nWe could instead use the np.zeros function, passing a tuple where each element of the tuple describes how many elements should be made in each dimension:\nA = np.zeros((2,)) # 1 dimensional\nA = np.zeros((2, 2))  # 2 dimensional\nA = np.zeros((2, 5, 5))  # 3 dimensional\nAnother commonly used array creation function is the np.random.randn function. This creates an array where elements are sampled from a normal distribution.\nA = np.random.randn(2, 2)\nprint(A)\nResults: \n# =&gt; [[-0.68213848 -0.44274759]\n# =&gt;  [ 0.6748596   0.64244208]]\nNote the interface is a little different than .zeros, where instead of passing a tuple, we pass multiple arguments to the function.\nIt is also convenient to create arrays with ranges of elements.\nA = np.arange(5, 10) # optional step\nprint(A)\nResults: \n# =&gt; [5 6 7 8 9]\nA = np.linspace(5, 10, 20)\nprint(A)\nResults: \n# =&gt; [ 5.          5.26315789  5.52631579  5.78947368  6.05263158  6.31578947\n# =&gt;   6.57894737  6.84210526  7.10526316  7.36842105  7.63157895  7.89473684\n# =&gt;   8.15789474  8.42105263  8.68421053  8.94736842  9.21052632  9.47368421\n# =&gt;   9.73684211 10.        ]\nThere are many more ways to create arrays. Some include:\n\nnp.ones - a matrix of 1’s\nnp.eye - an identity matrix\nnp.diag - create a matrix with supplied elements across the diagonal\nnp.fromfunction - load elements from the return of a function\nnp.fromfile - load elements from a data file\n\nThough, the best resource for understanding is NumPy’s own documentation on the subject: https://numpy.org/doc/stable/user/basics.creation.html"
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-4.html#what-is-numpy",
    "href": "teaching/2023-2024/Programming Level-up/lecture-4.html#what-is-numpy",
    "title": "Introduction to Numpy",
    "section": "",
    "text": "NumPy (https://numpy.org/) is one of the fundamental Python libraries for scientific computing. In essence, its aim is to make vector and array processing in Python much more efficient. Therefore, it would be your go-to for (numerical) data processing.\nNumerical data processing with NumPy can, most often that not, be magnitudes faster than what you can write in Python, even if the operations are the same. This is because NumPy is partly written in C.\nFor example, if we want to compute the matrix multiplication of two arrays:\nA = [[1, 4], [9, 5]]  # 2 dimensional 'matrices' A and B\nB = [[1, 2], [3, 4]]\nC = [[0, 0], [0, 0]]  # our result 'pre-allocated' with zeros\n\nfor i in range(len(A)):\n    for j in range(len(B)):\n        for k in range(len(B)):\n            C[i][j] += A[i][k] * B[k][j]\nThe previous example is quite un-weidly. We have to manually loop through the matrices and apply the computation for each element. This can be very slow in Python. NumPy provides a much cleaner and quicker interface:\nimport numpy as np\nA = np.array([[1, 4], [9, 5]])\nB = np.array([[1, 2], [3, 4]])\nC = A @ B  # or np.matmul(A, B)\nprint(C)\nResults: \n# =&gt; [[13 18]\n# =&gt;  [24 38]]"
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-4.html#install-numpy",
    "href": "teaching/2023-2024/Programming Level-up/lecture-4.html#install-numpy",
    "title": "Introduction to Numpy",
    "section": "",
    "text": "Before we can use NumPy, we must first install it if its not already. NumPy can easily be installed with one of your package managers of choice. For example, if you want to install via conda:\nconda install numpy\nor with pip:\npip install numpy"
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-4.html#creating-a-numpy-array",
    "href": "teaching/2023-2024/Programming Level-up/lecture-4.html#creating-a-numpy-array",
    "title": "Introduction to Numpy",
    "section": "",
    "text": "As we’ve seen previously, we use np.array to create a numpy array from a Python data type\nA = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\nprint(A)\nResults: \n# =&gt; [[1 2 3]\n# =&gt;  [4 5 6]\n# =&gt;  [7 8 9]]\nWe’ve created a 3x3 matrix of integers. Note that, out-of-the-box, NumPy doesn’t support ragged arrays (matrices that are not rectangular), so this will not work as you expect:\nA = np.array([[1], [1, 2]])"
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-4.html#basic-attributes",
    "href": "teaching/2023-2024/Programming Level-up/lecture-4.html#basic-attributes",
    "title": "Introduction to Numpy",
    "section": "",
    "text": "A numpy array has various attributes that are useful for our numerical computing. Some of these include:\nA = np.array([[1, 4], [9, 5]])\n\nprint(A.shape)  # the shape of the array\nprint(A.size)   # number of elements\nprint(A.ndim)   # number of dimensions\nprint(A.nbytes) # storage used\nprint(A.dtype)  # data type of elements\nResults: \n# =&gt; (2, 2)\n# =&gt; 4\n# =&gt; 2\n# =&gt; 32\n# =&gt; int64"
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-4.html#different-data-types",
    "href": "teaching/2023-2024/Programming Level-up/lecture-4.html#different-data-types",
    "title": "Introduction to Numpy",
    "section": "",
    "text": "In the previous example, the elements in the array we int64. But normally, we will see float64. However, there are many other available data types, where each of the different data types affects how much memory is used to represent the data.\n\nint (8, 16, 32, 64)\nuint (unsigned integers)\nbool\nfloat (8, 16, 32, 64)\ncomplex\n\nhttps://numpy.org/doc/stable/user/basics.types.html https://numpy.org/doc/stable/reference/arrays.dtypes.html"
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-4.html#creating-arrays-with-different-dtypes",
    "href": "teaching/2023-2024/Programming Level-up/lecture-4.html#creating-arrays-with-different-dtypes",
    "title": "Introduction to Numpy",
    "section": "",
    "text": "When creating a NumPy array, NumPy will select what it thinks to be the most appropriate data type. However, we can tell NumPy explicitly what the data type should be with the dtype argument.\nA = np.array([[1, 2], [9, 5]], dtype=np.int8)\nprint(A)\nprint(A.dtype)\n\nA = np.array([[1, 2], [9, 5]], dtype=np.float)\nprint(A)\nprint(A.dtype)\nResults: \n# =&gt; [[1 2]\n# =&gt;  [9 5]]\n# =&gt; int8\n# =&gt; [[1. 2.]\n# =&gt;  [9. 5.]]\n# =&gt; float64"
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-4.html#changing-dtypes",
    "href": "teaching/2023-2024/Programming Level-up/lecture-4.html#changing-dtypes",
    "title": "Introduction to Numpy",
    "section": "",
    "text": "In some cases, we wish to change the data type of arrays after its creation. For this we use the .astype() method. This method takes a single argument: the data type you wish to change the array to.\nA = np.array([1, 2, 3, 4])\nprint(A.dtype)\nint64"
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-4.html#section",
    "href": "teaching/2023-2024/Programming Level-up/lecture-4.html#section",
    "title": "Introduction to Numpy",
    "section": "",
    "text": "We could change it to a float64 array:\nA = A.astype(float)\nprint(A.dtype)\nfloat64"
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-4.html#section-1",
    "href": "teaching/2023-2024/Programming Level-up/lecture-4.html#section-1",
    "title": "Introduction to Numpy",
    "section": "",
    "text": "Or float32:\nA = A.astype(np.float32)\nprint(A.dtype)\nfloat32"
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-4.html#different-ways-of-creating-arrays",
    "href": "teaching/2023-2024/Programming Level-up/lecture-4.html#different-ways-of-creating-arrays",
    "title": "Introduction to Numpy",
    "section": "",
    "text": "NumPy also provides us with a number of different functions to create arrays. Instead of doing this:\nA = np.array([[0, 0], [0, 0]])\nWe could instead use the np.zeros function, passing a tuple where each element of the tuple describes how many elements should be made in each dimension:\nA = np.zeros((2,)) # 1 dimensional\nA = np.zeros((2, 2))  # 2 dimensional\nA = np.zeros((2, 5, 5))  # 3 dimensional\nAnother commonly used array creation function is the np.random.randn function. This creates an array where elements are sampled from a normal distribution.\nA = np.random.randn(2, 2)\nprint(A)\nResults: \n# =&gt; [[-0.68213848 -0.44274759]\n# =&gt;  [ 0.6748596   0.64244208]]\nNote the interface is a little different than .zeros, where instead of passing a tuple, we pass multiple arguments to the function.\nIt is also convenient to create arrays with ranges of elements.\nA = np.arange(5, 10) # optional step\nprint(A)\nResults: \n# =&gt; [5 6 7 8 9]\nA = np.linspace(5, 10, 20)\nprint(A)\nResults: \n# =&gt; [ 5.          5.26315789  5.52631579  5.78947368  6.05263158  6.31578947\n# =&gt;   6.57894737  6.84210526  7.10526316  7.36842105  7.63157895  7.89473684\n# =&gt;   8.15789474  8.42105263  8.68421053  8.94736842  9.21052632  9.47368421\n# =&gt;   9.73684211 10.        ]\nThere are many more ways to create arrays. Some include:\n\nnp.ones - a matrix of 1’s\nnp.eye - an identity matrix\nnp.diag - create a matrix with supplied elements across the diagonal\nnp.fromfunction - load elements from the return of a function\nnp.fromfile - load elements from a data file\n\nThough, the best resource for understanding is NumPy’s own documentation on the subject: https://numpy.org/doc/stable/user/basics.creation.html"
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-4.html#slicing-numpy-arrays",
    "href": "teaching/2023-2024/Programming Level-up/lecture-4.html#slicing-numpy-arrays",
    "title": "Introduction to Numpy",
    "section": "Slicing NumPy arrays",
    "text": "Slicing NumPy arrays\nIn native Python, when we have a ‘matrix’ like data structure (just a list of lists), and we want to access a particular element from this matrix, we have to do something like:\nA = [[1, 2], [3, 4]]\nprint(A[1][0])\nResults: \n# =&gt; 3\nHowever, in NumPy, we seperate the indexes by comma:\nA = np.array([[1, 2], [3, 4]])\nprint(A[1, 0])\nResults: \n# =&gt; 3\nIf we wanted to get all elements from the 2nd column we would use the : notation. For example:\nA = np.array([[1, 2], [3, 4]])\nprint(A[:, 1])\nResults: \n# =&gt; [2 4]\nLikewise, all elements from the 2nd row:\nprint(A[1, :])\nResults: \n# =&gt; [3 4]\nNote that when we slice an array, we are not copying the elements:\nA = np.array([[1, 2], [3, 4]])\nb = A[:, 1]\n\nb[0] = 10\n\nprint(A)\nResults: \n# =&gt; [[ 1 10]\n# =&gt;  [ 3  4]]\nAny modification you make to the b variable will also affect A. For that we must use .copy()\nA = np.array([[1, 2], [3, 4]])\nb = A[:, 1].copy()\n...\nIf we have a multi-dimensional array, to which we wish to index on the final dimension, one way to achieve this is by doing the following:\nA = np.random.randn(10, 2, 5, 4)  # our array to slice\nA[:, :, :, 1:2]  # slice on the last dimension\nThis can get pretty tedious the more that the number of dimensions increases. But! we have one syntactical shortcut at our disposal: the ellipses ‘…’. Using the ellipses in place of the many ‘:’ slices on each dimension, we’re telling NumPy to just take all elements from the prior dimensions. For example:\nA[..., 1:2]  # same slice on the last dimension"
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-4.html#boolean-indexing",
    "href": "teaching/2023-2024/Programming Level-up/lecture-4.html#boolean-indexing",
    "title": "Introduction to Numpy",
    "section": "Boolean Indexing",
    "text": "Boolean Indexing\nNumPy arrays can also be composed of boolean elements\nA = np.array([[1, -1], [0, 5]])\nprint(A &gt; 0)\nResults: \n# =&gt; [[ True False]\n# =&gt;  [False  True]]\nAnd we can also use boolean elements to help with indexing:\nvalues_above_zero = A[A &gt; 0]\nprint(values_above_zero)\nResults: \n# =&gt; [1 5]\nTherefore we can apply computations to only part of the array using this indexing feature:\nmask = A &gt; 0\nA[mask] = A[mask] + 10\nprint(A)\nResults: \n# =&gt; [[11 -1]\n# =&gt;  [ 0 15]]"
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-4.html#reshape",
    "href": "teaching/2023-2024/Programming Level-up/lecture-4.html#reshape",
    "title": "Introduction to Numpy",
    "section": "Reshape",
    "text": "Reshape\nAfter an array has been created, we can modify its structure/shape using various functions. The first we shall look at is .reshape. For example, let us create a vector of 4 elements and then reshape it into an array of 2x2 elements. Of course, the new shape of the array must be proportional to the original number of elements: 2x2 elements = 4 elements.\nA = np.arange(1, 5)\n\nmat_A = A.reshape(2, 2)\nprint(mat_A)\nprint(A)  # A is not changed! No need for copy\nResults: \n# =&gt; [[1 2]\n# =&gt;  [3 4]]\n# =&gt; [1 2 3 4]"
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-4.html#flatten",
    "href": "teaching/2023-2024/Programming Level-up/lecture-4.html#flatten",
    "title": "Introduction to Numpy",
    "section": "Flatten",
    "text": "Flatten\nIf we wanted to take a 2d array and reshape it into a vector, we could of course use the .reshape function again. But we could also use .flatten.\nflat_A = mat_A.flatten()\nprint(flat_A)\nResults: \n# =&gt; [1 2 3 4]\nWhen specifying the new dimensionality of the reshaped array, -1 is a shortcut to specify the dimensionality to allow reshaping to occur correctly. For example:\nA = np.arange(1, 5)\nprint(A)\n\nprint(A.reshape(2, -1))\nResults: \n# =&gt; [1 2 3 4]\n# =&gt; [[1 2]\n# =&gt;  [3 4]]\nWe’re telling NumPy to create an array with 2 elements on the 1st dimension, and then however many elements on the second dimension."
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-4.html#add-a-dimension",
    "href": "teaching/2023-2024/Programming Level-up/lecture-4.html#add-a-dimension",
    "title": "Introduction to Numpy",
    "section": "Add a dimension",
    "text": "Add a dimension\nWe can add and remove dimensions using .expand_dims and .squeeze, respectively.\nprint(A)\nprint(np.expand_dims(A, 1))\nResults: \n# =&gt; [1 2 3 4]\n# =&gt; [[1]\n# =&gt;  [2]\n# =&gt;  [3]\n# =&gt;  [4]]\nWe are taking a vector and adding a dimension. Note that we have to use np.expand_dims passing the object we want to expand and not A.expand_dims.\nWe can use an indexing trick with None to do the expansion in just the same way:\nprint(A)\nprint(A[:, None])\nResults: \n# =&gt; [1 2 3 4]\n# =&gt; [[1]\n# =&gt;  [2]\n# =&gt;  [3]\n# =&gt;  [4]]\nWhere None indicates to NumPy where we want to add the new dimension."
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-4.html#remove-a-dimension",
    "href": "teaching/2023-2024/Programming Level-up/lecture-4.html#remove-a-dimension",
    "title": "Introduction to Numpy",
    "section": "Remove a dimension",
    "text": "Remove a dimension\nIf we want to instead remove a dimension, we can use .squeeze()\nprint(A[:, None].squeeze(1))\nResults: \n# =&gt; [1 2 3 4]\nWe are removing the 2nd dimension, but note that the elements must be singletons. So you cannot squeeze a 2x2 array."
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-4.html#matrix-transpose",
    "href": "teaching/2023-2024/Programming Level-up/lecture-4.html#matrix-transpose",
    "title": "Introduction to Numpy",
    "section": "Matrix transpose",
    "text": "Matrix transpose\nAnother useful feature is the matrix transpose:\nprint(mat_A)\n\nprint(mat_A.transpose())\nResults: \n# =&gt; [[1 2]\n# =&gt;  [3 4]]\n# =&gt; [[1 3]\n# =&gt;  [2 4]]\nor even:\n    print(mat_A.T)\nResults: \n# =&gt; [[1 3]\n# =&gt;  [2 4]]"
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-4.html#composing-arrays",
    "href": "teaching/2023-2024/Programming Level-up/lecture-4.html#composing-arrays",
    "title": "Introduction to Numpy",
    "section": "Composing arrays",
    "text": "Composing arrays\nIf we have multiple arrays we want to ‘join’ together, we can use np.hstack for horizontally joining, or np.vstack for vertically joining arrays. Note the dimensions must match in the direction your stacking.\nA = np.array([1, 2, 3])\nB = np.array([4, 5, 6])\n\nprint(np.hstack([A, B]))\n[1 2 3 4 5 6]\nprint(np.vstack([A, B]))\nResults: \n# =&gt; [[1 2 3]\n# =&gt;  [4 5 6]]\nhstack and vstack can be useful when the required output shape is simply defined. However, there is a more general function - np.concatenate - that will be more often useful to us.\nprint(np.concatenate([A, B], axis=0))\n[1 2 3 4 5 6]\nHere we see that we can achieve the same result as np.hstack using concatenate. Notice also that there is a second argument to the concatenate function: the dimension upon which the concatenation will take place.\nhttps://numpy.org/doc/stable/reference/generated/numpy.concatenate.html"
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-4.html#arithmetic-operations-1",
    "href": "teaching/2023-2024/Programming Level-up/lecture-4.html#arithmetic-operations-1",
    "title": "Introduction to Numpy",
    "section": "Arithmetic Operations",
    "text": "Arithmetic Operations\nWe have already seen some basic examples of arithmetic operations in NumPy. But its worth looking at these in detail.\nOne of the best reasons to use NumPy is that the computations are vectorized and can be broadcast. We’ll see examples of what these mean.\nA = np.array([1, 2, 3])\nB = np.array([[1, 2, 3],\n                [4, 5, 6]])\n\nprint(A * B)\nResults: \n# =&gt; [[ 1  4  9]\n# =&gt;  [ 4 10 18]]\nWe can perform vector and matrix arithmetic using Python’s infix operators like +, *, etc.\nWhen we perform arithmetic operations, NumPy will convert the data into arrays for us. While this can help, its not best practice for vectors and matrices, for scalars it will be fine.\nA = [1, 2, 3]\n\nprint(A * B)\nResults: \n# =&gt; [[ 1  4  9]\n# =&gt;  [ 4 10 18]]"
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-4.html#broadcasting",
    "href": "teaching/2023-2024/Programming Level-up/lecture-4.html#broadcasting",
    "title": "Introduction to Numpy",
    "section": "Broadcasting",
    "text": "Broadcasting\nWhen we are working with singletons or scalar values, NumPy will automatically perform the broadcasting for us. So for example, if we want to double each element of an array:\nprint(B * 2)\nResults: \n# =&gt; [[ 2  4  6]\n# =&gt;  [ 8 10 12]]\nNumPy will automatically broadcast the scalar 2 to every element of the shape and size of B."
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-4.html#comparison-with-functions",
    "href": "teaching/2023-2024/Programming Level-up/lecture-4.html#comparison-with-functions",
    "title": "Introduction to Numpy",
    "section": "Comparison with Functions",
    "text": "Comparison with Functions\nNumPy provides, in many cases, both infix and function operations.\n\n\n\n\n\n\n\n\n\nOperation\n\n\nInfix\n\n\nFunction\n\n\n\n\n\n\nAddition\n\n\n+\n\n\nnp.add\n\n\n\n\nSubtraction\n\n\n-\n\n\nnp.subtract\n\n\n\n\nMultiplication\n\n\n*\n\n\nnp.multiply\n\n\n\n\nDivision\n\n\n/\n\n\nnp.divide\n\n\n\n\nMatrix Multiplication\n\n\n@\n\n\nnp.matmul\n\n\n\n\nPower\n\n\n**\n\n\nnp.power\n\n\n\n\nCos/Tan/Sin\n\n\n \n\n\nnp.cos, np.tan, np.sin\n\n\n\n\nSquare root\n\n\n \n\n\nnp.sqrt\n\n\n\n\nExponential, Logarithm\n\n\n \n\n\nnp.exp, np.log\n\n\n\n\nhttps://numpy.org/doc/stable/reference/routines.math.html"
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-4.html#more-complex-operations",
    "href": "teaching/2023-2024/Programming Level-up/lecture-4.html#more-complex-operations",
    "title": "Introduction to Numpy",
    "section": "More complex operations",
    "text": "More complex operations\nThere are a number of different operations one can perform on a matrix. Such as the dot product of two matrices:\nA = np.array([1, 2])\nB = np.array([[1, 2], [3, 4]])\nprint(np.dot(A, B))\nResults: \n# =&gt; [ 7 10]\nThe inner product:\nprint(np.inner(A, B))\nResults: \n# =&gt; [ 5 11]\nOne mystical function is the einsum function. This function can effectively replace other functions like dot and inner but it takes some understanding on how it works. einsum is the application of Einstein Summation, a succinct method of describing the multiplication between matrices. Lets first look at an example of the outer product:\nprint(np.einsum('i,ij-&gt;j', A, B))\nResults: \n# =&gt; [ 7 10]\nOr the inner product:\nprint(np.einsum('j,ij-&gt;i', A, B))\nResults: \n# =&gt; [ 5 11]\nIn einsum we are giving a letter for each dimension of each array we pass to the function.\nSo with: 'i,ij-&gt;j' for the inner product of matrices A and B, we are saying that the first dimension of A (its only dimension) is labelled i, while for B the dimensions are labelled as i and j respectively. The labels that exist in both sequences are summed over.\nEinsum can take a little time to fully understand and appreciate, but it can be a very powerful function with a very succinct syntax.\nhttps://www.youtube.com/watch?v=CLrTj7D2fLM - Khan Academy - Einstein Summation Convention"
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-4.html#vectorizing-a-function",
    "href": "teaching/2023-2024/Programming Level-up/lecture-4.html#vectorizing-a-function",
    "title": "Introduction to Numpy",
    "section": "Vectorizing a function",
    "text": "Vectorizing a function\nLets say you have some function that computes the square of a number:\ndef my_square(x):\n    return x**2\n\nprint(my_square(4))\nResults: \n# =&gt; 16\nAs the function is simple, it takes one argument and returns one argument, we can pass a NumPy array and will get the correct result.\nA = np.arange(1, 10)\nprint(my_square(A))\nResults: \n# =&gt; [ 1  4  9 16 25 36 49 64 81]\nHowever, if the function is more complicated, it will not work.\ndef myfunc(a, b):\n    \"Return a-b if a&gt;b, otherwise return a+b\"\n    if a &gt; b:\n        return a - b\n    else:\n        return a + b\n\nprint(myfunc(A, 2))\nResults: \n# =&gt; Traceback (most recent call last):\n# =&gt;   File \"&lt;stdin&gt;\", line 1, in &lt;module&gt;\n# =&gt;   File \"/tmp/pyqVNaN0\", line 3, in &lt;module&gt;\n# =&gt;   File \"/tmp/babel-jHhWMz/python-nKlyRH\", line 8, in &lt;module&gt;\n# =&gt;     print(myfunc(A, 2))\n# =&gt;   File \"/tmp/babel-jHhWMz/python-nKlyRH\", line 3, in myfunc\n# =&gt;     if a &gt; b:\n# =&gt; ValueError: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()\nTo allow us to use this function over an array, we can use the np.vectorize function to create a new function, which applies myfunc over each element.\nvfunc = np.vectorize(myfunc)\nprint(vfunc(A, 2))\nResults: \n# =&gt; [3 4 1 2 3 4 5 6 7]\nHere we pass the function we want to vectorize myfunc to the np.vectorize function. The return of this function is another function!"
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-4-reveal.html#what-is-numpy",
    "href": "teaching/2023-2024/Programming Level-up/lecture-4-reveal.html#what-is-numpy",
    "title": "Introduction to Numpy",
    "section": "What is NumPy?",
    "text": "What is NumPy?\nNumPy (https://numpy.org/) is one of the fundamental Python libraries for scientific computing. In essence, its aim is to make vector and array processing in Python much more efficient. Therefore, it would be your go-to for (numerical) data processing.\nNumerical data processing with NumPy can, most often that not, be magnitudes faster than what you can write in Python, even if the operations are the same. This is because NumPy is partly written in C.\nFor example, if we want to compute the matrix multiplication of two arrays:\nA = [[1, 4], [9, 5]]  # 2 dimensional 'matrices' A and B\nB = [[1, 2], [3, 4]]\nC = [[0, 0], [0, 0]]  # our result 'pre-allocated' with zeros\n\nfor i in range(len(A)):\n    for j in range(len(B)):\n        for k in range(len(B)):\n            C[i][j] += A[i][k] * B[k][j]\nThe previous example is quite un-weidly. We have to manually loop through the matrices and apply the computation for each element. This can be very slow in Python. NumPy provides a much cleaner and quicker interface:\nimport numpy as np\nA = np.array([[1, 4], [9, 5]])\nB = np.array([[1, 2], [3, 4]])\nC = A @ B  # or np.matmul(A, B)\nprint(C)\nResults: \n# =&gt; [[13 18]\n# =&gt;  [24 38]]"
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-4-reveal.html#install-numpy",
    "href": "teaching/2023-2024/Programming Level-up/lecture-4-reveal.html#install-numpy",
    "title": "Introduction to Numpy",
    "section": "Install NumPy",
    "text": "Install NumPy\nBefore we can use NumPy, we must first install it if its not already. NumPy can easily be installed with one of your package managers of choice. For example, if you want to install via conda:\nconda install numpy\nor with pip:\npip install numpy"
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-4-reveal.html#creating-a-numpy-array",
    "href": "teaching/2023-2024/Programming Level-up/lecture-4-reveal.html#creating-a-numpy-array",
    "title": "Introduction to Numpy",
    "section": "Creating a numpy array",
    "text": "Creating a numpy array\nAs we’ve seen previously, we use np.array to create a numpy array from a Python data type\nA = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\nprint(A)\nResults: \n# =&gt; [[1 2 3]\n# =&gt;  [4 5 6]\n# =&gt;  [7 8 9]]\nWe’ve created a 3x3 matrix of integers. Note that, out-of-the-box, NumPy doesn’t support ragged arrays (matrices that are not rectangular), so this will not work as you expect:\nA = np.array([[1], [1, 2]])"
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-4-reveal.html#basic-attributes",
    "href": "teaching/2023-2024/Programming Level-up/lecture-4-reveal.html#basic-attributes",
    "title": "Introduction to Numpy",
    "section": "Basic attributes",
    "text": "Basic attributes\nA numpy array has various attributes that are useful for our numerical computing. Some of these include:\nA = np.array([[1, 4], [9, 5]])\n\nprint(A.shape)  # the shape of the array\nprint(A.size)   # number of elements\nprint(A.ndim)   # number of dimensions\nprint(A.nbytes) # storage used\nprint(A.dtype)  # data type of elements\nResults: \n# =&gt; (2, 2)\n# =&gt; 4\n# =&gt; 2\n# =&gt; 32\n# =&gt; int64"
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-4-reveal.html#different-data-types",
    "href": "teaching/2023-2024/Programming Level-up/lecture-4-reveal.html#different-data-types",
    "title": "Introduction to Numpy",
    "section": "Different data types",
    "text": "Different data types\nIn the previous example, the elements in the array we int64. But normally, we will see float64. However, there are many other available data types, where each of the different data types affects how much memory is used to represent the data.\n\nint (8, 16, 32, 64)\nuint (unsigned integers)\nbool\nfloat (8, 16, 32, 64)\ncomplex\n\nhttps://numpy.org/doc/stable/user/basics.types.html https://numpy.org/doc/stable/reference/arrays.dtypes.html"
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-4-reveal.html#creating-arrays-with-different-dtypes",
    "href": "teaching/2023-2024/Programming Level-up/lecture-4-reveal.html#creating-arrays-with-different-dtypes",
    "title": "Introduction to Numpy",
    "section": "Creating arrays with different dtypes",
    "text": "Creating arrays with different dtypes\nWhen creating a NumPy array, NumPy will select what it thinks to be the most appropriate data type. However, we can tell NumPy explicitly what the data type should be with the dtype argument.\nA = np.array([[1, 2], [9, 5]], dtype=np.int8)\nprint(A)\nprint(A.dtype)\n\nA = np.array([[1, 2], [9, 5]], dtype=np.float)\nprint(A)\nprint(A.dtype)\nResults: \n# =&gt; [[1 2]\n# =&gt;  [9 5]]\n# =&gt; int8\n# =&gt; [[1. 2.]\n# =&gt;  [9. 5.]]\n# =&gt; float64"
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-4-reveal.html#changing-dtypes",
    "href": "teaching/2023-2024/Programming Level-up/lecture-4-reveal.html#changing-dtypes",
    "title": "Introduction to Numpy",
    "section": "Changing dtypes",
    "text": "Changing dtypes\nIn some cases, we wish to change the data type of arrays after its creation. For this we use the .astype() method. This method takes a single argument: the data type you wish to change the array to.\nA = np.array([1, 2, 3, 4])\nprint(A.dtype)\nint64"
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-4-reveal.html#section",
    "href": "teaching/2023-2024/Programming Level-up/lecture-4-reveal.html#section",
    "title": "Introduction to Numpy",
    "section": "",
    "text": "We could change it to a float64 array:\nA = A.astype(float)\nprint(A.dtype)\nfloat64"
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-4-reveal.html#section-1",
    "href": "teaching/2023-2024/Programming Level-up/lecture-4-reveal.html#section-1",
    "title": "Introduction to Numpy",
    "section": "",
    "text": "Or float32:\nA = A.astype(np.float32)\nprint(A.dtype)\nfloat32"
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-4-reveal.html#different-ways-of-creating-arrays",
    "href": "teaching/2023-2024/Programming Level-up/lecture-4-reveal.html#different-ways-of-creating-arrays",
    "title": "Introduction to Numpy",
    "section": "Different ways of creating arrays",
    "text": "Different ways of creating arrays\nNumPy also provides us with a number of different functions to create arrays. Instead of doing this:\nA = np.array([[0, 0], [0, 0]])\nWe could instead use the np.zeros function, passing a tuple where each element of the tuple describes how many elements should be made in each dimension:\nA = np.zeros((2,)) # 1 dimensional\nA = np.zeros((2, 2))  # 2 dimensional\nA = np.zeros((2, 5, 5))  # 3 dimensional\nAnother commonly used array creation function is the np.random.randn function. This creates an array where elements are sampled from a normal distribution.\nA = np.random.randn(2, 2)\nprint(A)\nResults: \n# =&gt; [[-0.68213848 -0.44274759]\n# =&gt;  [ 0.6748596   0.64244208]]\nNote the interface is a little different than .zeros, where instead of passing a tuple, we pass multiple arguments to the function.\nIt is also convenient to create arrays with ranges of elements.\nA = np.arange(5, 10) # optional step\nprint(A)\nResults: \n# =&gt; [5 6 7 8 9]\nA = np.linspace(5, 10, 20)\nprint(A)\nResults: \n# =&gt; [ 5.          5.26315789  5.52631579  5.78947368  6.05263158  6.31578947\n# =&gt;   6.57894737  6.84210526  7.10526316  7.36842105  7.63157895  7.89473684\n# =&gt;   8.15789474  8.42105263  8.68421053  8.94736842  9.21052632  9.47368421\n# =&gt;   9.73684211 10.        ]\nThere are many more ways to create arrays. Some include:\n\nnp.ones - a matrix of 1’s\nnp.eye - an identity matrix\nnp.diag - create a matrix with supplied elements across the diagonal\nnp.fromfunction - load elements from the return of a function\nnp.fromfile - load elements from a data file\n\nThough, the best resource for understanding is NumPy’s own documentation on the subject: https://numpy.org/doc/stable/user/basics.creation.html"
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-4-reveal.html#slicing-numpy-arrays",
    "href": "teaching/2023-2024/Programming Level-up/lecture-4-reveal.html#slicing-numpy-arrays",
    "title": "Introduction to Numpy",
    "section": "Slicing NumPy arrays",
    "text": "Slicing NumPy arrays\nIn native Python, when we have a ‘matrix’ like data structure (just a list of lists), and we want to access a particular element from this matrix, we have to do something like:\nA = [[1, 2], [3, 4]]\nprint(A[1][0])\nResults: \n# =&gt; 3\nHowever, in NumPy, we seperate the indexes by comma:\nA = np.array([[1, 2], [3, 4]])\nprint(A[1, 0])\nResults: \n# =&gt; 3\nIf we wanted to get all elements from the 2nd column we would use the : notation. For example:\nA = np.array([[1, 2], [3, 4]])\nprint(A[:, 1])\nResults: \n# =&gt; [2 4]\nLikewise, all elements from the 2nd row:\nprint(A[1, :])\nResults: \n# =&gt; [3 4]\nNote that when we slice an array, we are not copying the elements:\nA = np.array([[1, 2], [3, 4]])\nb = A[:, 1]\n\nb[0] = 10\n\nprint(A)\nResults: \n# =&gt; [[ 1 10]\n# =&gt;  [ 3  4]]\nAny modification you make to the b variable will also affect A. For that we must use .copy()\nA = np.array([[1, 2], [3, 4]])\nb = A[:, 1].copy()\n...\nIf we have a multi-dimensional array, to which we wish to index on the final dimension, one way to achieve this is by doing the following:\nA = np.random.randn(10, 2, 5, 4)  # our array to slice\nA[:, :, :, 1:2]  # slice on the last dimension\nThis can get pretty tedious the more that the number of dimensions increases. But! we have one syntactical shortcut at our disposal: the ellipses ‘…’. Using the ellipses in place of the many ‘:’ slices on each dimension, we’re telling NumPy to just take all elements from the prior dimensions. For example:\nA[..., 1:2]  # same slice on the last dimension"
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-4-reveal.html#boolean-indexing",
    "href": "teaching/2023-2024/Programming Level-up/lecture-4-reveal.html#boolean-indexing",
    "title": "Introduction to Numpy",
    "section": "Boolean Indexing",
    "text": "Boolean Indexing\nNumPy arrays can also be composed of boolean elements\nA = np.array([[1, -1], [0, 5]])\nprint(A &gt; 0)\nResults: \n# =&gt; [[ True False]\n# =&gt;  [False  True]]\nAnd we can also use boolean elements to help with indexing:\nvalues_above_zero = A[A &gt; 0]\nprint(values_above_zero)\nResults: \n# =&gt; [1 5]\nTherefore we can apply computations to only part of the array using this indexing feature:\nmask = A &gt; 0\nA[mask] = A[mask] + 10\nprint(A)\nResults: \n# =&gt; [[11 -1]\n# =&gt;  [ 0 15]]"
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-4-reveal.html#reshape",
    "href": "teaching/2023-2024/Programming Level-up/lecture-4-reveal.html#reshape",
    "title": "Introduction to Numpy",
    "section": "Reshape",
    "text": "Reshape\nAfter an array has been created, we can modify its structure/shape using various functions. The first we shall look at is .reshape. For example, let us create a vector of 4 elements and then reshape it into an array of 2x2 elements. Of course, the new shape of the array must be proportional to the original number of elements: 2x2 elements = 4 elements.\nA = np.arange(1, 5)\n\nmat_A = A.reshape(2, 2)\nprint(mat_A)\nprint(A)  # A is not changed! No need for copy\nResults: \n# =&gt; [[1 2]\n# =&gt;  [3 4]]\n# =&gt; [1 2 3 4]"
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-4-reveal.html#flatten",
    "href": "teaching/2023-2024/Programming Level-up/lecture-4-reveal.html#flatten",
    "title": "Introduction to Numpy",
    "section": "Flatten",
    "text": "Flatten\nIf we wanted to take a 2d array and reshape it into a vector, we could of course use the .reshape function again. But we could also use .flatten.\nflat_A = mat_A.flatten()\nprint(flat_A)\nResults: \n# =&gt; [1 2 3 4]\nWhen specifying the new dimensionality of the reshaped array, -1 is a shortcut to specify the dimensionality to allow reshaping to occur correctly. For example:\nA = np.arange(1, 5)\nprint(A)\n\nprint(A.reshape(2, -1))\nResults: \n# =&gt; [1 2 3 4]\n# =&gt; [[1 2]\n# =&gt;  [3 4]]\nWe’re telling NumPy to create an array with 2 elements on the 1st dimension, and then however many elements on the second dimension."
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-4-reveal.html#add-a-dimension",
    "href": "teaching/2023-2024/Programming Level-up/lecture-4-reveal.html#add-a-dimension",
    "title": "Introduction to Numpy",
    "section": "Add a dimension",
    "text": "Add a dimension\nWe can add and remove dimensions using .expand_dims and .squeeze, respectively.\nprint(A)\nprint(np.expand_dims(A, 1))\nResults: \n# =&gt; [1 2 3 4]\n# =&gt; [[1]\n# =&gt;  [2]\n# =&gt;  [3]\n# =&gt;  [4]]\nWe are taking a vector and adding a dimension. Note that we have to use np.expand_dims passing the object we want to expand and not A.expand_dims.\nWe can use an indexing trick with None to do the expansion in just the same way:\nprint(A)\nprint(A[:, None])\nResults: \n# =&gt; [1 2 3 4]\n# =&gt; [[1]\n# =&gt;  [2]\n# =&gt;  [3]\n# =&gt;  [4]]\nWhere None indicates to NumPy where we want to add the new dimension."
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-4-reveal.html#remove-a-dimension",
    "href": "teaching/2023-2024/Programming Level-up/lecture-4-reveal.html#remove-a-dimension",
    "title": "Introduction to Numpy",
    "section": "Remove a dimension",
    "text": "Remove a dimension\nIf we want to instead remove a dimension, we can use .squeeze()\nprint(A[:, None].squeeze(1))\nResults: \n# =&gt; [1 2 3 4]\nWe are removing the 2nd dimension, but note that the elements must be singletons. So you cannot squeeze a 2x2 array."
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-4-reveal.html#matrix-transpose",
    "href": "teaching/2023-2024/Programming Level-up/lecture-4-reveal.html#matrix-transpose",
    "title": "Introduction to Numpy",
    "section": "Matrix transpose",
    "text": "Matrix transpose\nAnother useful feature is the matrix transpose:\nprint(mat_A)\n\nprint(mat_A.transpose())\nResults: \n# =&gt; [[1 2]\n# =&gt;  [3 4]]\n# =&gt; [[1 3]\n# =&gt;  [2 4]]\nor even:\n    print(mat_A.T)\nResults: \n# =&gt; [[1 3]\n# =&gt;  [2 4]]"
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-4-reveal.html#composing-arrays",
    "href": "teaching/2023-2024/Programming Level-up/lecture-4-reveal.html#composing-arrays",
    "title": "Introduction to Numpy",
    "section": "Composing arrays",
    "text": "Composing arrays\nIf we have multiple arrays we want to ‘join’ together, we can use np.hstack for horizontally joining, or np.vstack for vertically joining arrays. Note the dimensions must match in the direction your stacking.\nA = np.array([1, 2, 3])\nB = np.array([4, 5, 6])\n\nprint(np.hstack([A, B]))\n[1 2 3 4 5 6]\nprint(np.vstack([A, B]))\nResults: \n# =&gt; [[1 2 3]\n# =&gt;  [4 5 6]]\nhstack and vstack can be useful when the required output shape is simply defined. However, there is a more general function - np.concatenate - that will be more often useful to us.\nprint(np.concatenate([A, B], axis=0))\n[1 2 3 4 5 6]\nHere we see that we can achieve the same result as np.hstack using concatenate. Notice also that there is a second argument to the concatenate function: the dimension upon which the concatenation will take place.\nhttps://numpy.org/doc/stable/reference/generated/numpy.concatenate.html"
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-4-reveal.html#arithmetic-operations-1",
    "href": "teaching/2023-2024/Programming Level-up/lecture-4-reveal.html#arithmetic-operations-1",
    "title": "Introduction to Numpy",
    "section": "Arithmetic Operations",
    "text": "Arithmetic Operations\nWe have already seen some basic examples of arithmetic operations in NumPy. But its worth looking at these in detail.\nOne of the best reasons to use NumPy is that the computations are vectorized and can be broadcast. We’ll see examples of what these mean.\nA = np.array([1, 2, 3])\nB = np.array([[1, 2, 3],\n                [4, 5, 6]])\n\nprint(A * B)\nResults: \n# =&gt; [[ 1  4  9]\n# =&gt;  [ 4 10 18]]\nWe can perform vector and matrix arithmetic using Python’s infix operators like +, *, etc.\nWhen we perform arithmetic operations, NumPy will convert the data into arrays for us. While this can help, its not best practice for vectors and matrices, for scalars it will be fine.\nA = [1, 2, 3]\n\nprint(A * B)\nResults: \n# =&gt; [[ 1  4  9]\n# =&gt;  [ 4 10 18]]"
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-4-reveal.html#broadcasting",
    "href": "teaching/2023-2024/Programming Level-up/lecture-4-reveal.html#broadcasting",
    "title": "Introduction to Numpy",
    "section": "Broadcasting",
    "text": "Broadcasting\nWhen we are working with singletons or scalar values, NumPy will automatically perform the broadcasting for us. So for example, if we want to double each element of an array:\nprint(B * 2)\nResults: \n# =&gt; [[ 2  4  6]\n# =&gt;  [ 8 10 12]]\nNumPy will automatically broadcast the scalar 2 to every element of the shape and size of B."
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-4-reveal.html#comparison-with-functions",
    "href": "teaching/2023-2024/Programming Level-up/lecture-4-reveal.html#comparison-with-functions",
    "title": "Introduction to Numpy",
    "section": "Comparison with Functions",
    "text": "Comparison with Functions\nNumPy provides, in many cases, both infix and function operations.\n\n\n\n\n\n\n\n\n\nOperation\n\n\nInfix\n\n\nFunction\n\n\n\n\n\n\nAddition\n\n\n+\n\n\nnp.add\n\n\n\n\nSubtraction\n\n\n-\n\n\nnp.subtract\n\n\n\n\nMultiplication\n\n\n*\n\n\nnp.multiply\n\n\n\n\nDivision\n\n\n/\n\n\nnp.divide\n\n\n\n\nMatrix Multiplication\n\n\n@\n\n\nnp.matmul\n\n\n\n\nPower\n\n\n**\n\n\nnp.power\n\n\n\n\nCos/Tan/Sin\n\n\n \n\n\nnp.cos, np.tan, np.sin\n\n\n\n\nSquare root\n\n\n \n\n\nnp.sqrt\n\n\n\n\nExponential, Logarithm\n\n\n \n\n\nnp.exp, np.log\n\n\n\n\nhttps://numpy.org/doc/stable/reference/routines.math.html"
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-4-reveal.html#more-complex-operations",
    "href": "teaching/2023-2024/Programming Level-up/lecture-4-reveal.html#more-complex-operations",
    "title": "Introduction to Numpy",
    "section": "More complex operations",
    "text": "More complex operations\nThere are a number of different operations one can perform on a matrix. Such as the dot product of two matrices:\nA = np.array([1, 2])\nB = np.array([[1, 2], [3, 4]])\nprint(np.dot(A, B))\nResults: \n# =&gt; [ 7 10]\nThe inner product:\nprint(np.inner(A, B))\nResults: \n# =&gt; [ 5 11]\nOne mystical function is the einsum function. This function can effectively replace other functions like dot and inner but it takes some understanding on how it works. einsum is the application of Einstein Summation, a succinct method of describing the multiplication between matrices. Lets first look at an example of the outer product:\nprint(np.einsum('i,ij-&gt;j', A, B))\nResults: \n# =&gt; [ 7 10]\nOr the inner product:\nprint(np.einsum('j,ij-&gt;i', A, B))\nResults: \n# =&gt; [ 5 11]\nIn einsum we are giving a letter for each dimension of each array we pass to the function.\nSo with: 'i,ij-&gt;j' for the inner product of matrices A and B, we are saying that the first dimension of A (its only dimension) is labelled i, while for B the dimensions are labelled as i and j respectively. The labels that exist in both sequences are summed over.\nEinsum can take a little time to fully understand and appreciate, but it can be a very powerful function with a very succinct syntax.\nhttps://www.youtube.com/watch?v=CLrTj7D2fLM - Khan Academy - Einstein Summation Convention"
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-4-reveal.html#vectorizing-a-function",
    "href": "teaching/2023-2024/Programming Level-up/lecture-4-reveal.html#vectorizing-a-function",
    "title": "Introduction to Numpy",
    "section": "Vectorizing a function",
    "text": "Vectorizing a function\nLets say you have some function that computes the square of a number:\ndef my_square(x):\n    return x**2\n\nprint(my_square(4))\nResults: \n# =&gt; 16\nAs the function is simple, it takes one argument and returns one argument, we can pass a NumPy array and will get the correct result.\nA = np.arange(1, 10)\nprint(my_square(A))\nResults: \n# =&gt; [ 1  4  9 16 25 36 49 64 81]\nHowever, if the function is more complicated, it will not work.\ndef myfunc(a, b):\n    \"Return a-b if a&gt;b, otherwise return a+b\"\n    if a &gt; b:\n        return a - b\n    else:\n        return a + b\n\nprint(myfunc(A, 2))\nResults: \n# =&gt; Traceback (most recent call last):\n# =&gt;   File \"&lt;stdin&gt;\", line 1, in &lt;module&gt;\n# =&gt;   File \"/tmp/pyqVNaN0\", line 3, in &lt;module&gt;\n# =&gt;   File \"/tmp/babel-jHhWMz/python-nKlyRH\", line 8, in &lt;module&gt;\n# =&gt;     print(myfunc(A, 2))\n# =&gt;   File \"/tmp/babel-jHhWMz/python-nKlyRH\", line 3, in myfunc\n# =&gt;     if a &gt; b:\n# =&gt; ValueError: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()\nTo allow us to use this function over an array, we can use the np.vectorize function to create a new function, which applies myfunc over each element.\nvfunc = np.vectorize(myfunc)\nprint(vfunc(A, 2))\nResults: \n# =&gt; [3 4 1 2 3 4 5 6 7]\nHere we pass the function we want to vectorize myfunc to the np.vectorize function. The return of this function is another function!"
  },
  {
    "objectID": "teaching/2023-2024/Machine Learning/lab-3.html",
    "href": "teaching/2023-2024/Machine Learning/lab-3.html",
    "title": "K-Nereast Neighbours",
    "section": "",
    "text": "In this lab, we’re going to create a K-Nearest Neighbour (KNN) classifier. This lab is optional, and will not be marked.\n\nDownload the Data\nIn creating the KNN, we’ll use another toy dataset, the wine quality dataset https://archive.ics.uci.edu/dataset/186/wine+quality. Specifically, the red wine.\nTo get access to the dataset, click on the download button. Inside the now downloaded folder, there will be two CSV files, one for red wine, and another for white wine. For this lab, we’ll be using the red wine dataset.\n\n\nLoad the Data\nThe next task is to load the data in Python. For this section, we’ll want to write some code to load the red wine CSV file as a pandas dataframe.\n\n\nSplit the data\nNow that we’ve loaded the data as a pandas dataframe, we’ll partition the data off into a train and test subset.\nRandomly sample 70% of the data for training, and the other 30% will be used for testing.\n\n\nNormalise the data\nTo ensure all of the columns are within the same range, we’ll normalise them (except from the score column of course!).\nWe can normalise a column \\(x\\) by the following equation:\n\\[\n\\text{normalise}(x) = \\frac{x - \\min_x}{\\max_x - \\min_x}\n\\]\nTherefore, we’ll need to calculate the \\(\\min\\) and \\(\\max\\) values of each column in the training subset, then apply the normalising function, using these values.\n\n\nLooking at the correlations\nUsing the training subset, we’ll want to find out which columns to use in our classifier.\nWe’ll visually inspect the correlations between the input columns and the target score column.\nCreate a series of 2D scatter plots with an input column across the \\(x\\)-axis, and the target score column across the \\(y\\)-axis.\nWhich of these columns show a strong relationship between the input and target columns?\n\n\nCreate a K-Nearest Neighbour\nCreate a KNN classifier and \\(k=3\\), using some of the input colums (the best ones as decided by the correlation plots).\n\n\nCreate Classification performance metrics\nCreate a series of classification metrics for the new KNN classifier:\n\n\\(F_1\\) score (averaged over all classes)\nPlot a confusion matrix.\n\n\n\nPlot performance metrics for different \\(k\\)\nUsing the KNN classifier, modify the \\(k\\) value from 1 to \\(N\\) and plot the \\(F_1\\) score for each value of \\(k\\). What is the optimal value for \\(k\\)?"
  },
  {
    "objectID": "teaching/2023-2024/Machine Learning/index.html",
    "href": "teaching/2023-2024/Machine Learning/index.html",
    "title": "Machine Learning",
    "section": "",
    "text": "Welcome to the Machine Learning course developed for the MIR Masters Engineering and Complex Systems. In this series of lectures, we’re going to learn about how to learn! Specifically, we’re going to learn about how computers learn using Machine Learning algorithms. We’ll learn about the basic understanding of learning algorithms, as well as specific algorithms that include: linear models, support vector machines, and clustering methods. In addition to these algorithms, we will also look at a key part of using any learning algorithm – evaluating it!\nBelow you can find the lectures presented in this course, in a HTML or PDF format. If you have any questions or concerns, you can contact me using my email address jay.morgan@univ-tln.fr"
  },
  {
    "objectID": "teaching/2023-2024/Machine Learning/index.html#lectures",
    "href": "teaching/2023-2024/Machine Learning/index.html#lectures",
    "title": "Machine Learning",
    "section": "Lectures",
    "text": "Lectures\n\nLecture 1 - Introduction\nLecture 2 - Linear Models\nLecture 3 - Evaluation of Models\nLecture 4 - Support Vector Machines\nLecture 5 - K-Nearest Neighbours & K-Means"
  },
  {
    "objectID": "teaching/2023-2024/Machine Learning/index.html#labs",
    "href": "teaching/2023-2024/Machine Learning/index.html#labs",
    "title": "Machine Learning",
    "section": "Labs",
    "text": "Labs\n\nLab 1 - Linear Models\nLab 2 - Evaluation of Models\nLab 3 - K-Nearest Neighbours"
  },
  {
    "objectID": "teaching/2023-2024/Machine Learning/lecture-3.html",
    "href": "teaching/2023-2024/Machine Learning/lecture-3.html",
    "title": "Model Performance",
    "section": "",
    "text": "We’ve seen in the previous lecture how we can fit a linear regression model to a set of data, and we can measure the performance of this model.\nBut we do not understand how well this model works in the ‘real-world’, how well it performs on data that has not yet been ‘seen’, how well the model generalises to this unknown data.\nSo, when we want to create a machine learning model, we usually take our data, and split into two (sometimes three) sets of data. These different sets are named:\n\ntraining set,\ntesting set,\nand (optionally) validation set.\n\n\n\n\nThe training dataset, is the set of data, that we’re allowing the model to `see’ or learn from.\nIn our example of the linear regression, this is the set of data points to which we find the optimal parameters of our model.\nIt is not very useful to evaluate our model’s performance with the training set as it doesn’t tell us how well it’s actually doing (we’ll come back to this when we talk about over-/under-fitting).\n\n\n\nThe testing set is the set of data that we use to evaluate the generalisation of our machine learning model. The model is not allowed to use this set of data during training, but it is simply used for the evaluation of the model.\nIn general the testing set is between 10-30% of the overall available data, but this rule is not something dictated, and may vary depending on the amount of data available and the overall use case.\nOnce the 10-30% of the data has been sampled for the testing set, the rest of the data can be used for the training and validation sets.\n\n\n\nIf we have an iterative optimisation process (such as what we saw with gradient descent), we might want to know how well our model is possibly generalising to unseen data.\nThe validation dataset, is the set of data that we use to measure the generalisation of our model during the course of its learning process. Like the test set, this validation data should not be used to train the model, but only used to measure the model’s generalisation during the lifetime of the learning process."
  },
  {
    "objectID": "teaching/2023-2024/Machine Learning/lecture-3.html#why-do-we-have-different-sets-of-data",
    "href": "teaching/2023-2024/Machine Learning/lecture-3.html#why-do-we-have-different-sets-of-data",
    "title": "Model Performance",
    "section": "",
    "text": "We’ve seen in the previous lecture how we can fit a linear regression model to a set of data, and we can measure the performance of this model.\nBut we do not understand how well this model works in the ‘real-world’, how well it performs on data that has not yet been ‘seen’, how well the model generalises to this unknown data.\nSo, when we want to create a machine learning model, we usually take our data, and split into two (sometimes three) sets of data. These different sets are named:\n\ntraining set,\ntesting set,\nand (optionally) validation set."
  },
  {
    "objectID": "teaching/2023-2024/Machine Learning/lecture-3.html#training-set",
    "href": "teaching/2023-2024/Machine Learning/lecture-3.html#training-set",
    "title": "Model Performance",
    "section": "",
    "text": "The training dataset, is the set of data, that we’re allowing the model to `see’ or learn from.\nIn our example of the linear regression, this is the set of data points to which we find the optimal parameters of our model.\nIt is not very useful to evaluate our model’s performance with the training set as it doesn’t tell us how well it’s actually doing (we’ll come back to this when we talk about over-/under-fitting)."
  },
  {
    "objectID": "teaching/2023-2024/Machine Learning/lecture-3.html#testing-set",
    "href": "teaching/2023-2024/Machine Learning/lecture-3.html#testing-set",
    "title": "Model Performance",
    "section": "",
    "text": "The testing set is the set of data that we use to evaluate the generalisation of our machine learning model. The model is not allowed to use this set of data during training, but it is simply used for the evaluation of the model.\nIn general the testing set is between 10-30% of the overall available data, but this rule is not something dictated, and may vary depending on the amount of data available and the overall use case.\nOnce the 10-30% of the data has been sampled for the testing set, the rest of the data can be used for the training and validation sets."
  },
  {
    "objectID": "teaching/2023-2024/Machine Learning/lecture-3.html#validation-set",
    "href": "teaching/2023-2024/Machine Learning/lecture-3.html#validation-set",
    "title": "Model Performance",
    "section": "",
    "text": "If we have an iterative optimisation process (such as what we saw with gradient descent), we might want to know how well our model is possibly generalising to unseen data.\nThe validation dataset, is the set of data that we use to measure the generalisation of our model during the course of its learning process. Like the test set, this validation data should not be used to train the model, but only used to measure the model’s generalisation during the lifetime of the learning process."
  },
  {
    "objectID": "teaching/2023-2024/Machine Learning/lecture-3.html#the-ability-of-the-model",
    "href": "teaching/2023-2024/Machine Learning/lecture-3.html#the-ability-of-the-model",
    "title": "Model Performance",
    "section": "The ability of the model",
    "text": "The ability of the model\nWhen we created a linear regression model, we saw that it was not possible to predict the house price exactly, there was always some error that we could not overcome with the linear model.\nIf we have a model complicated model, such as polynomial regression (where we have polynomial terms in line equation), it may be possible to fit every training data point exactly. But is that what we want?.\nIn this section, we’ll explore the concept of over- and under-fitting, and how we can use the testing set to understanding if these processes are happening."
  },
  {
    "objectID": "teaching/2023-2024/Machine Learning/lecture-3.html#over-fitting",
    "href": "teaching/2023-2024/Machine Learning/lecture-3.html#over-fitting",
    "title": "Model Performance",
    "section": "Over-fitting",
    "text": "Over-fitting\nWe’ll begin with over-fitting. Over-fitting occurs when our model has a very high or perfect performance on the testing set, but does not perform well at all on the testing set.\nThere may be many reasons for this happening, such as the model being very complex, having too many variables."
  },
  {
    "objectID": "teaching/2023-2024/Machine Learning/lecture-3.html#under-fitting",
    "href": "teaching/2023-2024/Machine Learning/lecture-3.html#under-fitting",
    "title": "Model Performance",
    "section": "Under-fitting",
    "text": "Under-fitting\nUnder-fitting, as the name suggests is what happens when we cannot fit the model to the data, it doesn’t even perform well on the training data, the data the model is allowed to learn from. This can happen when the model is too simple and cannot learn the intrinsic relationship between the input and output. For example, trying to use a linear model to learn from data that is not linear by nature."
  },
  {
    "objectID": "teaching/2023-2024/Machine Learning/lecture-3.html#validation-curves",
    "href": "teaching/2023-2024/Machine Learning/lecture-3.html#validation-curves",
    "title": "Model Performance",
    "section": "Validation Curves",
    "text": "Validation Curves\nIf we have an iterative learning process, we can use the training and validation datasets to measure whether our model is over-fitting, and stop training the model at an optimal point before it overfits.\nTo do this, at every iteration of the learning process, we evaluate the model’s performance using both the training and validation datasets. If the performance on both datasets is decreasing we can infer that the model is learning something useful that helps with it’s generalisation to unseen data.\nHowever, if the performance on the training set is decreasing, while the performance on the validation dataset is no longer decreasing or indeed increasing, we know the model is over-fitting to the training data."
  },
  {
    "objectID": "teaching/2023-2024/Machine Learning/lecture-3.html#biasvariance-tradeoff",
    "href": "teaching/2023-2024/Machine Learning/lecture-3.html#biasvariance-tradeoff",
    "title": "Model Performance",
    "section": "Bias/Variance Tradeoff",
    "text": "Bias/Variance Tradeoff\nThe Bias/Variance tradeoff is a property of machine learning models. It describes a model’s expected generalisation abilities based upon how the parameters are estimated across a dataset.\n\nBias - the model’s `flexibility’ to represent the true relationship in the data. Model’s with low bias have a tendency to underfit. An example would be a linear model model trying to fit against non-linear function.\nVariance - the impact that a single sample in the data has on the model. Model’s with high variance tend to overfit to the training data."
  },
  {
    "objectID": "teaching/2023-2024/Machine Learning/lecture-3.html#metrics",
    "href": "teaching/2023-2024/Machine Learning/lecture-3.html#metrics",
    "title": "Model Performance",
    "section": "Metrics",
    "text": "Metrics\nNow that we’ve looked at the various sets of data, and the potential scenarios when we fit a model, we’ll now want to look at some actual methods of evaluating our model.\nThese we call metrics. Metrics are values that help us understand how well a model might perform in the real world. Metrics are helpful to explain the predictive power of a model with one value.\nThere are many different types of metrics that can be used depending on the class of problem that is being dealt with. For instance, there are different set of metrics for Regression and classification problems.\nWe’ll first look at some metrics we can use to evaluate a regression model (some of which we’ve already seen in the Linear models lecture), and then we’ll have a look at metrics for a classification task."
  },
  {
    "objectID": "teaching/2023-2024/Machine Learning/lecture-3.html#mean-squared-error-mse",
    "href": "teaching/2023-2024/Machine Learning/lecture-3.html#mean-squared-error-mse",
    "title": "Model Performance",
    "section": "Mean Squared Error (MSE)",
    "text": "Mean Squared Error (MSE)\nA mean squared error (sometimes called the sum of squared residuals) is the measure of mean magnitude between two sets of points \\(y, \\overline{y}\\).\nThe formula for MSE is:\n\\(\\text{MSE} = \\frac{1}{N} \\sum_i^N (y_i, \\overline{y_i})^2\\)\nfor \\(N\\) points.\nMSE is always non-negative, and the lower the MSE the better."
  },
  {
    "objectID": "teaching/2023-2024/Machine Learning/lecture-3.html#root-mean-squared-error-rmse",
    "href": "teaching/2023-2024/Machine Learning/lecture-3.html#root-mean-squared-error-rmse",
    "title": "Model Performance",
    "section": "Root Mean Squared Error (RMSE)",
    "text": "Root Mean Squared Error (RMSE)\n\\[\n\\text{RMSE} = \\sqrt{\\text{MSE}}\n\\]\nDue to the squared error term, larger errors have a large effect on the outcome of the equation, so both RMSE and MSE is sensitive to outliers.\nMSE’s error is measured in squared units, while RMSE is measured in the same unit as the target."
  },
  {
    "objectID": "teaching/2023-2024/Machine Learning/lecture-3.html#mean-absolute-error-mae",
    "href": "teaching/2023-2024/Machine Learning/lecture-3.html#mean-absolute-error-mae",
    "title": "Model Performance",
    "section": "Mean Absolute Error (MAE)",
    "text": "Mean Absolute Error (MAE)\nMean absolute error or MAE is one objective function for measure the \\(L_1\\) between two sets of points.\n\\(\\text{MAE} = \\frac{1}{N} \\sum_i^N | y_i - \\overline{y_i} |\\)\nfor \\(N\\) of points.\nLike MSE, RMSE, the lower the MAE value, the better the fit on the statistical model."
  },
  {
    "objectID": "teaching/2023-2024/Machine Learning/lecture-3.html#binary-classification-labelling-as-positive-or-negative",
    "href": "teaching/2023-2024/Machine Learning/lecture-3.html#binary-classification-labelling-as-positive-or-negative",
    "title": "Model Performance",
    "section": "Binary classification & labelling as positive or negative",
    "text": "Binary classification & labelling as positive or negative\nWe now move onto some of the more typical classification metrics. But first, we must first understand when our classifier predicts positive or negative in a binary classification task.\nLet’s say we have a binary classifier \\(\\mathcal{M}\\) which predicts the positive class if the predicted probability is \\(\\geq 0.5\\). I.e.:\n\\[\nL(x)  = \\begin{cases}\n1 & \\text{if}, \\; \\mathcal{M}(x) \\geq 0.5 \\\\\n0 & \\text{otherwise}\n\\end{cases}\n\\]\nwhere \\(L\\) is our labelling function.\nHere 0.5 is the threshold for predicting the positive class."
  },
  {
    "objectID": "teaching/2023-2024/Machine Learning/lecture-3.html#tptnfpfn",
    "href": "teaching/2023-2024/Machine Learning/lecture-3.html#tptnfpfn",
    "title": "Model Performance",
    "section": "TP/TN/FP/FN",
    "text": "TP/TN/FP/FN\nBefore we look at other metrics to evaluate our classification metrics, I first want to describe these acronyms.\n\nList :B_column:BMCOL:\n\nTP - True-Positive – our model has predicted positive (it was correct) and the actual label is positive.\nTN - True-Negative – our model has predicted negative (it was correct) and the actual label is negative.\nFP - False-Positive – our model has predicted positive (it was wrong) the actual label was negative.\nFN - False-Negative – our model has predicted negative (it was wrong) the actual label was positive.\n\nDiagram :B_column:BMCOL:"
  },
  {
    "objectID": "teaching/2023-2024/Machine Learning/lecture-3.html#accuracy",
    "href": "teaching/2023-2024/Machine Learning/lecture-3.html#accuracy",
    "title": "Model Performance",
    "section": "Accuracy",
    "text": "Accuracy\nIn a binary classification task, accuracy is measured using:\n\\[\n\\text{Accuracy} = \\frac{TP+TN}{TP+TN+FP+FN}\n\\]\nor multi-classification:\n\\[\n\\text{Accuracy} = \\frac{\\text{number of correct}}{\\text{number of samples}}\n\\]\nThe range of accuracy is in \\([0, 1]\\), the higher the value of accuracy the better. Accuracy is often presented in the form of a percentage i.e. \\(100 \\cdot \\text{Accuracy}\\)"
  },
  {
    "objectID": "teaching/2023-2024/Machine Learning/lecture-3.html#precision",
    "href": "teaching/2023-2024/Machine Learning/lecture-3.html#precision",
    "title": "Model Performance",
    "section": "Precision",
    "text": "Precision\nMeasuring the precision tells us how many how accurate our model was in predicting positive cases. Here we have \\(TP\\) or the number of True-Positive, divided by \\(TP + FP\\) where \\(FP\\) is the number of False-Positive cases.\n\\[\n\\frac{TP}{TP + FP}\n\\]\nValid values for the precision metric are in the range \\([0, 1]\\) where the higher the value the better."
  },
  {
    "objectID": "teaching/2023-2024/Machine Learning/lecture-3.html#recall",
    "href": "teaching/2023-2024/Machine Learning/lecture-3.html#recall",
    "title": "Model Performance",
    "section": "Recall",
    "text": "Recall\nRecall tells us: out of all the positive cases, how many of them were actually found/predicted to be positive. How many of these positive cases was our model able to recall?\n\\[\n\\frac{TP}{TP+FN}\n\\]\nLike precision, recall is in the range \\([0, 1]\\) where the higher the value the better the recall."
  },
  {
    "objectID": "teaching/2023-2024/Machine Learning/lecture-3.html#confusion-matrix",
    "href": "teaching/2023-2024/Machine Learning/lecture-3.html#confusion-matrix",
    "title": "Model Performance",
    "section": "Confusion Matrix",
    "text": "Confusion Matrix\nA confusion matrix is a visual representation of these different type of predictive cases (TP/TN/FP/FN).\nAn optimal confusion matrix, is a diagonal matrix (all entries outside of the diagonal are zero). Here is one example of a confusion matrix.\n\n\n\n\n\n\n\n\n\n\n \n\n\n \n\n\nPredicted\n\n\n \n\n\n\n\n \n\n\n \n\n\nPositive\n\n\nNegative\n\n\n\n\nActual\n\n\nPositive\n\n\n5\n\n\n2\n\n\n\n\n \n\n\nNegative\n\n\n3\n\n\n1\n\n\n\n\n\nValues :B_column:BMCOL:\n\nTP = 5\nTN = 1\nFP = 3\nFN = 2\n\nCalculation :B_column:BMCOL:\n\nPrecision = \\(\\frac{5}{5+3} = 0.625\\)\nRecall = \\(\\frac{5}{5+2}\\) \\(= 0.714\\)"
  },
  {
    "objectID": "teaching/2023-2024/Machine Learning/lecture-3.html#f_beta-f_1",
    "href": "teaching/2023-2024/Machine Learning/lecture-3.html#f_beta-f_1",
    "title": "Model Performance",
    "section": "\\(F_\\beta\\) & \\(F_1\\)",
    "text": "\\(F_\\beta\\) & \\(F_1\\)\nWith the precision/recall metrics, it is trivial to optimise for one over the over:\n\nWe can achieve perfect precision (\\(\\text{precision} = 1\\)) by predicting everything is negative (no false positives)\nWe can achieve perfect recall (\\(\\text{recall} = 1\\)) by predicting that everything is positive (no false negatives).\n\nBut predicting everything is negative, or everything is positive is not really a useful model. So we have another metric that is the harmonic combination of precision and recall: \\(F_1\\) and \\(F_\\beta\\) score.\n\\[\nF_\\beta = (1 + \\beta^2) \\frac{p \\cdot r}{\\beta^2 p + r}\n\\]\nwhere \\(p, r\\) is the precision and recall metric respectively. For the \\(F_1\\) score, we simple set \\(\\beta = 1\\)."
  },
  {
    "objectID": "teaching/2023-2024/Machine Learning/lecture-3.html#receiver-operating-characteristic-roc",
    "href": "teaching/2023-2024/Machine Learning/lecture-3.html#receiver-operating-characteristic-roc",
    "title": "Model Performance",
    "section": "Receiver Operating Characteristic (ROC)",
    "text": "Receiver Operating Characteristic (ROC)\nIn the previous slides, we have labelled our samples as positive if our classifier predicts \\(\\geq 0.5\\), else it is labelled as negative. This \\(0.5\\) is our threshold for our labelling function. But we can vary this threshold if we want. Lowering the threshold will typically mean our classifier labels positive cases more often. While increasing the threshold makes the classifier more conservative, and typically predicts labels positive cases less often.\nIf we vary this threshold from 0 to 1 and calculate the true- and false-positive rate, we can visualise something we call the Receiver Operating Characteristic or ROC for short.\n\nThis ROC curve, with the dotted line directly in the centre, first shows us what a random classifier would look like. This random classifier randomly predicts positive or negative for any case.\nWe can say that our classifier is better than random, if the line is to the top-left of the random classifier. In general, the more to the top-left the line is, the better."
  },
  {
    "objectID": "teaching/2023-2024/Machine Learning/lecture-3.html#area-under-curve-auc",
    "href": "teaching/2023-2024/Machine Learning/lecture-3.html#area-under-curve-auc",
    "title": "Model Performance",
    "section": "Area Under Curve (AUC)",
    "text": "Area Under Curve (AUC)\nWe’ve just seen how the ROC curve can visually point to which model is better than others, and which threshold we may want to choose for our labelling function. However, we can also turn these types of curves in a number, a metric.\nThis next metric we’re going to look at does just that. The Area Under Curve or AUC for short, takes our ROC curve, and measures the area underneath the curve, giving us a single value for each model that we can use for comparison.\n\nOne method to calculate this area is to use the trapezoid rule to approximate the region underneath the graph of a function:\n\\[\n\\text{Area} = 0.5 \\frac{1}{N} \\times \\left[ \\text{TP}_1 + 2 (\\text{TP}_2 + ... + \\text{TP}_{N-1}) + \\text{TP}_N \\right]\n\\]\nIf the AUC is close to one we know that the model at any threshold has very good discriminatory power."
  },
  {
    "objectID": "teaching/2023-2024/Machine Learning/lecture-3.html#cross-validation-using-k-fold",
    "href": "teaching/2023-2024/Machine Learning/lecture-3.html#cross-validation-using-k-fold",
    "title": "Model Performance",
    "section": "Cross Validation using K-fold",
    "text": "Cross Validation using K-fold\nWe have seen why having a separate set of data for training, testing, and validation is necessary – to give some indication as to the generalisation performance of our model, and to track possible over-fitting.\nTo create these separate sets of data, we may have just sampled randomly or using a stratified method (more on this in a few slides). However, this is only one test of the model’s generalisation abilities.\nCross-validation is a statistical method to test the model on many resamplings on the test set.\n\nCross-validation works selecting a subset of the data for testing (leaving the rest for training), training the model, and then calculating the performance on this test set. Next, sample a different subset of data for a new testing set, training the model, and calculating the performance. Repeat this process until all data has been sampled for the testing set, and calculate the mean and standard deviation of model performance.\nK-fold cross-validation is this method where \\(k\\) is the number of iterations it will take to have used the entire available data for testing. I.e., if you’re performing 5-fold cross-validation, you would have trained and tested your model 5 different types, on 5 different samples from your available data."
  },
  {
    "objectID": "teaching/2023-2024/Machine Learning/lecture-3.html#random-stratified-sampling",
    "href": "teaching/2023-2024/Machine Learning/lecture-3.html#random-stratified-sampling",
    "title": "Model Performance",
    "section": "Random & Stratified Sampling",
    "text": "Random & Stratified Sampling\nWhen sampling data for our training and testing set, we could use two different methods:\n\nRandom\nStratified\n\nTo perform stratified sampling, we first split the dataset into stratas or distinct groups. For a classification problem, this could be splitting samplings by their respective class labels. Then, after splitting the data into their respective groups, we randomly sample from each group.\nLet’s say we have 150 samples, where:\n\n40 samples are in group 1,\n25 samples are in group 2,\n85 samples are in group 3.\n\nAnd we want to sample from this dataset for our test set using stratified sampling. First, we calculate the proportion of each group in the overall data:\n\n\\(100 \\times \\frac{40}{150} = 26.\\overline{6}\\; \\%\\),\n\\(100 \\times \\frac{25}{150} = 16.\\overline{6}\\; \\%\\),\n\\(100 \\times \\frac{85}{150} = 56.\\overline{6} \\; \\%\\).\n\nTherefore, in our testing set, \\(26.\\overline{6} \\; \\%\\) of the data should be randomly sampled from group 1, and so on for all groups.\nSo if we want to use \\(10 \\; \\%\\) of our data for testing, that means we would have 15 samples in our dataset (\\(\\frac{150}{10}\\)) sampled using:\n\ngroup 1: \\(40 \\times (\\frac{15}{150}) = 4\\) samples,\ngroup 2: \\(25\\times (\\frac{15}{150}) = 2.5\\) samples,\ngroup 3: \\(85 \\times ( \\frac{15}{150}) = 8.5\\) samples.\n\nThe proportion of samples in our test set from each group should roughly match the proportion of the overall available data. We can verify this by calculating the proportion of each group’s representation, i.e. : \\(100 \\times \\frac{4}{15} =\n26.\\overline{6} \\; \\%\\) and we see that it matches the proportion of the overall data.\nStratified sampling is especially useful when we have a class-imbalance, and randomly sampling data could potentially lead to a situation where our test or training set only has one class label."
  },
  {
    "objectID": "teaching/2023-2024/Machine Learning/lecture-3-reveal.html#why-do-we-have-different-sets-of-data",
    "href": "teaching/2023-2024/Machine Learning/lecture-3-reveal.html#why-do-we-have-different-sets-of-data",
    "title": "Model Performance",
    "section": "Why do we have different ‘sets’ of data?",
    "text": "Why do we have different ‘sets’ of data?\nWe’ve seen in the previous lecture how we can fit a linear regression model to a set of data, and we can measure the performance of this model.\nBut we do not understand how well this model works in the ‘real-world’, how well it performs on data that has not yet been ‘seen’, how well the model generalises to this unknown data.\nSo, when we want to create a machine learning model, we usually take our data, and split into two (sometimes three) sets of data. These different sets are named:\n\ntraining set,\ntesting set,\nand (optionally) validation set."
  },
  {
    "objectID": "teaching/2023-2024/Machine Learning/lecture-3-reveal.html#training-set",
    "href": "teaching/2023-2024/Machine Learning/lecture-3-reveal.html#training-set",
    "title": "Model Performance",
    "section": "Training Set",
    "text": "Training Set\nThe training dataset, is the set of data, that we’re allowing the model to `see’ or learn from.\nIn our example of the linear regression, this is the set of data points to which we find the optimal parameters of our model.\nIt is not very useful to evaluate our model’s performance with the training set as it doesn’t tell us how well it’s actually doing (we’ll come back to this when we talk about over-/under-fitting)."
  },
  {
    "objectID": "teaching/2023-2024/Machine Learning/lecture-3-reveal.html#testing-set",
    "href": "teaching/2023-2024/Machine Learning/lecture-3-reveal.html#testing-set",
    "title": "Model Performance",
    "section": "Testing Set",
    "text": "Testing Set\nThe testing set is the set of data that we use to evaluate the generalisation of our machine learning model. The model is not allowed to use this set of data during training, but it is simply used for the evaluation of the model.\nIn general the testing set is between 10-30% of the overall available data, but this rule is not something dictated, and may vary depending on the amount of data available and the overall use case.\nOnce the 10-30% of the data has been sampled for the testing set, the rest of the data can be used for the training and validation sets."
  },
  {
    "objectID": "teaching/2023-2024/Machine Learning/lecture-3-reveal.html#validation-set",
    "href": "teaching/2023-2024/Machine Learning/lecture-3-reveal.html#validation-set",
    "title": "Model Performance",
    "section": "Validation Set",
    "text": "Validation Set\nIf we have an iterative optimisation process (such as what we saw with gradient descent), we might want to know how well our model is possibly generalising to unseen data.\nThe validation dataset, is the set of data that we use to measure the generalisation of our model during the course of its learning process. Like the test set, this validation data should not be used to train the model, but only used to measure the model’s generalisation during the lifetime of the learning process."
  },
  {
    "objectID": "teaching/2023-2024/Machine Learning/lecture-3-reveal.html#the-ability-of-the-model",
    "href": "teaching/2023-2024/Machine Learning/lecture-3-reveal.html#the-ability-of-the-model",
    "title": "Model Performance",
    "section": "The ability of the model",
    "text": "The ability of the model\nWhen we created a linear regression model, we saw that it was not possible to predict the house price exactly, there was always some error that we could not overcome with the linear model.\nIf we have a model complicated model, such as polynomial regression (where we have polynomial terms in line equation), it may be possible to fit every training data point exactly. But is that what we want?.\nIn this section, we’ll explore the concept of over- and under-fitting, and how we can use the testing set to understanding if these processes are happening."
  },
  {
    "objectID": "teaching/2023-2024/Machine Learning/lecture-3-reveal.html#over-fitting",
    "href": "teaching/2023-2024/Machine Learning/lecture-3-reveal.html#over-fitting",
    "title": "Model Performance",
    "section": "Over-fitting",
    "text": "Over-fitting\nWe’ll begin with over-fitting. Over-fitting occurs when our model has a very high or perfect performance on the testing set, but does not perform well at all on the testing set.\nThere may be many reasons for this happening, such as the model being very complex, having too many variables."
  },
  {
    "objectID": "teaching/2023-2024/Machine Learning/lecture-3-reveal.html#under-fitting",
    "href": "teaching/2023-2024/Machine Learning/lecture-3-reveal.html#under-fitting",
    "title": "Model Performance",
    "section": "Under-fitting",
    "text": "Under-fitting\nUnder-fitting, as the name suggests is what happens when we cannot fit the model to the data, it doesn’t even perform well on the training data, the data the model is allowed to learn from. This can happen when the model is too simple and cannot learn the intrinsic relationship between the input and output. For example, trying to use a linear model to learn from data that is not linear by nature."
  },
  {
    "objectID": "teaching/2023-2024/Machine Learning/lecture-3-reveal.html#validation-curves",
    "href": "teaching/2023-2024/Machine Learning/lecture-3-reveal.html#validation-curves",
    "title": "Model Performance",
    "section": "Validation Curves",
    "text": "Validation Curves\nIf we have an iterative learning process, we can use the training and validation datasets to measure whether our model is over-fitting, and stop training the model at an optimal point before it overfits.\nTo do this, at every iteration of the learning process, we evaluate the model’s performance using both the training and validation datasets. If the performance on both datasets is decreasing we can infer that the model is learning something useful that helps with it’s generalisation to unseen data.\nHowever, if the performance on the training set is decreasing, while the performance on the validation dataset is no longer decreasing or indeed increasing, we know the model is over-fitting to the training data."
  },
  {
    "objectID": "teaching/2023-2024/Machine Learning/lecture-3-reveal.html#biasvariance-tradeoff",
    "href": "teaching/2023-2024/Machine Learning/lecture-3-reveal.html#biasvariance-tradeoff",
    "title": "Model Performance",
    "section": "Bias/Variance Tradeoff",
    "text": "Bias/Variance Tradeoff\nThe Bias/Variance tradeoff is a property of machine learning models. It describes a model’s expected generalisation abilities based upon how the parameters are estimated across a dataset.\n\nBias - the model’s `flexibility’ to represent the true relationship in the data. Model’s with low bias have a tendency to underfit. An example would be a linear model model trying to fit against non-linear function.\nVariance - the impact that a single sample in the data has on the model. Model’s with high variance tend to overfit to the training data."
  },
  {
    "objectID": "teaching/2023-2024/Machine Learning/lecture-3-reveal.html#metrics",
    "href": "teaching/2023-2024/Machine Learning/lecture-3-reveal.html#metrics",
    "title": "Model Performance",
    "section": "Metrics",
    "text": "Metrics\nNow that we’ve looked at the various sets of data, and the potential scenarios when we fit a model, we’ll now want to look at some actual methods of evaluating our model.\nThese we call metrics. Metrics are values that help us understand how well a model might perform in the real world. Metrics are helpful to explain the predictive power of a model with one value.\nThere are many different types of metrics that can be used depending on the class of problem that is being dealt with. For instance, there are different set of metrics for Regression and classification problems.\nWe’ll first look at some metrics we can use to evaluate a regression model (some of which we’ve already seen in the Linear models lecture), and then we’ll have a look at metrics for a classification task."
  },
  {
    "objectID": "teaching/2023-2024/Machine Learning/lecture-3-reveal.html#mean-squared-error-mse",
    "href": "teaching/2023-2024/Machine Learning/lecture-3-reveal.html#mean-squared-error-mse",
    "title": "Model Performance",
    "section": "Mean Squared Error (MSE)",
    "text": "Mean Squared Error (MSE)\nA mean squared error (sometimes called the sum of squared residuals) is the measure of mean magnitude between two sets of points \\(y, \\overline{y}\\).\nThe formula for MSE is:\n\\(\\text{MSE} = \\frac{1}{N} \\sum_i^N (y_i, \\overline{y_i})^2\\)\nfor \\(N\\) points.\nMSE is always non-negative, and the lower the MSE the better."
  },
  {
    "objectID": "teaching/2023-2024/Machine Learning/lecture-3-reveal.html#root-mean-squared-error-rmse",
    "href": "teaching/2023-2024/Machine Learning/lecture-3-reveal.html#root-mean-squared-error-rmse",
    "title": "Model Performance",
    "section": "Root Mean Squared Error (RMSE)",
    "text": "Root Mean Squared Error (RMSE)\n\\[\n\\text{RMSE} = \\sqrt{\\text{MSE}}\n\\]\nDue to the squared error term, larger errors have a large effect on the outcome of the equation, so both RMSE and MSE is sensitive to outliers.\nMSE’s error is measured in squared units, while RMSE is measured in the same unit as the target."
  },
  {
    "objectID": "teaching/2023-2024/Machine Learning/lecture-3-reveal.html#mean-absolute-error-mae",
    "href": "teaching/2023-2024/Machine Learning/lecture-3-reveal.html#mean-absolute-error-mae",
    "title": "Model Performance",
    "section": "Mean Absolute Error (MAE)",
    "text": "Mean Absolute Error (MAE)\nMean absolute error or MAE is one objective function for measure the \\(L_1\\) between two sets of points.\n\\(\\text{MAE} = \\frac{1}{N} \\sum_i^N | y_i - \\overline{y_i} |\\)\nfor \\(N\\) of points.\nLike MSE, RMSE, the lower the MAE value, the better the fit on the statistical model."
  },
  {
    "objectID": "teaching/2023-2024/Machine Learning/lecture-3-reveal.html#binary-classification-labelling-as-positive-or-negative",
    "href": "teaching/2023-2024/Machine Learning/lecture-3-reveal.html#binary-classification-labelling-as-positive-or-negative",
    "title": "Model Performance",
    "section": "Binary classification & labelling as positive or negative",
    "text": "Binary classification & labelling as positive or negative\nWe now move onto some of the more typical classification metrics. But first, we must first understand when our classifier predicts positive or negative in a binary classification task.\nLet’s say we have a binary classifier \\(\\mathcal{M}\\) which predicts the positive class if the predicted probability is \\(\\geq 0.5\\). I.e.:\n\\[\nL(x)  = \\begin{cases}\n1 & \\text{if}, \\; \\mathcal{M}(x) \\geq 0.5 \\\\\n0 & \\text{otherwise}\n\\end{cases}\n\\]\nwhere \\(L\\) is our labelling function.\nHere 0.5 is the threshold for predicting the positive class."
  },
  {
    "objectID": "teaching/2023-2024/Machine Learning/lecture-3-reveal.html#tptnfpfn",
    "href": "teaching/2023-2024/Machine Learning/lecture-3-reveal.html#tptnfpfn",
    "title": "Model Performance",
    "section": "TP/TN/FP/FN",
    "text": "TP/TN/FP/FN\nBefore we look at other metrics to evaluate our classification metrics, I first want to describe these acronyms.\n\nList :B_column:BMCOL:\n\nTP - True-Positive – our model has predicted positive (it was correct) and the actual label is positive.\nTN - True-Negative – our model has predicted negative (it was correct) and the actual label is negative.\nFP - False-Positive – our model has predicted positive (it was wrong) the actual label was negative.\nFN - False-Negative – our model has predicted negative (it was wrong) the actual label was positive.\n\nDiagram :B_column:BMCOL:"
  },
  {
    "objectID": "teaching/2023-2024/Machine Learning/lecture-3-reveal.html#accuracy",
    "href": "teaching/2023-2024/Machine Learning/lecture-3-reveal.html#accuracy",
    "title": "Model Performance",
    "section": "Accuracy",
    "text": "Accuracy\nIn a binary classification task, accuracy is measured using:\n\\[\n\\text{Accuracy} = \\frac{TP+TN}{TP+TN+FP+FN}\n\\]\nor multi-classification:\n\\[\n\\text{Accuracy} = \\frac{\\text{number of correct}}{\\text{number of samples}}\n\\]\nThe range of accuracy is in \\([0, 1]\\), the higher the value of accuracy the better. Accuracy is often presented in the form of a percentage i.e. \\(100 \\cdot \\text{Accuracy}\\)"
  },
  {
    "objectID": "teaching/2023-2024/Machine Learning/lecture-3-reveal.html#precision",
    "href": "teaching/2023-2024/Machine Learning/lecture-3-reveal.html#precision",
    "title": "Model Performance",
    "section": "Precision",
    "text": "Precision\nMeasuring the precision tells us how many how accurate our model was in predicting positive cases. Here we have \\(TP\\) or the number of True-Positive, divided by \\(TP + FP\\) where \\(FP\\) is the number of False-Positive cases.\n\\[\n\\frac{TP}{TP + FP}\n\\]\nValid values for the precision metric are in the range \\([0, 1]\\) where the higher the value the better."
  },
  {
    "objectID": "teaching/2023-2024/Machine Learning/lecture-3-reveal.html#recall",
    "href": "teaching/2023-2024/Machine Learning/lecture-3-reveal.html#recall",
    "title": "Model Performance",
    "section": "Recall",
    "text": "Recall\nRecall tells us: out of all the positive cases, how many of them were actually found/predicted to be positive. How many of these positive cases was our model able to recall?\n\\[\n\\frac{TP}{TP+FN}\n\\]\nLike precision, recall is in the range \\([0, 1]\\) where the higher the value the better the recall."
  },
  {
    "objectID": "teaching/2023-2024/Machine Learning/lecture-3-reveal.html#confusion-matrix",
    "href": "teaching/2023-2024/Machine Learning/lecture-3-reveal.html#confusion-matrix",
    "title": "Model Performance",
    "section": "Confusion Matrix",
    "text": "Confusion Matrix\nA confusion matrix is a visual representation of these different type of predictive cases (TP/TN/FP/FN).\nAn optimal confusion matrix, is a diagonal matrix (all entries outside of the diagonal are zero). Here is one example of a confusion matrix.\n\n\n\n\n\n\n\n\n\n\n \n\n\n \n\n\nPredicted\n\n\n \n\n\n\n\n \n\n\n \n\n\nPositive\n\n\nNegative\n\n\n\n\nActual\n\n\nPositive\n\n\n5\n\n\n2\n\n\n\n\n \n\n\nNegative\n\n\n3\n\n\n1\n\n\n\n\n\nValues :B_column:BMCOL:\n\nTP = 5\nTN = 1\nFP = 3\nFN = 2\n\nCalculation :B_column:BMCOL:\n\nPrecision = \\(\\frac{5}{5+3} = 0.625\\)\nRecall = \\(\\frac{5}{5+2}\\) \\(= 0.714\\)"
  },
  {
    "objectID": "teaching/2023-2024/Machine Learning/lecture-3-reveal.html#f_beta-f_1",
    "href": "teaching/2023-2024/Machine Learning/lecture-3-reveal.html#f_beta-f_1",
    "title": "Model Performance",
    "section": "\\(F_\\beta\\) & \\(F_1\\)",
    "text": "\\(F_\\beta\\) & \\(F_1\\)\nWith the precision/recall metrics, it is trivial to optimise for one over the over:\n\nWe can achieve perfect precision (\\(\\text{precision} = 1\\)) by predicting everything is negative (no false positives)\nWe can achieve perfect recall (\\(\\text{recall} = 1\\)) by predicting that everything is positive (no false negatives).\n\nBut predicting everything is negative, or everything is positive is not really a useful model. So we have another metric that is the harmonic combination of precision and recall: \\(F_1\\) and \\(F_\\beta\\) score.\n\\[\nF_\\beta = (1 + \\beta^2) \\frac{p \\cdot r}{\\beta^2 p + r}\n\\]\nwhere \\(p, r\\) is the precision and recall metric respectively. For the \\(F_1\\) score, we simple set \\(\\beta = 1\\)."
  },
  {
    "objectID": "teaching/2023-2024/Machine Learning/lecture-3-reveal.html#receiver-operating-characteristic-roc",
    "href": "teaching/2023-2024/Machine Learning/lecture-3-reveal.html#receiver-operating-characteristic-roc",
    "title": "Model Performance",
    "section": "Receiver Operating Characteristic (ROC)",
    "text": "Receiver Operating Characteristic (ROC)\nIn the previous slides, we have labelled our samples as positive if our classifier predicts \\(\\geq 0.5\\), else it is labelled as negative. This \\(0.5\\) is our threshold for our labelling function. But we can vary this threshold if we want. Lowering the threshold will typically mean our classifier labels positive cases more often. While increasing the threshold makes the classifier more conservative, and typically predicts labels positive cases less often.\nIf we vary this threshold from 0 to 1 and calculate the true- and false-positive rate, we can visualise something we call the Receiver Operating Characteristic or ROC for short.\n\nThis ROC curve, with the dotted line directly in the centre, first shows us what a random classifier would look like. This random classifier randomly predicts positive or negative for any case.\nWe can say that our classifier is better than random, if the line is to the top-left of the random classifier. In general, the more to the top-left the line is, the better."
  },
  {
    "objectID": "teaching/2023-2024/Machine Learning/lecture-3-reveal.html#area-under-curve-auc",
    "href": "teaching/2023-2024/Machine Learning/lecture-3-reveal.html#area-under-curve-auc",
    "title": "Model Performance",
    "section": "Area Under Curve (AUC)",
    "text": "Area Under Curve (AUC)\nWe’ve just seen how the ROC curve can visually point to which model is better than others, and which threshold we may want to choose for our labelling function. However, we can also turn these types of curves in a number, a metric.\nThis next metric we’re going to look at does just that. The Area Under Curve or AUC for short, takes our ROC curve, and measures the area underneath the curve, giving us a single value for each model that we can use for comparison.\n\nOne method to calculate this area is to use the trapezoid rule to approximate the region underneath the graph of a function:\n\\[\n\\text{Area} = 0.5 \\frac{1}{N} \\times \\left[ \\text{TP}_1 + 2 (\\text{TP}_2 + ... + \\text{TP}_{N-1}) + \\text{TP}_N \\right]\n\\]\nIf the AUC is close to one we know that the model at any threshold has very good discriminatory power."
  },
  {
    "objectID": "teaching/2023-2024/Machine Learning/lecture-3-reveal.html#cross-validation-using-k-fold",
    "href": "teaching/2023-2024/Machine Learning/lecture-3-reveal.html#cross-validation-using-k-fold",
    "title": "Model Performance",
    "section": "Cross Validation using K-fold",
    "text": "Cross Validation using K-fold\nWe have seen why having a separate set of data for training, testing, and validation is necessary – to give some indication as to the generalisation performance of our model, and to track possible over-fitting.\nTo create these separate sets of data, we may have just sampled randomly or using a stratified method (more on this in a few slides). However, this is only one test of the model’s generalisation abilities.\nCross-validation is a statistical method to test the model on many resamplings on the test set.\n\nCross-validation works selecting a subset of the data for testing (leaving the rest for training), training the model, and then calculating the performance on this test set. Next, sample a different subset of data for a new testing set, training the model, and calculating the performance. Repeat this process until all data has been sampled for the testing set, and calculate the mean and standard deviation of model performance.\nK-fold cross-validation is this method where \\(k\\) is the number of iterations it will take to have used the entire available data for testing. I.e., if you’re performing 5-fold cross-validation, you would have trained and tested your model 5 different types, on 5 different samples from your available data."
  },
  {
    "objectID": "teaching/2023-2024/Machine Learning/lecture-3-reveal.html#random-stratified-sampling",
    "href": "teaching/2023-2024/Machine Learning/lecture-3-reveal.html#random-stratified-sampling",
    "title": "Model Performance",
    "section": "Random & Stratified Sampling",
    "text": "Random & Stratified Sampling\nWhen sampling data for our training and testing set, we could use two different methods:\n\nRandom\nStratified\n\nTo perform stratified sampling, we first split the dataset into stratas or distinct groups. For a classification problem, this could be splitting samplings by their respective class labels. Then, after splitting the data into their respective groups, we randomly sample from each group.\nLet’s say we have 150 samples, where:\n\n40 samples are in group 1,\n25 samples are in group 2,\n85 samples are in group 3.\n\nAnd we want to sample from this dataset for our test set using stratified sampling. First, we calculate the proportion of each group in the overall data:\n\n\\(100 \\times \\frac{40}{150} = 26.\\overline{6}\\; \\%\\),\n\\(100 \\times \\frac{25}{150} = 16.\\overline{6}\\; \\%\\),\n\\(100 \\times \\frac{85}{150} = 56.\\overline{6} \\; \\%\\).\n\nTherefore, in our testing set, \\(26.\\overline{6} \\; \\%\\) of the data should be randomly sampled from group 1, and so on for all groups.\nSo if we want to use \\(10 \\; \\%\\) of our data for testing, that means we would have 15 samples in our dataset (\\(\\frac{150}{10}\\)) sampled using:\n\ngroup 1: \\(40 \\times (\\frac{15}{150}) = 4\\) samples,\ngroup 2: \\(25\\times (\\frac{15}{150}) = 2.5\\) samples,\ngroup 3: \\(85 \\times ( \\frac{15}{150}) = 8.5\\) samples.\n\nThe proportion of samples in our test set from each group should roughly match the proportion of the overall available data. We can verify this by calculating the proportion of each group’s representation, i.e. : \\(100 \\times \\frac{4}{15} =\n26.\\overline{6} \\; \\%\\) and we see that it matches the proportion of the overall data.\nStratified sampling is especially useful when we have a class-imbalance, and randomly sampling data could potentially lead to a situation where our test or training set only has one class label."
  },
  {
    "objectID": "teaching/2023-2024/Machine Learning/lecture-5.html",
    "href": "teaching/2023-2024/Machine Learning/lecture-5.html",
    "title": "K-Nearest Neighbour & K-Means",
    "section": "",
    "text": "The first algorithm we’re going to see today is a very simple one. Let’s image we have a feature space with labelled data points, such as this:\n\nWe want to use these labelled data points as our training data to be able to predict the classification of new data points (such as those from our testing set).\nThe algorithm we’re going to use to do this classification is called K-nearest neighbour, or kNN for short. This algorithm isn’t mathematically derived as some others we’ve seen, but rather based on intuition.\n\n\n\nkNN is a classification algorithm where, we as the user, get to set \\(K\\) ourselves. \\(K\\) is the number of neighbours that will be considered for the model’s classification.\nNeighbour’s of a new data point can be determined using the euclidean distance, and selecting \\(K\\) closest points.\n\nLet’s say we set \\(K=3\\), this means that when we have a new data point we want to classify, we’re going to find out where this new data point falls in the feature space, and find 3 of it’s closest neighbours. Using these closet neighbours, we will assign this new data point the same class as the class majority of it’s neighbours.\n\n\n\n\\(K\\) in the kNN algorithm is user defined, and the larger the number, the more neighbours will be used. One fun example of the effect of \\(K\\) is that if we were to set \\(K=N\\) where \\(N\\) is the number of data points in our training set, then we will always assign new data points the majority class.\n\n\n\n\nWhat if, when using \\(K=4\\), two neighbours are of class 1, while the other two neighbours are of class 2. Which class is assigned to our new data point? Well, since the k-NN algorithm is not a mathematically derived algorithm, but based on the intuition that with similar coordinates in a feature space should be similar classes, then it’s up to you to decide how to deal with ‘ties’. One example, would be to avoid them all together and only use an odd \\(K\\). Another option would be to weight the neighbours by the distance to the new point to be classified. So that closer points have a higher weight. In summary here are some options:\n\nOnly use odd valued \\(K\\).\nDecrease \\(K\\) until the tie is broken.\nWeight neighbours by the distance."
  },
  {
    "objectID": "teaching/2023-2024/Machine Learning/lecture-5.html#problem-statement",
    "href": "teaching/2023-2024/Machine Learning/lecture-5.html#problem-statement",
    "title": "K-Nearest Neighbour & K-Means",
    "section": "",
    "text": "The first algorithm we’re going to see today is a very simple one. Let’s image we have a feature space with labelled data points, such as this:\n\nWe want to use these labelled data points as our training data to be able to predict the classification of new data points (such as those from our testing set).\nThe algorithm we’re going to use to do this classification is called K-nearest neighbour, or kNN for short. This algorithm isn’t mathematically derived as some others we’ve seen, but rather based on intuition."
  },
  {
    "objectID": "teaching/2023-2024/Machine Learning/lecture-5.html#example-solution",
    "href": "teaching/2023-2024/Machine Learning/lecture-5.html#example-solution",
    "title": "K-Nearest Neighbour & K-Means",
    "section": "",
    "text": "kNN is a classification algorithm where, we as the user, get to set \\(K\\) ourselves. \\(K\\) is the number of neighbours that will be considered for the model’s classification.\nNeighbour’s of a new data point can be determined using the euclidean distance, and selecting \\(K\\) closest points.\n\nLet’s say we set \\(K=3\\), this means that when we have a new data point we want to classify, we’re going to find out where this new data point falls in the feature space, and find 3 of it’s closest neighbours. Using these closet neighbours, we will assign this new data point the same class as the class majority of it’s neighbours."
  },
  {
    "objectID": "teaching/2023-2024/Machine Learning/lecture-5.html#the-effect-of-k",
    "href": "teaching/2023-2024/Machine Learning/lecture-5.html#the-effect-of-k",
    "title": "K-Nearest Neighbour & K-Means",
    "section": "",
    "text": "\\(K\\) in the kNN algorithm is user defined, and the larger the number, the more neighbours will be used. One fun example of the effect of \\(K\\) is that if we were to set \\(K=N\\) where \\(N\\) is the number of data points in our training set, then we will always assign new data points the majority class."
  },
  {
    "objectID": "teaching/2023-2024/Machine Learning/lecture-5.html#accounting-for-tiesdraws",
    "href": "teaching/2023-2024/Machine Learning/lecture-5.html#accounting-for-tiesdraws",
    "title": "K-Nearest Neighbour & K-Means",
    "section": "",
    "text": "What if, when using \\(K=4\\), two neighbours are of class 1, while the other two neighbours are of class 2. Which class is assigned to our new data point? Well, since the k-NN algorithm is not a mathematically derived algorithm, but based on the intuition that with similar coordinates in a feature space should be similar classes, then it’s up to you to decide how to deal with ‘ties’. One example, would be to avoid them all together and only use an odd \\(K\\). Another option would be to weight the neighbours by the distance to the new point to be classified. So that closer points have a higher weight. In summary here are some options:\n\nOnly use odd valued \\(K\\).\nDecrease \\(K\\) until the tie is broken.\nWeight neighbours by the distance."
  },
  {
    "objectID": "teaching/2023-2024/Machine Learning/lecture-5.html#problem-statement-1",
    "href": "teaching/2023-2024/Machine Learning/lecture-5.html#problem-statement-1",
    "title": "K-Nearest Neighbour & K-Means",
    "section": "Problem statement",
    "text": "Problem statement\nSay we had a set of data, un-labelled data, and we wanted to separate them into groups or classes. Below we have an example where, as humans, we can see 3 distinct groups of data points. In today’s lecture, we’re going to look at an algorithm that can identify these same clusters or groups systematically."
  },
  {
    "objectID": "teaching/2023-2024/Machine Learning/lecture-5.html#k-means-clustering",
    "href": "teaching/2023-2024/Machine Learning/lecture-5.html#k-means-clustering",
    "title": "K-Nearest Neighbour & K-Means",
    "section": "K-Means clustering",
    "text": "K-Means clustering\nThis algorithm is called K-means. In essence, it is an algorithm that finds \\(K\\) different clusters or groups of points, where \\(K\\) is defined by the user.\n\nOf course, we have to, ourselves, pick a value of for \\(K\\). For data that has more than 3-dimensions, we might not know how many groups there are inherently in the data."
  },
  {
    "objectID": "teaching/2023-2024/Machine Learning/lecture-5.html#starting-point",
    "href": "teaching/2023-2024/Machine Learning/lecture-5.html#starting-point",
    "title": "K-Nearest Neighbour & K-Means",
    "section": "Starting point",
    "text": "Starting point\nK-means is an iterative algorithm, which means that the centroids of the clusters will be randomly assigned in the feature space. Let’s say that we initialise a K-means algorithm with \\(K = 3\\). We might have something that looks like:"
  },
  {
    "objectID": "teaching/2023-2024/Machine Learning/lecture-5.html#iterative-process",
    "href": "teaching/2023-2024/Machine Learning/lecture-5.html#iterative-process",
    "title": "K-Nearest Neighbour & K-Means",
    "section": "Iterative process",
    "text": "Iterative process\nAs mentioned, K-means is an iterative process of assigning the position of the cluster’s centroid. Therefore, after randomly assigning each centroid to a different point in the feature space, the algorithm will iteratively move the centroid to better match the true clustering of data points. We’ll get back to how this is mathematically done later in the lecture, but for now we want to understand this intuition."
  },
  {
    "objectID": "teaching/2023-2024/Machine Learning/lecture-5.html#assigning-centroids",
    "href": "teaching/2023-2024/Machine Learning/lecture-5.html#assigning-centroids",
    "title": "K-Nearest Neighbour & K-Means",
    "section": "Assigning centroids",
    "text": "Assigning centroids\nAfter the algorithm has converged or stopped, we will have 3 centroids, that will, hopefully, match the true clustering of data points.\nAfter we have these positioned centroids, they can be used to label new data points by determining to which cluster do the new data points fall under, or are closet to."
  },
  {
    "objectID": "teaching/2023-2024/Machine Learning/lecture-5.html#initialisation",
    "href": "teaching/2023-2024/Machine Learning/lecture-5.html#initialisation",
    "title": "K-Nearest Neighbour & K-Means",
    "section": "Initialisation",
    "text": "Initialisation\nLet \\(C\\) be the set of cluster centroids:\n\\[C = \\{c_1, c_2, ..., c_K\\}\\]\nAnd let \\(S(c_i)\\) be the set of all points \\(x_i\\) that are located within the cluster \\(c_i\\). The intersection of all \\(S\\) will be the null set (each point will be assigned to only one cluster):\n\\[ \\bigcap_{i=1}^{K} S(c_i) = \\emptyset \\]\nTo initialise the K-means algorithm, we randomly select \\(K\\) data points as the location of the centroids, i.e. \\(x_i = c_i\\).\nAfter, we compute \\(S(c_i)\\) by the minimum euclidean distance to each centroid. I.e., to determine whether a new point falls within the cluster of \\(c_i\\), we can use the euclidean distance between \\(x_i\\) and \\(c_i\\):\n\\[ \\arg \\min_{c_i \\in C} || x_i - c_i ||^2 \\]\nSo we select the cluster to which our new \\(x_i\\) data point is closest to.\nThe position of each centroid \\(c_i\\) is the geometric mean of the data points contained within the cluster:\n\\[ c_i = \\frac{1}{|S(c_i)|} \\sum_{x_j \\in S(c_i)} x_j \\]"
  },
  {
    "objectID": "teaching/2023-2024/Machine Learning/lecture-5.html#iteration",
    "href": "teaching/2023-2024/Machine Learning/lecture-5.html#iteration",
    "title": "K-Nearest Neighbour & K-Means",
    "section": "Iteration",
    "text": "Iteration\nClassic optimisation problem:\n\\[ \\arg \\min_c \\sum_{c_i \\in C} \\sum_{x_j \\in S(c_i)} || x_j - c_i ||^2 \\]\nThere are 3 criterions for stopping the iterative process:\n\nThere are no more changes in clusters by moving the centroids.\nPoints remain within the same cluster as before.\nA maximum number of steps/iterations has been reached."
  },
  {
    "objectID": "teaching/2023-2024/Machine Learning/lecture-5.html#classification",
    "href": "teaching/2023-2024/Machine Learning/lecture-5.html#classification",
    "title": "K-Nearest Neighbour & K-Means",
    "section": "Classification",
    "text": "Classification\nTo determine whether a new point falls within the cluster of \\(c_i\\), we can use the euclidean distance between \\(x_i\\) and \\(c_i\\):\n\\[ \\arg \\min_{c_i \\in C} || x_i - c_i ||^2 \\]\nSo we select the cluster to which our new \\(x_i\\) data point is closest to."
  },
  {
    "objectID": "teaching/2023-2024/Machine Learning/lecture-5.html#evaluation-of-k-means",
    "href": "teaching/2023-2024/Machine Learning/lecture-5.html#evaluation-of-k-means",
    "title": "K-Nearest Neighbour & K-Means",
    "section": "Evaluation of K-means",
    "text": "Evaluation of K-means\nSince we don’t have true labels with which to evaluate the k-means algorithm against, we must take a different tactic for evaluating the classifications or group of points it has clustered together. This works by evaluating the structure of the clusters.\nintra-cluster distance – the average distance between all data points in the same cluster.\n\nintra-cluster diameter – the distance between the two most remote objects in a cluster."
  },
  {
    "objectID": "teaching/2023-2024/Machine Learning/lecture-5.html#inter-cluster-distance",
    "href": "teaching/2023-2024/Machine Learning/lecture-5.html#inter-cluster-distance",
    "title": "K-Nearest Neighbour & K-Means",
    "section": "Inter-cluster distance",
    "text": "Inter-cluster distance\n\ninter-cluster distance – average smallest distance to a different cluster.\nsilhouette score – \\(\\frac{\\text{intra} - \\text{inter}}{\\max(\\text{intra}, \\text{inter})}\\)"
  },
  {
    "objectID": "teaching/2023-2024/Machine Learning/lecture-5.html#the-effect-of-k-1",
    "href": "teaching/2023-2024/Machine Learning/lecture-5.html#the-effect-of-k-1",
    "title": "K-Nearest Neighbour & K-Means",
    "section": "The effect of \\(K\\)",
    "text": "The effect of \\(K\\)\nThe \\(K\\) in k-means clustering determines how many clusters the algorithm will try to find. But if our data is un-labelled, how do we know what to set \\(K\\) equal to? The answer is that we don’t necessarily. So we might create several different clustering algorithms where we vary the value for \\(K\\) and evaluate the resulting model.\nThis may give us some indication as to how many clusters to use.\nOther times the value for \\(K\\) will be inherent to the problem you’re trying to solve. For example, if we’re trying to cluster and label the calls of different birds, we may know the number of different bird species that were recorded, thus providing some grounds for setting \\(K\\)."
  },
  {
    "objectID": "teaching/2023-2024/Machine Learning/lecture-5-revealjs.html#problem-statement",
    "href": "teaching/2023-2024/Machine Learning/lecture-5-revealjs.html#problem-statement",
    "title": "K-Nearest Neighbour & K-Means",
    "section": "Problem statement",
    "text": "Problem statement\nThe first algorithm we’re going to see today is a very simple one. Let’s image we have a feature space with labelled data points, such as this:\n\nWe want to use these labelled data points as our training data to be able to predict the classification of new data points (such as those from our testing set).\nThe algorithm we’re going to use to do this classification is called K-nearest neighbour, or kNN for short. This algorithm isn’t mathematically derived as some others we’ve seen, but rather based on intuition."
  },
  {
    "objectID": "teaching/2023-2024/Machine Learning/lecture-5-revealjs.html#example-solution",
    "href": "teaching/2023-2024/Machine Learning/lecture-5-revealjs.html#example-solution",
    "title": "K-Nearest Neighbour & K-Means",
    "section": "Example solution",
    "text": "Example solution\nkNN is a classification algorithm where, we as the user, get to set \\(K\\) ourselves. \\(K\\) is the number of neighbours that will be considered for the model’s classification.\nNeighbour’s of a new data point can be determined using the euclidean distance, and selecting \\(K\\) closest points.\n\nLet’s say we set \\(K=3\\), this means that when we have a new data point we want to classify, we’re going to find out where this new data point falls in the feature space, and find 3 of it’s closest neighbours. Using these closet neighbours, we will assign this new data point the same class as the class majority of it’s neighbours."
  },
  {
    "objectID": "teaching/2023-2024/Machine Learning/lecture-5-revealjs.html#the-effect-of-k",
    "href": "teaching/2023-2024/Machine Learning/lecture-5-revealjs.html#the-effect-of-k",
    "title": "K-Nearest Neighbour & K-Means",
    "section": "The effect of \\(K\\)",
    "text": "The effect of \\(K\\)\n\\(K\\) in the kNN algorithm is user defined, and the larger the number, the more neighbours will be used. One fun example of the effect of \\(K\\) is that if we were to set \\(K=N\\) where \\(N\\) is the number of data points in our training set, then we will always assign new data points the majority class."
  },
  {
    "objectID": "teaching/2023-2024/Machine Learning/lecture-5-revealjs.html#accounting-for-tiesdraws",
    "href": "teaching/2023-2024/Machine Learning/lecture-5-revealjs.html#accounting-for-tiesdraws",
    "title": "K-Nearest Neighbour & K-Means",
    "section": "Accounting for ‘ties’/‘draws’",
    "text": "Accounting for ‘ties’/‘draws’\nWhat if, when using \\(K=4\\), two neighbours are of class 1, while the other two neighbours are of class 2. Which class is assigned to our new data point? Well, since the k-NN algorithm is not a mathematically derived algorithm, but based on the intuition that with similar coordinates in a feature space should be similar classes, then it’s up to you to decide how to deal with ‘ties’. One example, would be to avoid them all together and only use an odd \\(K\\). Another option would be to weight the neighbours by the distance to the new point to be classified. So that closer points have a higher weight. In summary here are some options:\n\nOnly use odd valued \\(K\\).\nDecrease \\(K\\) until the tie is broken.\nWeight neighbours by the distance."
  },
  {
    "objectID": "teaching/2023-2024/Machine Learning/lecture-5-revealjs.html#problem-statement-1",
    "href": "teaching/2023-2024/Machine Learning/lecture-5-revealjs.html#problem-statement-1",
    "title": "K-Nearest Neighbour & K-Means",
    "section": "Problem statement",
    "text": "Problem statement\nSay we had a set of data, un-labelled data, and we wanted to separate them into groups or classes. Below we have an example where, as humans, we can see 3 distinct groups of data points. In today’s lecture, we’re going to look at an algorithm that can identify these same clusters or groups systematically."
  },
  {
    "objectID": "teaching/2023-2024/Machine Learning/lecture-5-revealjs.html#k-means-clustering",
    "href": "teaching/2023-2024/Machine Learning/lecture-5-revealjs.html#k-means-clustering",
    "title": "K-Nearest Neighbour & K-Means",
    "section": "K-Means clustering",
    "text": "K-Means clustering\nThis algorithm is called K-means. In essence, it is an algorithm that finds \\(K\\) different clusters or groups of points, where \\(K\\) is defined by the user.\n\nOf course, we have to, ourselves, pick a value of for \\(K\\). For data that has more than 3-dimensions, we might not know how many groups there are inherently in the data."
  },
  {
    "objectID": "teaching/2023-2024/Machine Learning/lecture-5-revealjs.html#starting-point",
    "href": "teaching/2023-2024/Machine Learning/lecture-5-revealjs.html#starting-point",
    "title": "K-Nearest Neighbour & K-Means",
    "section": "Starting point",
    "text": "Starting point\nK-means is an iterative algorithm, which means that the centroids of the clusters will be randomly assigned in the feature space. Let’s say that we initialise a K-means algorithm with \\(K = 3\\). We might have something that looks like:"
  },
  {
    "objectID": "teaching/2023-2024/Machine Learning/lecture-5-revealjs.html#iterative-process",
    "href": "teaching/2023-2024/Machine Learning/lecture-5-revealjs.html#iterative-process",
    "title": "K-Nearest Neighbour & K-Means",
    "section": "Iterative process",
    "text": "Iterative process\nAs mentioned, K-means is an iterative process of assigning the position of the cluster’s centroid. Therefore, after randomly assigning each centroid to a different point in the feature space, the algorithm will iteratively move the centroid to better match the true clustering of data points. We’ll get back to how this is mathematically done later in the lecture, but for now we want to understand this intuition."
  },
  {
    "objectID": "teaching/2023-2024/Machine Learning/lecture-5-revealjs.html#assigning-centroids",
    "href": "teaching/2023-2024/Machine Learning/lecture-5-revealjs.html#assigning-centroids",
    "title": "K-Nearest Neighbour & K-Means",
    "section": "Assigning centroids",
    "text": "Assigning centroids\nAfter the algorithm has converged or stopped, we will have 3 centroids, that will, hopefully, match the true clustering of data points.\nAfter we have these positioned centroids, they can be used to label new data points by determining to which cluster do the new data points fall under, or are closet to."
  },
  {
    "objectID": "teaching/2023-2024/Machine Learning/lecture-5-revealjs.html#initialisation",
    "href": "teaching/2023-2024/Machine Learning/lecture-5-revealjs.html#initialisation",
    "title": "K-Nearest Neighbour & K-Means",
    "section": "Initialisation",
    "text": "Initialisation\nLet \\(C\\) be the set of cluster centroids:\n\\[C = \\{c_1, c_2, ..., c_K\\}\\]\nAnd let \\(S(c_i)\\) be the set of all points \\(x_i\\) that are located within the cluster \\(c_i\\). The intersection of all \\(S\\) will be the null set (each point will be assigned to only one cluster):\n\\[ \\bigcap_{i=1}^{K} S(c_i) = \\emptyset \\]\nTo initialise the K-means algorithm, we randomly select \\(K\\) data points as the location of the centroids, i.e. \\(x_i = c_i\\).\nAfter, we compute \\(S(c_i)\\) by the minimum euclidean distance to each centroid. I.e., to determine whether a new point falls within the cluster of \\(c_i\\), we can use the euclidean distance between \\(x_i\\) and \\(c_i\\):\n\\[ \\arg \\min_{c_i \\in C} || x_i - c_i ||^2 \\]\nSo we select the cluster to which our new \\(x_i\\) data point is closest to.\nThe position of each centroid \\(c_i\\) is the geometric mean of the data points contained within the cluster:\n\\[ c_i = \\frac{1}{|S(c_i)|} \\sum_{x_j \\in S(c_i)} x_j \\]"
  },
  {
    "objectID": "teaching/2023-2024/Machine Learning/lecture-5-revealjs.html#iteration",
    "href": "teaching/2023-2024/Machine Learning/lecture-5-revealjs.html#iteration",
    "title": "K-Nearest Neighbour & K-Means",
    "section": "Iteration",
    "text": "Iteration\nClassic optimisation problem:\n\\[ \\arg \\min_c \\sum_{c_i \\in C} \\sum_{x_j \\in S(c_i)} || x_j - c_i ||^2 \\]\nThere are 3 criterions for stopping the iterative process:\n\nThere are no more changes in clusters by moving the centroids.\nPoints remain within the same cluster as before.\nA maximum number of steps/iterations has been reached."
  },
  {
    "objectID": "teaching/2023-2024/Machine Learning/lecture-5-revealjs.html#classification",
    "href": "teaching/2023-2024/Machine Learning/lecture-5-revealjs.html#classification",
    "title": "K-Nearest Neighbour & K-Means",
    "section": "Classification",
    "text": "Classification\nTo determine whether a new point falls within the cluster of \\(c_i\\), we can use the euclidean distance between \\(x_i\\) and \\(c_i\\):\n\\[ \\arg \\min_{c_i \\in C} || x_i - c_i ||^2 \\]\nSo we select the cluster to which our new \\(x_i\\) data point is closest to."
  },
  {
    "objectID": "teaching/2023-2024/Machine Learning/lecture-5-revealjs.html#evaluation-of-k-means",
    "href": "teaching/2023-2024/Machine Learning/lecture-5-revealjs.html#evaluation-of-k-means",
    "title": "K-Nearest Neighbour & K-Means",
    "section": "Evaluation of K-means",
    "text": "Evaluation of K-means\nSince we don’t have true labels with which to evaluate the k-means algorithm against, we must take a different tactic for evaluating the classifications or group of points it has clustered together. This works by evaluating the structure of the clusters.\nintra-cluster distance – the average distance between all data points in the same cluster.\n\nintra-cluster diameter – the distance between the two most remote objects in a cluster."
  },
  {
    "objectID": "teaching/2023-2024/Machine Learning/lecture-5-revealjs.html#inter-cluster-distance",
    "href": "teaching/2023-2024/Machine Learning/lecture-5-revealjs.html#inter-cluster-distance",
    "title": "K-Nearest Neighbour & K-Means",
    "section": "Inter-cluster distance",
    "text": "Inter-cluster distance\n\ninter-cluster distance – average smallest distance to a different cluster.\nsilhouette score – \\(\\frac{\\text{intra} - \\text{inter}}{\\max(\\text{intra}, \\text{inter})}\\)"
  },
  {
    "objectID": "teaching/2023-2024/Machine Learning/lecture-5-revealjs.html#the-effect-of-k-1",
    "href": "teaching/2023-2024/Machine Learning/lecture-5-revealjs.html#the-effect-of-k-1",
    "title": "K-Nearest Neighbour & K-Means",
    "section": "The effect of \\(K\\)",
    "text": "The effect of \\(K\\)\nThe \\(K\\) in k-means clustering determines how many clusters the algorithm will try to find. But if our data is un-labelled, how do we know what to set \\(K\\) equal to? The answer is that we don’t necessarily. So we might create several different clustering algorithms where we vary the value for \\(K\\) and evaluate the resulting model.\nThis may give us some indication as to how many clusters to use.\nOther times the value for \\(K\\) will be inherent to the problem you’re trying to solve. For example, if we’re trying to cluster and label the calls of different birds, we may know the number of different bird species that were recorded, thus providing some grounds for setting \\(K\\)."
  },
  {
    "objectID": "artwork.html",
    "href": "artwork.html",
    "title": "Artwork",
    "section": "",
    "text": "When I was younger, I used to be very passionate about art. But over the last 10-15 years, the experience has languished. During the summer of 2024, I decided to pick it back up, to revitalise that old spirit. Being so long without regular practice, it does mean that I am somewhat learning from scratch, but one is always learning and improving in art anyway, no one ever makes it there.\nIn my spare time, I like to try and improve my artwork. Below I am posting some of my drawings and paintings as practice and make art. Sometimes, these maybe be practice drawings, simple sketches (not taking longer than 10-15 minutes), or works that take considerably more time.\n\n\n\n\n\n\n\n\n\n\n\n\nPoppy\n\n\n\ncharcoal\n\n\nsketch\n\n\nsimple\n\n\nanimal\n\n\n\n\n\n\n\nCharcoal on Paper\n\n\nNov 21, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nHalf of Bargue Plate 1\n\n\n\npencil\n\n\nsketch\n\n\nbargue\n\n\nstudy\n\n\n\n\n\n\n\nPencil on Paper\n\n\nNov 17, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nToby Profile\n\n\n\ncharcoal\n\n\nsketch\n\n\nsimple\n\n\nanimal\n\n\n\n\n\n\n\nCharcoal on Paper\n\n\nNov 16, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nPumpkins and Squash\n\n\n\ncharcoal\n\n\nsketch\n\n\nsimple\n\n\nstill life\n\n\n\n\n\n\n\nCharcoal on Paper\n\n\nNov 10, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nPenny\n\n\n\ncharcoal\n\n\nsketch\n\n\nanimal\n\n\n\n\n\n\n\nCharcoal on Paper\n\n\nNov 10, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nPenny Asleep\n\n\n\ncharcoal\n\n\nsketch\n\n\nsimple\n\n\nanimal\n\n\n\n\n\n\n\nCharcoal on Paper\n\n\nNov 9, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nBrynmill\n\n\n\nwatercolour\n\n\nlandscape\n\n\n\n\n\n\n\nWatercolour on Paper\n\n\nNov 3, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nMad Cats\n\n\n\ncharcoal\n\n\nsimple\n\n\nsketch\n\n\nanimal\n\n\n\n\n\n\n\nCharcoal on Paper\n\n\nOct 24, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nSingleton Tree\n\n\n\npencil\n\n\nsketch\n\n\nlandscape\n\n\n\n\n\n\n\nPencil on Paper\n\n\nOct 5, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nSmall Study of Hands\n\n\n\nstudy\n\n\ncharcoal\n\n\n\n\n\n\n\nCharcoal on Paper\n\n\nSep 22, 2024\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Home",
    "section": "",
    "text": "Hello, my name is Jay Paul Morgan. I am a tutor in Computer Science at Swansea University. My research focuses on the integration of domain knowledge into the design of deep neural networks.\nI conducted my post-doc research as part of the LIS/DYNI lab in the University of Toulon."
  },
  {
    "objectID": "talks/2018-12-14-jurix/index.html#abstract",
    "href": "talks/2018-12-14-jurix/index.html#abstract",
    "title": "\n      A Chatbot Framework for the Children’s Legal Centre\n    ",
    "section": "Abstract",
    "text": "Abstract\nThis is the conference presentation of our paper: https://morganwastaken.com/publications/2018-01-01-chatbot/"
  },
  {
    "objectID": "talks/2021-03-30-trustable-machine-learning-systems/index.html#abstract",
    "href": "talks/2021-03-30-trustable-machine-learning-systems/index.html#abstract",
    "title": "\n      Trustable Machine Learning Systems\n    ",
    "section": "Abstract",
    "text": "Abstract\nMachine Learning (ML) has had a remarkable impact on society. Everything from the phones in our pockets, to the cars that we drive, are being increasingly outfitted with this progressively sophisticated suite of algorithms. But while many of the most basic and fundamental algorithms from ML can be formally verified and tested for safety without much trouble, the same may not be said for Deep Learning (DL) – a prominent forerunner in the state-of-the-art for ML research. These DL models, while performing simple matrix-to-matrix operations at a micro-level, have evolved in scale far past what is tractable for current formal verification methods – all in the pursuit of improving accuracy and performance. This issue of tractability is unsettling considering that the existence of adversarial examples is well known in the ML community. These adversarial examples occur when very small changes to the input space result in a large change in the output space and cause a miss-classification made by the DL model. In the context of self-driving vehicles, small defects and visual artifacts in the sensor input of the DL model, could lead the vehicle to wrongly conclude a stop sign indicates to continue driving where it should have stopped. While the manufacturers will need to put safe-guards in place to prevent this from happening, we should formally prove the (non)-existence of these adversarial examples in the DL model itself. In this presentation, I present the foundational knowledge for understanding adversarial examples, how we can use the input space to dictate the search space for the existence of these examples, and demonstrate their presence with the use of SAT-solving. This work, as a free and open-source project, provides a framework for ML practitioners to verify their own architectures."
  },
  {
    "objectID": "talks/2024-08-28-bps/index.html#abstract",
    "href": "talks/2024-08-28-bps/index.html#abstract",
    "title": "\n      Icons: What do we know? Do we know things? Let’s find out\n    ",
    "section": "Abstract",
    "text": "Abstract\nIcons are used everywhere in modern life, but how well do we understand them? In this work, I worked with Irene Reppa of Psychology, Swansea University, to create new normative studies to find out how well people of different diversities and cultures understand icons. Using this information, we device Machine Learning algorithms to learn from them."
  },
  {
    "objectID": "publications/2024-09-09-cloud-removal/index.html",
    "href": "publications/2024-09-09-cloud-removal/index.html",
    "title": "Removing cloud shadows from ground-based solar imagery",
    "section": "",
    "text": "PDF  Google Scholar Bibtex"
  },
  {
    "objectID": "publications/2024-09-09-cloud-removal/index.html#install",
    "href": "publications/2024-09-09-cloud-removal/index.html#install",
    "title": "Removing cloud shadows from ground-based solar imagery",
    "section": "Install",
    "text": "Install\nYou can pip install directly from this repo:\npip install git+https://github.com/jaypmorgan/cloud-removal.git\nor if you’ve cloned the repo to a local directory:\ncd cloudremoval\npip install ./"
  },
  {
    "objectID": "publications/2024-09-09-cloud-removal/index.html#usage",
    "href": "publications/2024-09-09-cloud-removal/index.html#usage",
    "title": "Removing cloud shadows from ground-based solar imagery",
    "section": "Usage",
    "text": "Usage\nUsing the existing synthetic clouds dataset:\nimport dfp\nfrom cloudremoval.dataset import SyntheticClouds, CloudsTransform\n\n# download the data\ndataset = SyntheticClouds(download=True)\n\n# get only a single wavelength from the data\ncaii = dataset.filter(lambda row: dfp.has_props(row, {\"type\": \"Ca II\"}))\n\n# split into train and test\ntrain, test = caii.split(lambda row: dfp.has_props(row, {\"subset\": \"train\"}))\n\n# get the first instance:\nitem = train[0]\ninp1 = item.input\nitem.target\nitem.mask\n\n# Add a transform\ntrain.transform = CloudsTransform(hflip_p=0.5, vflip_p=0.5)\nitem = train[0]\ninp2 = item.input\nTo create a model, or load one using existing model weights:\nfrom cloudremoval.model import CloudRemover\n\n# create a new model from scratch (i.e. random model weights)\nmodel = CloudRemover()\n\n# create a model using the existing weights\nmodel = CloudRemover(pretrained=True)\n\n# create a model using a different wavelength\nmodel = CloudRemover(wavelength=\"H-alpha\", pretrained=True)\n\n# test making of predictions\ndataset = SyntheticClouds(download=True, transform=CloudsTransform())\nmodel = CloudRemover(pretrained=True)\nout = model(dataset[0].input[None,...])*dataset[0].mask[None,...]\n\nimport matplotlib.pyplot as plt\nplt.imshow(out[0,0].detach().cpu().numpy(), cmap=\"Greys_r\")"
  },
  {
    "objectID": "publications/2022-01-02-thesis/index.html",
    "href": "publications/2022-01-02-thesis/index.html",
    "title": "Strategies to use prior knowledge to improve the performance of Deep Learning: an approach towards trustable Machine Learning systems",
    "section": "",
    "text": "Google Scholar Bibtex\n\nAbstract\nMachine Learning (ML) has been a transformative technology in society by automating otherwise difficult tasks such as image recognition and natural language understand-ing. The performance of Deep Learning (DL), in particular, has improved to the point where it can be applied to automotive vehicles – a situation in which trust is placed on the ML systems to operate correctly and safely. Yet, while fundamental ML algorithms can be formally verified for safety without much trouble, the same may not be said for DL. A key problem preventing the trustworthiness of DL is the existence of adver-sarial examples, where small changes in input result in catastrophic misclassifications, thereby undermining their use in safety-critical systems.Using pre-existing knowledge from domain experts has been shown to successfully in-crease not only the performance but critically the resilience of DL models to adversarial examples. The current thesis developed four different strategies of integrating prior expert knowledge into DL models: feature specialisation, specialised information pro-cessing, stimulation of attention mechanisms, and augmentation of training data. Prior knowledge from three scientific domains was used (Quantum Chemistry, Corpus Lin-guistics and Astrophysics) as case studies to provide a comprehensive framework for evaluation of the strategies performance given different types of data (i.e., text-based, image-based, and graph-based) and model architectures (e.g. recurrent, graph, and convolutional). For the Quantum Chemistry and Corpus Linguistics case studies, two novel datasets are introduced to facilitate the training of prior knowledge informed DL models. Each of the four proposed strategies were tested independently on the case studies to understand their isolated contribution, as well as combined with other strategies to evaluate their interaction.The results show that, combined, the four prior knowledge integration strategies (a) are an effective method of increasing model performance; (b) result in fewer misclas-sifications as a result of misleading features; (c) lead to increased model robustness to adversarial examples; (d) create informative representations by visualising learnt representations of prior knowledge; (e) lessen the number of training samples needed to achieve adequate model performance; and (f) lead to better generalisation to dif-ferent problem tasks other than those the model was trained for. The findings show the prior knowledge integration strategies used here improve the performance of ML while being more resilient to adversarial examples. This can lead to more trustworthy ML systems in practice."
  },
  {
    "objectID": "publications/2023-04-04-remove-clouds/index.html",
    "href": "publications/2023-04-04-remove-clouds/index.html",
    "title": "Removing cloud shadows from ground-based solar imagery",
    "section": "",
    "text": "PDF  Google Scholar Bibtex\n\nAbstract\nThe study and prediction of space weather entails the analysis of solar images showing structures of the Sun’s atmosphere. When imaged from the Earth’s ground, images may be polluted by terrestrial clouds which hinder the detection of solar structures. We propose a new method to remove cloud shadows, based on a U-Net architecture, and compare classical supervision with conditional GAN. We evaluate our method on two different imaging modalities, using both real images and a new dataset of synthetic clouds. Quantitative assessments are obtained through image quality indices (RMSE, PSNR, SSIM). We demonstrate improved results with regards to the traditional cloud removal technique and a sparse coding baseline, on different cloud types and textures."
  },
  {
    "objectID": "publications/2022-01-01-computability/index.html",
    "href": "publications/2022-01-01-computability/index.html",
    "title": "A Computability Perspective on (Verified) Machine Learning",
    "section": "",
    "text": "PDF  Google Scholar Bibtex\n\nAbstract\nIn Computer Science there is a strong consensus that it is highly desirable to combine the versatility of Machine Learning (ML) with the assurances formal verification can provide. However, it is unclear what such ‘verified ML’ should look like. This paper is the first to formalise the concepts of classifiers and learners in ML in terms of computable analysis. It provides results about which properties of classifiers and learners are computable. By doing this we establish a bridge between the continuous mathematics underpinning ML and the discrete setting of most of computer science. We define the computational tasks underlying the newly suggested verified ML in a model-agnostic way, i.e., they work for all machine learning approaches including, e.g., random forests, support vector machines, and Neural Networks. We show that they are in principle computable."
  },
  {
    "objectID": "artwork/2024-11-03-brynmill/index.html",
    "href": "artwork/2024-11-03-brynmill/index.html",
    "title": "Brynmill",
    "section": "",
    "text": "Brynmill, Watercolour on Paper, 11/2024"
  },
  {
    "objectID": "artwork/2024-11-10-penny/index.html",
    "href": "artwork/2024-11-10-penny/index.html",
    "title": "Penny",
    "section": "",
    "text": "Penny, Charcoal on Paper, 11/2024"
  },
  {
    "objectID": "artwork/2024-11-17-bargue-plate-1/index.html",
    "href": "artwork/2024-11-17-bargue-plate-1/index.html",
    "title": "Half of Bargue Plate 1",
    "section": "",
    "text": "The Bargue plates are a set of reference lithographs used in the 19th century to teach art students. These plates were even used by Pablo Picasso and Vincent van Gogh as study.\n\n\n\nHalf of Bargue Plate 1, Pencil on Paper, 11/2024"
  },
  {
    "objectID": "artwork/2024-10-24-mad-cats/index.html",
    "href": "artwork/2024-10-24-mad-cats/index.html",
    "title": "Mad Cats",
    "section": "",
    "text": "Mad Cat 1, Charcoal on Paper, 10/2024\n\n\n\n\n\nMad Cat 2, Charcoal on Paper, 10/2024"
  },
  {
    "objectID": "artwork/2024-11-09-penny-asleep/index.html",
    "href": "artwork/2024-11-09-penny-asleep/index.html",
    "title": "Penny Asleep",
    "section": "",
    "text": "Penny Asleep, Charcoal on Paper, 11/2024"
  },
  {
    "objectID": "posts/2023-04-21-mch23/index.html",
    "href": "posts/2023-04-21-mch23/index.html",
    "title": "MCH2023 - A retrospective",
    "section": "",
    "text": "The 2023 Machine Learning and Computer Vision in Heliophysics conference, hosted in the luxurious Millennium hotel, Sofia, Bulgaria, has now concluded after 3 days of interesting and thought-provoking lectures.\nFollowing this conference, I wanted to highlight some of the talks, as well as drawing and picking up common threads that were interwoven through all the presentations. From this, I hope to better understand what the current research is, more than one would gain for looking at each work in its isolation.\n\n\n\nimg\n\n\nFor a full list of the conference program, you can find it here.\nIf you were at this conference and you think that I’ve missed something that should be covered in this discussion, please do get in touch and let me know!\n\nSimple models are useful models\nMuch of the work showed thoughtful feature extraction, coupled with domain knowledge, and selection of traditional machine learning models can still produce reliable models upon which to make predictions. Take, for example, Hanne Baeke’s talk where active regions are classified using the magnetic properties. A small number of features were selected by evaluating the usefulness and duplication of information present in all the features. After a sparse autoencoder was used to encode a slightly larger representation, that was classified using a \\(k\\) -NN model in a supervised way, and \\(k\\) -means in a unsupervised way.\nBut while, we have seen such use of traditional machine learning, Deep Neural Networks (DNNs) also make their appearance. I noticed a use of common models through applications. In particular, we saw many applications using either U-Net or YOLO.\nAndrea Diercke created a labelled (the labels being bounding-boxes) dataset of filaments in the H-α wavelength. These labels were used to train a YOLO model to recognise the presence of filaments so other, more computationally expensive algorithms but potentially more accurate, could be used to create segmentation masks on smaller regions of the images.\n\n\nMore data is better data\nHeliophyics is no exception in the world where more data is needed to adequately train ML models. Despite many satellites, telescopes, and other sensoring equipment constantly gathering data, a very large percentage of the data being recorded contains nothing interesting. For example, take Alin Razvan Paraschiv’s talk in which they would like to classify whether, based on a small number of features, a cosmic mass ejection (CME) will interact with the Earth (geoeffective). In this talk, 99.3% of all data is non-geoeffective. Class-imbalance is then a persistent problem. The disruptive events we want to detect and predict happen very rarely. In Vanessa Mercea’s talk on the detection of sunquakes, these type of events only happen around 2 times per year. Given then length of time since they’ve been discovered, we haven’t observed a whole lot of them.\nTo combat the issue of small samples of positive data, the Synthetic Minority Oversampling Technique (SMOTE) algorithm was very often used to generate synthetic examples.\nOther cases used a DNN to generate data. Take, for example, Francesco Pio Ramunno demonstrating a very interesting method of generating solar disk images that contain desired solar features using a Diffusion Probabilistic Model (DDPM). Others like Juan Esteban Agudelo Ortiz used a GAN architecture to generate stokes parameters.\nAs the events we’re interested in happen very infrequently, but we’re recording all of the time, we are essentially wasting our storage with useless data. Pearse Murphy used a U-Net trained to segment type-II and type-III solar bursts so that data could be automatically binned and we reduce the storage costs by restricting the saving data closer to solar events.\n\n\n\nimg\n\n\nInstead of generating data, DNNs were used to clean existing data. For example Jeremiah Scully ’s work in cleaning of radio frequency interference using GANs. Or, Adeline Paiement presenting our work on the cleaning of cloud contaminants from H-α and Ca-II imaging. We used a U-Net model in a C-GAN architecture to learn the cloud transmittance. The transmittance values could then be added to the solar disk, resulting in a cleaned image. You can find out poster at on my github.\n\n\nOther talks\nNot all of the talks fit into my classification here. But I wanted to highlight some other interesting talks that do not follow the trend placed above, though this in itself is not an exhaustive list.\n\n\n\nimg\n\n\nFirst we have Manuel Luna’s work of detecting the oscillation of filament structures and its characterisation over a 6-month period. Secondlly, we have Benoit’s talk of creating a 3d-simulation of the sun by predicting the image of the solar disk from angles where there are no satellites. Other works include Connor O’Brien’s lecture on the probabilisitc determination of solar wind propagation using an RNN model.\n\n\n\nimg\n\n\n\n\n\n\nCitationBibTeX citation:@online{morgan2023,\n  author = {Morgan, Jay Paul},\n  title = {MCH2023 - {A} Retrospective},\n  date = {2023-04-21},\n  url = {https://morganwastaken.com/blog/2023-04-21-mch23},\n  langid = {en}\n}\nFor attribution, please cite this work as:\nMorgan, Jay Paul. 2023. “MCH2023 - A Retrospective.” April\n21, 2023. https://morganwastaken.com/blog/2023-04-21-mch23."
  },
  {
    "objectID": "posts/2023-03-19-MCH23/index.html",
    "href": "posts/2023-03-19-MCH23/index.html",
    "title": "Machine Learning and Computer Vision in Heliophysics",
    "section": "",
    "text": "We’ll be presenting a poster at the Machine Learning and Computer Vision in Heliophysics international workshop, Sofia, Bulgaria.\nThe poster concerns the our work on improving the down-stream feature detection of solar features by removing the contamination of clouds from ground-based observations. We’ve started to open-source our program code on github, but please come and ask some questions if you’re at the conference!\n\n\n\nCitationBibTeX citation:@online{morgan2023,\n  author = {Morgan, Jay Paul},\n  title = {Machine {Learning} and {Computer} {Vision} in {Heliophysics}},\n  date = {2023-03-19},\n  url = {https://morganwastaken.com/blog/2023-04-21-mch23},\n  langid = {en}\n}\nFor attribution, please cite this work as:\nMorgan, Jay Paul. 2023. “Machine Learning and Computer Vision in\nHeliophysics.” March 19, 2023. https://morganwastaken.com/blog/2023-04-21-mch23."
  },
  {
    "objectID": "posts/2023-06-27-GNN/index.html",
    "href": "posts/2023-06-27-GNN/index.html",
    "title": "Domain-informed graph neural networks: a quantum chemistry case study",
    "section": "",
    "text": "I would like to bring to attention that our (Jay Paul Morgan, Adeline Paiement, and Christian Klinke) paper ‘Domain-informed graph neural networks: a quantum chemistry case study’ has been accepted for publication in the journal ‘Neural Networks’, while we are waiting for the article to become available, we may direct you to an archive version at: https://hal.science/hal-04142152\nIn this paper, we investigate strategies to incorporate domain knowledge of atomic interaction processes into the design of graph neural networks. These take form of two overall strategies: an indirect but easier to implementation version of multi-task method; and a more direct but more successful method of learning modulation parameters for different edge relations of chemical bonds.\nWe show how these designs lead to concrete implementations in various neural network architectures, such as message-passing, or convolutional networks.\nFinally, we evaluate these different implementations and demonstrate how prior domain knowledge can help neural networks to improve in accuracy, while providing some means of explainability in results, and being more robust to tasks adjacent to ones the neural network was trained on.\n\n\n\nCitationBibTeX citation:@online{morgan2023,\n  author = {Morgan, Jay Paul},\n  title = {Domain-Informed Graph Neural Networks: A Quantum Chemistry\n    Case Study},\n  date = {2023-06-27},\n  url = {https:/morganwastaken.com/blog/2023-06-27-GNN/},\n  langid = {en}\n}\nFor attribution, please cite this work as:\nMorgan, Jay Paul. 2023. “Domain-Informed Graph Neural Networks: A\nQuantum Chemistry Case Study.” June 27, 2023. https:/morganwastaken.com/blog/2023-06-27-GNN/."
  },
  {
    "objectID": "posts/2022-12-15-org-babel-tramp/index.html",
    "href": "posts/2022-12-15-org-babel-tramp/index.html",
    "title": "Using a remote Python process in Org-mode files",
    "section": "",
    "text": "Introduction\nSometimes the work we do requires a lot of horse-power – a lot of compute resource. Perhaps more than what we can do locally. In these cases, we might need to use a remote server.\nIn this blog post, I wanted to demonstrate how I’ve used a local org-mode file to execute computations via a remote python process.\n\n\n\nSetup\nFirst, we setup the location of remote server, and where the python process will be started. I do this within the top of the org-mode file so that all python code blocks will use this location by default. We set this up using the #+PROPERTY: argument:\n#+PROPERTY: header-args:python :dir /ssh:&lt;server&gt;:/path/to/dir\nWe’ve added :dir that specifies the remote path using tramp. Whenever a python code block is executed normally with C-c C-c, it will connect to &lt;server&gt; and navigate to the /path/to/dir directory, start a python process, execute the source code and return the results.\nWe can verify that the code block is being executed on the remote server, and find out which python is being used by printing the hostname of the machine running the python process, and the path to the python executable:\n#+begin_src python :results output\nimport sys\nimport socket\nprint(socket.gethostname())\nprint(sys.executable)\n#+end_src\n\n\n\nChanging the Python Interpreter\nBy default, the python code blocks will be executed using the first “python” command found on the remote server’s path. Often, when working with Python, we have virtual environments.\nThe best (hacky) solution I’ve got to use the correct python environment is to manually change the org-babel-python-command to the path of the virtual environment to use:\n#+begin_src emacs-lisp\n(setq org-babel-python-command \"venv/bin/python\")\n#+end_src\nWe can then confirm that the correct virtual environment is being used by printing the path to the executable again.\n#+begin_src python :results output\nimport socket\nprint(sys.executable)\n#+end_src\n\n\n\nPlotting\nAlas there is still a pain point: plotting. When we execute a code block and specify that it returns a file (the path to the newly created plot), it will return a path on the local machine. Of course, this doesn’t exist as it was executed on the remote server. Take for example:\n#+begin_src python :results file\nimport matplotlib.pyplot as plt\nimport numpy as np\nx = np.arange(0, 10)\ny = np.random.randn(*x.shape) + x\nplt.plot(x, y, 'r--')\nplt.savefig(\"/tmp/test.png\")\n\"/tmp/test.png\"\n#+end_src\n\n#+RESULTS:\nfile:/tmp/testplot.png\nThis will not work. Instead, a workaround I’ve created is creating a named code block to save and return the remote path:\n#+name: savefig\n#+begin_src python :session testing :var filename=\"/tmp/plot.png\"\nf\"\"\"\nplt.savefig('{filename}')\nplt.close()\n'/ssh:&lt;server&gt;:{filename}'\n\"\"\"\n#+end_src\n\n#+RESULTS: savefig\n\n: plt.savefig('/tmp/plot.png')\n: plt.close()\n: '/ssh:&lt;server&gt;:/tmp/plot.png'\nThen when we want to create a plot:\n#+begin_src python :results file :noweb strip-export\nimport matplotlib.pyplot as plt\nimport numpy as np\nx = np.arange(0, 10)\ny = np.random.randn(*x.shape) + x\nplt.plot(x, y, 'r--')\n&lt;&lt;savefig(filename=\"/tmp/testplot.png\")&gt;&gt;\n#+end_src\n\n#+RESULTS:\nfile:/ssh:&lt;server&gt;:/tmp/testplot.png]]\nWe won’t be able to see the image within the notebook itself, but we can use C-c C-o to open the file into it’s own buffer, which is the best solution I’ve come up with for the moment.\n\n\n\n\nCitationBibTeX citation:@online{morgan2022,\n  author = {Morgan, Jay Paul},\n  title = {Using a Remote {Python} Process in {Org-mode} Files},\n  date = {2022-12-15},\n  url = {https://morganwastaken.com/blog/2022-12-15-org-babel-tramp},\n  langid = {en}\n}\nFor attribution, please cite this work as:\nMorgan, Jay Paul. 2022. “Using a Remote Python Process in Org-Mode\nFiles.” December 15, 2022. https://morganwastaken.com/blog/2022-12-15-org-babel-tramp."
  },
  {
    "objectID": "posts/2022-10-12-adaptive/index.html",
    "href": "posts/2022-10-12-adaptive/index.html",
    "title": "XTAI 2022 - Adaptive Neighbourhoods for the Discovery of Adversarial Examples",
    "section": "",
    "text": "Talk prepared for the AISB Workshop on Explainability and Transparency in AI, XTAI 2022.\nPresentation Abstract\nMachine Learning, in particular Deep Learning, has most recently provided the state-of-the-art results for many tasks such as object recognition, text-to-speech processing, and credit-card fraud detection. In many cases, Deep Learning has even out-performed human performance on these very same tasks. Despite this advance in performance, however, the existence of so-called adversarial examples is well known within the community. These adversarial examples are the metaphorical ‘blind-spot’ of Deep Learning models, where very small (often human-imperceptible) changes to model’s input can result catastrophic miss-classifications. These adversarial examples then pose a great safety risk, especially in systems where safety is critical such as fully-automotive vehicles.\nTo defend against and attempt to eradicate the existence of adversarial examples in Deep Learning models, principle works have sought to search for their existence within fixed-sized regions around training points, and use the found adversarial examples as a criterion for learning. These works have demonstrated how the robustness of Deep Learning models against adversarial examples improves through these training regimes.\nOur work means to compliment and improve on these existing approaches by adapting the size of the searchable regions around training points, based upon the complexity of the problem and data sampling density. The result is each training point has an adapted region around it to which adversarial examples can be searched for and found.\nWe demonstrate how, through the development of uniquely-adaptive searchable regions, existing methods can help to further improve the robustness of Deep Learning models, and also make the existing methods applicable to non-image related tasks by providing an upper bound for discovering adversarial examples.\nIn this presentation, we will explore how adversarial examples can be determined through the use of existing approaches. Further to these approaches, how our method allows us to generate unique and adapted region sizes for all training points in a dataset.\nPresentation Slides\nSlides\n\n\n\nCitationBibTeX citation:@online{morgan2022,\n  author = {Morgan, Jay Paul},\n  title = {XTAI 2022 - {Adaptive} {Neighbourhoods} for the {Discovery}\n    of {Adversarial} {Examples}},\n  date = {2022-10-12},\n  url = {https://morganwastaken.com/blog/2022-10-12-adaptive},\n  langid = {en}\n}\nFor attribution, please cite this work as:\nMorgan, Jay Paul. 2022. “XTAI 2022 - Adaptive Neighbourhoods for\nthe Discovery of Adversarial Examples.” October 12, 2022. https://morganwastaken.com/blog/2022-10-12-adaptive."
  },
  {
    "objectID": "teaching.html",
    "href": "teaching.html",
    "title": "Teaching",
    "section": "",
    "text": "Welcome to the Machine Learning course developed for the MIR Masters Engineering and Complex Systems. In this series of lectures, we’re going to learn about how to learn! Specifically, we’re going to learn about how computers learn using Machine Learning algorithms. We’ll learn about the basic understanding of learning algorithms, as well as specific algorithms that include: linear models, support vector machines, and clustering methods. In addition to these algorithms, we will also look at a key part of using any learning algorithm – evaluating it!\n\n\n   \n     \n     \n       Order By\n       Default\n         \n          Date - Oldest\n        \n         \n          Date - Newest\n        \n         \n          Title\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n\nDate\n\n\nTitle\n\n\n\n\n\n\n \n\n\nSupport Vector Machines\n\n\n\n\n \n\n\nK-Nearest Neighbour & K-Means\n\n\n\n\n \n\n\nLinear Models\n\n\n\n\n \n\n\nModel Performance\n\n\n\n\n \n\n\nIntroduction\n\n\n\n\n \n\n\nMachine Learning\n\n\n\n\n \n\n\nEvaluation of Models\n\n\n\n\n \n\n\nK-Nereast Neighbours\n\n\n\n\n \n\n\nLinear Models\n\n\n\n\n\nNo matching items\n\n\n\n\n\nWelcome to the Programming Level-up Course. In this series of lectures, we will cover everything we need to be able to program in a Linux-based environment, and use the high performance computers (also called cluster/supercomputers) to run experiments.\n\n\n   \n     \n     \n       Order By\n       Default\n         \n          Date - Oldest\n        \n         \n          Date - Newest\n        \n         \n          Title\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n\nDate\n\n\nTitle\n\n\n\n\n\n\n \n\n\nIntroduction to Numpy\n\n\n\n\n \n\n\nIntroduction to Matplotlib\n\n\n\n\n \n\n\nLinux & Supercomputer\n\n\n\n\n \n\n\nIntroduction to Pandas\n\n\n\n\n \n\n\nErrors & Object Oriented Programming\n\n\n\n\n \n\n\nPython Modules\n\n\n\n\n \n\n\nPython Introduction\n\n\n\n\n \n\n\nProgramming Level-up\n\n\n\n\n \n\n\nAll about Git\n\n\n\n\n \n\n\nCourse Introduction\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "teaching.html#machine-learning",
    "href": "teaching.html#machine-learning",
    "title": "Teaching",
    "section": "",
    "text": "Welcome to the Machine Learning course developed for the MIR Masters Engineering and Complex Systems. In this series of lectures, we’re going to learn about how to learn! Specifically, we’re going to learn about how computers learn using Machine Learning algorithms. We’ll learn about the basic understanding of learning algorithms, as well as specific algorithms that include: linear models, support vector machines, and clustering methods. In addition to these algorithms, we will also look at a key part of using any learning algorithm – evaluating it!\n\n\n   \n     \n     \n       Order By\n       Default\n         \n          Date - Oldest\n        \n         \n          Date - Newest\n        \n         \n          Title\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n\nDate\n\n\nTitle\n\n\n\n\n\n\n \n\n\nSupport Vector Machines\n\n\n\n\n \n\n\nK-Nearest Neighbour & K-Means\n\n\n\n\n \n\n\nLinear Models\n\n\n\n\n \n\n\nModel Performance\n\n\n\n\n \n\n\nIntroduction\n\n\n\n\n \n\n\nMachine Learning\n\n\n\n\n \n\n\nEvaluation of Models\n\n\n\n\n \n\n\nK-Nereast Neighbours\n\n\n\n\n \n\n\nLinear Models\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "teaching.html#programming-level-up",
    "href": "teaching.html#programming-level-up",
    "title": "Teaching",
    "section": "",
    "text": "Welcome to the Programming Level-up Course. In this series of lectures, we will cover everything we need to be able to program in a Linux-based environment, and use the high performance computers (also called cluster/supercomputers) to run experiments.\n\n\n   \n     \n     \n       Order By\n       Default\n         \n          Date - Oldest\n        \n         \n          Date - Newest\n        \n         \n          Title\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n\nDate\n\n\nTitle\n\n\n\n\n\n\n \n\n\nIntroduction to Numpy\n\n\n\n\n \n\n\nIntroduction to Matplotlib\n\n\n\n\n \n\n\nLinux & Supercomputer\n\n\n\n\n \n\n\nIntroduction to Pandas\n\n\n\n\n \n\n\nErrors & Object Oriented Programming\n\n\n\n\n \n\n\nPython Modules\n\n\n\n\n \n\n\nPython Introduction\n\n\n\n\n \n\n\nProgramming Level-up\n\n\n\n\n \n\n\nAll about Git\n\n\n\n\n \n\n\nCourse Introduction\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "teaching.html#machine-learning-1",
    "href": "teaching.html#machine-learning-1",
    "title": "Teaching",
    "section": "Machine Learning",
    "text": "Machine Learning\n\nLectures\n\nLecture 1. Introduction\nLecture 2. Linear Models\nLecture 3. Model Evaluations\nLecture 4. Support Vector Machines\nLecture 5. Clustering\n\n\n\nLabs\n\nLab 1. Linear Models\nLab 2. Evaluation of Models"
  },
  {
    "objectID": "teaching.html#programming-level-up-1",
    "href": "teaching.html#programming-level-up-1",
    "title": "Teaching",
    "section": "Programming Level-up",
    "text": "Programming Level-up\n\nLecture 1. Introduction\nLecture 2. Object Oriented Programming\nLecture 3. Development Environments\nLecture 4. Numerical Computing with Numpy\nLecture 5. Introduction to Linux\nLecture 6. Introduction to Matplotlib\nLecture 7. Introduction to Pandas"
  },
  {
    "objectID": "teaching.html#programming-level-up-2",
    "href": "teaching.html#programming-level-up-2",
    "title": "Teaching",
    "section": "Programming Level-up",
    "text": "Programming Level-up\n\nCourse outline\nLecture 1. Introduction and Basic Python Programming\nLecture 2. More advanced Python & Classes\nLecture 3. Modules & Development Environments\nLecture 4. An Introduction to Numerical Computing in Python\nLecture 5. An Introduction to using Linux\nLecture 6. An Introduction to Matplotlib\nLecture 7. An Introduction to Pandas"
  },
  {
    "objectID": "posts/2019-06-27-membership-functions/index.html",
    "href": "posts/2019-06-27-membership-functions/index.html",
    "title": "Fuzzy Logic Membership Functions",
    "section": "",
    "text": "A membership function is a method of translating a crisp value \\(x \\in\n\\mathbb{R}\\) into a fuzzy set. In other words, we can find the membership grade (the amount of membership) for x with a value between 0 and 1. If the membership grade is only 0 or 1, then we are using classical sets.\n\\[\nA = \\{(x, \\mu_A(x)) | x \\in X\\},\n\\]\nwhere \\(\\mu_A(x)\\) is the Membership function (MF) for the fuzzy set \\(A\\).\nTo make these MFs, we will use the FuzzyTorch library.\nimport os; os.chdir(\"../\")\n\nfrom functools import partial\n\nimport torch\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom mpl_toolkits.mplot3d import Axes3D\nimport seaborn as sns\n\n# Our Membership Functions import\nfrom src.functional.membership import *\n\nx = torch.linspace(0, 100, 100).view(-1, 1)\n\ndef draw_function(func):\n    sns.lineplot(x.flatten().numpy(), func.flatten())\n    plt.xlabel(\"$$x_i$$\")\n    plt.ylabel(\"Membership Value\")\n    plt.grid()\n\n\nTriangluar Function\nA triangular MF is created using three parameters \\(\\{a, b, c\\}, a &lt; b &lt; c\\):\n\\[\n\\operatorname{triangle}(x ; a, b, c)=\\left\\{\\begin{array}{cc}{0,} & {x \\leq a} \\\\ {\\frac{x-a}{b-a},} & {a \\leq x \\leq b} \\\\ {\\frac{c-x}{c-b},} & {b \\leq x \\leq c} \\\\ {0,} & {c \\leq x}\\end{array}\\right.\n\\]\nhelp(triangle)\n\nHelp on function triangle in module src.functional.membership:\n\ntriangle(x, a, b, c)\n    Triangular Membership Function\n\n    :param x: input value\n    :param a: start point where membership is 0\n    :param b: center point where membership is 1\n    :param c: end point where membership is 0\n\ntri = partial(triangle, a=20, b=60, c=80)\n\ndraw_function(tri(x))\n\nplt.text(22, tri(20), \"a\")\nplt.text(62, tri(60), \"b\")\nplt.text(82, tri(80), \"c\")\nText(82, tensor([0.]), ‘c’)\n\n\n\nimg\n\n\nTrapezoid Membership Function\n\\[\n\\operatorname{trapezoid}(x ; a, b, c, d)=\\left\\{\\begin{array}{ll}{0,} & {x \\leq a} \\\\ {\\frac{x-a}{b-a},} & {a \\leq x \\leq b} \\\\ {\\frac{d-x}{d-c},} & {c \\leq x \\leq d} \\\\ {0,} & {d \\leq x}\\end{array}\\right.\n\\]\nhelp(trapezoid)\n\nHelp on function trapezoid in module src.functional.membership:\n\ntrapezoid(x, a, b, c, d)\n    Trapezoidal Membership Function\n\n    :param x: input value\n    :param a: bottom left point where membership is 0\n    :param b: top left point where membership is 1\n    :param c: top right point where membership is 1\n    :param d: bottom right point where membership is 0\n\ntrap = partial(trapezoid, a=10, b=20, c=60, d=95)\n\ndraw_function(trap(x))\n\nplt.text(11, trap(10), \"a\")\nplt.text(21, trap(20), \"b\")\nplt.text(61, trap(60), \"c\")\nplt.text(96, trap(95), \"d\")\nText(96, tensor([0.]), ‘d’)\n\n\n\nimg\n\n\n\n\n\nGaussian Membership Function\n\\[\n\\operatorname{gaussian}(x ; c, \\sigma)=e^{-\\frac{1}{2}\\left(\\frac{x-c}{\\sigma}\\right)^{2}}\n\\]\nhelp(gaussian)\n\nHelp on function gaussian in module src.functional.membership:\n\ngaussian(x, a, b)\n    Gaussian Membership Function\n\n    :param x: input value\n    :param a: The mean of the Gaussian Distribution\n    :param b: The standard deviation of the Distribution\n\n    Usage: gaussian(40, a=50, b=20)\n           gaussian(torch.Tensor([[20],[30]]), a=50, b=20)\n\ngaus = partial(gaussian, a=50, b=20)\n\ndraw_function(gaus(x))\n\nplt.text(50-5, gaus(50)-0.1, \"Mean\")\nplt.text(50+22, gaus(50+20), \"Standard Deviation\")\nText(72, tensor([0.6065]), ‘Standard Deviation’)\n\n\n\nimg\n\n\nGeneral Bell Curve Membership Function\n\\[\n\\operatorname{bell}(x ; a, b, c)=\\frac{1}{1+\\left|\\frac{x-c}{a}\\right|^{2 b}}\n\\]\nhelp(bell)\n\nHelp on function bell in module src.functional.membership:\n\nbell(x, a, b, c)\n    General Bell Curve Membership Function\n\n    :param x: input value\n    :param a: width of bell curve.\n    :param b: slop of the curve, lower values = curvier\n    :param c: centre of the curve.\n\nbellf = partial(bell, a=20, b=4, c=50)\n\ndraw_function(bellf(x))\n\n\n\nimg\n\n\n\n\n\nSigmoidal Membership Function\n\\[\n\\operatorname{sigmoid}(x ; a, c)=\\frac{1}{1+\\exp [-a(x-c)]}\n\\]\nhelp(sigmoid)\n\nHelp on function sigmoid in module src.functional.membership:\n\nsigmoid(x, a, b)\n    Sigmoidal Membership Function\n\n    :param x: input value\n    :param a: amount of curvature, higher values = unit step\n    :param b: 0.5 centre posistion\n\nsig = partial(sigmoid, a=1, b=50)\n\ndraw_function(sig(x))\n\n\n\nimg\n\n\nLeft-Right (LR) Membership Function\n\\[\n\\operatorname{lr}(x ; c, \\alpha, \\beta)=\\left\\{\\begin{array}{ll}{F_{L}} & {\\left(\\frac{c-x}{\\alpha}\\right), \\quad x \\leq c} \\\\ {F_{R}} & {\\left(\\frac{x-c}{\\beta}\\right), \\quad x \\geq c}\\end{array}\\right.\n\\]\nwhere \\(F_L(x)\\) and \\(F_R(x)\\) are monotonically decreasing functions. Let\n\\[\\begin{aligned} F_{L}(x) &=\\max \\left(0, \\sqrt{1-x^{2}}\\right) \\\\ F_{R}(x) &=e^{-|x|^{3}} \\end{aligned}\\]\nhelp(lr)\n\nHelp on function lr in module src.functional.membership:\n\nlr(x, a, b, c)\n    Left-Right (LR) Membership Function\n\n    :param x: input value\n    :param a: centre point of change\n    :param b: rate of decay after change\n    :param c: length of decay\n\nlr1 = partial(lr, a=65, b=60, c=10)\nlr2 = partial(lr, a=25, b=10, c=40)\n\ndraw_function(lr1(x))\ndraw_function(lr2(x))\n\nplt.grid()\nplt.legend([\"a = 65, b = 60, c = 10\", \"a = 25, b = 10, c = 40\"])\n&lt;matplotlib.legend.Legend at 0x7f37d3458048&gt;\n\n\n\nimg\n\n\n\n\n\nMulti-Dimensional Functions\nThe combination of different functions can be applied to many inputs. Here, we shall consider two variables \\(x, y\\) to demonstrate how MFs can be used with AND, OR operations.\n# Our two variables\nx = torch.linspace(-5, 5, 50)\ny = torch.linspace(-5, 5, 50)\nThe single dimension function can be referred to as a \\(\\textit{base set}\\).\n\\[\n\\operatorname{Base Set} = \\mu_A(x) = \\operatorname{gaussian}(x; a, b)\n\\]\nfig = plt.figure()\n\ndraw_function(gaussian(x, 0, 1.5))\n\nplt.title(\"Base set of A\")\nText(0.5, 1.0, ‘Base set of A’)\n\n\n\nimg\n\n\nThis can be turned into a cylindrical extension through:\n\\[\n    c(A) = \\int_{X \\times Y} \\mu_A(X) / (x, y)\n\\]\nwhere c(A) is our cylindrical extension.\nfig = plt.figure()\nax = fig.add_subplot(111, projection=\"3d\")\n\nxx, yy = np.meshgrid(x.numpy(), y.numpy())\n\nax.plot_surface(xx, \n                yy,\n                gaussian(torch.Tensor(xx), 0., 1.5).numpy(),\n                cmap=\"jet\")\n\nax.set_xlabel(\"x input\")\nax.set_ylabel(\"y input\")\nax.set_zlabel(\"Membership Value\")\nText(0.5, 0, ‘Membership Value’)\n\n\n\nimg\n\n\nTo use AND and OR operations, we can use the min and max respectively of two MF functions for each input dimension. The logical `and` is:\n\\[\n\\mu_A(x) \\land \\mu_A(y) = max(\\mu_A(x), \\mu_A(y))\n\\]\nand the logical `or` is:\n\\[\n\\mu_A(x) \\lor \\mu_A(y) = min(\\mu_A(x), \\mu_A(y))\n\\]\nfig = plt.figure()\nax = fig.add_subplot(111, projection=\"3d\")\n\nxx, yy = np.meshgrid(x.numpy(), y.numpy())\n\nandOp = torch.max(gaussian(torch.Tensor(xx), 0, 1.5), gaussian(torch.Tensor(yy), 0, 1.5))\n\nax.plot_surface(xx, yy, andOp.numpy(), cmap=\"jet\")\n\n\n\nimg\n\n\nfig = plt.figure()\nax = fig.add_subplot(111, projection=\"3d\")\n\norOp = torch.min(gaussian(torch.Tensor(xx), 0, 1.5), gaussian(torch.Tensor(yy), 0, 1.5))\n\nax.plot_surface(xx, yy, orOp.numpy(), cmap=\"jet\")\n\n\n\nimg\n\n\n\n\n\n\nCitationBibTeX citation:@online{morgan2019,\n  author = {Morgan, Jay Paul},\n  title = {Fuzzy {Logic} {Membership} {Functions}},\n  date = {2019-06-27},\n  url = {https://morganwastaken.com/blog/2019-06-27-membership-functions},\n  langid = {en}\n}\nFor attribution, please cite this work as:\nMorgan, Jay Paul. 2019. “Fuzzy Logic Membership Functions.”\nJune 27, 2019. https://morganwastaken.com/blog/2019-06-27-membership-functions."
  },
  {
    "objectID": "posts/2024-05-08-utilise/index.html",
    "href": "posts/2024-05-08-utilise/index.html",
    "title": "How I utilise the word utilise",
    "section": "",
    "text": "To put it simply: I don’t. I don’t like the word utilise. Instead, I /use/ the word use. It’s a great word, use, it’s very short—one syllable, and easily conveys the intention. While utilise can also convey the meaning, it’s wrapped up in this air of pretentiousness that just isn’t needed.\nI don’t utilise the word utilise, I use the word use.\n\n\n\nCitationBibTeX citation:@online{morgan2024,\n  author = {Morgan, Jay Paul},\n  title = {How {I} Utilise the Word Utilise},\n  date = {2024-05-08},\n  url = {https://morganwastaken.com/blog/2024-05-08-utilise},\n  langid = {en}\n}\nFor attribution, please cite this work as:\nMorgan, Jay Paul. 2024. “How I Utilise the Word Utilise.”\nMay 8, 2024. https://morganwastaken.com/blog/2024-05-08-utilise."
  },
  {
    "objectID": "posts/2020-03-05-makefile/index.html",
    "href": "posts/2020-03-05-makefile/index.html",
    "title": "Makefile: Towards Reproducible Research-based Programming",
    "section": "",
    "text": "I’ve been experimenting with make to deliver research projects. It has been to be a great way to alleviate some particular pain points that arise from these types of projects. Sufficed to say, the make tool has been an excellent addition to my workflow, one that I shall continue to use and experiment with.\nIn this post, I would like to introduce you to make and how it can be used to help make research more reproducible and, ultimately, easier to manage complicated experiments. We shall first look at the problems that normally appear in research programming to give adequate background reason as to why make may be useful in this area. Then, after these problems have been understood, we will look at the basics of make and the construction of makefiles to both quickly automate our research while making it more reproducible for others.\nDISCLAIMER: I am by no means an expert in writing makefiles. And if you are, you may think some of the examples are not the optimal way to encode makefile rules. Indeed, many of the makefile examples will be somewhat more verbose than what you would want to use in production-grade products. However, for the purpose of this discussion, optimal and efficient makefiles are not conducive for learning about the basics. It may be better to create simple rules that work first, then once you’re comfortable, making the makefile more complicated yet concise in the name of efficiency."
  },
  {
    "objectID": "posts/2020-03-05-makefile/index.html#a-simple-example",
    "href": "posts/2020-03-05-makefile/index.html#a-simple-example",
    "title": "Makefile: Towards Reproducible Research-based Programming",
    "section": "A simple example",
    "text": "A simple example\nLet us begin with a very basic example. Our project is going to be very simple: we have a simple data source, a CSV file. With this data, we need to measure the mean and standard deviation. Not a very exciting example, and it certainly won’t win you a noble prize, but it will highlight how we might create our simple makefile to automate this process.\n\n\n\nimg\n\n\nIn this example, we have two starting files: (1) our data source – data.csv; and (2) our program with which we can import the data source and compute the mean and standard deviation, aptly named stats.py. This program needs no command line arguments, but when called it simply looks for data.csv, computes the statistics and writes a new file output.csv.\nIn the same directory, we shall create a new file called Makefile. The contents of our makefile are going look like this:\noutput.csv: data.csv stats.py\n    python stats.py \nThis simple example includes the majority of what you will be doing in makefiles. We have a target in this case output.csv. We can tell its a target because it is followed by a colon ‘:’. This is the command we will pass to make when we wish to execute our make file.\nNext, we specify our (optional) dependencies. Our target depends on two files: data.csv and stats.py. This is simple a space delimited list of files after our target. Simply stated, we are telling make that in order to create our CSV file, both data.csv and stats.py must exist. But there’s more: make is smart and by listing the dependencies, we are telling make that if either our data or our program changes then output.csv will need to be re-made. If they haven’t change and output.csv already exists, make will tell us that nothing more needs to be done (it doesn’t bother executing the program twice).\nThe next line tells make what to do in order to create our target, our rule. In this case we call python stats.py. Like python, makefiles are indentation delimited. But unlike python where this indentation can be done either with tabs or spaces (but definitely not both), makefiles are always indented with tabs.\nTo run this makefile, we type make output.csv into the command line. If everything is setup correctly, make will run python stats.py and our output.csv will be created."
  },
  {
    "objectID": "posts/2020-03-05-makefile/index.html#a-more-complicated-example",
    "href": "posts/2020-03-05-makefile/index.html#a-more-complicated-example",
    "title": "Makefile: Towards Reproducible Research-based Programming",
    "section": "A more complicated example",
    "text": "A more complicated example\nSuppose we have two algorithms and we wish to generate some comparative metrics. Like the previous example, we have a single data source called data.csv, but this time, we have two python programs: one for each algorithm. Each of these programs will create its own CSV file output. The process flow will look like this:\n\n\n\nimg\n\n\nIn this case, we wish to execute both python programs to create both outputs.\noutput_1.csv: data.csv algorithm_1.py \n    python algorithm_1.py\n\noutput_2.csv: data.csv algorithm_2.py\n    python algorithm_2.py \nThis time we have created two targets, one for each of our output csv files. Each target has their own dependencies and the rule to create the different outputs.\nIn order to actually create the CSV files, we will type:\nmake output_1.csv\nmake output_2.csv\ninto the command line. make is of course happy to take these two requests, but there is more onerous on us to make sure to execute both commands. While this is okay for these two CSVs, it will become more laborious when we have more.\nTo overcome this issue, we can use a PHONY target. A phony target is one that won’t exist but serves as a alias to provide make with a command we can type. In our previous example, both output_1.csv and output_2.csv were files that will exist after make has executed the two rules. With a phony target, however, make won’t bother to look for the target’s existence.\nWe can create a phony target with:\n.PHONY: output\noutput: output_1.csv output_2.csv\nOur phony target, named output, depends on both our CSV files. Now, we can get make to create both of these output files with a single command: make output."
  },
  {
    "objectID": "posts/2020-03-05-makefile/index.html#multistage-processing",
    "href": "posts/2020-03-05-makefile/index.html#multistage-processing",
    "title": "Makefile: Towards Reproducible Research-based Programming",
    "section": "Multistage processing",
    "text": "Multistage processing\nOur previous examples have consisted of only one processing step, we take our input data, and produce an output. In these cases, keeping track of what is up-to-date and what still needs to be executed is easy enough. But when we introduce processing pipelines where the output of one program feeds into another, things can get a little more complicated.\n\n\n\nimg\n\n\nWe have introduced a significantly more complicated process. We use a c++ program squares.cpp to take all of the data in the CSV, square it, and save the intermediate version as squared_data.csv. Processes such as this may occur when the dataset is large enough that we apply computations in batches or jobs via high-performance computing. In these cases, it is better to keep the original data source and preserve its mutability.\nWith this squared data, our third algorithm – algorithm_3.py – is executed to produce output3.csv. To automate this process, we will add the following rule to our makefile:\noutput_1.csv: data.csv algorithm_1.py\n    python algorithm_1.py\n\noutput_2.csv: data.csv algorithm_2.py\n    python algorithm_2.py\n\noutput_3.csv: data.csv squares.cpp\n    g++ -i squares.cpp squares.o\n    ./squares.o \n    python algorithm_3.py\n\n.PHONY: outputs\noutputs: output_1.csv output_2.csv output_3.csv\nand all outputs can be made with make outputs.\nBoth algorithm 1 and 2 are the same as the previous examples, but algorithm 3 has more computation steps. First, we must ensure that our c++ code is compiled, then we must produce the squares_data.csv (done by ./squares in this example), and then finally run python algorithm_3.py to produce the results.\nThis is great, but what if algorithm 2 depended on both data.csv and squared_data.csv?\n\n\n\nimg\n\n\nWe could change our output_2.csv target to something like this:\noutput_2.csv: data.csv squared_data.csv algorithm_2.py \n    g++ -i squares.cpp squares.o \n    ./squares.o \n    python algorithm_2.py \nBut we may notice that the compilation of the c++ program occurs twice. So, instead, lets make the executable a target within its own right:\nsquares.o: squares.cpp \n    g++ -i squares.cpp squares.o \nIn addition, we can also create a target for the squared_data.csv as we only with to create it once.\nsquared_data.csv: squares.o \n    ./squares.o\nand we’ll amend our previous versions of targets output_2.csv and output_3.csv to depend on this executable already existing and being up-to-date.\noutput_2.csv: data.csv algorithm_2.py squared_data.csv\n    python algorithm_2.py\n\noutput_3.csv: data.csv algorithm_3.py squared_data.csv\n    python algorithm_3.py \nThis way, both the compilation and creation of squared_data.csv happens once.\nOur final makefile shall look like the following:\noutput_1.csv: data.csv algorithm_1.py\n    python algorithm_1.py\n\noutput_2.csv: data.csv algorithm_2.py squared_data.csv\n    python algorithm_2.py\n\noutput_3.csv: data.csv algorithm_3.py squared_data.csv \n    python algorithm_3.py\n\nsquares.o: squares.cpp \n    g++ -i squares.cpp squares.o\n\nsquared_data.csv: squares.o \n    ./squares.o\n\n.PHONY: outputs \noutputs: output_1.csv output_2.csv output_3.csv\nand all output CSV files can still be created with one single command: make outputs. If we wish to just execute one pathway or algorithm, we can just specify that particular target. For example, if we just wish to run algorithm 1, we can run make output_1.csv."
  },
  {
    "objectID": "posts/2020-03-05-makefile/index.html#creating-a-summarised-report",
    "href": "posts/2020-03-05-makefile/index.html#creating-a-summarised-report",
    "title": "Makefile: Towards Reproducible Research-based Programming",
    "section": "Creating a summarised report",
    "text": "Creating a summarised report\nWe can go further and improve our process of research. Now that we have our outputs from each of the algorithm, we may summarise them and produce a final CSV file to present in a report.\n\n\n\nimg\n\n\nOur summarise.py takes all the results from each algorithm, provides some summary statistics, and outputs a single CSV file that is suitable for a report.\nIf we use latex, and the PGFplotstable package, we can also automate the process of getting these results into our report.\n\\documentclass{article}\n\n\\usepackage{pgfplotstable} % must use this package\n\n\\title{Report}\n\n\\begin{document}\n\n% import our table from the CSV file\n\\begin{table}\n\\centering\n\\caption{My table}\n\\label{tab:my_table}\n\\pgfplotstableread[col sep=comma]{final_results.csv}\\data\n\\pgfplotstypeset[\n    % column options\n]{\\data}\n\\end{table}\n\n\\end{document}\nNow, every time our results file changes, either because we added more algorithms, or we have modified the code or data, our report will always be up to date.\nPGFPlotstable is a very useful package for importing, formatting, and even doing basic evaluations of data. Moreover, if you combine this package with the regular PGFplots, you data tables and plots can be automatically kept in sync with one another.\nWe can go further and add the compilation of this latex document to our makefile:\n.PHONY: report\nreport: final_results.csv report.tex\n    pdflatex report.tex\nAnd compile it using make report. These is an added benefit here that we may also add the recompilation rules for if our document contains a bibliography:\n.PHONY: report\nreport: final_results.csv report.tex references.bib\n    pdflatex report.tex\n    bibtex report.aux\n    pdflatex report.tex\n    pdflatex report.tex"
  },
  {
    "objectID": "posts/2023-03-18-Org-babel-remote-images/index.html",
    "href": "posts/2023-03-18-Org-babel-remote-images/index.html",
    "title": "Displaying remote images in Org-mode",
    "section": "",
    "text": "In one of my previous posts, I explained how a remote python process can be setup in an org-mode documents. Therefore, allowing you to offload any large compute to a remote server.\nHowever, in the previous post, I mentioned how I was unable to get images created as a result of a remote process (i.e. plotting with matplotlib) to display inline. My workaround was just to visit the remote file in a separate buffer using C-c C-o. But today, I chanced upon this stackoverflow answer that exactly solves my issue.\nUnbeknownst to me, there is an variable that specifies how org-mode should handle remote paths. This variable, aptly named org-display-remote-inline-images (perhaps I should have searched in emacs’s variable list for some combination of these keywords), can be change from skip (which ignores any remote paths), to download which will display the image inline!\nThis is the documentation for this variable.\norg-display-remote-inline-images is a variable defined in ‘org.el’.\n\nIts value is ‘skip’\n\nHow to display remote inline images.\nPossible values of this option are:\n\nskip        Don’t display remote images.\ndownload    Always download and display remote images.\ncache       Display remote images, and open them in separate buffers\n            for caching.  Silently update the image buffer when a file\n            change is detected.\nBy setting this variable appropriately, working with a remote process in org-mode is just as it is with a local process – seamless.\n\n\n\nCitationBibTeX citation:@online{morgan2023,\n  author = {Morgan, Jay Paul},\n  title = {Displaying Remote Images in {Org-mode}},\n  date = {2023-03-18},\n  url = {https://morganwastaken.com/blog/2023-03-18-Org-babel-remote-images},\n  langid = {en}\n}\nFor attribution, please cite this work as:\nMorgan, Jay Paul. 2023. “Displaying Remote Images in\nOrg-Mode.” March 18, 2023. https://morganwastaken.com/blog/2023-03-18-Org-babel-remote-images."
  },
  {
    "objectID": "posts/2024-04-21-scientific-ethics/index.html",
    "href": "posts/2024-04-21-scientific-ethics/index.html",
    "title": "On Scientific Ethics",
    "section": "",
    "text": "“I am a scientist, and I solve problems. I don’t have to care about ethics!”\nThis statement concerns the ethics of scientists – scientific ethics. To understand whether the person making this statement is correct or not in their view, we must first understand the contents of the statement. Namely, the nature of ethics, and what it means to be a scientist.\nTo begin, let us look at ethics.\nEthics comes from the ancient Greek word, ethos, meaning character; personal disposition. Ethics by definition are the moral principles that guides the behaviour or conducting of an activity. But what are these principles? Immanuel Kant believed there were universal principles. He believed that our ethical framework is not situational-dependent and personal, such as making ourselves happy, but there were laws by which a rational actor behaves. Therefore to act ethically is to act rationally as expressed by following of the ethical principles.\nAristotle agrees with the relation of rationality and ethical standards. In his series of lectures, Nicomachean ethics, Aristotle explains the absurdity of letting barbarians massacre your family without any fight. Aristotle was a strong believer that there is a middle ground to all things and situations, and a person who acts rationally always strives to determine this middle ground. But, like in the situation of barbarians, the middle ground does not simply mean a neutrality and apathy and not doing anything potentially bad, but it means to the right thing at the right time. As agreed by Dante ‘There is a special place in hell for people who, in a time of a moral crisis, maintain their neutrality’. Sometimes we must act in order to act rationally and ethically given the circumstance and situation.\nLet us now turn to the subject of the circumstance: being a scientist.\nThe Science Council defines a scientist as someone who systematically gathers and uses evidence, to make a hypothesis and test them, to gain and share understanding and knowledge. In this way, we may define the scientific ethical framework by the guiding principles:\n\nHonesty in scientific reporting.\nUnbiased analysis of results\nOpen sharing of methods, code, data.\nCorrect citation and refrain from plagiarism or stealing of ideas.\nMoral obligations to society in general, and, in some disciplines, responsibility in weighing the rights of human and animal subjects.\n\nTo be a scientist is to follow these guiding principles. To go against these principles is to not act ethically, and therefore not rational. Someone who does not care about ethics is acting with absurdity, and by definition not a scientist.\nBut our statement concerns someone who wishes to disregard ethics in pursuit of ‘solving problems’. This person is following the hedonistic view that their desires of solving problems overrides those of any moral principles and ethical concerns. This, in nature, in very unscientific as their interest is not in the scientific method, but in the result of having ‘solved a problem’.\nSomeone who claims to be a scientist to want to solve problems, must do so with accordance to the ethical principles therein. Acting ethically, is not a chain with which we bind ourselves, but a compass that guides us to do correct science. To solve problems we must find a hypothesis and method of testing it that follows our ethical principles of science. Solving problems does not require us to throw away our ethics—for that would not be science. To act against these ethical codes would not be scientific and therefore irrational. From this we may conclude that the statement presented paints a picture of someone who is living paradoxically with their desired character of scientist.\nFinally, I would like to end my argument with a quote from Albert Einstein, who says ‘Most people say that it is the intellect which makes a great scientist. They are wrong: it is character.’ When we understand that in ancient Greek ‘character’ was ‘ethos’, we see this quote to be correct.\n\n\n\nCitationBibTeX citation:@online{morgan2024,\n  author = {Morgan, Jay Paul},\n  title = {On {Scientific} {Ethics}},\n  date = {2024-04-21},\n  url = {https://morganwastaken.com/posts/2024-04-21-scientific-ethics/},\n  langid = {en}\n}\nFor attribution, please cite this work as:\nMorgan, Jay Paul. 2024. “On Scientific Ethics.” April 21,\n2024. https://morganwastaken.com/posts/2024-04-21-scientific-ethics/."
  },
  {
    "objectID": "posts/2021-03-29-bctcs/index.html",
    "href": "posts/2021-03-29-bctcs/index.html",
    "title": "British Colloquium for Theoretical Computer Science (BCTCS) 2021",
    "section": "",
    "text": "Presentation Abstract\nMachine Learning (ML) has had a remarkable impact on society. Everything from the phones in our pockets, to the cars that we drive, are being increasingly outfitted with this progressively sophisticated suite of algorithms. But while many of the most basic and fundamental algorithms from ML can be formally verified and tested for safety without much trouble, the same may not be said for Deep Learning (DL) – a prominent forerunner in the state-of-the-art for ML research. These DL models, while performing simple matrix-to-matrix operations at a micro-level, have evolved in scale far past what is tractable for current formal verification methods – all in the pursuit of improving accuracy and performance. This issue of tractability is unsettling considering that the existence of adversarial examples is well known in the ML community. These adversarial examples occur when very small changes to the input space result in a large change in the output space and cause a miss-classification made by the DL model. In the context of self-driving vehicles, small defects and visual artifacts in the sensor input of the DL model, could lead the vehicle to wrongly conclude a stop sign indicates to continue driving where it should have stopped. While the manufacturers will need to put safe-guards in place to prevent this from happening, we should formally prove the (non)-existence of these adversarial examples in the DL model itself. In this presentation, I present the foundational knowledge for understanding adversarial examples, how we can use the input space to dictate the search space for the existence of these examples, and demonstrate their presence with the use of SAT-solving. This work, as a free and open-source project, provides a framework for ML practitioners to verify their own architectures.\nPresentation Slides\nSlides\n\n\n\nCitationBibTeX citation:@online{morgan2021,\n  author = {Morgan, Jay Paul},\n  title = {British {Colloquium} for {Theoretical} {Computer} {Science}\n    {(BCTCS)} 2021},\n  date = {2021-03-29},\n  url = {https://morganwastaken.com/blog/2021-03-29-bctcs},\n  langid = {en}\n}\nFor attribution, please cite this work as:\nMorgan, Jay Paul. 2021. “British Colloquium for Theoretical\nComputer Science (BCTCS) 2021.” March 29, 2021. https://morganwastaken.com/blog/2021-03-29-bctcs."
  },
  {
    "objectID": "artwork/2024-11-21-poppy/index.html",
    "href": "artwork/2024-11-21-poppy/index.html",
    "title": "Poppy",
    "section": "",
    "text": "Poppy, Charcoal on Paper, 11/2024"
  },
  {
    "objectID": "artwork/2024-09-22-study-of-hands/index.html",
    "href": "artwork/2024-09-22-study-of-hands/index.html",
    "title": "Small Study of Hands",
    "section": "",
    "text": "Small Study of Hands, Charcoal on Paper, 09/2024"
  },
  {
    "objectID": "artwork/2024-11-10-pumpkins/index.html",
    "href": "artwork/2024-11-10-pumpkins/index.html",
    "title": "Pumpkins and Squash",
    "section": "",
    "text": "It’s that time of year, plenty of pumpkins and squashes about!\n\n\n\nPumpkins and Squash, Pencil on Paper, 11/2024"
  },
  {
    "objectID": "artwork/2024-11-16-toby-profile/index.html",
    "href": "artwork/2024-11-16-toby-profile/index.html",
    "title": "Toby Profile",
    "section": "",
    "text": "Profile of Toby, charcoal on paper, 11/2024."
  },
  {
    "objectID": "artwork/2024-10-05-singleton-tree/index.html",
    "href": "artwork/2024-10-05-singleton-tree/index.html",
    "title": "Singleton Tree",
    "section": "",
    "text": "Singleton Tree, Pencil on Paper, 10/2024"
  },
  {
    "objectID": "talks.html",
    "href": "talks.html",
    "title": "Talks and Presentations",
    "section": "",
    "text": "Order By\n       Default\n         \n          Title\n        \n         \n          Date - Oldest\n        \n         \n          Date - Newest\n        \n         \n          Author\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n\n\n\n\n\n\nTemporal Phenotype of Human Information Search\n\n\n\n\n\n\nconference\n\n\nposter\n\n\n\nFrom the paper: Predicting Temporal Patterns in Keyword Searches with Recurrent Neural Networks - Phenotyping Human Behaviour from Search Engine Usage\n\n\n\n\n\nDec 18, 2024\n\n\nJay Paul Morgan\n\n\n\n\n\n\n\n\n\n\n\n\nIcons: What do we know? Do we know things? Let’s find out\n\n\n\n\n\n\nconference\n\n\npresentation\n\n\n\nAnalysis of psychological normative studies and learning with Deep Learning models.\n\n\n\n\n\nAug 28, 2024\n\n\nJay Paul Morgan\n\n\n\n\n\n\n\n\n\n\n\n\nManifold-aware Adversarial Examples\n\n\n\n\n\n\nworkshop\n\n\npresentation\n\n\n\nConstructing manifold-aware adversarial examples using our adaptive neighbourhoods algorithm.\n\n\n\n\n\nJul 4, 2024\n\n\nJay Paul Morgan\n\n\n\n\n\n\n\n\n\n\n\n\nCloud Removal\n\n\n\n\n\n\nworkshop\n\n\nposter\n\n\n\nPoster presentation of our work of removing cloud contaminants from ground-based solar imagery.\n\n\n\n\n\nApr 19, 2023\n\n\nJay Paul Morgan\n\n\n\n\n\n\n\n\n\n\n\n\nAdaptive Neighbourhoods for the Discovery of Adversarial Examples\n\n\n\n\n\n\nworkshop\n\n\npresentation\n\n\n\nWe demonstrate how, through the development of uniquely-adaptive searchable regions, existing methods can help to further improve the robustness of Deep Learning models, and also make the existing methods applicable to non-image related tasks by providing an upper bound for discovering adversarial examples.\n\n\n\n\n\nOct 13, 2022\n\n\nJay Paul Morgan\n\n\n\n\n\n\n\n\n\n\n\n\nLearning how to Learn with Deep Learning\n\n\n\n\n\n\npresentation\n\n\n\nA small presentation given to a select group of students during the summer months. This presentation gives a very brief introduction to Deep Learning and the basic components that make up the feed-forward network.\n\n\n\n\n\nAug 5, 2021\n\n\nJay Paul Morgan\n\n\n\n\n\n\n\n\n\n\n\n\nTrustable Machine Learning Systems\n\n\n\n\n\n\npresentation\n\n\nworkshop\n\n\n\nI present the foundational knowledge for understanding adversarial examples, how we can use the input space to dictate the search space for the existence of these examples, and demonstrate their presence with the use of SAT-solving. This work, as a free and open-source project, provides a framework for ML practitioners to verify their own architectures.\n\n\n\n\n\nMar 30, 2021\n\n\nJay Paul Morgan\n\n\n\n\n\n\n\n\n\n\n\n\nA Chatbot Framework for the Children’s Legal Centre\n\n\n\n\n\n\nconference\n\n\npresentation\n\n\n\nWe present novel method to address legal rights for children through a chatbot framework by integrating machine learning, a dialogue graph, and information extraction.\n\n\n\n\n\nDec 14, 2018\n\n\nJay Paul Morgan\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "publications/2024-11-06-whales/index.html",
    "href": "publications/2024-11-06-whales/index.html",
    "title": "A first vocal repertoire characterization of long-finned pilot whales (Globicephala melas) in the Mediterranean Sea: a machine learning approach",
    "section": "",
    "text": "PDF  Google Scholar Bibtex\n\nAbstract\nThe acoustic repertoires of long-finned pilot whales (Globicephala melas) in the Mediterranean Sea are poorly understood. This study aims to create a catalogue of calls, analyse acoustic parameters, and propose a classification tree for future research. An acoustic database was compiled using recordings from the Alboran Sea, Gulf of Lion and Ligurian Sea (Western Mediterranean Basin) between 2008 and 2022, totalling 640 calls. Using a deep neural network, the calls were clustered based on frequency contour similarities, leading to the identification of 40 distinct call types defining the local population’s vocal repertoire. These categories encompass pulsed calls with varied complexities, from simplistic to highly intricate structures comprising multiple elements and segments. This study marks the initial documentation of the vocal catalogue of long-finned pilot whales in the Mediterranean Sea. Subsequent research should delve deeper into this multifaceted communication system and explore its potential linkages with social structures."
  },
  {
    "objectID": "publications/2023-12-12-chemistry/index.html",
    "href": "publications/2023-12-12-chemistry/index.html",
    "title": "Domain-informed graph neural networks: a quantum chemistry case study",
    "section": "",
    "text": "PDF  Google Scholar Bibtex\n\nAbstract\nWe explore different strategies to integrate prior domain knowledge into the design of a deep neural network (DNN). We focus on graph neural networks (GNN), with a use case of estimating the potential energy of chemical systems (molecules and crystals) represented as graphs. We integrate two elements of domain knowledge into the design of the GNN to constrain and regularise its learning, towards higher accuracy and generalisation. First, knowledge on the existence of different types of relations (chemical bonds) between atoms is used to modulate the interaction of nodes in the GNN. Second, knowledge of the relevance of some physical quantities is used to constrain the learnt features towards a higher physical relevance using a simple multi-task paradigm. We demonstrate the general applicability of our knowledge integrations by applying them to two architectures that rely on different mechanisms to propagate information between nodes and to update node states."
  },
  {
    "objectID": "publications/2021-01-01-adversarials/index.html",
    "href": "publications/2021-01-01-adversarials/index.html",
    "title": "Adaptive Neighbourhoods for the Discovery of Adversarial Examples",
    "section": "",
    "text": "PDF  Google Scholar Bibtex\n\nAbstract\nDeep Neural Networks (DNNs) have often supplied state-of-the-art results in pattern recognition tasks. Despite their advances, however, the existence of adversarial examples have caught the attention of the community. Many existing works have proposed methods for searching for adversarial examples within fixed-sized regions around training points. Our work complements and improves these existing approaches by adapting the size of these regions based on the problem complexity and data sampling density. This makes such approaches more appropriate for other types of data and may further improve adversarial training methods by increasing the region sizes without creating incorrect labels."
  },
  {
    "objectID": "publications/2018-01-01-chatbot/index.html",
    "href": "publications/2018-01-01-chatbot/index.html",
    "title": "A Chatbot Framework for the Children’s Legal Centre",
    "section": "",
    "text": "PDF  Google Scholar Bibtex\n\nAbstract\nThis paper presents a novel method to address legal rights for children through a chatbot framework by integrating machine learning, a dialogue graph, and information extraction. The method addresses a significant problem: we cannot presume that children have common knowledge about their rights or express themselves as an adult might. In our framework, a chatbot user begins a conversation, where based on the circumstance described, a neural network predicts both speech acts, relating to a dialogue graph, and legal types. Information is extracted in order to create a case for a legal advisor. In collaboration with the Children’s Legal Centre Wales, who advocate for the improvement of legal rights in Wales, a corpus has been constructed and a prototype chatbot developed. The framework has been evaluated with classification measures and a user study."
  },
  {
    "objectID": "talks/2023-04-19-cloud-removal/index.html#abstract",
    "href": "talks/2023-04-19-cloud-removal/index.html#abstract",
    "title": "\n      Cloud Removal\n    ",
    "section": "Abstract",
    "text": "Abstract\nAll ground based observatories face a same problem: images may be polluted by terrestrial clouds. These clouds are often thin, due to no observations being usually performed in case of thick clouds. We propose a new method to remove these cloud shadows, based on deep learning and recover the underlying solar features.\nThis work follows from our published source code."
  },
  {
    "objectID": "talks/2022-10-13-adaptive-neighbourhoods/index.html#abstract",
    "href": "talks/2022-10-13-adaptive-neighbourhoods/index.html#abstract",
    "title": "\n      Adaptive Neighbourhoods for the Discovery of Adversarial Examples\n    ",
    "section": "Abstract",
    "text": "Abstract\nTalk prepared for the AISB Workshop on Explainability and Transparency in AI, XTAI 2022.\nMachine Learning, in particular Deep Learning, has most recently provided the state-of-the-art results for many tasks such as object recognition, text-to-speech processing, and credit-card fraud detection. In many cases, Deep Learning has even out-performed human performance on these very same tasks. Despite this advance in performance, however, the existence of so-called adversarial examples is well known within the community. These adversarial examples are the metaphorical ‘blind-spot’ of Deep Learning models, where very small (often human-imperceptible) changes to model’s input can result catastrophic miss-classifications. These adversarial examples then pose a great safety risk, especially in systems where safety is critical such as fully-automotive vehicles.\nTo defend against and attempt to eradicate the existence of adversarial examples in Deep Learning models, principle works have sought to search for their existence within fixed-sized regions around training points, and use the found adversarial examples as a criterion for learning. These works have demonstrated how the robustness of Deep Learning models against adversarial examples improves through these training regimes.\nOur work means to compliment and improve on these existing approaches by adapting the size of the searchable regions around training points, based upon the complexity of the problem and data sampling density. The result is each training point has an adapted region around it to which adversarial examples can be searched for and found.\nWe demonstrate how, through the development of uniquely-adaptive searchable regions, existing methods can help to further improve the robustness of Deep Learning models, and also make the existing methods applicable to non-image related tasks by providing an upper bound for discovering adversarial examples.\nIn this presentation, we will explore how adversarial examples can be determined through the use of existing approaches. Further to these approaches, how our method allows us to generate unique and adapted region sizes for all training points in a dataset."
  },
  {
    "objectID": "talks/2021-08-05-Learning-how-to-learn-with-deep-learning/index.html",
    "href": "talks/2021-08-05-Learning-how-to-learn-with-deep-learning/index.html",
    "title": "\n      Learning how to Learn with Deep Learning\n    ",
    "section": "",
    "text": "Link to the presentation"
  },
  {
    "objectID": "talks/2021-08-05-Learning-how-to-learn-with-deep-learning/index.html#abstract",
    "href": "talks/2021-08-05-Learning-how-to-learn-with-deep-learning/index.html#abstract",
    "title": "\n      Learning how to Learn with Deep Learning\n    ",
    "section": "Abstract",
    "text": "Abstract\nA small presentation given to a select group of students during the summer months. This presentation gives a very brief introduction to Deep Learning and the basic components that make up the feed-forward network. This simplification of Deep Learning is intended to give a basic intuition about how learning works, even if the resultant models are not considered state-of-the-art (for that, more complex computations will be needed).\n\nRunning the presentation\nThe presentation is written as a Pluto.jl notebook to interactively demonstrate some of the core concepts of Deep Learning. Therefore, you have a few choices in running the presentation. Firstly, if you have the Julia programming language installed on your computer, you can download presentation.jl, and open up the Julia REPL by running julia from this same directory where presentation.jl was downloaded to. In the REPL, enter the following commands:\nusing Pluto;\nPluto.run()\nThe Pluto.jl server will begin running and a new web-page will be opened on your default web browser. From there, type presentation.jl into the ‘Open from file’ text box and click open. The notebook should now start and install the required libraries (this might take a while the first time you open it).\nAn alternative is to using Binder. By clicking this link, a container will be created in a couple of minutes, and you will be able to view the presentation."
  },
  {
    "objectID": "talks/2024-07-04-goscai/index.html#abstract",
    "href": "talks/2024-07-04-goscai/index.html#abstract",
    "title": "\n      Manifold-aware Adversarial Examples\n    ",
    "section": "Abstract",
    "text": "Abstract\nIn this presentation, I detail the motivation behind our research of the Adaptive Neighbourhoods algorithm. In this way, we construct ‘manifold-aware’ adversarial examples."
  },
  {
    "objectID": "projects.html",
    "href": "projects.html",
    "title": "Projects",
    "section": "",
    "text": "The Development of an Accessible, Diverse and Inclusive Digital Visual Language – Icons, symbols, and signs represent a visual language that facilitates communication because it conveys large amounts of information in single units intended to be understood by everyone irrespective of culture or language. The development of a visual language of icons and symbols that is accessible, inclusive, diverse and neutral is of paramount importance now that the number of digital interfaces that use such language keep expanding at a global level. The proposed project is the first to gather evidence from a diverse population that will be, by default inclusive, and create web application to make those evidence-based guidelines easily accessible to all. This knowledge will be disseminated to a wider audience to promote better use of icon design that is inclusive to a wider audience; one that includes different cultures and languages. From research outputs of the first stage of the project, with the help of the RA we will design and build a machine learning model to learn how icons are rated across groups based on their 7 key properties. This machine learning model will provide the classification and usability scores that will form the basis of an online searchable database for all the key icon characteristics, thereby removing the obstacles for developers to use good icons based on research-backed principles.\n\nProject Name: The Development of an Accessible, Diverse and Inclusive Digital Visual Language\nAwarded: August 2022\nAwarding Body: Morgan Advanced Studies Institute (MASI)\n\nPREdicting Solar Activity using machine learning on heteroGEneous data (PRESAGE) – Our project concerns itself with the activity of the Sun, those events (e.g. flares, coronal mass ejections (CME)) are dynamical phenomena that may have strong impacts on the solar-terrestrial environment. Events of solar activity seem to be strongly associated with the evolution of solar structures (e.g. active regions, filaments), which are objects of the solar atmosphere that differ from the “quiet Sun” and which appear, evolve, and disappear over a period of days to months. The exact mechanisms of solar activity, and the links between solar structures and activity events, are still ill-understood.\n\nProject Name: PREdicting Solar Activity using machine learning on heteroGEneous data (PRESAGE)\n\nDeveloping Resilience against Online Grooming (DRaOG) – The grant application was based on the research outputs of `Integrating linguistic knowledge into DNNs: Application to online grooming detection’. This work and its outputs were included in a grant application to further collaborate with police forces and social workers in the UK. This grant is a collaborative effort between the Department of Computer Science, and College of Law, Swansea, and Université de Toulon, France. More information about the grant and the funding body can be found on the End Violence Against Children website at https://www.end-violence.org/grants/swansea-university and at the Project’s website: https://www.swansea.ac.uk/project-dragon-s/\n\nProject Name: DRAGON-S\nAwarded: January 2021\nAwarding Body: End Violence Against Children (EVAC)"
  },
  {
    "objectID": "publications.html",
    "href": "publications.html",
    "title": "Publications",
    "section": "",
    "text": "Order By\n       Default\n         \n          Title\n        \n         \n          Date - Oldest\n        \n         \n          Date - Newest\n        \n         \n          Author\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n\n\n\n\n\n\nA first vocal repertoire characterization of long-finned pilot whales (Globicephala melas) in the Mediterranean Sea: a machine learning approach\n\n\n\n\n\n\nResearch\n\n\nNeural Network\n\n\nBioacoustics\n\n\n\nThe acoustic repertoires of long-finned pilot whales (Globicephala melas) in the Mediterranean Sea are poorly understood. This study aims to create a catalogue of calls, analyse acoustic parameters, and propose a classification tree for future research. An acoustic database was compiled using recordings from the Alboran Sea, Gulf of Lion and Ligurian Sea (Western Mediterranean Basin) between 2008 and 2022, totalling 640 calls. Using a deep neural network, the calls were clustered based on frequency contour similarities, leading to the identification of 40 distinct call types defining the local population’s vocal repertoire. These categories encompass pulsed calls with varied complexities, from simplistic to highly intricate structures comprising multiple elements and segments. This study marks the initial documentation of the vocal catalogue of long-finned pilot whales in the Mediterranean Sea.\n\n\n\n\n\nNov 6, 2024\n\n\nMarion Poupard, Paul Best, Jay Paul Morgan, Gianni Pavan, Hervé Glotin\n\n\n\n\n\n\n\n\n\n\n\n\nRemoving cloud shadows from ground-based solar imagery\n\n\n\n\n\n\nResearch\n\n\nNeural Network\n\n\nHeliophysics\n\n\nImage Processing\n\n\nComputer Vision\n\n\n\nCloud coverage can contaminate and occlude our vision of the Sun. This cloud-contamination can vastly reduce the amount of usable data for scientists studying the weather conditions on the Sun. In this work, we address this issue using Neural Networks to remove clouds from solar imagery.\n\n\n\n\n\nSep 9, 2024\n\n\nAmal Chaoui, Jay Paul Morgan, Adeline Paiement, Jean Aboudarham\n\n\n\n\n\n\n\n\n\n\n\n\nDomain-informed graph neural networks: a quantum chemistry case study\n\n\n\n\n\n\nResearch\n\n\nQuantum Chemistry\n\n\nNeural Network\n\n\n\nEstimating the potential energies of out-of-equilibrium molecules and crystals using expert-informed Neural Networks.\n\n\n\n\n\nDec 12, 2023\n\n\nJay Paul Morgan, Adeline Paiement, Christian Klinke\n\n\n\n\n\n\n\n\n\n\n\n\nRemoving cloud shadows from ground-based solar imagery\n\n\n\n\n\n\nResearch\n\n\nHeliophysics\n\n\nNeural Network\n\n\n\nA U-Net-style Neural Network to remove cloud contaminants from ground-based solar imagery.\n\n\n\n\n\nApr 4, 2023\n\n\nAmal Chaoui, Jay Paul Morgan, Adeline Paiement, Jean Aboudarham\n\n\n\n\n\n\n\n\n\n\n\n\nStrategies to use prior knowledge to improve the performance of Deep Learning: an approach towards trustable Machine Learning systems\n\n\n\n\n\nPhD Thesis of developing strategies for incorporating priors and domain knowledge into design of Deep Neural Networks.\n\n\n\n\n\nJan 2, 2022\n\n\nJay Paul Morgan\n\n\n\n\n\n\n\n\n\n\n\n\nA Computability Perspective on (Verified) Machine Learning\n\n\n\n\n\nDefine the computational tasks underlying the newly suggested verified ML in a model-agnostic way, i.e., they work for all machine learning approaches including, e.g., random forests, support vector machines, and Neural Networks.\n\n\n\n\n\nJan 1, 2022\n\n\nTonicha Crook, Jay Paul Morgan, Arno Pauly, Markus Roggenbach\n\n\n\n\n\n\n\n\n\n\n\n\nAdaptive Neighbourhoods for the Discovery of Adversarial Examples\n\n\n\n\n\nConstructing unique and informed bounds for constructing adversarial examples.\n\n\n\n\n\nJan 1, 2021\n\n\nJay Paul Morgan, Adeline Paiement, Arno Pauly, Monika Seisenberger\n\n\n\n\n\n\n\n\n\n\n\n\nA Chatbot Framework for the Children’s Legal Centre\n\n\n\n\n\nThis paper presents a novel method to address legal rights for children through a chatbot framework by integrating machine learning, a dialogue graph, and information extraction.\n\n\n\n\n\nJan 1, 2018\n\n\nJay Paul Morgan, Adeline Paiement, Monika Seisenberger, Jane Williams, Adam Wyner\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "teaching/2023-2024/Machine Learning/lecture-4-reveal.html#problem-statement",
    "href": "teaching/2023-2024/Machine Learning/lecture-4-reveal.html#problem-statement",
    "title": "Support Vector Machines",
    "section": "Problem Statement",
    "text": "Problem Statement"
  },
  {
    "objectID": "teaching/2023-2024/Machine Learning/lecture-4-reveal.html#which-separator-is-best",
    "href": "teaching/2023-2024/Machine Learning/lecture-4-reveal.html#which-separator-is-best",
    "title": "Support Vector Machines",
    "section": "Which separator is best?",
    "text": "Which separator is best?\n\nTo get to the point of create such a decision boundary, we are going to look at three methods that build off of one another. These are:\n\nMaximal Margin classifier (MMC).\nSupport Vector classifier (SVC).\nSupport Vector Machine (SVM).\n\nFor the maximal margin classifier, we wish to position the decision boundary directly in the centre of these classes (more on this in the next slides), thus `maximising the margin’. The constraint for this model to which we must optimise is:\n\\[\ny_i (\\beta_0 + x \\beta_1) \\geq M\n\\]\nwhere \\(y_i \\in [-1, 1]\\) (the label of the binary classification), and \\(M\\) is the margin between classes that we wish to maximise."
  },
  {
    "objectID": "teaching/2023-2024/Machine Learning/lecture-4-reveal.html#a-1-dimensional-example",
    "href": "teaching/2023-2024/Machine Learning/lecture-4-reveal.html#a-1-dimensional-example",
    "title": "Support Vector Machines",
    "section": "A 1-dimensional example",
    "text": "A 1-dimensional example"
  },
  {
    "objectID": "teaching/2023-2024/Machine Learning/lecture-4-reveal.html#finding-the-best-separator",
    "href": "teaching/2023-2024/Machine Learning/lecture-4-reveal.html#finding-the-best-separator",
    "title": "Support Vector Machines",
    "section": "Finding the best separator",
    "text": "Finding the best separator"
  },
  {
    "objectID": "teaching/2023-2024/Machine Learning/lecture-4-reveal.html#widest-margin",
    "href": "teaching/2023-2024/Machine Learning/lecture-4-reveal.html#widest-margin",
    "title": "Support Vector Machines",
    "section": "Widest margin",
    "text": "Widest margin"
  },
  {
    "objectID": "teaching/2023-2024/Machine Learning/lecture-4-reveal.html#support-vectors",
    "href": "teaching/2023-2024/Machine Learning/lecture-4-reveal.html#support-vectors",
    "title": "Support Vector Machines",
    "section": "Support vectors",
    "text": "Support vectors\n\nBias/Variance trade-off: If one of these support vectors changes then the maximal margin classifier will drastically change. This model has low bias, and high variance."
  },
  {
    "objectID": "teaching/2023-2024/Machine Learning/lecture-4-reveal.html#accounting-for-miss-classifications",
    "href": "teaching/2023-2024/Machine Learning/lecture-4-reveal.html#accounting-for-miss-classifications",
    "title": "Support Vector Machines",
    "section": "Accounting for miss-classifications",
    "text": "Accounting for miss-classifications\n\n\\[\ny_i (\\beta_0 + x \\beta_1) \\geq M (1 - \\varepsilon_i)\n\\]\nThis type of classifier is called the Support Vector Classifier with a soft-margin as it allows for miss-classifications to reduce the model’s variance.\nwhere \\(\\varepsilon_i\\) is the positive slack variable for each data point. In practice, the sum of all slack variables are bound by a user-defined norm: \\(\\sum_i\n\\varepsilon_i \\leq D\\), where \\(D\\) is the tolerance for violating the margin of the SVC hyperplane.\nThere are three scenarios given the slack variable:\n\n\\(\\varepsilon_i = 0\\) the data point lies on the correct side of the hyperplane and not within the margin (i.e. the point is correctly classified).\n\\(\\varepsilon_i &gt; 0\\) the point lies with the margin but on the correct side of the separator.\n\\(\\varepsilon_i &gt; 1\\) the point lies on the wrong side of the separator (i.e. that the data point is miss-classified).\n\nSolution of the optimisation problem can be re-framed as unknown parameters (\\(\\alpha\\)) of the function \\(f(x)\\) and the inner product to all other support vectors:\n\\[\nf(x) = \\beta_0 + \\sum_{i=1}^m \\alpha_i \\langle x, x_i \\rangle\n\\]\nAs the constant \\(\\beta_0\\) the number of allowed miss-classifications increases also."
  },
  {
    "objectID": "teaching/2023-2024/Machine Learning/lecture-4-reveal.html#dimensional",
    "href": "teaching/2023-2024/Machine Learning/lecture-4-reveal.html#dimensional",
    "title": "Support Vector Machines",
    "section": "1-dimensional",
    "text": "1-dimensional\n\n\n1 dimensional space with a 0-dimensional separator, a point.\nflat affine 0-dimensional subspace"
  },
  {
    "objectID": "teaching/2023-2024/Machine Learning/lecture-4-reveal.html#dimensional-1",
    "href": "teaching/2023-2024/Machine Learning/lecture-4-reveal.html#dimensional-1",
    "title": "Support Vector Machines",
    "section": "2-dimensional",
    "text": "2-dimensional\n\n\n2 dimensional space with a 1-dimensional separator, a line\nflat affine 1-dimensional subspace"
  },
  {
    "objectID": "teaching/2023-2024/Machine Learning/lecture-4-reveal.html#dimensional-2",
    "href": "teaching/2023-2024/Machine Learning/lecture-4-reveal.html#dimensional-2",
    "title": "Support Vector Machines",
    "section": "3-dimensional",
    "text": "3-dimensional\n\n\n3-dimensional space with a 2-dimensional seperator, a plane\nflat affine 2-dimensional subspace"
  },
  {
    "objectID": "teaching/2023-2024/Machine Learning/lecture-4-reveal.html#dimensional-3",
    "href": "teaching/2023-2024/Machine Learning/lecture-4-reveal.html#dimensional-3",
    "title": "Support Vector Machines",
    "section": "4+-dimensional",
    "text": "4+-dimensional\nHere we lose the ability to be able to visualise the space easily… but nevertheless we can still create a SVC model. The separator in this space we refer to as a hyperplane.\n\nSide note :B_block:\nTechnically all of the seperators in 1/2/3 dimensions can also be called hyperplanes, but we generally only this say this for 4+…"
  },
  {
    "objectID": "teaching/2023-2024/Machine Learning/lecture-4-reveal.html#how-do-we-separate-this-space",
    "href": "teaching/2023-2024/Machine Learning/lecture-4-reveal.html#how-do-we-separate-this-space",
    "title": "Support Vector Machines",
    "section": "How do we separate this space",
    "text": "How do we separate this space"
  },
  {
    "objectID": "teaching/2023-2024/Machine Learning/lecture-4-reveal.html#add-dimensionality",
    "href": "teaching/2023-2024/Machine Learning/lecture-4-reveal.html#add-dimensionality",
    "title": "Support Vector Machines",
    "section": "Add dimensionality",
    "text": "Add dimensionality\nWe’ll take this 1-dimensional space, and add another dimension where the y-axis is \\(x^2\\). Suddenly, we’re able to separate the space:"
  },
  {
    "objectID": "teaching/2023-2024/Machine Learning/lecture-4-reveal.html#how-do-we-find-an-applicable-transformation",
    "href": "teaching/2023-2024/Machine Learning/lecture-4-reveal.html#how-do-we-find-an-applicable-transformation",
    "title": "Support Vector Machines",
    "section": "How do we find an applicable transformation?",
    "text": "How do we find an applicable transformation?\nTo make the space linearly separable in the previous example, we transformed the data into a higher dimension with the \\(x^2\\) transformation. But how do we decide which transformation to apply?\nWe’ll look at two types of transformations:\n\nPolynomial Kernel\nRadial Basis Function (RBF) Kernel\n\nInstead of using the inner product, we now choose to use a kernel \\(K\\), and then our solution to the decision boundary looks like:\n\\[\nf(x) = \\beta_0 + \\sum_{i=1}^m \\alpha_i K(x, x_i)\n\\]\nThis then is our Support Vector Machine we have been working towards. The kernel in this case, allows the method to classify non-linear relationships, which just wasn’t possible with the maximal margin classifier or the support vector classifier."
  },
  {
    "objectID": "teaching/2023-2024/Machine Learning/lecture-4-reveal.html#polynomial-kernel",
    "href": "teaching/2023-2024/Machine Learning/lecture-4-reveal.html#polynomial-kernel",
    "title": "Support Vector Machines",
    "section": "Polynomial Kernel",
    "text": "Polynomial Kernel\n\\[\n(a \\times b + r)^d\n\\]\nWhere \\(r\\) and \\(d\\) are user-defined parameters to the kernel.\nWe show how, using this kernel, we needn’t explicitly transform the data to the higher dimensions as the kernel is equal to the dot product in these higher dimension feature spaces:\nFor convience, let \\(r = \\frac{1}{2}\\), and \\(d = 2\\). Expanding the brackets:\n\\[\n(a \\times b  + \\frac{1}{2})(a \\times b + \\frac{1}{2})\n\\]\nand simplifying to:\n\\[\nab + a^2 b^2 + \\frac{1}{4}\n\\]\nWhich can be represented as the dot product:\n\\[\n(a, a^2, \\frac{1}{4}) \\cdot (b, b^2, \\frac{1}{4})\n\\]\nwhere \\(a\\) is the coordinate of the first sample on the first dimension, \\(a^2\\) is the coordinate on the second dimension and so on. Since \\(\\frac{1}{4}\\) is present in both sides of the expression, we can drop this.\nTherefore we see that, instead of computing the dot product in the higher dimensions, it is sufficient to apply the kernel."
  },
  {
    "objectID": "teaching/2023-2024/Machine Learning/lecture-4-reveal.html#radial-basis-function-kernel",
    "href": "teaching/2023-2024/Machine Learning/lecture-4-reveal.html#radial-basis-function-kernel",
    "title": "Support Vector Machines",
    "section": "Radial Basis Function Kernel",
    "text": "Radial Basis Function Kernel\n\\[\ne^{-\\gamma(a - b)^2}\n\\]\nwhere \\(\\gamma\\) is the scale of the kernel. This kernel generalises to infinite dimensions, and we return to how this can be true at the end of the lecture."
  },
  {
    "objectID": "teaching/2023-2024/Machine Learning/lecture-4-reveal.html#kernel-trick",
    "href": "teaching/2023-2024/Machine Learning/lecture-4-reveal.html#kernel-trick",
    "title": "Support Vector Machines",
    "section": "Kernel Trick",
    "text": "Kernel Trick\nLet \\(\\phi(x)\\) be a function transformation into a higher dimension. So we would have the following equation to compute the relationship in the higher dimension space:\n\\[\n\\phi(x_i) \\cdot \\phi(x_j)\n\\]\nThe kernel trick is that we have a kernel function \\(K(x_i, x_j) = \\langle \\phi(x_i),\n\\phi(x_j) \\rangle\\) to which computes the relationship as if \\(x_i, x_j\\) was in a higher dimension, without needing to explicitly transformation \\(x_i, x_j\\) to these higher dimensional feature spaces!"
  },
  {
    "objectID": "teaching/2023-2024/Machine Learning/lecture-4-reveal.html#how-the-rbf-works-in-infinite-dimensions",
    "href": "teaching/2023-2024/Machine Learning/lecture-4-reveal.html#how-the-rbf-works-in-infinite-dimensions",
    "title": "Support Vector Machines",
    "section": "How the RBF works in infinite dimensions",
    "text": "How the RBF works in infinite dimensions\nWe are going to take a look at an interesting aspect of the RBF kernel: how does it work in infinite dimensions? But first, we’ll revisit the polynomial kernel. Let’s take our polynomial kernel with \\(r = 0\\), we have:\n\\[\n(a \\times b + r)^d = a^d b^d\n\\]\nAll this does is scale the space on the one dimension.\nBut we can also add multiple polynomial kernels with different values for \\(d\\).\n\\[\na^1b^1 + a^2b^2 + ... + a^\\infty b^\\infty\n\\]\nAnd it continues to scale the space to infinity. We shall show how the RBF kernel works in very much this way.\nLet’s first take our RBF kernel and expand the brackets and simplify:\n\\[\\begin{align}e^{-\\gamma(a-b)^2} &= e^{-\\gamma(a^2-ab+b^2-ab)} \\\\\n&= e^{-\\gamma(a^2 - ab + b^2 - ab)} \\\\\n&= e^{-\\gamma(a^2 + b^2)} e^{\\gamma 2ab}\\end{align}\\]\nSetting \\(\\gamma = \\frac{1}{2}\\) to remove the 2 from the second term we have:\n\\[\ne^{-\\gamma(a^2+b^2)}e^{ab}\n\\]\nWe can use taylor series expansion (a function is equal to an infinite sum) on the second term. For example, we have the taylor series expansion for some function \\(f\\):\n\\[\nf(x) = f(a) + \\frac{f'(a)}{1 !} (x - a) + \\frac{f''(a)}{2 !} (x - a)^2 +\n... \\frac{f^\\infty(a)}{\\infty !}(x - a)^\\infty\n\\]\nThe same can be done for an exponential where the \\(\\frac{d}{dx} e^x = e^x\\):\n\\[\ne^x = e^a + \\frac{e^a}{1!} (x - a) + \\frac{e^a}{2!} (x - a)^2 + ... + \\frac{e^a}{\\infty!}(x-a)^\\infty\n\\]\nBut what is \\(a\\)? A can be anything so long as \\(f(a)\\) exists. So let’s choose something that makes our life simpler. We know that \\(e^0 = 1\\), so let \\(a = 0\\) :\n\\[\ne^x = 1 + \\frac{1}{1!} x + \\frac{1}{2!} x^2 + ... + \\frac{1}{\\infty!}x^\\infty\n\\]\nthus, going back our RBF kernel we have:\n\\[\ne^{ab} = 1 + \\frac{1}{1!} ab + \\frac{1}{2!} (ab)^2 + ... + \\frac{1}{\\infty!}(ab)^\\infty\n\\]\nThis looks very much like what the polynomial kernel was doing! Then if we take this term and position it in terms of a dot product instead we have:\n\\[\ne^{ab} = \\left( 1, \\sqrt{\\frac{1}{1!}}a, \\sqrt{\\frac{1}{2!}}a^2, ...,\n\\sqrt{\\frac{1}{\\infty!}}a^\\infty \\right) \\cdot \\left( 1, \\sqrt{\\frac{1}{1!}}b, \\sqrt{\\frac{1}{2!}}b^2, ...,\n\\sqrt{\\frac{1}{\\infty!}}b^\\infty \\right)\n\\]\nAnd we can add the left term in terms of a dot product \\(\\sqrt{e^{-\\frac{1}{2}(a^2 +\nb^2)}}\\), which conciseness, we’ll refer to as \\(s\\)\n\\[\ne^{-\\frac{1}{2}(a^2+b^2)}e^{ab} =\n\\]\n\\[\n\\left( s, s\\sqrt{\\frac{1}{1!}}a, s\\sqrt{\\frac{1}{2!}}a^2, ...,\ns\\sqrt{\\frac{1}{\\infty!}}a^\\infty \\right) \\cdot \\left( s, s\\sqrt{\\frac{1}{1!}}b, s\\sqrt{\\frac{1}{2!}}b^2, ...,\ns\\sqrt{\\frac{1}{\\infty!}}b^\\infty \\right)\n\\]"
  },
  {
    "objectID": "teaching/2023-2024/Machine Learning/lecture-4.html",
    "href": "teaching/2023-2024/Machine Learning/lecture-4.html",
    "title": "Support Vector Machines",
    "section": "",
    "text": "To get to the point of create such a decision boundary, we are going to look at three methods that build off of one another. These are:\n\nMaximal Margin classifier (MMC).\nSupport Vector classifier (SVC).\nSupport Vector Machine (SVM).\n\nFor the maximal margin classifier, we wish to position the decision boundary directly in the centre of these classes (more on this in the next slides), thus `maximising the margin’. The constraint for this model to which we must optimise is:\n\\[\ny_i (\\beta_0 + x \\beta_1) \\geq M\n\\]\nwhere \\(y_i \\in [-1, 1]\\) (the label of the binary classification), and \\(M\\) is the margin between classes that we wish to maximise."
  },
  {
    "objectID": "teaching/2023-2024/Machine Learning/lecture-4.html#which-separator-is-best",
    "href": "teaching/2023-2024/Machine Learning/lecture-4.html#which-separator-is-best",
    "title": "Support Vector Machines",
    "section": "",
    "text": "To get to the point of create such a decision boundary, we are going to look at three methods that build off of one another. These are:\n\nMaximal Margin classifier (MMC).\nSupport Vector classifier (SVC).\nSupport Vector Machine (SVM).\n\nFor the maximal margin classifier, we wish to position the decision boundary directly in the centre of these classes (more on this in the next slides), thus `maximising the margin’. The constraint for this model to which we must optimise is:\n\\[\ny_i (\\beta_0 + x \\beta_1) \\geq M\n\\]\nwhere \\(y_i \\in [-1, 1]\\) (the label of the binary classification), and \\(M\\) is the margin between classes that we wish to maximise."
  },
  {
    "objectID": "teaching/2023-2024/Machine Learning/lecture-4.html#finding-the-best-separator",
    "href": "teaching/2023-2024/Machine Learning/lecture-4.html#finding-the-best-separator",
    "title": "Support Vector Machines",
    "section": "Finding the best separator",
    "text": "Finding the best separator"
  },
  {
    "objectID": "teaching/2023-2024/Machine Learning/lecture-4.html#widest-margin",
    "href": "teaching/2023-2024/Machine Learning/lecture-4.html#widest-margin",
    "title": "Support Vector Machines",
    "section": "Widest margin",
    "text": "Widest margin"
  },
  {
    "objectID": "teaching/2023-2024/Machine Learning/lecture-4.html#support-vectors",
    "href": "teaching/2023-2024/Machine Learning/lecture-4.html#support-vectors",
    "title": "Support Vector Machines",
    "section": "Support vectors",
    "text": "Support vectors\n\nBias/Variance trade-off: If one of these support vectors changes then the maximal margin classifier will drastically change. This model has low bias, and high variance."
  },
  {
    "objectID": "teaching/2023-2024/Machine Learning/lecture-4.html#accounting-for-miss-classifications",
    "href": "teaching/2023-2024/Machine Learning/lecture-4.html#accounting-for-miss-classifications",
    "title": "Support Vector Machines",
    "section": "Accounting for miss-classifications",
    "text": "Accounting for miss-classifications\n\n\\[\ny_i (\\beta_0 + x \\beta_1) \\geq M (1 - \\varepsilon_i)\n\\]\nThis type of classifier is called the Support Vector Classifier with a soft-margin as it allows for miss-classifications to reduce the model’s variance.\nwhere \\(\\varepsilon_i\\) is the positive slack variable for each data point. In practice, the sum of all slack variables are bound by a user-defined norm: \\(\\sum_i\n\\varepsilon_i \\leq D\\), where \\(D\\) is the tolerance for violating the margin of the SVC hyperplane.\nThere are three scenarios given the slack variable:\n\n\\(\\varepsilon_i = 0\\) the data point lies on the correct side of the hyperplane and not within the margin (i.e. the point is correctly classified).\n\\(\\varepsilon_i &gt; 0\\) the point lies with the margin but on the correct side of the separator.\n\\(\\varepsilon_i &gt; 1\\) the point lies on the wrong side of the separator (i.e. that the data point is miss-classified).\n\nSolution of the optimisation problem can be re-framed as unknown parameters (\\(\\alpha\\)) of the function \\(f(x)\\) and the inner product to all other support vectors:\n\\[\nf(x) = \\beta_0 + \\sum_{i=1}^m \\alpha_i \\langle x, x_i \\rangle\n\\]\nAs the constant \\(\\beta_0\\) the number of allowed miss-classifications increases also."
  },
  {
    "objectID": "teaching/2023-2024/Machine Learning/lecture-4.html#dimensional",
    "href": "teaching/2023-2024/Machine Learning/lecture-4.html#dimensional",
    "title": "Support Vector Machines",
    "section": "1-dimensional",
    "text": "1-dimensional\n\n\n1 dimensional space with a 0-dimensional separator, a point.\nflat affine 0-dimensional subspace"
  },
  {
    "objectID": "teaching/2023-2024/Machine Learning/lecture-4.html#dimensional-1",
    "href": "teaching/2023-2024/Machine Learning/lecture-4.html#dimensional-1",
    "title": "Support Vector Machines",
    "section": "2-dimensional",
    "text": "2-dimensional\n\n\n2 dimensional space with a 1-dimensional separator, a line\nflat affine 1-dimensional subspace"
  },
  {
    "objectID": "teaching/2023-2024/Machine Learning/lecture-4.html#dimensional-2",
    "href": "teaching/2023-2024/Machine Learning/lecture-4.html#dimensional-2",
    "title": "Support Vector Machines",
    "section": "3-dimensional",
    "text": "3-dimensional\n\n\n3-dimensional space with a 2-dimensional seperator, a plane\nflat affine 2-dimensional subspace"
  },
  {
    "objectID": "teaching/2023-2024/Machine Learning/lecture-4.html#dimensional-3",
    "href": "teaching/2023-2024/Machine Learning/lecture-4.html#dimensional-3",
    "title": "Support Vector Machines",
    "section": "4+-dimensional",
    "text": "4+-dimensional\nHere we lose the ability to be able to visualise the space easily… but nevertheless we can still create a SVC model. The separator in this space we refer to as a hyperplane.\n\nSide note :B_block:\nTechnically all of the seperators in 1/2/3 dimensions can also be called hyperplanes, but we generally only this say this for 4+…"
  },
  {
    "objectID": "teaching/2023-2024/Machine Learning/lecture-4.html#how-do-we-separate-this-space",
    "href": "teaching/2023-2024/Machine Learning/lecture-4.html#how-do-we-separate-this-space",
    "title": "Support Vector Machines",
    "section": "How do we separate this space",
    "text": "How do we separate this space"
  },
  {
    "objectID": "teaching/2023-2024/Machine Learning/lecture-4.html#add-dimensionality",
    "href": "teaching/2023-2024/Machine Learning/lecture-4.html#add-dimensionality",
    "title": "Support Vector Machines",
    "section": "Add dimensionality",
    "text": "Add dimensionality\nWe’ll take this 1-dimensional space, and add another dimension where the y-axis is \\(x^2\\). Suddenly, we’re able to separate the space:"
  },
  {
    "objectID": "teaching/2023-2024/Machine Learning/lecture-4.html#how-do-we-find-an-applicable-transformation",
    "href": "teaching/2023-2024/Machine Learning/lecture-4.html#how-do-we-find-an-applicable-transformation",
    "title": "Support Vector Machines",
    "section": "How do we find an applicable transformation?",
    "text": "How do we find an applicable transformation?\nTo make the space linearly separable in the previous example, we transformed the data into a higher dimension with the \\(x^2\\) transformation. But how do we decide which transformation to apply?\nWe’ll look at two types of transformations:\n\nPolynomial Kernel\nRadial Basis Function (RBF) Kernel\n\nInstead of using the inner product, we now choose to use a kernel \\(K\\), and then our solution to the decision boundary looks like:\n\\[\nf(x) = \\beta_0 + \\sum_{i=1}^m \\alpha_i K(x, x_i)\n\\]\nThis then is our Support Vector Machine we have been working towards. The kernel in this case, allows the method to classify non-linear relationships, which just wasn’t possible with the maximal margin classifier or the support vector classifier."
  },
  {
    "objectID": "teaching/2023-2024/Machine Learning/lecture-4.html#polynomial-kernel",
    "href": "teaching/2023-2024/Machine Learning/lecture-4.html#polynomial-kernel",
    "title": "Support Vector Machines",
    "section": "Polynomial Kernel",
    "text": "Polynomial Kernel\n\\[\n(a \\times b + r)^d\n\\]\nWhere \\(r\\) and \\(d\\) are user-defined parameters to the kernel.\nWe show how, using this kernel, we needn’t explicitly transform the data to the higher dimensions as the kernel is equal to the dot product in these higher dimension feature spaces:\nFor convience, let \\(r = \\frac{1}{2}\\), and \\(d = 2\\). Expanding the brackets:\n\\[\n(a \\times b  + \\frac{1}{2})(a \\times b + \\frac{1}{2})\n\\]\nand simplifying to:\n\\[\nab + a^2 b^2 + \\frac{1}{4}\n\\]\nWhich can be represented as the dot product:\n\\[\n(a, a^2, \\frac{1}{4}) \\cdot (b, b^2, \\frac{1}{4})\n\\]\nwhere \\(a\\) is the coordinate of the first sample on the first dimension, \\(a^2\\) is the coordinate on the second dimension and so on. Since \\(\\frac{1}{4}\\) is present in both sides of the expression, we can drop this.\nTherefore we see that, instead of computing the dot product in the higher dimensions, it is sufficient to apply the kernel."
  },
  {
    "objectID": "teaching/2023-2024/Machine Learning/lecture-4.html#radial-basis-function-kernel",
    "href": "teaching/2023-2024/Machine Learning/lecture-4.html#radial-basis-function-kernel",
    "title": "Support Vector Machines",
    "section": "Radial Basis Function Kernel",
    "text": "Radial Basis Function Kernel\n\\[\ne^{-\\gamma(a - b)^2}\n\\]\nwhere \\(\\gamma\\) is the scale of the kernel. This kernel generalises to infinite dimensions, and we return to how this can be true at the end of the lecture."
  },
  {
    "objectID": "teaching/2023-2024/Machine Learning/lecture-4.html#kernel-trick",
    "href": "teaching/2023-2024/Machine Learning/lecture-4.html#kernel-trick",
    "title": "Support Vector Machines",
    "section": "Kernel Trick",
    "text": "Kernel Trick\nLet \\(\\phi(x)\\) be a function transformation into a higher dimension. So we would have the following equation to compute the relationship in the higher dimension space:\n\\[\n\\phi(x_i) \\cdot \\phi(x_j)\n\\]\nThe kernel trick is that we have a kernel function \\(K(x_i, x_j) = \\langle \\phi(x_i),\n\\phi(x_j) \\rangle\\) to which computes the relationship as if \\(x_i, x_j\\) was in a higher dimension, without needing to explicitly transformation \\(x_i, x_j\\) to these higher dimensional feature spaces!"
  },
  {
    "objectID": "teaching/2023-2024/Machine Learning/lecture-4.html#how-the-rbf-works-in-infinite-dimensions",
    "href": "teaching/2023-2024/Machine Learning/lecture-4.html#how-the-rbf-works-in-infinite-dimensions",
    "title": "Support Vector Machines",
    "section": "How the RBF works in infinite dimensions",
    "text": "How the RBF works in infinite dimensions\nWe are going to take a look at an interesting aspect of the RBF kernel: how does it work in infinite dimensions? But first, we’ll revisit the polynomial kernel. Let’s take our polynomial kernel with \\(r = 0\\), we have:\n\\[\n(a \\times b + r)^d = a^d b^d\n\\]\nAll this does is scale the space on the one dimension.\nBut we can also add multiple polynomial kernels with different values for \\(d\\).\n\\[\na^1b^1 + a^2b^2 + ... + a^\\infty b^\\infty\n\\]\nAnd it continues to scale the space to infinity. We shall show how the RBF kernel works in very much this way.\nLet’s first take our RBF kernel and expand the brackets and simplify:\n\\[\\begin{align}e^{-\\gamma(a-b)^2} &= e^{-\\gamma(a^2-ab+b^2-ab)} \\\\\n&= e^{-\\gamma(a^2 - ab + b^2 - ab)} \\\\\n&= e^{-\\gamma(a^2 + b^2)} e^{\\gamma 2ab}\\end{align}\\]\nSetting \\(\\gamma = \\frac{1}{2}\\) to remove the 2 from the second term we have:\n\\[\ne^{-\\gamma(a^2+b^2)}e^{ab}\n\\]\nWe can use taylor series expansion (a function is equal to an infinite sum) on the second term. For example, we have the taylor series expansion for some function \\(f\\):\n\\[\nf(x) = f(a) + \\frac{f'(a)}{1 !} (x - a) + \\frac{f''(a)}{2 !} (x - a)^2 +\n... \\frac{f^\\infty(a)}{\\infty !}(x - a)^\\infty\n\\]\nThe same can be done for an exponential where the \\(\\frac{d}{dx} e^x = e^x\\):\n\\[\ne^x = e^a + \\frac{e^a}{1!} (x - a) + \\frac{e^a}{2!} (x - a)^2 + ... + \\frac{e^a}{\\infty!}(x-a)^\\infty\n\\]\nBut what is \\(a\\)? A can be anything so long as \\(f(a)\\) exists. So let’s choose something that makes our life simpler. We know that \\(e^0 = 1\\), so let \\(a = 0\\) :\n\\[\ne^x = 1 + \\frac{1}{1!} x + \\frac{1}{2!} x^2 + ... + \\frac{1}{\\infty!}x^\\infty\n\\]\nthus, going back our RBF kernel we have:\n\\[\ne^{ab} = 1 + \\frac{1}{1!} ab + \\frac{1}{2!} (ab)^2 + ... + \\frac{1}{\\infty!}(ab)^\\infty\n\\]\nThis looks very much like what the polynomial kernel was doing! Then if we take this term and position it in terms of a dot product instead we have:\n\\[\ne^{ab} = \\left( 1, \\sqrt{\\frac{1}{1!}}a, \\sqrt{\\frac{1}{2!}}a^2, ...,\n\\sqrt{\\frac{1}{\\infty!}}a^\\infty \\right) \\cdot \\left( 1, \\sqrt{\\frac{1}{1!}}b, \\sqrt{\\frac{1}{2!}}b^2, ...,\n\\sqrt{\\frac{1}{\\infty!}}b^\\infty \\right)\n\\]\nAnd we can add the left term in terms of a dot product \\(\\sqrt{e^{-\\frac{1}{2}(a^2 +\nb^2)}}\\), which conciseness, we’ll refer to as \\(s\\)\n\\[\ne^{-\\frac{1}{2}(a^2+b^2)}e^{ab} =\n\\]\n\\[\n\\left( s, s\\sqrt{\\frac{1}{1!}}a, s\\sqrt{\\frac{1}{2!}}a^2, ...,\ns\\sqrt{\\frac{1}{\\infty!}}a^\\infty \\right) \\cdot \\left( s, s\\sqrt{\\frac{1}{1!}}b, s\\sqrt{\\frac{1}{2!}}b^2, ...,\ns\\sqrt{\\frac{1}{\\infty!}}b^\\infty \\right)\n\\]"
  },
  {
    "objectID": "teaching/2023-2024/Machine Learning/lecture-2-reveal.html#linear-models",
    "href": "teaching/2023-2024/Machine Learning/lecture-2-reveal.html#linear-models",
    "title": "Linear Models",
    "section": "Linear models",
    "text": "Linear models\nHaving learnt a little about what it means to learn, we’re going to look at our first Machine Learning algorithm, the staple for much of statistics, numeric prediction using a linear model."
  },
  {
    "objectID": "teaching/2023-2024/Machine Learning/lecture-2-reveal.html#what-is-a-linear-model",
    "href": "teaching/2023-2024/Machine Learning/lecture-2-reveal.html#what-is-a-linear-model",
    "title": "Linear Models",
    "section": "What is a linear model?",
    "text": "What is a linear model?\nA linear model is a prediction (a response) to an input variable. We have the following terms:\n\nResponse/prediction/dependant – the output of the model.\nfeature/variable/independant variable – the variable upon which the prediction is being made.\n\nFor a linear model based on one independant we have the following:\n\\[\ny = \\beta_0 + \\beta_1 x\n\\]\nwhere \\(y\\) is the response/output/prediction of the model, \\(x\\) is the independant variable, and \\(\\beta_0, \\beta_1\\) are the model parameters."
  },
  {
    "objectID": "teaching/2023-2024/Machine Learning/lecture-2-reveal.html#slope-intercept",
    "href": "teaching/2023-2024/Machine Learning/lecture-2-reveal.html#slope-intercept",
    "title": "Linear Models",
    "section": "Slope & intercept",
    "text": "Slope & intercept\nIf we look at our linear model equation, we’ll notice that it’s the same equation for a straight line.\n\nAs we’ve seen, the linear model, or linear regression, has two parameters: \\(\\beta_1,\n\\beta_0\\). What do these parameters represent?\n\nThe \\(\\beta_1\\) parameter is the slope or strength of relationship between the independant variable and the response.\nMeanwhile, the \\(\\beta_0\\) parameter is called the intercept, as it’s the value of the response when the independant variable is zero.\n\nLet’s look at these two parameters.\n\nHere we see that when \\(\\beta_1\\) is 0 (left figure), any change in \\(x\\) results in 0 change in \\(y\\). While, with \\(\\beta_1 = 2\\), \\(y\\) increases two-fold by every change in \\(x\\). Finally, when the slope is negative, we see that \\(y\\) decreases.\nNotice how the line is at 5 when \\(x\\) is zero, this is because \\(\\beta_0 = 5\\)."
  },
  {
    "objectID": "teaching/2023-2024/Machine Learning/lecture-2-reveal.html#multiple-variables",
    "href": "teaching/2023-2024/Machine Learning/lecture-2-reveal.html#multiple-variables",
    "title": "Linear Models",
    "section": "Multiple variables",
    "text": "Multiple variables\nSo we’ve seen how we can take an input variable x, and through the combination multiplication and addition with the learnt \\(\\beta_0, \\beta_1\\) values, we can create a pretty accurate prediction.\nHowever, this was only for a singular variable.\nIn our dataset, we have many variables/features/columns that we may want to use for our prediction. It may be possible to get an even more accurate prediction by adding features to our linear regression model.\n\\[\ny = \\beta_0 + \\sum_{i=1}^m x_i \\beta_i\n\\]\nwhere \\(m\\) is the number of features/variables we’re adding to the model."
  },
  {
    "objectID": "teaching/2023-2024/Machine Learning/lecture-2-reveal.html#supporting-example",
    "href": "teaching/2023-2024/Machine Learning/lecture-2-reveal.html#supporting-example",
    "title": "Linear Models",
    "section": "Supporting example",
    "text": "Supporting example\nLet’s have a look at how we would use this linear model with one of the datasets: The Boston housing prices."
  },
  {
    "objectID": "teaching/2023-2024/Machine Learning/lecture-2-reveal.html#lets-fit-a-linear-model",
    "href": "teaching/2023-2024/Machine Learning/lecture-2-reveal.html#lets-fit-a-linear-model",
    "title": "Linear Models",
    "section": "Let’s fit a linear model",
    "text": "Let’s fit a linear model\nWe have seen that there seems to be some correlation between the number of rooms and the house price. I.e. we can use the number of rooms of the house to get the estimated price. To get an estimated price we’ll use our linear model:\n\\[\ny = \\beta_0+\\beta_1 x\n\\]\nIn this case, \\(x\\) will be the number of rooms. But what values should we set for \\(\\beta_0\\) and \\(\\beta_1\\)? Or put another way, what is optimal value for our model parameters.\nWe’ll return to the question of optimal later, but for now, let’s just select some random values!\n\\[\\begin{aligned}\n\\beta_0 = 1 \\\\\n\\beta_1 = 1\n\\end{aligned}\n\\]\n\nWell that doesn’t look very good, it could be ‘fit’ better to what we’re seeing in the scatter plot! I wonder how wrong the linear model is – how incorrect our predicted house prices are?"
  },
  {
    "objectID": "teaching/2023-2024/Machine Learning/lecture-2-reveal.html#evaluating-our-initial-linear-model",
    "href": "teaching/2023-2024/Machine Learning/lecture-2-reveal.html#evaluating-our-initial-linear-model",
    "title": "Linear Models",
    "section": "Evaluating our initial linear model",
    "text": "Evaluating our initial linear model\nTo evaluate how well, or in this case, how badly our linear model is doing, let’s compare the predicted value from the model against the actual house price. For example, we’ll take a single sample from our dataset.\nIf we have 4 rooms, our model estimates the house price to be \\(2(4) + 5 = 13\\), $13,000, but the actual cost was $24,000. This means we have underestimated the cost by $11,000.\nWhat we’ve done there is the following:\n\\[\n\\delta = | y - \\hat{y} |\n\\]\nwhere \\(\\hat{y}\\) is \\(\\beta_0 + \\beta_1 x\\)\nWe’ve calculated the difference or delta between the real house price \\(y\\) and the predicted house price.\nThat gives us the error for one sample though, what about for the whole dataset? Well we could take the mean over all samples:\n\\[\n\\text{MAE}(X; \\beta_0,\\beta_1) = \\frac{1}{N}\\sum_{i=0}^N | y_i - (\\beta_0+\\beta_1x_i) |\n\\]\nIf we calculate that our linear model we see that the average difference between our estimated value and real value is $15,000!\nAnother common method of calculating how well or how badly our model is performing is to use the sum of squared residuals or perhaps more commonly known in the field of machine learning: mean squared error (MSE).\n\\[\n\\text{MSE}(X; \\beta_0, \\beta_1) = \\frac{1}{N}\\sum_{i=0}^N (y - (\\beta_0 + \\beta_1 x_i))^2\n\\]"
  },
  {
    "objectID": "teaching/2023-2024/Machine Learning/lecture-2-reveal.html#getting-better-model-parameters",
    "href": "teaching/2023-2024/Machine Learning/lecture-2-reveal.html#getting-better-model-parameters",
    "title": "Linear Models",
    "section": "Getting better model parameters",
    "text": "Getting better model parameters\nOkay, so we made our initial guess at the model parameters (random values for \\(\\beta_0,\n\\beta_1\\)), and these weren’t very good. We were incorrectly guessing the house value by $15,000. So how do we get better values?\nWell if we visualise how badly we do vs the value for \\(\\beta_1\\) we get the following:\n\nIn figure 44, we see that as we change the \\(\\beta_1\\) parameter, the mean absolute error (MAE), i.e. the average difference between the predicted house prices and the true house prices, changes. Ideally, we would like the error or loss to be as low as possible. In this case, when \\(\\beta_0 = 1\\) the lowest possible loss we can hope to achieve with the linear model is ~ $5,500.\nBut what value for \\(\\beta_1\\) gets us this lowest value for the loss? Looking at the graph, we see that the lowest point on the loss curve is somewhere between 0 and 5. Maybe even 4? While we could look at the curve and pick these parameter values, we’re going to use a better method – one that give us an optimal value for this loss curve automatically.\nWe’re going to look at the method called Gradient Descent.\nIf we visualise our loss curve again, and visualise where \\(\\beta_1 = 1\\) is on this curve, we will see:\n\nSo we want this rot dot to move down the loss curve and reach the bottom of the curve. Using the Gradient Descent algorithm, we’re going to take very small steps down the loss curve.\n\nTo determine which way is up, and which way is down the curve, we use the Gradient of the curve (hence Gradient Descent). We compute the gradient using finite differences method:\n\\[\n\\Delta = \\frac{f(x+h) - f(x)}{h}\n\\]\nwhere \\(f(x)\\) is the loss when \\(\\beta_1\\) takes on the value of \\(x\\). \\(h\\) is a very small value.\n\nIf we select \\(h = 0.5\\) then we will have the formula:\n\\[\n\\Delta_{\\beta_1} = \\frac{L(\\beta_1 + 0.5) - L(\\beta_1)}{\\beta_1}\n\\]\nwhere \\(L\\) represents our loss function, MAE. If we calculate this we have:\n\\[\\begin{aligned}\n\\Delta_{\\beta_1} &= \\frac{L(\\beta_1 + 0.5) - L(\\beta_1)}{h} \\\\\n&= \\frac{L(1.5)- L(1)}{0.5} \\\\\n&= \\frac{12 - 15}{0.5} \\\\\n&= -6.0\n\\end{aligned}\n\\]\nGiven that the gradient is a negative number, we know that the curve is going down/decreasing. So we will want to move \\(\\beta_1\\) in this direction – we want to move \\(\\beta_1\\) so that the loss decreases.\n\\[\n\\overline{\\beta_1} = \\beta_1 - \\eta \\Delta_{\\beta_1}\n\\]\nIf we plug in the numbers we’ve calculated for when \\(\\beta_1 = 1\\) we get and \\(eta = 0.5\\):\n\\[\\begin{aligned}\n\\overline{\\beta_1} &= \\beta_1 - \\eta \\Delta_{\\beta_1} \\\\\n&= 1.0 - (0.5 * -6.0) \\\\\n&= 1.0 - (-3.0) \\\\\n&= 4.0\n\\end{aligned}\n\\]\nOur new value for the \\(\\beta_1\\) parameter (\\(\\overline{\\beta_1}\\)) is computed by taking its original value and subtracting the gradient modulated/multiplied by \\(\\eta\\). \\(\\eta\\) in this case is what will allow us to take our small steps. It is important to set \\(\\eta\\) to a suitably small value, as high values for \\(\\eta\\) will cause the Gradient Descent to behave erratically, and even, make our loss worse!\n\nIn figure 65, we’ve varied the value of \\(\\eta\\) and computed 10 steps of updating the \\(\\beta_1\\) parameter in our linear model. When \\(\\eta=0.05\\), we see that \\(\\beta_1\\) is slowly being updated in a way that is causing our loss to decrease, but it is more so slowly that we don’t reach the optimal value for \\(\\beta_1\\). When \\(\\eta=3\\), each change in \\(\\beta_1\\) is too large, so we over-shoot the optimal value, and end up bouncing back and forth without ever improving. Finally, when we set \\(\\eta=0.3\\), the changes in \\(\\beta_1\\) are sufficiently large enough such that we reach the global minima in time, but they are also small enough so that we don’t over-shoot this same minimum.\nIf we then apply the Gradient Descent algorithm to both parameters of the linear model \\(\\beta_0, \\beta_1\\), then we can find the optimal trend line for this data. Furthermore, visualising this will look something like figure 68."
  },
  {
    "objectID": "teaching/2023-2024/Machine Learning/lecture-2-reveal.html#solving-the-linear-model-directly",
    "href": "teaching/2023-2024/Machine Learning/lecture-2-reveal.html#solving-the-linear-model-directly",
    "title": "Linear Models",
    "section": "Solving the linear model directly",
    "text": "Solving the linear model directly\nThe way we’ve trained our linear regression is not necessarily the best, yes it does help us understand how we can optimise to a solution (especially if not all of our data can fit into memory at the same time). But, when it comes to linear models, we can compute the values for \\(\\beta_0, \\beta_1\\) directly.\nThis is called a closed-form solution.\n\\[\n\\beta_1 = \\frac{N \\sum xy - \\sum x \\sum y}{N \\sum (x^2) - \\sum (x)^2}\n\\]\n\\[\n\\beta_0 = \\frac{\\sum y - \\beta_1 \\sum x}{N}\n\\]\nwhere \\(N\\) is the number of samples in our data."
  },
  {
    "objectID": "teaching/2023-2024/Machine Learning/lecture-2-reveal.html#moving-from-regression-to-classification",
    "href": "teaching/2023-2024/Machine Learning/lecture-2-reveal.html#moving-from-regression-to-classification",
    "title": "Linear Models",
    "section": "Moving from regression to classification",
    "text": "Moving from regression to classification\nWe now turn to the problem of classification. We have seen in some of our toy datasets (namely the Iris dataset), that we don’t want to predict a continuous value, but rather predict the class each data point belongs to.\nTo predict the class, we use a model called a logistic regressor.\nA logistic regressor is a model from the class of `Generalised Linear Models’ (GLM). In fact, the linear regressor we investigated in the previous section is also part of this class of models."
  },
  {
    "objectID": "teaching/2023-2024/Machine Learning/lecture-2-reveal.html#multi-class-vs-binary-classification",
    "href": "teaching/2023-2024/Machine Learning/lecture-2-reveal.html#multi-class-vs-binary-classification",
    "title": "Linear Models",
    "section": "Multi-class vs binary classification",
    "text": "Multi-class vs binary classification\n\nIn terms of Iris dataset, this means we want to select one class from 3 possible classes.\nWe’ll return to the problem of multiple classes later. But let’s suppose that we only want to decide if the flower is a Setosa, or not Setosa. We’ve changed our classification problem from multi-class to binary classification."
  },
  {
    "objectID": "teaching/2023-2024/Machine Learning/lecture-2-reveal.html#probability-likelihood-1",
    "href": "teaching/2023-2024/Machine Learning/lecture-2-reveal.html#probability-likelihood-1",
    "title": "Linear Models",
    "section": "Probability likelihood",
    "text": "Probability likelihood\n\nOur model will eventually look like this, where we have two classes of points, and for each point we give a probability (p) that our point belongs to a class."
  },
  {
    "objectID": "teaching/2023-2024/Machine Learning/lecture-2-reveal.html#making-it-linear",
    "href": "teaching/2023-2024/Machine Learning/lecture-2-reveal.html#making-it-linear",
    "title": "Linear Models",
    "section": "Making it linear",
    "text": "Making it linear\nIf we apply the logarithm to each probability, we get back to our linear line.\n\n\\[\n\\log \\left( \\frac{p}{1-p} \\right)\n\\]"
  },
  {
    "objectID": "teaching/2023-2024/Machine Learning/lecture-2-reveal.html#enter-the-maximum-likelihood",
    "href": "teaching/2023-2024/Machine Learning/lecture-2-reveal.html#enter-the-maximum-likelihood",
    "title": "Linear Models",
    "section": "Enter the maximum likelihood",
    "text": "Enter the maximum likelihood\nBut there is a problem…we can no longer use the sum of residuals as the value would always be \\(\\infty\\), but instead we can use the maximum likelihood. First we project each sample to its ‘odds’ (i.e. the value of \\(y\\) on the linear line)."
  },
  {
    "objectID": "teaching/2023-2024/Machine Learning/lecture-2-reveal.html#back-to-the-probability-curve",
    "href": "teaching/2023-2024/Machine Learning/lecture-2-reveal.html#back-to-the-probability-curve",
    "title": "Linear Models",
    "section": "Back to the probability curve",
    "text": "Back to the probability curve\n\nOur logistic or ‘sigmoid’ function:\n\\[\np = \\frac{1}{1 + e^{-(\\beta_0+\\beta_1x)}} = \\frac{e^{(\\beta_0+\\beta_1x)}}{1 + e^{(\\beta_0+\\beta_1x)}}\n\\]"
  },
  {
    "objectID": "teaching/2023-2024/Machine Learning/lecture-2-reveal.html#likelihood",
    "href": "teaching/2023-2024/Machine Learning/lecture-2-reveal.html#likelihood",
    "title": "Linear Models",
    "section": "Likelihood",
    "text": "Likelihood\nProbability of class 1\n\\[\np(1) = p\n\\]\nProbability of class 0 (or not class 1).\n\\[\np(0) = 1 - p\n\\]\nMaximum likelihood loss (which we wish to maximise), using the points on the probability curve:\n\\[ L = (0.9) + (0.89) + (0.6) + (1 - 0.4) + (1 - 0.2) + (1 - 0.05)\n\\]"
  },
  {
    "objectID": "teaching/2023-2024/Machine Learning/lecture-2-reveal.html#optimising-the-curve",
    "href": "teaching/2023-2024/Machine Learning/lecture-2-reveal.html#optimising-the-curve",
    "title": "Linear Models",
    "section": "Optimising the curve",
    "text": "Optimising the curve"
  },
  {
    "objectID": "teaching/2023-2024/Machine Learning/lecture-2-reveal.html#binary-cross-entropy-1",
    "href": "teaching/2023-2024/Machine Learning/lecture-2-reveal.html#binary-cross-entropy-1",
    "title": "Linear Models",
    "section": "Binary Cross-Entropy",
    "text": "Binary Cross-Entropy\nWe could still use MSE in order to compute our models loss. This may still work. But there is another objective function that we would use for binary classification problems: Binary Cross-entropy (BCE).\n\\[\n\\text{BCE}(X; \\beta_0, \\beta_1) = -(Y \\log(\\beta_0+\\beta_1*X) + (1 - Y) \\log(1- \\beta_0+\\beta_1*X))\n\\]\nIssues when using MSE for binary classification:\n\nMSE is non-convex for binary classification problems.\nMSE assumes the data was generated from a normal distribution, while binary classification problems form a Bernoulli distribution."
  },
  {
    "objectID": "teaching/2023-2024/Machine Learning/lecture-2.html",
    "href": "teaching/2023-2024/Machine Learning/lecture-2.html",
    "title": "Linear Models",
    "section": "",
    "text": "Having learnt a little about what it means to learn, we’re going to look at our first Machine Learning algorithm, the staple for much of statistics, numeric prediction using a linear model.\n\n\n\nA linear model is a prediction (a response) to an input variable. We have the following terms:\n\nResponse/prediction/dependant – the output of the model.\nfeature/variable/independant variable – the variable upon which the prediction is being made.\n\nFor a linear model based on one independant we have the following:\n\\[\ny = \\beta_0 + \\beta_1 x\n\\]\nwhere \\(y\\) is the response/output/prediction of the model, \\(x\\) is the independant variable, and \\(\\beta_0, \\beta_1\\) are the model parameters."
  },
  {
    "objectID": "teaching/2023-2024/Machine Learning/lecture-2.html#linear-models",
    "href": "teaching/2023-2024/Machine Learning/lecture-2.html#linear-models",
    "title": "Linear Models",
    "section": "",
    "text": "Having learnt a little about what it means to learn, we’re going to look at our first Machine Learning algorithm, the staple for much of statistics, numeric prediction using a linear model."
  },
  {
    "objectID": "teaching/2023-2024/Machine Learning/lecture-2.html#what-is-a-linear-model",
    "href": "teaching/2023-2024/Machine Learning/lecture-2.html#what-is-a-linear-model",
    "title": "Linear Models",
    "section": "",
    "text": "A linear model is a prediction (a response) to an input variable. We have the following terms:\n\nResponse/prediction/dependant – the output of the model.\nfeature/variable/independant variable – the variable upon which the prediction is being made.\n\nFor a linear model based on one independant we have the following:\n\\[\ny = \\beta_0 + \\beta_1 x\n\\]\nwhere \\(y\\) is the response/output/prediction of the model, \\(x\\) is the independant variable, and \\(\\beta_0, \\beta_1\\) are the model parameters."
  },
  {
    "objectID": "teaching/2023-2024/Machine Learning/lecture-2.html#slope-intercept",
    "href": "teaching/2023-2024/Machine Learning/lecture-2.html#slope-intercept",
    "title": "Linear Models",
    "section": "Slope & intercept",
    "text": "Slope & intercept\nIf we look at our linear model equation, we’ll notice that it’s the same equation for a straight line.\n\nAs we’ve seen, the linear model, or linear regression, has two parameters: \\(\\beta_1,\n\\beta_0\\). What do these parameters represent?\n\nThe \\(\\beta_1\\) parameter is the slope or strength of relationship between the independant variable and the response.\nMeanwhile, the \\(\\beta_0\\) parameter is called the intercept, as it’s the value of the response when the independant variable is zero.\n\nLet’s look at these two parameters.\n\nHere we see that when \\(\\beta_1\\) is 0 (left figure), any change in \\(x\\) results in 0 change in \\(y\\). While, with \\(\\beta_1 = 2\\), \\(y\\) increases two-fold by every change in \\(x\\). Finally, when the slope is negative, we see that \\(y\\) decreases.\nNotice how the line is at 5 when \\(x\\) is zero, this is because \\(\\beta_0 = 5\\)."
  },
  {
    "objectID": "teaching/2023-2024/Machine Learning/lecture-2.html#multiple-variables",
    "href": "teaching/2023-2024/Machine Learning/lecture-2.html#multiple-variables",
    "title": "Linear Models",
    "section": "Multiple variables",
    "text": "Multiple variables\nSo we’ve seen how we can take an input variable x, and through the combination multiplication and addition with the learnt \\(\\beta_0, \\beta_1\\) values, we can create a pretty accurate prediction.\nHowever, this was only for a singular variable.\nIn our dataset, we have many variables/features/columns that we may want to use for our prediction. It may be possible to get an even more accurate prediction by adding features to our linear regression model.\n\\[\ny = \\beta_0 + \\sum_{i=1}^m x_i \\beta_i\n\\]\nwhere \\(m\\) is the number of features/variables we’re adding to the model."
  },
  {
    "objectID": "teaching/2023-2024/Machine Learning/lecture-2.html#supporting-example",
    "href": "teaching/2023-2024/Machine Learning/lecture-2.html#supporting-example",
    "title": "Linear Models",
    "section": "Supporting example",
    "text": "Supporting example\nLet’s have a look at how we would use this linear model with one of the datasets: The Boston housing prices."
  },
  {
    "objectID": "teaching/2023-2024/Machine Learning/lecture-2.html#lets-fit-a-linear-model",
    "href": "teaching/2023-2024/Machine Learning/lecture-2.html#lets-fit-a-linear-model",
    "title": "Linear Models",
    "section": "Let’s fit a linear model",
    "text": "Let’s fit a linear model\nWe have seen that there seems to be some correlation between the number of rooms and the house price. I.e. we can use the number of rooms of the house to get the estimated price. To get an estimated price we’ll use our linear model:\n\\[\ny = \\beta_0+\\beta_1 x\n\\]\nIn this case, \\(x\\) will be the number of rooms. But what values should we set for \\(\\beta_0\\) and \\(\\beta_1\\)? Or put another way, what is optimal value for our model parameters.\nWe’ll return to the question of optimal later, but for now, let’s just select some random values!\n\\[\\begin{aligned}\n\\beta_0 = 1 \\\\\n\\beta_1 = 1\n\\end{aligned}\n\\]\n\nWell that doesn’t look very good, it could be ‘fit’ better to what we’re seeing in the scatter plot! I wonder how wrong the linear model is – how incorrect our predicted house prices are?"
  },
  {
    "objectID": "teaching/2023-2024/Machine Learning/lecture-2.html#evaluating-our-initial-linear-model",
    "href": "teaching/2023-2024/Machine Learning/lecture-2.html#evaluating-our-initial-linear-model",
    "title": "Linear Models",
    "section": "Evaluating our initial linear model",
    "text": "Evaluating our initial linear model\nTo evaluate how well, or in this case, how badly our linear model is doing, let’s compare the predicted value from the model against the actual house price. For example, we’ll take a single sample from our dataset.\nIf we have 4 rooms, our model estimates the house price to be \\(2(4) + 5 = 13\\), $13,000, but the actual cost was $24,000. This means we have underestimated the cost by $11,000.\nWhat we’ve done there is the following:\n\\[\n\\delta = | y - \\hat{y} |\n\\]\nwhere \\(\\hat{y}\\) is \\(\\beta_0 + \\beta_1 x\\)\nWe’ve calculated the difference or delta between the real house price \\(y\\) and the predicted house price.\nThat gives us the error for one sample though, what about for the whole dataset? Well we could take the mean over all samples:\n\\[\n\\text{MAE}(X; \\beta_0,\\beta_1) = \\frac{1}{N}\\sum_{i=0}^N | y_i - (\\beta_0+\\beta_1x_i) |\n\\]\nIf we calculate that our linear model we see that the average difference between our estimated value and real value is $15,000!\nAnother common method of calculating how well or how badly our model is performing is to use the sum of squared residuals or perhaps more commonly known in the field of machine learning: mean squared error (MSE).\n\\[\n\\text{MSE}(X; \\beta_0, \\beta_1) = \\frac{1}{N}\\sum_{i=0}^N (y - (\\beta_0 + \\beta_1 x_i))^2\n\\]"
  },
  {
    "objectID": "teaching/2023-2024/Machine Learning/lecture-2.html#getting-better-model-parameters",
    "href": "teaching/2023-2024/Machine Learning/lecture-2.html#getting-better-model-parameters",
    "title": "Linear Models",
    "section": "Getting better model parameters",
    "text": "Getting better model parameters\nOkay, so we made our initial guess at the model parameters (random values for \\(\\beta_0,\n\\beta_1\\)), and these weren’t very good. We were incorrectly guessing the house value by $15,000. So how do we get better values?\nWell if we visualise how badly we do vs the value for \\(\\beta_1\\) we get the following:\n\nIn figure 44, we see that as we change the \\(\\beta_1\\) parameter, the mean absolute error (MAE), i.e. the average difference between the predicted house prices and the true house prices, changes. Ideally, we would like the error or loss to be as low as possible. In this case, when \\(\\beta_0 = 1\\) the lowest possible loss we can hope to achieve with the linear model is ~ $5,500.\nBut what value for \\(\\beta_1\\) gets us this lowest value for the loss? Looking at the graph, we see that the lowest point on the loss curve is somewhere between 0 and 5. Maybe even 4? While we could look at the curve and pick these parameter values, we’re going to use a better method – one that give us an optimal value for this loss curve automatically.\nWe’re going to look at the method called Gradient Descent.\nIf we visualise our loss curve again, and visualise where \\(\\beta_1 = 1\\) is on this curve, we will see:\n\nSo we want this rot dot to move down the loss curve and reach the bottom of the curve. Using the Gradient Descent algorithm, we’re going to take very small steps down the loss curve.\n\nTo determine which way is up, and which way is down the curve, we use the Gradient of the curve (hence Gradient Descent). We compute the gradient using finite differences method:\n\\[\n\\Delta = \\frac{f(x+h) - f(x)}{h}\n\\]\nwhere \\(f(x)\\) is the loss when \\(\\beta_1\\) takes on the value of \\(x\\). \\(h\\) is a very small value.\n\nIf we select \\(h = 0.5\\) then we will have the formula:\n\\[\n\\Delta_{\\beta_1} = \\frac{L(\\beta_1 + 0.5) - L(\\beta_1)}{\\beta_1}\n\\]\nwhere \\(L\\) represents our loss function, MAE. If we calculate this we have:\n\\[\\begin{aligned}\n\\Delta_{\\beta_1} &= \\frac{L(\\beta_1 + 0.5) - L(\\beta_1)}{h} \\\\\n&= \\frac{L(1.5)- L(1)}{0.5} \\\\\n&= \\frac{12 - 15}{0.5} \\\\\n&= -6.0\n\\end{aligned}\n\\]\nGiven that the gradient is a negative number, we know that the curve is going down/decreasing. So we will want to move \\(\\beta_1\\) in this direction – we want to move \\(\\beta_1\\) so that the loss decreases.\n\\[\n\\overline{\\beta_1} = \\beta_1 - \\eta \\Delta_{\\beta_1}\n\\]\nIf we plug in the numbers we’ve calculated for when \\(\\beta_1 = 1\\) we get and \\(eta = 0.5\\):\n\\[\\begin{aligned}\n\\overline{\\beta_1} &= \\beta_1 - \\eta \\Delta_{\\beta_1} \\\\\n&= 1.0 - (0.5 * -6.0) \\\\\n&= 1.0 - (-3.0) \\\\\n&= 4.0\n\\end{aligned}\n\\]\nOur new value for the \\(\\beta_1\\) parameter (\\(\\overline{\\beta_1}\\)) is computed by taking its original value and subtracting the gradient modulated/multiplied by \\(\\eta\\). \\(\\eta\\) in this case is what will allow us to take our small steps. It is important to set \\(\\eta\\) to a suitably small value, as high values for \\(\\eta\\) will cause the Gradient Descent to behave erratically, and even, make our loss worse!\n\nIn figure 65, we’ve varied the value of \\(\\eta\\) and computed 10 steps of updating the \\(\\beta_1\\) parameter in our linear model. When \\(\\eta=0.05\\), we see that \\(\\beta_1\\) is slowly being updated in a way that is causing our loss to decrease, but it is more so slowly that we don’t reach the optimal value for \\(\\beta_1\\). When \\(\\eta=3\\), each change in \\(\\beta_1\\) is too large, so we over-shoot the optimal value, and end up bouncing back and forth without ever improving. Finally, when we set \\(\\eta=0.3\\), the changes in \\(\\beta_1\\) are sufficiently large enough such that we reach the global minima in time, but they are also small enough so that we don’t over-shoot this same minimum.\nIf we then apply the Gradient Descent algorithm to both parameters of the linear model \\(\\beta_0, \\beta_1\\), then we can find the optimal trend line for this data. Furthermore, visualising this will look something like figure 68."
  },
  {
    "objectID": "teaching/2023-2024/Machine Learning/lecture-2.html#solving-the-linear-model-directly",
    "href": "teaching/2023-2024/Machine Learning/lecture-2.html#solving-the-linear-model-directly",
    "title": "Linear Models",
    "section": "Solving the linear model directly",
    "text": "Solving the linear model directly\nThe way we’ve trained our linear regression is not necessarily the best, yes it does help us understand how we can optimise to a solution (especially if not all of our data can fit into memory at the same time). But, when it comes to linear models, we can compute the values for \\(\\beta_0, \\beta_1\\) directly.\nThis is called a closed-form solution.\n\\[\n\\beta_1 = \\frac{N \\sum xy - \\sum x \\sum y}{N \\sum (x^2) - \\sum (x)^2}\n\\]\n\\[\n\\beta_0 = \\frac{\\sum y - \\beta_1 \\sum x}{N}\n\\]\nwhere \\(N\\) is the number of samples in our data."
  },
  {
    "objectID": "teaching/2023-2024/Machine Learning/lecture-2.html#moving-from-regression-to-classification",
    "href": "teaching/2023-2024/Machine Learning/lecture-2.html#moving-from-regression-to-classification",
    "title": "Linear Models",
    "section": "Moving from regression to classification",
    "text": "Moving from regression to classification\nWe now turn to the problem of classification. We have seen in some of our toy datasets (namely the Iris dataset), that we don’t want to predict a continuous value, but rather predict the class each data point belongs to.\nTo predict the class, we use a model called a logistic regressor.\nA logistic regressor is a model from the class of `Generalised Linear Models’ (GLM). In fact, the linear regressor we investigated in the previous section is also part of this class of models."
  },
  {
    "objectID": "teaching/2023-2024/Machine Learning/lecture-2.html#multi-class-vs-binary-classification",
    "href": "teaching/2023-2024/Machine Learning/lecture-2.html#multi-class-vs-binary-classification",
    "title": "Linear Models",
    "section": "Multi-class vs binary classification",
    "text": "Multi-class vs binary classification\n\nIn terms of Iris dataset, this means we want to select one class from 3 possible classes.\nWe’ll return to the problem of multiple classes later. But let’s suppose that we only want to decide if the flower is a Setosa, or not Setosa. We’ve changed our classification problem from multi-class to binary classification."
  },
  {
    "objectID": "teaching/2023-2024/Machine Learning/lecture-2.html#probability-likelihood-1",
    "href": "teaching/2023-2024/Machine Learning/lecture-2.html#probability-likelihood-1",
    "title": "Linear Models",
    "section": "Probability likelihood",
    "text": "Probability likelihood\n\nOur model will eventually look like this, where we have two classes of points, and for each point we give a probability (p) that our point belongs to a class."
  },
  {
    "objectID": "teaching/2023-2024/Machine Learning/lecture-2.html#making-it-linear",
    "href": "teaching/2023-2024/Machine Learning/lecture-2.html#making-it-linear",
    "title": "Linear Models",
    "section": "Making it linear",
    "text": "Making it linear\nIf we apply the logarithm to each probability, we get back to our linear line.\n\n\\[\n\\log \\left( \\frac{p}{1-p} \\right)\n\\]"
  },
  {
    "objectID": "teaching/2023-2024/Machine Learning/lecture-2.html#enter-the-maximum-likelihood",
    "href": "teaching/2023-2024/Machine Learning/lecture-2.html#enter-the-maximum-likelihood",
    "title": "Linear Models",
    "section": "Enter the maximum likelihood",
    "text": "Enter the maximum likelihood\nBut there is a problem…we can no longer use the sum of residuals as the value would always be \\(\\infty\\), but instead we can use the maximum likelihood. First we project each sample to its ‘odds’ (i.e. the value of \\(y\\) on the linear line)."
  },
  {
    "objectID": "teaching/2023-2024/Machine Learning/lecture-2.html#back-to-the-probability-curve",
    "href": "teaching/2023-2024/Machine Learning/lecture-2.html#back-to-the-probability-curve",
    "title": "Linear Models",
    "section": "Back to the probability curve",
    "text": "Back to the probability curve\n\nOur logistic or ‘sigmoid’ function:\n\\[\np = \\frac{1}{1 + e^{-(\\beta_0+\\beta_1x)}} = \\frac{e^{(\\beta_0+\\beta_1x)}}{1 + e^{(\\beta_0+\\beta_1x)}}\n\\]"
  },
  {
    "objectID": "teaching/2023-2024/Machine Learning/lecture-2.html#likelihood",
    "href": "teaching/2023-2024/Machine Learning/lecture-2.html#likelihood",
    "title": "Linear Models",
    "section": "Likelihood",
    "text": "Likelihood\nProbability of class 1\n\\[\np(1) = p\n\\]\nProbability of class 0 (or not class 1).\n\\[\np(0) = 1 - p\n\\]\nMaximum likelihood loss (which we wish to maximise), using the points on the probability curve:\n\\[ L = (0.9) + (0.89) + (0.6) + (1 - 0.4) + (1 - 0.2) + (1 - 0.05)\n\\]"
  },
  {
    "objectID": "teaching/2023-2024/Machine Learning/lecture-2.html#optimising-the-curve",
    "href": "teaching/2023-2024/Machine Learning/lecture-2.html#optimising-the-curve",
    "title": "Linear Models",
    "section": "Optimising the curve",
    "text": "Optimising the curve"
  },
  {
    "objectID": "teaching/2023-2024/Machine Learning/lecture-2.html#binary-cross-entropy-1",
    "href": "teaching/2023-2024/Machine Learning/lecture-2.html#binary-cross-entropy-1",
    "title": "Linear Models",
    "section": "Binary Cross-Entropy",
    "text": "Binary Cross-Entropy\nWe could still use MSE in order to compute our models loss. This may still work. But there is another objective function that we would use for binary classification problems: Binary Cross-entropy (BCE).\n\\[\n\\text{BCE}(X; \\beta_0, \\beta_1) = -(Y \\log(\\beta_0+\\beta_1*X) + (1 - Y) \\log(1- \\beta_0+\\beta_1*X))\n\\]\nIssues when using MSE for binary classification:\n\nMSE is non-convex for binary classification problems.\nMSE assumes the data was generated from a normal distribution, while binary classification problems form a Bernoulli distribution."
  },
  {
    "objectID": "teaching/2023-2024/Machine Learning/lecture-1-reveal.html#welcome",
    "href": "teaching/2023-2024/Machine Learning/lecture-1-reveal.html#welcome",
    "title": "Introduction",
    "section": "Welcome!",
    "text": "Welcome!\nWelcome to all the new students! Here I am going to be talking about Machine Learning and all of the great things that this “technology” has to offer. To begin our course, I shall start with a bit of house keeping – more specifically, I will be talking about what exactly we’ll be learning about in the course (Machine Learning is a broad subject after-all). In addition, I will tell you where you can find the resources related to the course and how you can contact me, should you have any questions."
  },
  {
    "objectID": "teaching/2023-2024/Machine Learning/lecture-1-reveal.html#what-this-course-is-about",
    "href": "teaching/2023-2024/Machine Learning/lecture-1-reveal.html#what-this-course-is-about",
    "title": "Introduction",
    "section": "What this course is about?",
    "text": "What this course is about?\nIn this course, we will be learning about Machine Learning: firstly, what Machine Learning actually is; secondly, we’ll take a look at some of the algorithms within the scope of Machine Learning, and develop an intuition about how these algorithms work and when they would be useful; and finally, how we can compare and evaluate the algorithms we’ve learnt about."
  },
  {
    "objectID": "teaching/2023-2024/Machine Learning/lecture-1-reveal.html#how-this-course-will-be-taught",
    "href": "teaching/2023-2024/Machine Learning/lecture-1-reveal.html#how-this-course-will-be-taught",
    "title": "Introduction",
    "section": "How this course will be taught",
    "text": "How this course will be taught\nI intended to deliver this course via a series of lectures. These lectures will be accompanied by the PDF lecture slides, in which I will provide the definitions and provide reference links should you wish to do some extra reading."
  },
  {
    "objectID": "teaching/2023-2024/Machine Learning/lecture-1-reveal.html#outline-of-the-course",
    "href": "teaching/2023-2024/Machine Learning/lecture-1-reveal.html#outline-of-the-course",
    "title": "Introduction",
    "section": "Outline of the course",
    "text": "Outline of the course\n\n\n\n\n\n\n\n\n\nLecture\n\n\nType\n\n\nTopic\n\n\n\n\n\n\n1\n\n\nTheory\n\n\nIntroduction\n\n\n\n\n2\n\n\nTheory\n\n\nLinear models\n\n\n\n\n3\n\n\nLab\n\n\nLab on Linear models\n\n\n\n\n4\n\n\nTheory/Lab\n\n\nEvaluation of models\n\n\n\n\n5\n\n\nTheory/Lab\n\n\nSupport Vector Machines\n\n\n\n\n6\n\n\nTheory/Lab\n\n\nKernel methods"
  },
  {
    "objectID": "teaching/2023-2024/Machine Learning/lecture-1-reveal.html#source-code",
    "href": "teaching/2023-2024/Machine Learning/lecture-1-reveal.html#source-code",
    "title": "Introduction",
    "section": "Source code",
    "text": "Source code\nDuring the course, I would also like to supplement my algorithmic definitions and explanations with some programming code – for this I will use the Python programming language. The code snippets would look something like:\nimport random\nx = [1, 2, 3, 4]\ny = [random.random() + xi for xi in x]\nprint(y)\n\n[1.4898241502582414, 2.4805286156642175, 3.065379052563245, 4.05328483072365]"
  },
  {
    "objectID": "teaching/2023-2024/Machine Learning/lecture-1-reveal.html#running-the-source-code-yourself",
    "href": "teaching/2023-2024/Machine Learning/lecture-1-reveal.html#running-the-source-code-yourself",
    "title": "Introduction",
    "section": "Running the source code yourself",
    "text": "Running the source code yourself\nAll of the source can be run by yourselves if you use the same python environment (i.e. that you have installed all the appropriate libraries). On the git repository, I’ve included the environment.yml file used in the production of these lectures.\nTo run the code:\n    wget https://git.sr.ht/~jaymorgan/teaching/blob/master/2022-2023/Machine%20Learning/environment.yml\n    conda env create -f environment.yml  # recreate the conda env\n    conda activate ml-lectures           # activate the new env\n    python &lt;scripts&gt;"
  },
  {
    "objectID": "teaching/2023-2024/Machine Learning/lecture-1-reveal.html#references",
    "href": "teaching/2023-2024/Machine Learning/lecture-1-reveal.html#references",
    "title": "Introduction",
    "section": "References",
    "text": "References\nIn some cases, and is the norm with academic traditions, we’ll want to include a reference, a link to previous written works.\nHere is an example of a sentence that includes a reference:\n“This is a very important sentence which I assert to be true, to convince you of this fact I shall appeal to authority and include a reference: (Shalev-Shwartz, Shai and Ben-David, Shai, 2014)”\nMore information on the referenced material (such as title, publishing date) will be found in the bibliography slide (or bottom of the webpage if you’re viewing the HTML version of the lectures)."
  },
  {
    "objectID": "teaching/2023-2024/Machine Learning/lecture-1-reveal.html#about-me",
    "href": "teaching/2023-2024/Machine Learning/lecture-1-reveal.html#about-me",
    "title": "Introduction",
    "section": "About Me",
    "text": "About Me\nMy name is Dr Jay Paul Morgan. I am a researcher at the Université de Toulon, where I am developing Deep Learning models (a sub-field of Machine Learning research) for the study of astrophysical phenomenon.\nYou can find more information and links on my personal (LIS-Lab) website: https://pageperso.lis-lab.fr/jay.morgan/\nI also publish libraries and source code online:\n\nGithub: https://github.com/jaypmorgan\nGitlab: https://gitlab.com/jaymorgan\nSource Hut: https://sr.ht/~jaymorgan/\n\nIf you have any questions, you can email me at jay.morgan@univ-tln.fr"
  },
  {
    "objectID": "teaching/2023-2024/Machine Learning/lecture-1-reveal.html#where-you-can-find-the-resources",
    "href": "teaching/2023-2024/Machine Learning/lecture-1-reveal.html#where-you-can-find-the-resources",
    "title": "Introduction",
    "section": "Where you can find the resources",
    "text": "Where you can find the resources\nI try to make this course as accessible as possible, which means that I host these slides in a variety of ways to suit you.\nFirstly, you can find the links to all my courses on my personal website at: https://pageperso.lis-lab.fr/jay.morgan/teaching.html\nHere you can find the links to each lecture in a PDF or HTML format. Additionally, you can view the source code used to make these lectures on source hut: https://git.sr.ht/~jaymorgan/teaching. On this git repository you can find all my lectures from all years."
  },
  {
    "objectID": "teaching/2023-2024/Machine Learning/lecture-1-reveal.html#lets-answer-the-question-of-learning",
    "href": "teaching/2023-2024/Machine Learning/lecture-1-reveal.html#lets-answer-the-question-of-learning",
    "title": "Introduction",
    "section": "Let’s answer the question of learning",
    "text": "Let’s answer the question of learning\nWe’ll begin our journey into the world of Machine Learning by tackling the question of what it means to ‘learn’ – how may a machine actually learn anything?"
  },
  {
    "objectID": "teaching/2023-2024/Machine Learning/lecture-1-reveal.html#bait-shyness",
    "href": "teaching/2023-2024/Machine Learning/lecture-1-reveal.html#bait-shyness",
    "title": "Introduction",
    "section": "Bait-shyness",
    "text": "Bait-shyness\n\nTo begin to answer the question of learning, we may turn to nature for advice. Principally, if we look at the studies conducted with Mice we find some idea to notion of learning (Shalev-Shwartz, Shai and Ben-David, Shai, 2014). (Image by brgfx on Freepik)\nWhen a rat encounters a novel source of food, it will first eat a little bit of it. If the food is edible for the rat, it will continue to eat the food, even in future encounters. If, however, on the initial contact with the food, the rat deems the food poisonous, it will ignore and not eat the food in future encounters. This process we call ‘bait-shyness’.\nHere then we see the rat, on finding something new, learn from its experience, and use that knowledge of the experience for future encounters.\nOur initial understanding of rat’s bait-shyness was limited, but we’ve come to understand more about it. For instance, we learn that their learning process is more complex than originally thought. In a later experiment, where the ‘poison’ in the food is replaced by a different unpleasant stimulus such as a electric shock – i.e. when a rat eats a food, it is then shocked. It was found that this did not deter the rat from eating the food in future encounters, unlike the poison.\nIt is presumed that the rat’s have some ‘prior knowledge’ about the world and do not infer a temporal relationship between the food and being shocked, while they can infer the same relationship with food and illness."
  },
  {
    "objectID": "teaching/2023-2024/Machine Learning/lecture-1-reveal.html#computer-programs",
    "href": "teaching/2023-2024/Machine Learning/lecture-1-reveal.html#computer-programs",
    "title": "Introduction",
    "section": "Computer Programs",
    "text": "Computer Programs\nFrom these two examples of how rats may learn we see: the rat will make a guess about something now (i.e. that the food is not poisonous), it will find out how good this guess is (i.e. it either gets ill or it does not), and learn from how well its guess was for the future. We also see that its learning can be impacted by the rat’s prior knowledge about how the world may work.\nBut how does this framework for the process of learning translate to computers? For a more formal definition of how computer programs could be said to learn, we have a similar idea:\n\nA computer program is said to learn from experience \\(E\\) with respect to some class of tasks \\(T\\) and performance measure \\(P\\), if its performance a tasks in \\(T\\), as measured by \\(P\\), improves with experience \\(E\\).\n\n(Mitchell, Tom M, 1997)"
  },
  {
    "objectID": "teaching/2023-2024/Machine Learning/lecture-1-reveal.html#quiz",
    "href": "teaching/2023-2024/Machine Learning/lecture-1-reveal.html#quiz",
    "title": "Introduction",
    "section": "Quiz!",
    "text": "Quiz!\nWhat function is being used here?\n    8 ? 5   =   13\n    9 ? 1   =   10\n    1 ? 2   =    3"
  },
  {
    "objectID": "teaching/2023-2024/Machine Learning/lecture-1-reveal.html#something-more-difficult",
    "href": "teaching/2023-2024/Machine Learning/lecture-1-reveal.html#something-more-difficult",
    "title": "Introduction",
    "section": "Something more difficult…",
    "text": "Something more difficult…\nWhat values are being used here?\n    x * 1 + y   =   4\n    x * 3 + y   =   8\n    x * 5 + y   =  12"
  },
  {
    "objectID": "teaching/2023-2024/Machine Learning/lecture-1-reveal.html#when-might-we-need-machine-learning",
    "href": "teaching/2023-2024/Machine Learning/lecture-1-reveal.html#when-might-we-need-machine-learning",
    "title": "Introduction",
    "section": "When might we need Machine Learning",
    "text": "When might we need Machine Learning\n\nWhy do we need computer programs that ‘learn’ anyway? We already have programming languages, why can’t we just use them?\nLet’s suppose we’re creating a very simple Optical Character Recognition (OCR) program.\nThis program looks at a PDF document and converts the text into something we can copy and paste. Part of this program’s task is to take an individual character, say the number ‘8’, and recognise that it’s an 8 and add that to the already scanned text.\nHow would we go about creating a program where we can define how to identify ‘8’ or ‘1’ or ‘l’ – with all the varieties of lighting conditions, handwriting, fonts, sizes. We could find the process of encompassing all different variations tiresome – if not impossible, and that’s only for a single character!\nWith Machine Learning, instead of enumerating all possible solutions within a programming language, we collect a bunch of examples of ’8’s and give them to the algorithm to learn from.\nThrough looking at these many different examples, the algorithm will/should be able to recognise what an 8 generally looks like."
  },
  {
    "objectID": "teaching/2023-2024/Machine Learning/lecture-1-reveal.html#different-types-of-learning",
    "href": "teaching/2023-2024/Machine Learning/lecture-1-reveal.html#different-types-of-learning",
    "title": "Introduction",
    "section": "Different types of Learning",
    "text": "Different types of Learning\nWhat we have just demonstrated by way of the OCR example, is the type of learning we call ‘Supervised Learning’. We have many examples of input (lots of different kinds of handwritten 8’s), and we tell the learning algorithm, that they are indeed the number 8.\nBut there are other kind of different learning frameworks. Specifically we have the following:\n\nSupervised Learning\nUnsupervised, or sometimes called self-supervised Learning\nReinforcement Learning"
  },
  {
    "objectID": "teaching/2023-2024/Machine Learning/lecture-1-reveal.html#supervised-learning",
    "href": "teaching/2023-2024/Machine Learning/lecture-1-reveal.html#supervised-learning",
    "title": "Introduction",
    "section": "Supervised Learning",
    "text": "Supervised Learning\nTo better formalise Supervised Learning from our previous OCR example, Supervised Learning is when the learning algorithm “see’s” or has access to both the input and output.\nLet’s have a dataset \\(X\\), which is a set consisting of tuple pairs \\(x_i, y_i\\). \\(x_i\\) is an input, i.e. a single image with an ‘8’, and \\(y_i\\) is a label which tells the learning algorithm if the input is indeed an ‘8’ or something else. Mathematically we have:\n\\(X = \\{(x_1, y_1), (x_2, y_2), ..., (x_n, y_n)\\}\\)"
  },
  {
    "objectID": "teaching/2023-2024/Machine Learning/lecture-1-reveal.html#unsupervised-learning",
    "href": "teaching/2023-2024/Machine Learning/lecture-1-reveal.html#unsupervised-learning",
    "title": "Introduction",
    "section": "Unsupervised Learning",
    "text": "Unsupervised Learning\nIn Unsupervised learning, we have again have a dataset \\(X\\), who’s elements are only inputs. In other words, there are no corresponding labels for each input. Instead, the learning algorithm must learn inherent patterns in the data and create labels itself. Throughout the course, we’ll see examples of Unsupervised Learning in action.\nOne thing to note: Recent methodologies have started to call Unsupervised Learning, self-supervised. As we have just discussed, the labels are inherent to the data from the discovered patterns, it’s just we are not explicitly giving them to the learning algorithm ourselves. So it’s sort of like a supervised learning setup, except the learning algorithm is providing the labels itself – hence the self-supervised."
  },
  {
    "objectID": "teaching/2023-2024/Machine Learning/lecture-1-reveal.html#reinforcement-learning",
    "href": "teaching/2023-2024/Machine Learning/lecture-1-reveal.html#reinforcement-learning",
    "title": "Introduction",
    "section": "Reinforcement Learning",
    "text": "Reinforcement Learning\nReinforcement Learning is very different to both Supervised and Unsupervised Learning. Here is the type of learning you might be familiar with if you’ve seen ‘AI’ that learns to play video games. In this type of learning, we have the following elements:\n\nAn agent\nAn environment\nA set of allowed actions the agent can make within its environment.\n\nIn this situation, an agent will interact with it’s environment, and when it does something it can receive a reward (a reward can be positive or negative). The agent will remember what it has done to receive the reward. The objective for the agent is to maximise the reward score, and learns to do this through many iterations or play-through."
  },
  {
    "objectID": "teaching/2023-2024/Machine Learning/lecture-1-reveal.html#what-will-our-data-look-like",
    "href": "teaching/2023-2024/Machine Learning/lecture-1-reveal.html#what-will-our-data-look-like",
    "title": "Introduction",
    "section": "What will our data look like?",
    "text": "What will our data look like?\nIn this section we shall take a look at the different types of data we might expect and the different terminology used to name them.\nData in Machine Learning applications can come in a variety of different formats. The most typical data formats we might see are:\n\nTables\nImages/Videos\nText\nSound\n\nThese are the initial formats, though, before actually doing any learning, we will want to transform them into a different representation that we can use."
  },
  {
    "objectID": "teaching/2023-2024/Machine Learning/lecture-1-reveal.html#tables",
    "href": "teaching/2023-2024/Machine Learning/lecture-1-reveal.html#tables",
    "title": "Introduction",
    "section": "Tables",
    "text": "Tables\nA table, or tabular, format is a \\(n \\times m\\) set of data with \\(n\\) samples or examples, and \\(m\\) features for each sample. For example, suppose we have a table consisting the price of 100 different houses:\n\n\n\n\n\n\n\n\n\n\nNumber of bedrooms\n\n\nGarden size (ft)\n\n\n…\n\n\nPrice ($)\n\n\n\n\n\n\n3\n\n\n0\n\n\n…\n\n\n150,000\n\n\n\n\n5\n\n\n10\n\n\n…\n\n\n200,000\n\n\n\n\n…\n\n\n…\n\n\n…\n\n\n \n\n\n\n\n10\n\n\n1000\n\n\n…\n\n\n2,000,000\n\n\n\n\nIn a supervised learning setting, where we want to predict the price of a house we may then have the following dataset:\n\\(X = \\{([3, 0, ...], 150,000), ([5, 10, ...], 200,000), \\\\..., ([10, 1000, ...], 2,000,000)\\}\\)"
  },
  {
    "objectID": "teaching/2023-2024/Machine Learning/lecture-1-reveal.html#imagesvideos",
    "href": "teaching/2023-2024/Machine Learning/lecture-1-reveal.html#imagesvideos",
    "title": "Introduction",
    "section": "Images/Videos",
    "text": "Images/Videos\nImages are composed of 2D or 3D arrays of numeric values. For example, in a RGB image that is 1024x500 pixels, we would have the array of size 1024x500x3 – where 3 is the red, green, and blue channel, respectively. If we have just a grayscale image, we could represent it as either 1024x500x1 or 1024x500 as the channel ‘dimension’ of the array is singular.\nWe may already know that videos are simply a sequence of images that are iterated through 24+ times a second. For a 24 frames per second video, we would have an array size of 1024x500x3x24 – a 4-dimensional array."
  },
  {
    "objectID": "teaching/2023-2024/Machine Learning/lecture-1-reveal.html#text",
    "href": "teaching/2023-2024/Machine Learning/lecture-1-reveal.html#text",
    "title": "Introduction",
    "section": "Text",
    "text": "Text\nText and language data is perhaps one of the most flexible formats of data, in terms of the person implementing the Machine Learning algorithm is somewhat free in determining how to represent the language to the algorithm.\nWith text data, we have a series of ‘tokens’ – these tokens could be words, groups of words, parts of words, and even just characters. For example, consider:\n“this is a sentence, that shouldn’t be misunderstood.”"
  },
  {
    "objectID": "teaching/2023-2024/Machine Learning/lecture-1-reveal.html#tokenisation-of-text",
    "href": "teaching/2023-2024/Machine Learning/lecture-1-reveal.html#tokenisation-of-text",
    "title": "Introduction",
    "section": "Tokenisation of text",
    "text": "Tokenisation of text\n“this is a sentence, that shouldn’t be misunderstood.”\nWe could ‘tokenise’ (the process of converting a string into a series of tokens that represent the original string) this sentence by splitting at white-space:\n{\"this\", \"is\", \"a\", \"sentence,\", \"that\" \"shouldn't\", \"be\", \"misunderstood.\"}\nNotice how with the words “sentence” and “misunderstood”, the punctuation is considered part of the word and so “misunderstood.” != “misunderstood”.\nThese kinds of questions of how to best represent text and language we will talk more about in later lectures!"
  },
  {
    "objectID": "teaching/2023-2024/Machine Learning/lecture-1-reveal.html#time-series",
    "href": "teaching/2023-2024/Machine Learning/lecture-1-reveal.html#time-series",
    "title": "Introduction",
    "section": "Time-series",
    "text": "Time-series\nI named this section time-series to be as general as possible. Within the type ‘time-series’, we could have the following types of information:\n\nSound waves\nStock prices\nNetwork messaging\n\nThese types of data all share a property in that the ‘time’ component is important in their meaning."
  },
  {
    "objectID": "teaching/2023-2024/Machine Learning/lecture-1-reveal.html#types-of-outputs-regression-classification",
    "href": "teaching/2023-2024/Machine Learning/lecture-1-reveal.html#types-of-outputs-regression-classification",
    "title": "Introduction",
    "section": "Types of Outputs – Regression & Classification",
    "text": "Types of Outputs – Regression & Classification\nFirst, however, I wish to explain the difference between the terms Regression and Classification.\n\nRegression: the prediction of a continuous quantity, i.e. how much does this house cost?\nClassification: the prediction of a discrete value or class label, i.e. dog or cat?\n\nIn the following toy datasets, we’ll see different types of predictions that fall under the regression/classification output type."
  },
  {
    "objectID": "teaching/2023-2024/Machine Learning/lecture-1-reveal.html#boston-house-prices-dataset-tabular-regression",
    "href": "teaching/2023-2024/Machine Learning/lecture-1-reveal.html#boston-house-prices-dataset-tabular-regression",
    "title": "Introduction",
    "section": "Boston House Prices Dataset – Tabular Regression",
    "text": "Boston House Prices Dataset – Tabular Regression\nA dataset of 506 houses in Boston, USA, collected during US Census.\n\n13 features/properties about each house\n1 target property: the price of the house\n\nMore information about each of the features can be found at: https://www.cs.toronto.edu/~delve/data/boston/bostonDetail.html\n(Harrison Jr, David and Rubinfeld, Daniel L, 1978)"
  },
  {
    "objectID": "teaching/2023-2024/Machine Learning/lecture-1-reveal.html#boston-house-prices-example-rows",
    "href": "teaching/2023-2024/Machine Learning/lecture-1-reveal.html#boston-house-prices-example-rows",
    "title": "Introduction",
    "section": "Boston House Prices – example rows",
    "text": "Boston House Prices – example rows\nimport warnings\nfrom sklearn.datasets import load_boston\nwith warnings.catch_warnings():\n    warnings.filterwarnings(\"ignore\")\n    boston = load_boston()\nboston = pd.DataFrame(\n    data=np.c_[boston['data'], boston['target']],\n    columns=boston['feature_names'].tolist() + ['target'])\nprint(boston[:2])\n      CRIM    ZN  INDUS  CHAS    NOX     RM  ...  RAD    TAX  PTRATIO      B  LSTAT  target\n0  0.00632  18.0   2.31   0.0  0.538  6.575  ...  1.0  296.0     15.3  396.9   4.98    24.0\n1  0.02731   0.0   7.07   0.0  0.469  6.421  ...  2.0  242.0     17.8  396.9   9.14    21.6\n\n[2 rows x 14 columns]"
  },
  {
    "objectID": "teaching/2023-2024/Machine Learning/lecture-1-reveal.html#boston-house-prices-concerns",
    "href": "teaching/2023-2024/Machine Learning/lecture-1-reveal.html#boston-house-prices-concerns",
    "title": "Introduction",
    "section": "Boston House Prices – concerns",
    "text": "Boston House Prices – concerns\nThe Boston dataset is an excellent dataset in the fact that it contains some ethical issues when it comes to Machine Learning. More specifically, some of the features in the data are ‘dummy’ variables for racial attributes (Carlisle, M., 2020). Moreover, these features show a racial segregation has a positive impact on house prices.\nScikit-Learn (scikit-learn, 2022), one of the most prolific Machine Learning framework in the Python ecosystem, has decided to depreciate and remove the Boston dataset from their repository following these concerns.\nWe will continue to use the dataset here as it is an easy to understand regression problem, and to demonstrate how easy it is to be accidentally unethical if you’re not thinking about the data carefully enough."
  },
  {
    "objectID": "teaching/2023-2024/Machine Learning/lecture-1-reveal.html#iris-dataset-tabular-classification",
    "href": "teaching/2023-2024/Machine Learning/lecture-1-reveal.html#iris-dataset-tabular-classification",
    "title": "Introduction",
    "section": "Iris Dataset – Tabular Classification",
    "text": "Iris Dataset – Tabular Classification"
  },
  {
    "objectID": "teaching/2023-2024/Machine Learning/lecture-1-reveal.html#iris-dataset-features",
    "href": "teaching/2023-2024/Machine Learning/lecture-1-reveal.html#iris-dataset-features",
    "title": "Introduction",
    "section": "Iris Dataset – features",
    "text": "Iris Dataset – features\n\n150 examples\n4 features: Petal length/width, sepal length/width\n1 classification: type of flower: {viriginica, setosa, veriscolor}\nhttps://archive.ics.uci.edu/ml/datasets/iris (Fisher, Ronald A, 1936)"
  },
  {
    "objectID": "teaching/2023-2024/Machine Learning/lecture-1-reveal.html#iris-dataset-example-rows",
    "href": "teaching/2023-2024/Machine Learning/lecture-1-reveal.html#iris-dataset-example-rows",
    "title": "Introduction",
    "section": "Iris Dataset – example rows",
    "text": "Iris Dataset – example rows\nfrom sklearn.datasets import load_iris\niris = load_iris()\niris = pd.DataFrame(\n    data = np.c_[iris['data'], iris['target']],\n    columns = iris['feature_names'] + ['target'])\nprint(iris.head(2))\n   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  target\n0                5.1               3.5                1.4               0.2     0.0\n1                4.9               3.0                1.4               0.2     0.0"
  },
  {
    "objectID": "teaching/2023-2024/Machine Learning/lecture-1-reveal.html#mnist-dataset-image-classification",
    "href": "teaching/2023-2024/Machine Learning/lecture-1-reveal.html#mnist-dataset-image-classification",
    "title": "Introduction",
    "section": "MNIST Dataset – Image Classification",
    "text": "MNIST Dataset – Image Classification\n\nA dataset of images (of size 28x28) containing handwritten digits from 0 - 9.\nhttp://yann.lecun.com/exdb/mnist/\n(LeCun, Yann and Bottou, L{\\’e}on and Bengio, Yoshua and Haffner, Patrick, 1998)"
  },
  {
    "objectID": "teaching/2023-2024/Machine Learning/lecture-1-reveal.html#mnist-dataset-features",
    "href": "teaching/2023-2024/Machine Learning/lecture-1-reveal.html#mnist-dataset-features",
    "title": "Introduction",
    "section": "MNIST Dataset – Features",
    "text": "MNIST Dataset – Features\n\n60,000 images in the training dataset\n10,000 images in the test dataset\n28x28 pixels (grayscale)"
  },
  {
    "objectID": "teaching/2023-2024/Machine Learning/lecture-1-reveal.html#mnist-dataset-example-rows",
    "href": "teaching/2023-2024/Machine Learning/lecture-1-reveal.html#mnist-dataset-example-rows",
    "title": "Introduction",
    "section": "MNIST Dataset – Example Rows",
    "text": "MNIST Dataset – Example Rows\nfrom sklearn.datasets import fetch_openml\nmnist = fetch_openml(\"mnist_784\").data[:2]\npixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  pixel8  pixel9  \\\n0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n1     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n\npixel10  ...  pixel775  pixel776  pixel777  pixel778  pixel779  pixel780  \\\n0      0.0  ...       0.0       0.0       0.0       0.0       0.0       0.0   \n1      0.0  ...       0.0       0.0       0.0       0.0       0.0       0.0   \n\npixel781  pixel782  pixel783  pixel784  \n0       0.0       0.0       0.0       0.0  \n1       0.0       0.0       0.0       0.0  \n\n[2 rows x 784 columns]"
  },
  {
    "objectID": "teaching/2023-2024/Machine Learning/lecture-1-reveal.html#large-movie-review-dataset-text-classificationregression",
    "href": "teaching/2023-2024/Machine Learning/lecture-1-reveal.html#large-movie-review-dataset-text-classificationregression",
    "title": "Introduction",
    "section": "Large Movie Review Dataset – Text Classification/Regression",
    "text": "Large Movie Review Dataset – Text Classification/Regression\n\nStory of a man who has unnatural feelings for a pig. Starts out with a opening scene that is a terrific example of absurd comedy. A formal orchestra audience is turned into an insane, violent mob by the crazy chantings of it’s singers. Unfortunately it stays absurd the WHOLE time with no general narrative eventually making it just too off putting. Even those from the era should be turned off. The cryptic dialogue would make Shakespeare seem easy to a third grader. On a technical level it’s better than you might think with some good cinematography by future great Vilmos Zsigmond. Future stars Sally Kirkland and Frederic Forrest can be seen briefly.\n\nReview from: train/neg/0_3.txt\n\n50,000 movie reviews (25,000 for training and testing).\nEach review is labelled with a binary label of sentiment – a positive or negative review was towards the movie in question.\n\nhttps://ai.stanford.edu/~amaas/data/sentiment/\n(Maas, Andrew L. and Daly, Raymond E. and Pham, Peter T. and Huang, Dan and Ng, Andrew Y. and Potts, Christopher, 2011)"
  },
  {
    "objectID": "teaching/2023-2024/Machine Learning/lecture-1-reveal.html#ham-or-spam-text-classification",
    "href": "teaching/2023-2024/Machine Learning/lecture-1-reveal.html#ham-or-spam-text-classification",
    "title": "Introduction",
    "section": "Ham or Spam – Text Classification",
    "text": "Ham or Spam – Text Classification\n    Message-ID: &lt;8701134.1075856113926.JavaMail.evans@thyme&gt;\n    Date: Mon, 30 Oct 2000 02:06:00 -0800 (PST)\n    From: shona.wilson@enron.com\n    To: eugenio.perez@enron.com\n    Subject: meeting deadlines\n    Mime-Version: 1.0\n    Content-Type: text/plain; charset=us-ascii\n    Content-Transfer-Encoding: 7bit\n    X-From: Shona Wilson\n    X-To: Eugenio Perez\n    X-cc: \n    X-bcc: \n    X-Origin: Beck-S\n    X-FileName: sbeck.nsf\n    \n    Dear Eugenio,\n    \n    I did not want to say this when everyone else was around, but I am concerned \n    that no attempt was made to meet the deadline of this morning that we \n    discussed last Friday. (to decide on a name for the database).  Only Maria \n    Teresa had her information to me this am as requested. The deadline could \n    have been easily met by working diligently this morning, but Jennifer did not \n    come in until 8:30 and MT until 8:15.\n    \n    I thought we had discussed the urgency of this - to have something to present \n    at the 10am meeting.  We need to discuss this to ensure it does not happen \n    again.\n    \n    Best regards\n    \n    Shona\n\nEnron Spam classification of email messages.\nIs the email Spam – each email is labelled with a binary label, spam or not spam (ham).\nThe dataset contains 17,171 spam and 16,545 ham email messages.\n\nhttps://www2.aueb.gr/users/ion/data/enron-spam/\n(Metsis, Vangelis and Androutsopoulos, Ion and Paliouras, Georgios, 2006)"
  },
  {
    "objectID": "teaching/2023-2024/Machine Learning/lecture-1-reveal.html#compute-resources-environmental-concerns",
    "href": "teaching/2023-2024/Machine Learning/lecture-1-reveal.html#compute-resources-environmental-concerns",
    "title": "Introduction",
    "section": "Compute resources – environmental concerns",
    "text": "Compute resources – environmental concerns\n\nLarge-scale deployment of AI could also have both positive and negative impacts on the environment. Negative impacts include increased use of natural resources, such as rare earth metals, pollution and waste, as well as energy consumption. However, AI could help with waste management and conservation offering environmental benefits.\n\n\n[…] In the United States, data centres already account for about 2 percent of all electricity used. In one estimation, DeepMind’s AlphaGo – which beat Go Champion Lee Sedol in 2016 – took 50,000 times as much power as the human brain to do so.\n\n({European Parliament. Directorate General for Parliamentary Research Services.}, 2020)"
  },
  {
    "objectID": "teaching/2023-2024/Machine Learning/lecture-1-reveal.html#bias-in-language-models",
    "href": "teaching/2023-2024/Machine Learning/lecture-1-reveal.html#bias-in-language-models",
    "title": "Introduction",
    "section": "Bias in language models",
    "text": "Bias in language models\n\nBiases exist in language models trained on news articles (Bolukbasi, Tolga and Chang, Kai-Wei and Zou, James Y and Saligrama, Venkatesh and Kalai, Adam T, 2016)."
  },
  {
    "objectID": "teaching/2023-2024/Machine Learning/lecture-1-reveal.html#personal-information",
    "href": "teaching/2023-2024/Machine Learning/lecture-1-reveal.html#personal-information",
    "title": "Introduction",
    "section": "Personal information",
    "text": "Personal information\nIn Machine Learning applications where data is generated (such as generating faces that don’t exist), there is a possibility to expose personal information. For example, in a situation where these generative Machine Learning models create synthetic patient data, the model may be trained on real medical data. The output of the Machine Learning model could possibly leak personal information.\n(Arora, Anmol and Arora, Ananya, 2022)"
  },
  {
    "objectID": "teaching/2023-2024/Machine Learning/lecture-1-reveal.html#mental-health-of-optimisation-algorithms",
    "href": "teaching/2023-2024/Machine Learning/lecture-1-reveal.html#mental-health-of-optimisation-algorithms",
    "title": "Introduction",
    "section": "Mental health of optimisation algorithms",
    "text": "Mental health of optimisation algorithms\nThis example is more specific to how algorithms are used as opposed to their specific design. Yet, this should still be highlighted. We have seen increasing discussion surrounding the use of optimisation algorithms that try to increase the amount of ‘screen time’ or engagement from users of social media, and it’s no secret that spending lots of time of social media has a measurable effect on one’s mental health."
  },
  {
    "objectID": "teaching/2023-2024/Machine Learning/lecture-1-reveal.html#copyright-concerns",
    "href": "teaching/2023-2024/Machine Learning/lecture-1-reveal.html#copyright-concerns",
    "title": "Introduction",
    "section": "Copyright Concerns",
    "text": "Copyright Concerns\nA more recent addition to the concerns is that of Github’s co-pilot application that helps users write programming code. This application has been developed on open-source software – some of which includes licensing that specifies how this open-source code may be used (for example, with attribution or copy-left). Yet, Github’s co-pilot may insert code that its been trained on verbatim (though recent additions have been addressing these concerns), resulting in a situation of ‘code laundering’. https://twitter.com/mitsuhiko/status/1410886329924194309\n    float Q_rsqrt( float number )\n    {\n            long i;\n            float x2, y;\n            const float threehalfs = 1.5F;\n    \n            x2 = number * 0.5F;\n            y  = number;\n            i  = * ( long * ) &y;                       // evil floating point bit level hacking\n            i  = 0x5f3759df - ( i &gt;&gt; 1 );               // what the fuck? \n            y  = * ( float * ) &i;\n            y  = y * ( threehalfs - ( x2 * y * y ) );   // 1st iteration\n    //  y  = y * ( threehalfs - ( x2 * y * y ) );   // 2nd iteration, this can be removed\n    \n            return y;\n    }\n    \n    // Implementation from Quake III Arena under the GPL license."
  },
  {
    "objectID": "teaching/2023-2024/Machine Learning/lecture-1-reveal.html#what-is-machine-learning",
    "href": "teaching/2023-2024/Machine Learning/lecture-1-reveal.html#what-is-machine-learning",
    "title": "Introduction",
    "section": "What is Machine Learning",
    "text": "What is Machine Learning\n\nWe’ve taken a look at the different kinds of frameworks for learning – animal behaviour with bait-shyness, and how that translates in computer programs.\nWe’ve identified the different types of learning: supervised, unsupervised, and reinforcement learning.\nWe’ve looked at the different types of data we may encounter, from tabular to text data, and have also seen examples of some toy datasets we will be using in the course.\nFinally, we’ve highlighted some of the ethical concerns that can arise in Machine Learning."
  },
  {
    "objectID": "teaching/2023-2024/Machine Learning/lecture-1-reveal.html#bibliography-1",
    "href": "teaching/2023-2024/Machine Learning/lecture-1-reveal.html#bibliography-1",
    "title": "Introduction",
    "section": "Bibliography",
    "text": "Bibliography\nArora, Anmol and Arora, Ananya (2022). Generative Adversarial Networks and Synthetic Patient Data: Current Challenges and Future Perspectives, {Royal College of Physicians}.\nBolukbasi, Tolga and Chang, Kai-Wei and Zou, James Y and Saligrama, Venkatesh and Kalai, Adam T (2016). Man is to computer programmer as woman is to homemaker? debiasing word embeddings, Advances in neural information processing systems.\nCarlisle, M. (2020). Racist Data Destruction?, Medium.\nDiliff (2014). Iris germanica (Purple bearded Iris), Wakehurst Place, UK - Diliff.jpg.\nEric Guinther (2005). Image of a primrose willowherb Ludwigia octovalvis (family Onagraceae), flower showing petals and sepals.\nFisher, Ronald A (1936). The use of multiple measurements in taxonomic problems, Wiley Online Library.\nGonen, Hila and Goldberg, Yoav (2019). Lipstick on a {{Pig}}: {{Debiasing Methods Cover}} up {{Systematic Gender Biases}} in {{Word Embeddings But}} Do Not {{Remove Them}}, {arXiv}.\nHarrison Jr, David and Rubinfeld, Daniel L (1978). Hedonic housing prices and the demand for clean air, Elsevier.\nLeCun, Yann and Bottou, L{\\’e}on and Bengio, Yoshua and Haffner, Patrick (1998). Gradient-based learning applied to document recognition, Ieee.\nMaas, Andrew L. and Daly, Raymond E. and Pham, Peter T. and Huang, Dan and Ng, Andrew Y. and Potts, Christopher (2011). Learning Word Vectors for Sentiment Analysis, Association for Computational Linguistics.\nMetsis, Vangelis and Androutsopoulos, Ion and Paliouras, Georgios (2006). Spam filtering with naive bayes-which naive bayes?.\nMitchell, Tom M (1997). Machine learning, McGraw-hill New York.\nShalev-Shwartz, Shai and Ben-David, Shai (2014). Understanding machine learning: From theory to algorithms, Cambridge university press.\nscikit-learn (2022). Sklearn.Datasets.Load\\_boston, scikit-learn.\n{European Parliament. Directorate General for Parliamentary Research Services.} (2020). The Ethics of Artificial Intelligence: Issues and Initiatives., {Publications Office}."
  },
  {
    "objectID": "teaching/2023-2024/Machine Learning/lecture-1.html",
    "href": "teaching/2023-2024/Machine Learning/lecture-1.html",
    "title": "Introduction",
    "section": "",
    "text": "Welcome to all the new students! Here I am going to be talking about Machine Learning and all of the great things that this “technology” has to offer. To begin our course, I shall start with a bit of house keeping – more specifically, I will be talking about what exactly we’ll be learning about in the course (Machine Learning is a broad subject after-all). In addition, I will tell you where you can find the resources related to the course and how you can contact me, should you have any questions.\n\n\n\nIn this course, we will be learning about Machine Learning: firstly, what Machine Learning actually is; secondly, we’ll take a look at some of the algorithms within the scope of Machine Learning, and develop an intuition about how these algorithms work and when they would be useful; and finally, how we can compare and evaluate the algorithms we’ve learnt about.\n\n\n\nI intended to deliver this course via a series of lectures. These lectures will be accompanied by the PDF lecture slides, in which I will provide the definitions and provide reference links should you wish to do some extra reading.\n\n\n\n\n\n\n\n\n\n\n\n\nLecture\n\n\nType\n\n\nTopic\n\n\n\n\n\n\n1\n\n\nTheory\n\n\nIntroduction\n\n\n\n\n2\n\n\nTheory\n\n\nLinear models\n\n\n\n\n3\n\n\nLab\n\n\nLab on Linear models\n\n\n\n\n4\n\n\nTheory/Lab\n\n\nEvaluation of models\n\n\n\n\n5\n\n\nTheory/Lab\n\n\nSupport Vector Machines\n\n\n\n\n6\n\n\nTheory/Lab\n\n\nKernel methods"
  },
  {
    "objectID": "teaching/2023-2024/Machine Learning/lecture-1.html#welcome",
    "href": "teaching/2023-2024/Machine Learning/lecture-1.html#welcome",
    "title": "Introduction",
    "section": "",
    "text": "Welcome to all the new students! Here I am going to be talking about Machine Learning and all of the great things that this “technology” has to offer. To begin our course, I shall start with a bit of house keeping – more specifically, I will be talking about what exactly we’ll be learning about in the course (Machine Learning is a broad subject after-all). In addition, I will tell you where you can find the resources related to the course and how you can contact me, should you have any questions."
  },
  {
    "objectID": "teaching/2023-2024/Machine Learning/lecture-1.html#what-this-course-is-about",
    "href": "teaching/2023-2024/Machine Learning/lecture-1.html#what-this-course-is-about",
    "title": "Introduction",
    "section": "",
    "text": "In this course, we will be learning about Machine Learning: firstly, what Machine Learning actually is; secondly, we’ll take a look at some of the algorithms within the scope of Machine Learning, and develop an intuition about how these algorithms work and when they would be useful; and finally, how we can compare and evaluate the algorithms we’ve learnt about."
  },
  {
    "objectID": "teaching/2023-2024/Machine Learning/lecture-1.html#how-this-course-will-be-taught",
    "href": "teaching/2023-2024/Machine Learning/lecture-1.html#how-this-course-will-be-taught",
    "title": "Introduction",
    "section": "",
    "text": "I intended to deliver this course via a series of lectures. These lectures will be accompanied by the PDF lecture slides, in which I will provide the definitions and provide reference links should you wish to do some extra reading."
  },
  {
    "objectID": "teaching/2023-2024/Machine Learning/lecture-1.html#outline-of-the-course",
    "href": "teaching/2023-2024/Machine Learning/lecture-1.html#outline-of-the-course",
    "title": "Introduction",
    "section": "",
    "text": "Lecture\n\n\nType\n\n\nTopic\n\n\n\n\n\n\n1\n\n\nTheory\n\n\nIntroduction\n\n\n\n\n2\n\n\nTheory\n\n\nLinear models\n\n\n\n\n3\n\n\nLab\n\n\nLab on Linear models\n\n\n\n\n4\n\n\nTheory/Lab\n\n\nEvaluation of models\n\n\n\n\n5\n\n\nTheory/Lab\n\n\nSupport Vector Machines\n\n\n\n\n6\n\n\nTheory/Lab\n\n\nKernel methods"
  },
  {
    "objectID": "teaching/2023-2024/Machine Learning/lecture-1.html#source-code",
    "href": "teaching/2023-2024/Machine Learning/lecture-1.html#source-code",
    "title": "Introduction",
    "section": "Source code",
    "text": "Source code\nDuring the course, I would also like to supplement my algorithmic definitions and explanations with some programming code – for this I will use the Python programming language. The code snippets would look something like:\nimport random\nx = [1, 2, 3, 4]\ny = [random.random() + xi for xi in x]\nprint(y)\n\n[1.4898241502582414, 2.4805286156642175, 3.065379052563245, 4.05328483072365]"
  },
  {
    "objectID": "teaching/2023-2024/Machine Learning/lecture-1.html#running-the-source-code-yourself",
    "href": "teaching/2023-2024/Machine Learning/lecture-1.html#running-the-source-code-yourself",
    "title": "Introduction",
    "section": "Running the source code yourself",
    "text": "Running the source code yourself\nAll of the source can be run by yourselves if you use the same python environment (i.e. that you have installed all the appropriate libraries). On the git repository, I’ve included the environment.yml file used in the production of these lectures.\nTo run the code:\n    wget https://git.sr.ht/~jaymorgan/teaching/blob/master/2022-2023/Machine%20Learning/environment.yml\n    conda env create -f environment.yml  # recreate the conda env\n    conda activate ml-lectures           # activate the new env\n    python &lt;scripts&gt;"
  },
  {
    "objectID": "teaching/2023-2024/Machine Learning/lecture-1.html#references",
    "href": "teaching/2023-2024/Machine Learning/lecture-1.html#references",
    "title": "Introduction",
    "section": "References",
    "text": "References\nIn some cases, and is the norm with academic traditions, we’ll want to include a reference, a link to previous written works.\nHere is an example of a sentence that includes a reference:\n“This is a very important sentence which I assert to be true, to convince you of this fact I shall appeal to authority and include a reference: (Shalev-Shwartz, Shai and Ben-David, Shai, 2014)”\nMore information on the referenced material (such as title, publishing date) will be found in the bibliography slide (or bottom of the webpage if you’re viewing the HTML version of the lectures)."
  },
  {
    "objectID": "teaching/2023-2024/Machine Learning/lecture-1.html#about-me",
    "href": "teaching/2023-2024/Machine Learning/lecture-1.html#about-me",
    "title": "Introduction",
    "section": "About Me",
    "text": "About Me\nMy name is Dr Jay Paul Morgan. I am a researcher at the Université de Toulon, where I am developing Deep Learning models (a sub-field of Machine Learning research) for the study of astrophysical phenomenon.\nYou can find more information and links on my personal (LIS-Lab) website: https://pageperso.lis-lab.fr/jay.morgan/\nI also publish libraries and source code online:\n\nGithub: https://github.com/jaypmorgan\nGitlab: https://gitlab.com/jaymorgan\nSource Hut: https://sr.ht/~jaymorgan/\n\nIf you have any questions, you can email me at jay.morgan@univ-tln.fr"
  },
  {
    "objectID": "teaching/2023-2024/Machine Learning/lecture-1.html#where-you-can-find-the-resources",
    "href": "teaching/2023-2024/Machine Learning/lecture-1.html#where-you-can-find-the-resources",
    "title": "Introduction",
    "section": "Where you can find the resources",
    "text": "Where you can find the resources\nI try to make this course as accessible as possible, which means that I host these slides in a variety of ways to suit you.\nFirstly, you can find the links to all my courses on my personal website at: https://pageperso.lis-lab.fr/jay.morgan/teaching.html\nHere you can find the links to each lecture in a PDF or HTML format. Additionally, you can view the source code used to make these lectures on source hut: https://git.sr.ht/~jaymorgan/teaching. On this git repository you can find all my lectures from all years."
  },
  {
    "objectID": "teaching/2023-2024/Machine Learning/lecture-1.html#lets-answer-the-question-of-learning",
    "href": "teaching/2023-2024/Machine Learning/lecture-1.html#lets-answer-the-question-of-learning",
    "title": "Introduction",
    "section": "Let’s answer the question of learning",
    "text": "Let’s answer the question of learning\nWe’ll begin our journey into the world of Machine Learning by tackling the question of what it means to ‘learn’ – how may a machine actually learn anything?"
  },
  {
    "objectID": "teaching/2023-2024/Machine Learning/lecture-1.html#bait-shyness",
    "href": "teaching/2023-2024/Machine Learning/lecture-1.html#bait-shyness",
    "title": "Introduction",
    "section": "Bait-shyness",
    "text": "Bait-shyness\n\nTo begin to answer the question of learning, we may turn to nature for advice. Principally, if we look at the studies conducted with Mice we find some idea to notion of learning (Shalev-Shwartz, Shai and Ben-David, Shai, 2014). (Image by brgfx on Freepik)\nWhen a rat encounters a novel source of food, it will first eat a little bit of it. If the food is edible for the rat, it will continue to eat the food, even in future encounters. If, however, on the initial contact with the food, the rat deems the food poisonous, it will ignore and not eat the food in future encounters. This process we call ‘bait-shyness’.\nHere then we see the rat, on finding something new, learn from its experience, and use that knowledge of the experience for future encounters.\nOur initial understanding of rat’s bait-shyness was limited, but we’ve come to understand more about it. For instance, we learn that their learning process is more complex than originally thought. In a later experiment, where the ‘poison’ in the food is replaced by a different unpleasant stimulus such as a electric shock – i.e. when a rat eats a food, it is then shocked. It was found that this did not deter the rat from eating the food in future encounters, unlike the poison.\nIt is presumed that the rat’s have some ‘prior knowledge’ about the world and do not infer a temporal relationship between the food and being shocked, while they can infer the same relationship with food and illness."
  },
  {
    "objectID": "teaching/2023-2024/Machine Learning/lecture-1.html#computer-programs",
    "href": "teaching/2023-2024/Machine Learning/lecture-1.html#computer-programs",
    "title": "Introduction",
    "section": "Computer Programs",
    "text": "Computer Programs\nFrom these two examples of how rats may learn we see: the rat will make a guess about something now (i.e. that the food is not poisonous), it will find out how good this guess is (i.e. it either gets ill or it does not), and learn from how well its guess was for the future. We also see that its learning can be impacted by the rat’s prior knowledge about how the world may work.\nBut how does this framework for the process of learning translate to computers? For a more formal definition of how computer programs could be said to learn, we have a similar idea:\n\nA computer program is said to learn from experience \\(E\\) with respect to some class of tasks \\(T\\) and performance measure \\(P\\), if its performance a tasks in \\(T\\), as measured by \\(P\\), improves with experience \\(E\\).\n\n(Mitchell, Tom M, 1997)"
  },
  {
    "objectID": "teaching/2023-2024/Machine Learning/lecture-1.html#quiz",
    "href": "teaching/2023-2024/Machine Learning/lecture-1.html#quiz",
    "title": "Introduction",
    "section": "Quiz!",
    "text": "Quiz!\nWhat function is being used here?\n    8 ? 5   =   13\n    9 ? 1   =   10\n    1 ? 2   =    3"
  },
  {
    "objectID": "teaching/2023-2024/Machine Learning/lecture-1.html#something-more-difficult",
    "href": "teaching/2023-2024/Machine Learning/lecture-1.html#something-more-difficult",
    "title": "Introduction",
    "section": "Something more difficult…",
    "text": "Something more difficult…\nWhat values are being used here?\n    x * 1 + y   =   4\n    x * 3 + y   =   8\n    x * 5 + y   =  12"
  },
  {
    "objectID": "teaching/2023-2024/Machine Learning/lecture-1.html#when-might-we-need-machine-learning",
    "href": "teaching/2023-2024/Machine Learning/lecture-1.html#when-might-we-need-machine-learning",
    "title": "Introduction",
    "section": "When might we need Machine Learning",
    "text": "When might we need Machine Learning\n\nWhy do we need computer programs that ‘learn’ anyway? We already have programming languages, why can’t we just use them?\nLet’s suppose we’re creating a very simple Optical Character Recognition (OCR) program.\nThis program looks at a PDF document and converts the text into something we can copy and paste. Part of this program’s task is to take an individual character, say the number ‘8’, and recognise that it’s an 8 and add that to the already scanned text.\nHow would we go about creating a program where we can define how to identify ‘8’ or ‘1’ or ‘l’ – with all the varieties of lighting conditions, handwriting, fonts, sizes. We could find the process of encompassing all different variations tiresome – if not impossible, and that’s only for a single character!\nWith Machine Learning, instead of enumerating all possible solutions within a programming language, we collect a bunch of examples of ’8’s and give them to the algorithm to learn from.\nThrough looking at these many different examples, the algorithm will/should be able to recognise what an 8 generally looks like."
  },
  {
    "objectID": "teaching/2023-2024/Machine Learning/lecture-1.html#different-types-of-learning",
    "href": "teaching/2023-2024/Machine Learning/lecture-1.html#different-types-of-learning",
    "title": "Introduction",
    "section": "Different types of Learning",
    "text": "Different types of Learning\nWhat we have just demonstrated by way of the OCR example, is the type of learning we call ‘Supervised Learning’. We have many examples of input (lots of different kinds of handwritten 8’s), and we tell the learning algorithm, that they are indeed the number 8.\nBut there are other kind of different learning frameworks. Specifically we have the following:\n\nSupervised Learning\nUnsupervised, or sometimes called self-supervised Learning\nReinforcement Learning"
  },
  {
    "objectID": "teaching/2023-2024/Machine Learning/lecture-1.html#supervised-learning",
    "href": "teaching/2023-2024/Machine Learning/lecture-1.html#supervised-learning",
    "title": "Introduction",
    "section": "Supervised Learning",
    "text": "Supervised Learning\nTo better formalise Supervised Learning from our previous OCR example, Supervised Learning is when the learning algorithm “see’s” or has access to both the input and output.\nLet’s have a dataset \\(X\\), which is a set consisting of tuple pairs \\(x_i, y_i\\). \\(x_i\\) is an input, i.e. a single image with an ‘8’, and \\(y_i\\) is a label which tells the learning algorithm if the input is indeed an ‘8’ or something else. Mathematically we have:\n\\(X = \\{(x_1, y_1), (x_2, y_2), ..., (x_n, y_n)\\}\\)"
  },
  {
    "objectID": "teaching/2023-2024/Machine Learning/lecture-1.html#unsupervised-learning",
    "href": "teaching/2023-2024/Machine Learning/lecture-1.html#unsupervised-learning",
    "title": "Introduction",
    "section": "Unsupervised Learning",
    "text": "Unsupervised Learning\nIn Unsupervised learning, we have again have a dataset \\(X\\), who’s elements are only inputs. In other words, there are no corresponding labels for each input. Instead, the learning algorithm must learn inherent patterns in the data and create labels itself. Throughout the course, we’ll see examples of Unsupervised Learning in action.\nOne thing to note: Recent methodologies have started to call Unsupervised Learning, self-supervised. As we have just discussed, the labels are inherent to the data from the discovered patterns, it’s just we are not explicitly giving them to the learning algorithm ourselves. So it’s sort of like a supervised learning setup, except the learning algorithm is providing the labels itself – hence the self-supervised."
  },
  {
    "objectID": "teaching/2023-2024/Machine Learning/lecture-1.html#reinforcement-learning",
    "href": "teaching/2023-2024/Machine Learning/lecture-1.html#reinforcement-learning",
    "title": "Introduction",
    "section": "Reinforcement Learning",
    "text": "Reinforcement Learning\nReinforcement Learning is very different to both Supervised and Unsupervised Learning. Here is the type of learning you might be familiar with if you’ve seen ‘AI’ that learns to play video games. In this type of learning, we have the following elements:\n\nAn agent\nAn environment\nA set of allowed actions the agent can make within its environment.\n\nIn this situation, an agent will interact with it’s environment, and when it does something it can receive a reward (a reward can be positive or negative). The agent will remember what it has done to receive the reward. The objective for the agent is to maximise the reward score, and learns to do this through many iterations or play-through."
  },
  {
    "objectID": "teaching/2023-2024/Machine Learning/lecture-1.html#what-will-our-data-look-like",
    "href": "teaching/2023-2024/Machine Learning/lecture-1.html#what-will-our-data-look-like",
    "title": "Introduction",
    "section": "What will our data look like?",
    "text": "What will our data look like?\nIn this section we shall take a look at the different types of data we might expect and the different terminology used to name them.\nData in Machine Learning applications can come in a variety of different formats. The most typical data formats we might see are:\n\nTables\nImages/Videos\nText\nSound\n\nThese are the initial formats, though, before actually doing any learning, we will want to transform them into a different representation that we can use."
  },
  {
    "objectID": "teaching/2023-2024/Machine Learning/lecture-1.html#tables",
    "href": "teaching/2023-2024/Machine Learning/lecture-1.html#tables",
    "title": "Introduction",
    "section": "Tables",
    "text": "Tables\nA table, or tabular, format is a \\(n \\times m\\) set of data with \\(n\\) samples or examples, and \\(m\\) features for each sample. For example, suppose we have a table consisting the price of 100 different houses:\n\n\n\n\n\n\n\n\n\n\nNumber of bedrooms\n\n\nGarden size (ft)\n\n\n…\n\n\nPrice ($)\n\n\n\n\n\n\n3\n\n\n0\n\n\n…\n\n\n150,000\n\n\n\n\n5\n\n\n10\n\n\n…\n\n\n200,000\n\n\n\n\n…\n\n\n…\n\n\n…\n\n\n \n\n\n\n\n10\n\n\n1000\n\n\n…\n\n\n2,000,000\n\n\n\n\nIn a supervised learning setting, where we want to predict the price of a house we may then have the following dataset:\n\\(X = \\{([3, 0, ...], 150,000), ([5, 10, ...], 200,000), \\\\..., ([10, 1000, ...], 2,000,000)\\}\\)"
  },
  {
    "objectID": "teaching/2023-2024/Machine Learning/lecture-1.html#imagesvideos",
    "href": "teaching/2023-2024/Machine Learning/lecture-1.html#imagesvideos",
    "title": "Introduction",
    "section": "Images/Videos",
    "text": "Images/Videos\nImages are composed of 2D or 3D arrays of numeric values. For example, in a RGB image that is 1024x500 pixels, we would have the array of size 1024x500x3 – where 3 is the red, green, and blue channel, respectively. If we have just a grayscale image, we could represent it as either 1024x500x1 or 1024x500 as the channel ‘dimension’ of the array is singular.\nWe may already know that videos are simply a sequence of images that are iterated through 24+ times a second. For a 24 frames per second video, we would have an array size of 1024x500x3x24 – a 4-dimensional array."
  },
  {
    "objectID": "teaching/2023-2024/Machine Learning/lecture-1.html#text",
    "href": "teaching/2023-2024/Machine Learning/lecture-1.html#text",
    "title": "Introduction",
    "section": "Text",
    "text": "Text\nText and language data is perhaps one of the most flexible formats of data, in terms of the person implementing the Machine Learning algorithm is somewhat free in determining how to represent the language to the algorithm.\nWith text data, we have a series of ‘tokens’ – these tokens could be words, groups of words, parts of words, and even just characters. For example, consider:\n“this is a sentence, that shouldn’t be misunderstood.”"
  },
  {
    "objectID": "teaching/2023-2024/Machine Learning/lecture-1.html#tokenisation-of-text",
    "href": "teaching/2023-2024/Machine Learning/lecture-1.html#tokenisation-of-text",
    "title": "Introduction",
    "section": "Tokenisation of text",
    "text": "Tokenisation of text\n“this is a sentence, that shouldn’t be misunderstood.”\nWe could ‘tokenise’ (the process of converting a string into a series of tokens that represent the original string) this sentence by splitting at white-space:\n{\"this\", \"is\", \"a\", \"sentence,\", \"that\" \"shouldn't\", \"be\", \"misunderstood.\"}\nNotice how with the words “sentence” and “misunderstood”, the punctuation is considered part of the word and so “misunderstood.” != “misunderstood”.\nThese kinds of questions of how to best represent text and language we will talk more about in later lectures!"
  },
  {
    "objectID": "teaching/2023-2024/Machine Learning/lecture-1.html#time-series",
    "href": "teaching/2023-2024/Machine Learning/lecture-1.html#time-series",
    "title": "Introduction",
    "section": "Time-series",
    "text": "Time-series\nI named this section time-series to be as general as possible. Within the type ‘time-series’, we could have the following types of information:\n\nSound waves\nStock prices\nNetwork messaging\n\nThese types of data all share a property in that the ‘time’ component is important in their meaning."
  },
  {
    "objectID": "teaching/2023-2024/Machine Learning/lecture-1.html#types-of-outputs-regression-classification",
    "href": "teaching/2023-2024/Machine Learning/lecture-1.html#types-of-outputs-regression-classification",
    "title": "Introduction",
    "section": "Types of Outputs – Regression & Classification",
    "text": "Types of Outputs – Regression & Classification\nFirst, however, I wish to explain the difference between the terms Regression and Classification.\n\nRegression: the prediction of a continuous quantity, i.e. how much does this house cost?\nClassification: the prediction of a discrete value or class label, i.e. dog or cat?\n\nIn the following toy datasets, we’ll see different types of predictions that fall under the regression/classification output type."
  },
  {
    "objectID": "teaching/2023-2024/Machine Learning/lecture-1.html#boston-house-prices-dataset-tabular-regression",
    "href": "teaching/2023-2024/Machine Learning/lecture-1.html#boston-house-prices-dataset-tabular-regression",
    "title": "Introduction",
    "section": "Boston House Prices Dataset – Tabular Regression",
    "text": "Boston House Prices Dataset – Tabular Regression\nA dataset of 506 houses in Boston, USA, collected during US Census.\n\n13 features/properties about each house\n1 target property: the price of the house\n\nMore information about each of the features can be found at: https://www.cs.toronto.edu/~delve/data/boston/bostonDetail.html\n(Harrison Jr, David and Rubinfeld, Daniel L, 1978)"
  },
  {
    "objectID": "teaching/2023-2024/Machine Learning/lecture-1.html#boston-house-prices-example-rows",
    "href": "teaching/2023-2024/Machine Learning/lecture-1.html#boston-house-prices-example-rows",
    "title": "Introduction",
    "section": "Boston House Prices – example rows",
    "text": "Boston House Prices – example rows\nimport warnings\nfrom sklearn.datasets import load_boston\nwith warnings.catch_warnings():\n    warnings.filterwarnings(\"ignore\")\n    boston = load_boston()\nboston = pd.DataFrame(\n    data=np.c_[boston['data'], boston['target']],\n    columns=boston['feature_names'].tolist() + ['target'])\nprint(boston[:2])\n      CRIM    ZN  INDUS  CHAS    NOX     RM  ...  RAD    TAX  PTRATIO      B  LSTAT  target\n0  0.00632  18.0   2.31   0.0  0.538  6.575  ...  1.0  296.0     15.3  396.9   4.98    24.0\n1  0.02731   0.0   7.07   0.0  0.469  6.421  ...  2.0  242.0     17.8  396.9   9.14    21.6\n\n[2 rows x 14 columns]"
  },
  {
    "objectID": "teaching/2023-2024/Machine Learning/lecture-1.html#boston-house-prices-concerns",
    "href": "teaching/2023-2024/Machine Learning/lecture-1.html#boston-house-prices-concerns",
    "title": "Introduction",
    "section": "Boston House Prices – concerns",
    "text": "Boston House Prices – concerns\nThe Boston dataset is an excellent dataset in the fact that it contains some ethical issues when it comes to Machine Learning. More specifically, some of the features in the data are ‘dummy’ variables for racial attributes (Carlisle, M., 2020). Moreover, these features show a racial segregation has a positive impact on house prices.\nScikit-Learn (scikit-learn, 2022), one of the most prolific Machine Learning framework in the Python ecosystem, has decided to depreciate and remove the Boston dataset from their repository following these concerns.\nWe will continue to use the dataset here as it is an easy to understand regression problem, and to demonstrate how easy it is to be accidentally unethical if you’re not thinking about the data carefully enough."
  },
  {
    "objectID": "teaching/2023-2024/Machine Learning/lecture-1.html#iris-dataset-tabular-classification",
    "href": "teaching/2023-2024/Machine Learning/lecture-1.html#iris-dataset-tabular-classification",
    "title": "Introduction",
    "section": "Iris Dataset – Tabular Classification",
    "text": "Iris Dataset – Tabular Classification"
  },
  {
    "objectID": "teaching/2023-2024/Machine Learning/lecture-1.html#iris-dataset-features",
    "href": "teaching/2023-2024/Machine Learning/lecture-1.html#iris-dataset-features",
    "title": "Introduction",
    "section": "Iris Dataset – features",
    "text": "Iris Dataset – features\n\n150 examples\n4 features: Petal length/width, sepal length/width\n1 classification: type of flower: {viriginica, setosa, veriscolor}\nhttps://archive.ics.uci.edu/ml/datasets/iris (Fisher, Ronald A, 1936)"
  },
  {
    "objectID": "teaching/2023-2024/Machine Learning/lecture-1.html#iris-dataset-example-rows",
    "href": "teaching/2023-2024/Machine Learning/lecture-1.html#iris-dataset-example-rows",
    "title": "Introduction",
    "section": "Iris Dataset – example rows",
    "text": "Iris Dataset – example rows\nfrom sklearn.datasets import load_iris\niris = load_iris()\niris = pd.DataFrame(\n    data = np.c_[iris['data'], iris['target']],\n    columns = iris['feature_names'] + ['target'])\nprint(iris.head(2))\n   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  target\n0                5.1               3.5                1.4               0.2     0.0\n1                4.9               3.0                1.4               0.2     0.0"
  },
  {
    "objectID": "teaching/2023-2024/Machine Learning/lecture-1.html#mnist-dataset-image-classification",
    "href": "teaching/2023-2024/Machine Learning/lecture-1.html#mnist-dataset-image-classification",
    "title": "Introduction",
    "section": "MNIST Dataset – Image Classification",
    "text": "MNIST Dataset – Image Classification\n\nA dataset of images (of size 28x28) containing handwritten digits from 0 - 9.\nhttp://yann.lecun.com/exdb/mnist/\n(LeCun, Yann and Bottou, L{\\’e}on and Bengio, Yoshua and Haffner, Patrick, 1998)"
  },
  {
    "objectID": "teaching/2023-2024/Machine Learning/lecture-1.html#mnist-dataset-features",
    "href": "teaching/2023-2024/Machine Learning/lecture-1.html#mnist-dataset-features",
    "title": "Introduction",
    "section": "MNIST Dataset – Features",
    "text": "MNIST Dataset – Features\n\n60,000 images in the training dataset\n10,000 images in the test dataset\n28x28 pixels (grayscale)"
  },
  {
    "objectID": "teaching/2023-2024/Machine Learning/lecture-1.html#mnist-dataset-example-rows",
    "href": "teaching/2023-2024/Machine Learning/lecture-1.html#mnist-dataset-example-rows",
    "title": "Introduction",
    "section": "MNIST Dataset – Example Rows",
    "text": "MNIST Dataset – Example Rows\nfrom sklearn.datasets import fetch_openml\nmnist = fetch_openml(\"mnist_784\").data[:2]\npixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  pixel8  pixel9  \\\n0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n1     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n\npixel10  ...  pixel775  pixel776  pixel777  pixel778  pixel779  pixel780  \\\n0      0.0  ...       0.0       0.0       0.0       0.0       0.0       0.0   \n1      0.0  ...       0.0       0.0       0.0       0.0       0.0       0.0   \n\npixel781  pixel782  pixel783  pixel784  \n0       0.0       0.0       0.0       0.0  \n1       0.0       0.0       0.0       0.0  \n\n[2 rows x 784 columns]"
  },
  {
    "objectID": "teaching/2023-2024/Machine Learning/lecture-1.html#large-movie-review-dataset-text-classificationregression",
    "href": "teaching/2023-2024/Machine Learning/lecture-1.html#large-movie-review-dataset-text-classificationregression",
    "title": "Introduction",
    "section": "Large Movie Review Dataset – Text Classification/Regression",
    "text": "Large Movie Review Dataset – Text Classification/Regression\n\nStory of a man who has unnatural feelings for a pig. Starts out with a opening scene that is a terrific example of absurd comedy. A formal orchestra audience is turned into an insane, violent mob by the crazy chantings of it’s singers. Unfortunately it stays absurd the WHOLE time with no general narrative eventually making it just too off putting. Even those from the era should be turned off. The cryptic dialogue would make Shakespeare seem easy to a third grader. On a technical level it’s better than you might think with some good cinematography by future great Vilmos Zsigmond. Future stars Sally Kirkland and Frederic Forrest can be seen briefly.\n\nReview from: train/neg/0_3.txt\n\n50,000 movie reviews (25,000 for training and testing).\nEach review is labelled with a binary label of sentiment – a positive or negative review was towards the movie in question.\n\nhttps://ai.stanford.edu/~amaas/data/sentiment/\n(Maas, Andrew L. and Daly, Raymond E. and Pham, Peter T. and Huang, Dan and Ng, Andrew Y. and Potts, Christopher, 2011)"
  },
  {
    "objectID": "teaching/2023-2024/Machine Learning/lecture-1.html#ham-or-spam-text-classification",
    "href": "teaching/2023-2024/Machine Learning/lecture-1.html#ham-or-spam-text-classification",
    "title": "Introduction",
    "section": "Ham or Spam – Text Classification",
    "text": "Ham or Spam – Text Classification\n    Message-ID: &lt;8701134.1075856113926.JavaMail.evans@thyme&gt;\n    Date: Mon, 30 Oct 2000 02:06:00 -0800 (PST)\n    From: shona.wilson@enron.com\n    To: eugenio.perez@enron.com\n    Subject: meeting deadlines\n    Mime-Version: 1.0\n    Content-Type: text/plain; charset=us-ascii\n    Content-Transfer-Encoding: 7bit\n    X-From: Shona Wilson\n    X-To: Eugenio Perez\n    X-cc: \n    X-bcc: \n    X-Origin: Beck-S\n    X-FileName: sbeck.nsf\n    \n    Dear Eugenio,\n    \n    I did not want to say this when everyone else was around, but I am concerned \n    that no attempt was made to meet the deadline of this morning that we \n    discussed last Friday. (to decide on a name for the database).  Only Maria \n    Teresa had her information to me this am as requested. The deadline could \n    have been easily met by working diligently this morning, but Jennifer did not \n    come in until 8:30 and MT until 8:15.\n    \n    I thought we had discussed the urgency of this - to have something to present \n    at the 10am meeting.  We need to discuss this to ensure it does not happen \n    again.\n    \n    Best regards\n    \n    Shona\n\nEnron Spam classification of email messages.\nIs the email Spam – each email is labelled with a binary label, spam or not spam (ham).\nThe dataset contains 17,171 spam and 16,545 ham email messages.\n\nhttps://www2.aueb.gr/users/ion/data/enron-spam/\n(Metsis, Vangelis and Androutsopoulos, Ion and Paliouras, Georgios, 2006)"
  },
  {
    "objectID": "teaching/2023-2024/Machine Learning/lecture-1.html#compute-resources-environmental-concerns",
    "href": "teaching/2023-2024/Machine Learning/lecture-1.html#compute-resources-environmental-concerns",
    "title": "Introduction",
    "section": "Compute resources – environmental concerns",
    "text": "Compute resources – environmental concerns\n\nLarge-scale deployment of AI could also have both positive and negative impacts on the environment. Negative impacts include increased use of natural resources, such as rare earth metals, pollution and waste, as well as energy consumption. However, AI could help with waste management and conservation offering environmental benefits.\n\n\n[…] In the United States, data centres already account for about 2 percent of all electricity used. In one estimation, DeepMind’s AlphaGo – which beat Go Champion Lee Sedol in 2016 – took 50,000 times as much power as the human brain to do so.\n\n({European Parliament. Directorate General for Parliamentary Research Services.}, 2020)"
  },
  {
    "objectID": "teaching/2023-2024/Machine Learning/lecture-1.html#bias-in-language-models",
    "href": "teaching/2023-2024/Machine Learning/lecture-1.html#bias-in-language-models",
    "title": "Introduction",
    "section": "Bias in language models",
    "text": "Bias in language models\n\nBiases exist in language models trained on news articles (Bolukbasi, Tolga and Chang, Kai-Wei and Zou, James Y and Saligrama, Venkatesh and Kalai, Adam T, 2016)."
  },
  {
    "objectID": "teaching/2023-2024/Machine Learning/lecture-1.html#personal-information",
    "href": "teaching/2023-2024/Machine Learning/lecture-1.html#personal-information",
    "title": "Introduction",
    "section": "Personal information",
    "text": "Personal information\nIn Machine Learning applications where data is generated (such as generating faces that don’t exist), there is a possibility to expose personal information. For example, in a situation where these generative Machine Learning models create synthetic patient data, the model may be trained on real medical data. The output of the Machine Learning model could possibly leak personal information.\n(Arora, Anmol and Arora, Ananya, 2022)"
  },
  {
    "objectID": "teaching/2023-2024/Machine Learning/lecture-1.html#mental-health-of-optimisation-algorithms",
    "href": "teaching/2023-2024/Machine Learning/lecture-1.html#mental-health-of-optimisation-algorithms",
    "title": "Introduction",
    "section": "Mental health of optimisation algorithms",
    "text": "Mental health of optimisation algorithms\nThis example is more specific to how algorithms are used as opposed to their specific design. Yet, this should still be highlighted. We have seen increasing discussion surrounding the use of optimisation algorithms that try to increase the amount of ‘screen time’ or engagement from users of social media, and it’s no secret that spending lots of time of social media has a measurable effect on one’s mental health."
  },
  {
    "objectID": "teaching/2023-2024/Machine Learning/lecture-1.html#copyright-concerns",
    "href": "teaching/2023-2024/Machine Learning/lecture-1.html#copyright-concerns",
    "title": "Introduction",
    "section": "Copyright Concerns",
    "text": "Copyright Concerns\nA more recent addition to the concerns is that of Github’s co-pilot application that helps users write programming code. This application has been developed on open-source software – some of which includes licensing that specifies how this open-source code may be used (for example, with attribution or copy-left). Yet, Github’s co-pilot may insert code that its been trained on verbatim (though recent additions have been addressing these concerns), resulting in a situation of ‘code laundering’. https://twitter.com/mitsuhiko/status/1410886329924194309\n    float Q_rsqrt( float number )\n    {\n            long i;\n            float x2, y;\n            const float threehalfs = 1.5F;\n    \n            x2 = number * 0.5F;\n            y  = number;\n            i  = * ( long * ) &y;                       // evil floating point bit level hacking\n            i  = 0x5f3759df - ( i &gt;&gt; 1 );               // what the fuck? \n            y  = * ( float * ) &i;\n            y  = y * ( threehalfs - ( x2 * y * y ) );   // 1st iteration\n    //  y  = y * ( threehalfs - ( x2 * y * y ) );   // 2nd iteration, this can be removed\n    \n            return y;\n    }\n    \n    // Implementation from Quake III Arena under the GPL license."
  },
  {
    "objectID": "teaching/2023-2024/Machine Learning/lecture-1.html#what-is-machine-learning",
    "href": "teaching/2023-2024/Machine Learning/lecture-1.html#what-is-machine-learning",
    "title": "Introduction",
    "section": "What is Machine Learning",
    "text": "What is Machine Learning\n\nWe’ve taken a look at the different kinds of frameworks for learning – animal behaviour with bait-shyness, and how that translates in computer programs.\nWe’ve identified the different types of learning: supervised, unsupervised, and reinforcement learning.\nWe’ve looked at the different types of data we may encounter, from tabular to text data, and have also seen examples of some toy datasets we will be using in the course.\nFinally, we’ve highlighted some of the ethical concerns that can arise in Machine Learning."
  },
  {
    "objectID": "teaching/2023-2024/Machine Learning/lecture-1.html#bibliography-1",
    "href": "teaching/2023-2024/Machine Learning/lecture-1.html#bibliography-1",
    "title": "Introduction",
    "section": "Bibliography",
    "text": "Bibliography\nArora, Anmol and Arora, Ananya (2022). Generative Adversarial Networks and Synthetic Patient Data: Current Challenges and Future Perspectives, {Royal College of Physicians}.\nBolukbasi, Tolga and Chang, Kai-Wei and Zou, James Y and Saligrama, Venkatesh and Kalai, Adam T (2016). Man is to computer programmer as woman is to homemaker? debiasing word embeddings, Advances in neural information processing systems.\nCarlisle, M. (2020). Racist Data Destruction?, Medium.\nDiliff (2014). Iris germanica (Purple bearded Iris), Wakehurst Place, UK - Diliff.jpg.\nEric Guinther (2005). Image of a primrose willowherb Ludwigia octovalvis (family Onagraceae), flower showing petals and sepals.\nFisher, Ronald A (1936). The use of multiple measurements in taxonomic problems, Wiley Online Library.\nGonen, Hila and Goldberg, Yoav (2019). Lipstick on a {{Pig}}: {{Debiasing Methods Cover}} up {{Systematic Gender Biases}} in {{Word Embeddings But}} Do Not {{Remove Them}}, {arXiv}.\nHarrison Jr, David and Rubinfeld, Daniel L (1978). Hedonic housing prices and the demand for clean air, Elsevier.\nLeCun, Yann and Bottou, L{\\’e}on and Bengio, Yoshua and Haffner, Patrick (1998). Gradient-based learning applied to document recognition, Ieee.\nMaas, Andrew L. and Daly, Raymond E. and Pham, Peter T. and Huang, Dan and Ng, Andrew Y. and Potts, Christopher (2011). Learning Word Vectors for Sentiment Analysis, Association for Computational Linguistics.\nMetsis, Vangelis and Androutsopoulos, Ion and Paliouras, Georgios (2006). Spam filtering with naive bayes-which naive bayes?.\nMitchell, Tom M (1997). Machine learning, McGraw-hill New York.\nShalev-Shwartz, Shai and Ben-David, Shai (2014). Understanding machine learning: From theory to algorithms, Cambridge university press.\nscikit-learn (2022). Sklearn.Datasets.Load\\_boston, scikit-learn.\n{European Parliament. Directorate General for Parliamentary Research Services.} (2020). The Ethics of Artificial Intelligence: Issues and Initiatives., {Publications Office}."
  },
  {
    "objectID": "teaching/2023-2024/Machine Learning/lab-2-reveal.html#how-to-answer-the-questions",
    "href": "teaching/2023-2024/Machine Learning/lab-2-reveal.html#how-to-answer-the-questions",
    "title": "Evaluation of Models",
    "section": "How to answer the questions",
    "text": "How to answer the questions\nIn these lab sessions we will implement what we’ve learn during the theory lectures. These implementation will need to be using the Python Programming Language. You’re allowed to use 3rd party libraries such as pandas, matplotlib, numpy. But it is not allowed to use a library that implements exactly machine learning model we’re learning about. For example, in this lab, we’re learning about linear models, so you cannot use a library that provides functionality for computing a linear model. If you’re uncertain about whether a library can be used, please do ask!\nI am going to give you the maximum flexibility with how you want to program these linear models: you can create a Python script, or if you like, you can use jupyter notebooks. In both cases, You should preface your implementation with which question you’re answering with a comment (if you’re writing a python script), or markdown (if you want to use jupyter) like this:\n# Q1. Download, parse, and load the data into a pandas dataframe,\n# print the first 5 rows to ensure the data is formated correctly\nimport pandas as pd\n\ndef load_data(filepath: str) -&gt; pd.DataFrame:\n    # load_data logic\n    return df\nYou are to work individually.\nIn summary:\n\nWork individually.\nImplementation should be using the Python programming language.\nYou can use supplementary libraries such as pandas, matplotlib, numpy, but cannot use a library that provides a function call for the assignment."
  },
  {
    "objectID": "teaching/2023-2024/Machine Learning/lab-2-reveal.html#submission-procedure",
    "href": "teaching/2023-2024/Machine Learning/lab-2-reveal.html#submission-procedure",
    "title": "Evaluation of Models",
    "section": "Submission Procedure",
    "text": "Submission Procedure\nTo hand in your assignment, please zip all of your source code (do not include the data) into a zip-archive named using the following format:\n&lt;first-name&gt;-&lt;surname&gt;-machine-learning-lab-2.zip\nreplacing &lt;first-name&gt; and &lt;surname&gt; with your name. Please send this assignment to my email address: jay.morgan@univ-tln.fr using the subject Machine Learning Assignment 2 by the end of the lab session. I will accept late assignments, but will be deducted score accordingly."
  },
  {
    "objectID": "teaching/2023-2024/Machine Learning/lab-2-reveal.html#question-1",
    "href": "teaching/2023-2024/Machine Learning/lab-2-reveal.html#question-1",
    "title": "Evaluation of Models",
    "section": "Question 1",
    "text": "Question 1\nCopy the existing code from Lab 1, creating a new folder for this lab and pasting in the code for the linear regressor."
  },
  {
    "objectID": "teaching/2023-2024/Machine Learning/lab-2-reveal.html#question-2",
    "href": "teaching/2023-2024/Machine Learning/lab-2-reveal.html#question-2",
    "title": "Evaluation of Models",
    "section": "Question 2",
    "text": "Question 2\nDownload the Iris dataset from https://archive.ics.uci.edu/dataset/53/iris. The dataset can be downloaded from iris.data. Load the data into a pandas dataframe.\nFor this lab, we’re going to be performing a binary classification problem, but this dataset has 3 classes: setosa, virginica, and versicolor. So we want to take this multi-class problem and transform it into a binary classification.\nCreate a new column for the dataset called target. The value of target will be 1 if the row contains a setosa flower, else the value is 0. There should be \\(\\frac{1}{3}\\) rows with the value of 1, the rest should be 0."
  },
  {
    "objectID": "teaching/2023-2024/Machine Learning/lab-2-reveal.html#question-3",
    "href": "teaching/2023-2024/Machine Learning/lab-2-reveal.html#question-3",
    "title": "Evaluation of Models",
    "section": "Question 3",
    "text": "Question 3\nFor this question we want to take this dataset of 150 rows, and split it into a train, test, and validation dataset, using the following proportions for each split:\n\nTraining: 70%\nValidation: 10%\nTesting: 20%\n\nSample data for each subset using stratified sampling. I.e. the training data should have roughly \\(\\frac{1}{3}\\) positive samples, the testing and validation dataset should also have roughly \\(\\frac{1}{3}\\) positive samples."
  },
  {
    "objectID": "teaching/2023-2024/Machine Learning/lab-2-reveal.html#question-4",
    "href": "teaching/2023-2024/Machine Learning/lab-2-reveal.html#question-4",
    "title": "Evaluation of Models",
    "section": "Question 4",
    "text": "Question 4\nUsing the linear regression model you created in the previous lecture, transform it into a logistic regressor by applying the logistic function to the output of the model. The loss function for this model should be binary cross entropy.\nSelect two columns from the Iris dataset (i.e. petal length and petal width), and using these two columns, train a logistic regressor using gradient descent, measuring the gradient using finite differences approximation. This means that instead of having a single slope variable, we have multiple:\n\\[\n\\hat{y} = \\sigma(\\beta_0 + \\sum_{i=1}^m x_i \\beta_i)\n\\]\nwhere \\(\\hat{y}\\) is the model’s probability prediction, \\(\\sigma\\) is the logistic/sigmoid function, \\(\\beta_0\\) is the intercept, \\(\\beta_i\\) is the coefficient that modulates the \\(x_i\\) variable.\nI’ve made a start for you, please fill in the ‘#TODOs’:\nimport numpy as np\n\ndef bce(y, yhat):\n    # TODO: apply the binary cross entropy function returning the loss\n    return loss\n\nclass LogisticRegressor:\n    def __init__(self, n_features: int = 2):\n        self.params = np.random.randn(n_features + 1)\n\n    def logistic(self, x):\n        # TODO: apply the logistic function\n        return x\n\n    def __call__(self, x, logits=False):\n        y = self.params[0] + self.params[1:] @ x.T\n        if not logits:\n            y = self.logistic(y)\n        return y\n\n    def fit(train_x, train_y, valid_x, valid_y, epochs: int = 100, lr: float = 0.01):\n        # TODO: train the model using gradient descent and finite-differences\n        for epoch in range(1, epochs+1):\n            for xi, yi in zip(train_x, train_y):\n                # calculate loss and update model parameters using gradient descent\n            for xi, yi in zip(valid_x, valid_y):\n                # calculate validation loss (BUT DON'T UPDATE MODEL PARAMETERS!)\n\n    def predict(x, logits):\n        return self(x, logits=logits)"
  },
  {
    "objectID": "teaching/2023-2024/Machine Learning/lab-2-reveal.html#question-5",
    "href": "teaching/2023-2024/Machine Learning/lab-2-reveal.html#question-5",
    "title": "Evaluation of Models",
    "section": "Question 5",
    "text": "Question 5\nAs gradient descent is iterating, store (using class variables), the training and validation loss.\nVisualise the training and validation loss. Is there a point at which the model begins to over fit? How do you know that the model is beginning to overfit by looking at these curves?"
  },
  {
    "objectID": "teaching/2023-2024/Machine Learning/lab-2-reveal.html#question-6",
    "href": "teaching/2023-2024/Machine Learning/lab-2-reveal.html#question-6",
    "title": "Evaluation of Models",
    "section": "Question 6",
    "text": "Question 6\nPredict the class labels for the testing set.\nFor the testing set, calculate the:\n\nTP – number of true positives\nTN – number of true negatives\nFP – number of false positives\nFN – number of false negatives"
  },
  {
    "objectID": "teaching/2023-2024/Machine Learning/lab-2-reveal.html#question-7",
    "href": "teaching/2023-2024/Machine Learning/lab-2-reveal.html#question-7",
    "title": "Evaluation of Models",
    "section": "Question 7",
    "text": "Question 7\nCalculate the precision and recall and \\(F_1\\) score.\ndef precision(y, yhat):\n    # calculate the precision and return it\n    return\n\ndef recall(y, yhat):\n    # calculate the recall and return it\n    return\n\ndef f_beta(y, yhat, beta=1):\n    pr = precision(y, yhat)\n    rc = recall(y, yhat)\n    # calculate the f_beta score and return it\n    return\n\n\npr = precision(y, yhat&gt;=0.5)\nrc = recall(y, yhat&gt;=0.5)\n# ..."
  },
  {
    "objectID": "teaching/2023-2024/Machine Learning/lab-2-reveal.html#question-8",
    "href": "teaching/2023-2024/Machine Learning/lab-2-reveal.html#question-8",
    "title": "Evaluation of Models",
    "section": "Question 8",
    "text": "Question 8\nGenerate a report using the precision, recall and \\(F_1\\) and confusion matrix. The report should be printed like:\n    |        |          | Predicted |          |\n    |        |          |  Positive | Negative |\n    | Actual | Positive |         5 |        2 |\n    |        | Negative |         3 |        1 |\n    \n    - Precision: 0.6\n    - Recall: 0.6\n    - F_1 Score: 0.6\nReplacing the scores with the correct numbers."
  },
  {
    "objectID": "teaching/2023-2024/Machine Learning/lab-2-reveal.html#question-9",
    "href": "teaching/2023-2024/Machine Learning/lab-2-reveal.html#question-9",
    "title": "Evaluation of Models",
    "section": "Question 9",
    "text": "Question 9\nCalculate the true-positive and false positive rate, and from these values generate a ROC curve.\n    def roc(y, yhat, threshold_step=0.01):\n        # iteratively increase the threshold by threshold_step,\n        # calculating the TP and FP rate for each iteration. This function\n        # should return two lists, a list of TP rates, and a list of FP\n        # rates.\n        return tp, fp\n    \n    tp, fp = roc(y, yhat)\n    # visualise the ROC curve here"
  },
  {
    "objectID": "teaching/2023-2024/Machine Learning/lab-2-reveal.html#question-10",
    "href": "teaching/2023-2024/Machine Learning/lab-2-reveal.html#question-10",
    "title": "Evaluation of Models",
    "section": "Question 10",
    "text": "Question 10\nNow that you’ve created a logistic regressor for two features of the Iris dataset and have created some analytic results. Select another two columns (i.e. petal width and sepal length, or petal length and sepal width). Create a different logistic regressor using these new columns and create the same results as you did with questions 8 and 9.\nCompare these two models trained with different columns. Which model is best, and why do we know that it’s the best?"
  },
  {
    "objectID": "teaching/2023-2024/Machine Learning/lab-2.html",
    "href": "teaching/2023-2024/Machine Learning/lab-2.html",
    "title": "Evaluation of Models",
    "section": "",
    "text": "Welcome to the second lab for the Machine Learning course. In this lab we’re going to be implementing various methods to evaluate a logistic regressor.\nThis lab will build on what we created in the last lab, transforming the linear regressor into a logistic regressor.\n\n\nIn these lab sessions we will implement what we’ve learn during the theory lectures. These implementation will need to be using the Python Programming Language. You’re allowed to use 3rd party libraries such as pandas, matplotlib, numpy. But it is not allowed to use a library that implements exactly machine learning model we’re learning about. For example, in this lab, we’re learning about linear models, so you cannot use a library that provides functionality for computing a linear model. If you’re uncertain about whether a library can be used, please do ask!\nI am going to give you the maximum flexibility with how you want to program these linear models: you can create a Python script, or if you like, you can use jupyter notebooks. In both cases, You should preface your implementation with which question you’re answering with a comment (if you’re writing a python script), or markdown (if you want to use jupyter) like this:\n# Q1. Download, parse, and load the data into a pandas dataframe,\n# print the first 5 rows to ensure the data is formated correctly\nimport pandas as pd\n\ndef load_data(filepath: str) -&gt; pd.DataFrame:\n    # load_data logic\n    return df\nYou are to work individually.\nIn summary:\n\nWork individually.\nImplementation should be using the Python programming language.\nYou can use supplementary libraries such as pandas, matplotlib, numpy, but cannot use a library that provides a function call for the assignment.\n\n\n\n\nTo hand in your assignment, please zip all of your source code (do not include the data) into a zip-archive named using the following format:\n&lt;first-name&gt;-&lt;surname&gt;-machine-learning-lab-2.zip\nreplacing &lt;first-name&gt; and &lt;surname&gt; with your name. Please send this assignment to my email address: jay.morgan@univ-tln.fr using the subject Machine Learning Assignment 2 by the end of the lab session. I will accept late assignments, but will be deducted score accordingly."
  },
  {
    "objectID": "teaching/2023-2024/Machine Learning/lab-2.html#how-to-answer-the-questions",
    "href": "teaching/2023-2024/Machine Learning/lab-2.html#how-to-answer-the-questions",
    "title": "Evaluation of Models",
    "section": "",
    "text": "In these lab sessions we will implement what we’ve learn during the theory lectures. These implementation will need to be using the Python Programming Language. You’re allowed to use 3rd party libraries such as pandas, matplotlib, numpy. But it is not allowed to use a library that implements exactly machine learning model we’re learning about. For example, in this lab, we’re learning about linear models, so you cannot use a library that provides functionality for computing a linear model. If you’re uncertain about whether a library can be used, please do ask!\nI am going to give you the maximum flexibility with how you want to program these linear models: you can create a Python script, or if you like, you can use jupyter notebooks. In both cases, You should preface your implementation with which question you’re answering with a comment (if you’re writing a python script), or markdown (if you want to use jupyter) like this:\n# Q1. Download, parse, and load the data into a pandas dataframe,\n# print the first 5 rows to ensure the data is formated correctly\nimport pandas as pd\n\ndef load_data(filepath: str) -&gt; pd.DataFrame:\n    # load_data logic\n    return df\nYou are to work individually.\nIn summary:\n\nWork individually.\nImplementation should be using the Python programming language.\nYou can use supplementary libraries such as pandas, matplotlib, numpy, but cannot use a library that provides a function call for the assignment."
  },
  {
    "objectID": "teaching/2023-2024/Machine Learning/lab-2.html#submission-procedure",
    "href": "teaching/2023-2024/Machine Learning/lab-2.html#submission-procedure",
    "title": "Evaluation of Models",
    "section": "",
    "text": "To hand in your assignment, please zip all of your source code (do not include the data) into a zip-archive named using the following format:\n&lt;first-name&gt;-&lt;surname&gt;-machine-learning-lab-2.zip\nreplacing &lt;first-name&gt; and &lt;surname&gt; with your name. Please send this assignment to my email address: jay.morgan@univ-tln.fr using the subject Machine Learning Assignment 2 by the end of the lab session. I will accept late assignments, but will be deducted score accordingly."
  },
  {
    "objectID": "teaching/2023-2024/Machine Learning/lab-2.html#question-1",
    "href": "teaching/2023-2024/Machine Learning/lab-2.html#question-1",
    "title": "Evaluation of Models",
    "section": "Question 1",
    "text": "Question 1\nCopy the existing code from Lab 1, creating a new folder for this lab and pasting in the code for the linear regressor."
  },
  {
    "objectID": "teaching/2023-2024/Machine Learning/lab-2.html#question-2",
    "href": "teaching/2023-2024/Machine Learning/lab-2.html#question-2",
    "title": "Evaluation of Models",
    "section": "Question 2",
    "text": "Question 2\nDownload the Iris dataset from https://archive.ics.uci.edu/dataset/53/iris. The dataset can be downloaded from iris.data. Load the data into a pandas dataframe.\nFor this lab, we’re going to be performing a binary classification problem, but this dataset has 3 classes: setosa, virginica, and versicolor. So we want to take this multi-class problem and transform it into a binary classification.\nCreate a new column for the dataset called target. The value of target will be 1 if the row contains a setosa flower, else the value is 0. There should be \\(\\frac{1}{3}\\) rows with the value of 1, the rest should be 0."
  },
  {
    "objectID": "teaching/2023-2024/Machine Learning/lab-2.html#question-3",
    "href": "teaching/2023-2024/Machine Learning/lab-2.html#question-3",
    "title": "Evaluation of Models",
    "section": "Question 3",
    "text": "Question 3\nFor this question we want to take this dataset of 150 rows, and split it into a train, test, and validation dataset, using the following proportions for each split:\n\nTraining: 70%\nValidation: 10%\nTesting: 20%\n\nSample data for each subset using stratified sampling. I.e. the training data should have roughly \\(\\frac{1}{3}\\) positive samples, the testing and validation dataset should also have roughly \\(\\frac{1}{3}\\) positive samples."
  },
  {
    "objectID": "teaching/2023-2024/Machine Learning/lab-2.html#question-4",
    "href": "teaching/2023-2024/Machine Learning/lab-2.html#question-4",
    "title": "Evaluation of Models",
    "section": "Question 4",
    "text": "Question 4\nUsing the linear regression model you created in the previous lecture, transform it into a logistic regressor by applying the logistic function to the output of the model. The loss function for this model should be binary cross entropy.\nSelect two columns from the Iris dataset (i.e. petal length and petal width), and using these two columns, train a logistic regressor using gradient descent, measuring the gradient using finite differences approximation. This means that instead of having a single slope variable, we have multiple:\n\\[\n\\hat{y} = \\sigma(\\beta_0 + \\sum_{i=1}^m x_i \\beta_i)\n\\]\nwhere \\(\\hat{y}\\) is the model’s probability prediction, \\(\\sigma\\) is the logistic/sigmoid function, \\(\\beta_0\\) is the intercept, \\(\\beta_i\\) is the coefficient that modulates the \\(x_i\\) variable.\nI’ve made a start for you, please fill in the ‘#TODOs’:\nimport numpy as np\n\ndef bce(y, yhat):\n    # TODO: apply the binary cross entropy function returning the loss\n    return loss\n\nclass LogisticRegressor:\n    def __init__(self, n_features: int = 2):\n        self.params = np.random.randn(n_features + 1)\n\n    def logistic(self, x):\n        # TODO: apply the logistic function\n        return x\n\n    def __call__(self, x, logits=False):\n        y = self.params[0] + self.params[1:] @ x.T\n        if not logits:\n            y = self.logistic(y)\n        return y\n\n    def fit(train_x, train_y, valid_x, valid_y, epochs: int = 100, lr: float = 0.01):\n        # TODO: train the model using gradient descent and finite-differences\n        for epoch in range(1, epochs+1):\n            for xi, yi in zip(train_x, train_y):\n                # calculate loss and update model parameters using gradient descent\n            for xi, yi in zip(valid_x, valid_y):\n                # calculate validation loss (BUT DON'T UPDATE MODEL PARAMETERS!)\n\n    def predict(x, logits):\n        return self(x, logits=logits)"
  },
  {
    "objectID": "teaching/2023-2024/Machine Learning/lab-2.html#question-5",
    "href": "teaching/2023-2024/Machine Learning/lab-2.html#question-5",
    "title": "Evaluation of Models",
    "section": "Question 5",
    "text": "Question 5\nAs gradient descent is iterating, store (using class variables), the training and validation loss.\nVisualise the training and validation loss. Is there a point at which the model begins to over fit? How do you know that the model is beginning to overfit by looking at these curves?"
  },
  {
    "objectID": "teaching/2023-2024/Machine Learning/lab-2.html#question-6",
    "href": "teaching/2023-2024/Machine Learning/lab-2.html#question-6",
    "title": "Evaluation of Models",
    "section": "Question 6",
    "text": "Question 6\nPredict the class labels for the testing set.\nFor the testing set, calculate the:\n\nTP – number of true positives\nTN – number of true negatives\nFP – number of false positives\nFN – number of false negatives"
  },
  {
    "objectID": "teaching/2023-2024/Machine Learning/lab-2.html#question-7",
    "href": "teaching/2023-2024/Machine Learning/lab-2.html#question-7",
    "title": "Evaluation of Models",
    "section": "Question 7",
    "text": "Question 7\nCalculate the precision and recall and \\(F_1\\) score.\ndef precision(y, yhat):\n    # calculate the precision and return it\n    return\n\ndef recall(y, yhat):\n    # calculate the recall and return it\n    return\n\ndef f_beta(y, yhat, beta=1):\n    pr = precision(y, yhat)\n    rc = recall(y, yhat)\n    # calculate the f_beta score and return it\n    return\n\n\npr = precision(y, yhat&gt;=0.5)\nrc = recall(y, yhat&gt;=0.5)\n# ..."
  },
  {
    "objectID": "teaching/2023-2024/Machine Learning/lab-2.html#question-8",
    "href": "teaching/2023-2024/Machine Learning/lab-2.html#question-8",
    "title": "Evaluation of Models",
    "section": "Question 8",
    "text": "Question 8\nGenerate a report using the precision, recall and \\(F_1\\) and confusion matrix. The report should be printed like:\n    |        |          | Predicted |          |\n    |        |          |  Positive | Negative |\n    | Actual | Positive |         5 |        2 |\n    |        | Negative |         3 |        1 |\n    \n    - Precision: 0.6\n    - Recall: 0.6\n    - F_1 Score: 0.6\nReplacing the scores with the correct numbers."
  },
  {
    "objectID": "teaching/2023-2024/Machine Learning/lab-2.html#question-9",
    "href": "teaching/2023-2024/Machine Learning/lab-2.html#question-9",
    "title": "Evaluation of Models",
    "section": "Question 9",
    "text": "Question 9\nCalculate the true-positive and false positive rate, and from these values generate a ROC curve.\n    def roc(y, yhat, threshold_step=0.01):\n        # iteratively increase the threshold by threshold_step,\n        # calculating the TP and FP rate for each iteration. This function\n        # should return two lists, a list of TP rates, and a list of FP\n        # rates.\n        return tp, fp\n    \n    tp, fp = roc(y, yhat)\n    # visualise the ROC curve here"
  },
  {
    "objectID": "teaching/2023-2024/Machine Learning/lab-2.html#question-10",
    "href": "teaching/2023-2024/Machine Learning/lab-2.html#question-10",
    "title": "Evaluation of Models",
    "section": "Question 10",
    "text": "Question 10\nNow that you’ve created a logistic regressor for two features of the Iris dataset and have created some analytic results. Select another two columns (i.e. petal width and sepal length, or petal length and sepal width). Create a different logistic regressor using these new columns and create the same results as you did with questions 8 and 9.\nCompare these two models trained with different columns. Which model is best, and why do we know that it’s the best?"
  },
  {
    "objectID": "teaching/2023-2024/Machine Learning/lab-1-reveal.html#how-to-answer-the-questions",
    "href": "teaching/2023-2024/Machine Learning/lab-1-reveal.html#how-to-answer-the-questions",
    "title": "Linear Models",
    "section": "How to answer the questions",
    "text": "How to answer the questions\nIn these lab sessions we will implement what we’ve learn during the theory lectures. These implementation will need to be using the Python Programming Language. You’re allowed to use 3rd party libraries such as pandas, matplotlib, numpy. But it is not allowed to use a library that implements exactly machine learning model we’re learning about. For example, in this lab, we’re learning about linear models, so you cannot use a library that provides functionality for computing a linear model. If you’re uncertain about whether a library can be used, please do ask!\nI am going to give you the maximum flexibility with how you want to program these linear models: you can create a Python script, or if you like, you can use jupyter notebooks. In both cases, You should preface your implementation with which question you’re answering with a comment (if you’re writing a python script), or markdown (if you want to use jupyter) like this:\n# Q1. Download, parse, and load the data into a pandas dataframe,\n# print the first 5 rows to ensure the data is formated correctly\nimport pandas as pd\n\ndef load_data(filepath: str) -&gt; pd.DataFrame:\n    # load_data logic\n    return df\nYou are to work individually.\nIn summary:\n\nWork individually.\nImplementation should be using the Python programming language.\nYou can use supplementary libraries such as pandas, matplotlib, numpy, but cannot use a library that provides a function call for the assignment."
  },
  {
    "objectID": "teaching/2023-2024/Machine Learning/lab-1-reveal.html#submission-procedure",
    "href": "teaching/2023-2024/Machine Learning/lab-1-reveal.html#submission-procedure",
    "title": "Linear Models",
    "section": "Submission Procedure",
    "text": "Submission Procedure\nTo hand in your assignment, please zip all of your source code (do not include the data) into a zip-archive named using the following format:\n&lt;first-name&gt;-&lt;surname&gt;-machine-learning-lab-1.zip\nreplacing &lt;first-name&gt; and &lt;surname&gt; with your name. Please send this assignment to my email address: jay.morgan@univ-tln.fr using the subject Machine Learning Assignment 1 by the end of the lab session. I will accept late assignments, but will be deducted score accordingly."
  },
  {
    "objectID": "teaching/2023-2024/Machine Learning/lab-1-reveal.html#question-1",
    "href": "teaching/2023-2024/Machine Learning/lab-1-reveal.html#question-1",
    "title": "Linear Models",
    "section": "Question 1",
    "text": "Question 1\nTo start this lab session we want to setup our project. For this question, do the following:\n\nCreate a new directory for this lab.\nCreate a new conda environment.\nIn this new conda environment, install python, pandas, matplotlib, and numpy.\nExport this conda environment to an environment.yml into the root of the directory."
  },
  {
    "objectID": "teaching/2023-2024/Machine Learning/lab-1-reveal.html#question-2",
    "href": "teaching/2023-2024/Machine Learning/lab-1-reveal.html#question-2",
    "title": "Linear Models",
    "section": "Question 2",
    "text": "Question 2\nTo implement a linear regression model, we will be using a toy dataset to ensure we’ve implemented the model correctly. To begin with this lab, we will want to download the boston dataset from https://www.cs.toronto.edu/~delve/data/boston/bostonDetail.html. Download and save the dataset exactly as it is, and save it as a CSV.\nAfter we’ve downloaded the CSV file, we will want to parse and load the data into a pandas DataFrame.\nCreate a load_boston_data(filepath: str) -&gt; pd.DataFrame function.\nThis may require iterating through each line in the file until you read the data, at this point you will need to parse the data. Finally, return the data as a dataframe."
  },
  {
    "objectID": "teaching/2023-2024/Machine Learning/lab-1-reveal.html#question-3",
    "href": "teaching/2023-2024/Machine Learning/lab-1-reveal.html#question-3",
    "title": "Linear Models",
    "section": "Question 3",
    "text": "Question 3\nVisualise some scatter plots of the columns of your choice against the target house price column (i.e. the column of your choice will be on the x-axis, will house price will be the y-axis).\nDecide what you think will be the singular best column to use for using a linear model to predict the house price.\nWhat is this column?"
  },
  {
    "objectID": "teaching/2023-2024/Machine Learning/lab-1-reveal.html#question-4",
    "href": "teaching/2023-2024/Machine Learning/lab-1-reveal.html#question-4",
    "title": "Linear Models",
    "section": "Question 4",
    "text": "Question 4\nCreate a function called lm, that takes an x, and y, and returns the random m and b variables in the linear equation:\n\\[\ny = m x + b\n\\]\ndef lm(x, y) -&gt; tuple[float, float]:\n    # create random m, b\n    return m, b"
  },
  {
    "objectID": "teaching/2023-2024/Machine Learning/lab-1-reveal.html#question-5",
    "href": "teaching/2023-2024/Machine Learning/lab-1-reveal.html#question-5",
    "title": "Linear Models",
    "section": "Question 5",
    "text": "Question 5\nUsing these m, b variables, create a housing price prediction for each row of data."
  },
  {
    "objectID": "teaching/2023-2024/Machine Learning/lab-1-reveal.html#question-6",
    "href": "teaching/2023-2024/Machine Learning/lab-1-reveal.html#question-6",
    "title": "Linear Models",
    "section": "Question 6",
    "text": "Question 6\nCreate a function mae that calculate the mean absolute error of the true house price value and the predicted value. What is the error?\ndef mae(y, y_pred) -&gt; float:\n    # calculate the mean absolute error\n    return error"
  },
  {
    "objectID": "teaching/2023-2024/Machine Learning/lab-1-reveal.html#question-7",
    "href": "teaching/2023-2024/Machine Learning/lab-1-reveal.html#question-7",
    "title": "Linear Models",
    "section": "Question 7",
    "text": "Question 7\nVisualise the linear model returned from lm on top of the scatter plot of the input and target data."
  },
  {
    "objectID": "teaching/2023-2024/Machine Learning/lab-1-reveal.html#question-8",
    "href": "teaching/2023-2024/Machine Learning/lab-1-reveal.html#question-8",
    "title": "Linear Models",
    "section": "Question 8",
    "text": "Question 8\nRe-make the lm function. This time, when called with an x, y it returns the optimal m and b.\nYou are free to either implement least-squares regression, or the gradient descent method.\ndef lm(x, y) -&gt; tuple[float, float]:\n    # create the optimal values for m, b\n    return m, b"
  },
  {
    "objectID": "teaching/2023-2024/Machine Learning/lab-1-reveal.html#question-9",
    "href": "teaching/2023-2024/Machine Learning/lab-1-reveal.html#question-9",
    "title": "Linear Models",
    "section": "Question 9",
    "text": "Question 9\nRe-plot this linear model against the scatter plot."
  },
  {
    "objectID": "teaching/2023-2024/Machine Learning/lab-1-reveal.html#question-10",
    "href": "teaching/2023-2024/Machine Learning/lab-1-reveal.html#question-10",
    "title": "Linear Models",
    "section": "Question 10",
    "text": "Question 10\nRe-calculate the mean absolute error for these optimal m, b variables. What is the error now?"
  },
  {
    "objectID": "teaching/2023-2024/Machine Learning/lab-1.html",
    "href": "teaching/2023-2024/Machine Learning/lab-1.html",
    "title": "Linear Models",
    "section": "",
    "text": "Welcome to the first Machine Learning lab session! For this first session, we will be implementing and using linear models. In the following session we will be answering the questions below, of which will be marked using the marking criteria on the last page.\n\n\nIn these lab sessions we will implement what we’ve learn during the theory lectures. These implementation will need to be using the Python Programming Language. You’re allowed to use 3rd party libraries such as pandas, matplotlib, numpy. But it is not allowed to use a library that implements exactly machine learning model we’re learning about. For example, in this lab, we’re learning about linear models, so you cannot use a library that provides functionality for computing a linear model. If you’re uncertain about whether a library can be used, please do ask!\nI am going to give you the maximum flexibility with how you want to program these linear models: you can create a Python script, or if you like, you can use jupyter notebooks. In both cases, You should preface your implementation with which question you’re answering with a comment (if you’re writing a python script), or markdown (if you want to use jupyter) like this:\n# Q1. Download, parse, and load the data into a pandas dataframe,\n# print the first 5 rows to ensure the data is formated correctly\nimport pandas as pd\n\ndef load_data(filepath: str) -&gt; pd.DataFrame:\n    # load_data logic\n    return df\nYou are to work individually.\nIn summary:\n\nWork individually.\nImplementation should be using the Python programming language.\nYou can use supplementary libraries such as pandas, matplotlib, numpy, but cannot use a library that provides a function call for the assignment.\n\n\n\n\nTo hand in your assignment, please zip all of your source code (do not include the data) into a zip-archive named using the following format:\n&lt;first-name&gt;-&lt;surname&gt;-machine-learning-lab-1.zip\nreplacing &lt;first-name&gt; and &lt;surname&gt; with your name. Please send this assignment to my email address: jay.morgan@univ-tln.fr using the subject Machine Learning Assignment 1 by the end of the lab session. I will accept late assignments, but will be deducted score accordingly."
  },
  {
    "objectID": "teaching/2023-2024/Machine Learning/lab-1.html#how-to-answer-the-questions",
    "href": "teaching/2023-2024/Machine Learning/lab-1.html#how-to-answer-the-questions",
    "title": "Linear Models",
    "section": "",
    "text": "In these lab sessions we will implement what we’ve learn during the theory lectures. These implementation will need to be using the Python Programming Language. You’re allowed to use 3rd party libraries such as pandas, matplotlib, numpy. But it is not allowed to use a library that implements exactly machine learning model we’re learning about. For example, in this lab, we’re learning about linear models, so you cannot use a library that provides functionality for computing a linear model. If you’re uncertain about whether a library can be used, please do ask!\nI am going to give you the maximum flexibility with how you want to program these linear models: you can create a Python script, or if you like, you can use jupyter notebooks. In both cases, You should preface your implementation with which question you’re answering with a comment (if you’re writing a python script), or markdown (if you want to use jupyter) like this:\n# Q1. Download, parse, and load the data into a pandas dataframe,\n# print the first 5 rows to ensure the data is formated correctly\nimport pandas as pd\n\ndef load_data(filepath: str) -&gt; pd.DataFrame:\n    # load_data logic\n    return df\nYou are to work individually.\nIn summary:\n\nWork individually.\nImplementation should be using the Python programming language.\nYou can use supplementary libraries such as pandas, matplotlib, numpy, but cannot use a library that provides a function call for the assignment."
  },
  {
    "objectID": "teaching/2023-2024/Machine Learning/lab-1.html#submission-procedure",
    "href": "teaching/2023-2024/Machine Learning/lab-1.html#submission-procedure",
    "title": "Linear Models",
    "section": "",
    "text": "To hand in your assignment, please zip all of your source code (do not include the data) into a zip-archive named using the following format:\n&lt;first-name&gt;-&lt;surname&gt;-machine-learning-lab-1.zip\nreplacing &lt;first-name&gt; and &lt;surname&gt; with your name. Please send this assignment to my email address: jay.morgan@univ-tln.fr using the subject Machine Learning Assignment 1 by the end of the lab session. I will accept late assignments, but will be deducted score accordingly."
  },
  {
    "objectID": "teaching/2023-2024/Machine Learning/lab-1.html#question-1",
    "href": "teaching/2023-2024/Machine Learning/lab-1.html#question-1",
    "title": "Linear Models",
    "section": "Question 1",
    "text": "Question 1\nTo start this lab session we want to setup our project. For this question, do the following:\n\nCreate a new directory for this lab.\nCreate a new conda environment.\nIn this new conda environment, install python, pandas, matplotlib, and numpy.\nExport this conda environment to an environment.yml into the root of the directory."
  },
  {
    "objectID": "teaching/2023-2024/Machine Learning/lab-1.html#question-2",
    "href": "teaching/2023-2024/Machine Learning/lab-1.html#question-2",
    "title": "Linear Models",
    "section": "Question 2",
    "text": "Question 2\nTo implement a linear regression model, we will be using a toy dataset to ensure we’ve implemented the model correctly. To begin with this lab, we will want to download the boston dataset from https://www.cs.toronto.edu/~delve/data/boston/bostonDetail.html. Download and save the dataset exactly as it is, and save it as a CSV.\nAfter we’ve downloaded the CSV file, we will want to parse and load the data into a pandas DataFrame.\nCreate a load_boston_data(filepath: str) -&gt; pd.DataFrame function.\nThis may require iterating through each line in the file until you read the data, at this point you will need to parse the data. Finally, return the data as a dataframe."
  },
  {
    "objectID": "teaching/2023-2024/Machine Learning/lab-1.html#question-3",
    "href": "teaching/2023-2024/Machine Learning/lab-1.html#question-3",
    "title": "Linear Models",
    "section": "Question 3",
    "text": "Question 3\nVisualise some scatter plots of the columns of your choice against the target house price column (i.e. the column of your choice will be on the x-axis, will house price will be the y-axis).\nDecide what you think will be the singular best column to use for using a linear model to predict the house price.\nWhat is this column?"
  },
  {
    "objectID": "teaching/2023-2024/Machine Learning/lab-1.html#question-4",
    "href": "teaching/2023-2024/Machine Learning/lab-1.html#question-4",
    "title": "Linear Models",
    "section": "Question 4",
    "text": "Question 4\nCreate a function called lm, that takes an x, and y, and returns the random m and b variables in the linear equation:\n\\[\ny = m x + b\n\\]\ndef lm(x, y) -&gt; tuple[float, float]:\n    # create random m, b\n    return m, b"
  },
  {
    "objectID": "teaching/2023-2024/Machine Learning/lab-1.html#question-5",
    "href": "teaching/2023-2024/Machine Learning/lab-1.html#question-5",
    "title": "Linear Models",
    "section": "Question 5",
    "text": "Question 5\nUsing these m, b variables, create a housing price prediction for each row of data."
  },
  {
    "objectID": "teaching/2023-2024/Machine Learning/lab-1.html#question-6",
    "href": "teaching/2023-2024/Machine Learning/lab-1.html#question-6",
    "title": "Linear Models",
    "section": "Question 6",
    "text": "Question 6\nCreate a function mae that calculate the mean absolute error of the true house price value and the predicted value. What is the error?\ndef mae(y, y_pred) -&gt; float:\n    # calculate the mean absolute error\n    return error"
  },
  {
    "objectID": "teaching/2023-2024/Machine Learning/lab-1.html#question-7",
    "href": "teaching/2023-2024/Machine Learning/lab-1.html#question-7",
    "title": "Linear Models",
    "section": "Question 7",
    "text": "Question 7\nVisualise the linear model returned from lm on top of the scatter plot of the input and target data."
  },
  {
    "objectID": "teaching/2023-2024/Machine Learning/lab-1.html#question-8",
    "href": "teaching/2023-2024/Machine Learning/lab-1.html#question-8",
    "title": "Linear Models",
    "section": "Question 8",
    "text": "Question 8\nRe-make the lm function. This time, when called with an x, y it returns the optimal m and b.\nYou are free to either implement least-squares regression, or the gradient descent method.\ndef lm(x, y) -&gt; tuple[float, float]:\n    # create the optimal values for m, b\n    return m, b"
  },
  {
    "objectID": "teaching/2023-2024/Machine Learning/lab-1.html#question-9",
    "href": "teaching/2023-2024/Machine Learning/lab-1.html#question-9",
    "title": "Linear Models",
    "section": "Question 9",
    "text": "Question 9\nRe-plot this linear model against the scatter plot."
  },
  {
    "objectID": "teaching/2023-2024/Machine Learning/lab-1.html#question-10",
    "href": "teaching/2023-2024/Machine Learning/lab-1.html#question-10",
    "title": "Linear Models",
    "section": "Question 10",
    "text": "Question 10\nRe-calculate the mean absolute error for these optimal m, b variables. What is the error now?"
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-5-reveal.html#what-is-matplotlib",
    "href": "teaching/2023-2024/Programming Level-up/lecture-5-reveal.html#what-is-matplotlib",
    "title": "Introduction to Matplotlib",
    "section": "What is Matplotlib?",
    "text": "What is Matplotlib?\n\nIn summary:\n\nMatplotlib is one of the defacto plotting libraries for Python. While there are many others and certainly some that are built for specific plot types, Matplotlib continues to pervade scientific plotting.\nYou can create basic plots (such as line or scatter plots) to more complicated plots that include interactivity."
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-5-reveal.html#installing-and-importing-matplotlib",
    "href": "teaching/2023-2024/Programming Level-up/lecture-5-reveal.html#installing-and-importing-matplotlib",
    "title": "Introduction to Matplotlib",
    "section": "Installing and importing Matplotlib",
    "text": "Installing and importing Matplotlib\nMatplotlib can be installed via conda:\nconda install matplotlib\nor with pip:\npip install matplotlib\nRemember! You can install packages in ipython REPL/juypter notebook by inserting a ‘!’ to the beginning of a shell command."
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-5-reveal.html#basic-plotting",
    "href": "teaching/2023-2024/Programming Level-up/lecture-5-reveal.html#basic-plotting",
    "title": "Introduction to Matplotlib",
    "section": "Basic plotting",
    "text": "Basic plotting\nFirst, we will import the matplotlib module. The plotting function is located within the pyplot package within matplotlib. The use of this package is so common that 99% of Python users will alias this import as plt:\n\nimport matplotlib.pyplot as plt\n\nWith this package now imported, we can now use the plot function. To begin with, let’s just plot a simple line chart. In this case, the plot function takes an x and y argument, where x denotes the values along the x-axis and y are the values along the y-axis.\n\nimport numpy as np\nx = np.linspace(-10, 10, 100)\ny = np.sin(x)\nplt.plot(x, y)\nplt.show()\n\n\n\n\n\n\n\n\nIn this example, we have created two vectors. The first x, creates a vector of 100 values from -10 to 10. y is the sin function applied to x. Finally, in the third line, we plot the sin wave using these two vectors."
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-5-reveal.html#different-types-of-plots",
    "href": "teaching/2023-2024/Programming Level-up/lecture-5-reveal.html#different-types-of-plots",
    "title": "Introduction to Matplotlib",
    "section": "Different types of Plots",
    "text": "Different types of Plots\n\nThere are many different types of plots that one can make using matplotlib. These include the most popular:\n\nLine plots\nScatter plots\nBar plots\nHistograms\nBox plots\nImage plots\n\nWe’re going to take a look at how we create each type of plot, examining what type of inputs they require."
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-5-reveal.html#line-plots",
    "href": "teaching/2023-2024/Programming Level-up/lecture-5-reveal.html#line-plots",
    "title": "Introduction to Matplotlib",
    "section": "Line plots",
    "text": "Line plots\nWe’ve already seen one example of a line plot. This plot draws a line between each x,y point. For instance in the previous example, we created a sin wave by ‘sampling’ such wave using 100 samples from -10 to 10. Let’s see what happens when we sample only 10 points:\n\nx = np.linspace(-10, 10, 10)\ny = np.sin(x)\nplt.plot(x, y)\nplt.show()\n\n\n\n\n\n\n\n\nWe see the results are a less than ideal representation of a sin wave as plot will simply draw a straight line from each point."
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-5-reveal.html#scatter-plots",
    "href": "teaching/2023-2024/Programming Level-up/lecture-5-reveal.html#scatter-plots",
    "title": "Introduction to Matplotlib",
    "section": "Scatter plots",
    "text": "Scatter plots\nIf we want to see where each sample of the sin wave is, we could use instead the scatter plot, which will (by default) place a small circle at every x,y value. To create a scatter plot, we use scatter instead of the plot function. The arguments to this function are the same, however.\n\nx = np.linspace(-10, 10, 10)\ny = np.sin(x)\nplt.scatter(x, y)\nplt.show()\n\n\n\n\n\n\n\n\nNow we can see the position of each individual sample from the sin wave. If we, once again, sample 100 points from this curve, we will see better results.\n\n\nx = np.linspace(-10, 10, 100)\ny = np.sin(x)\nplt.scatter(x, y)\nplt.show()"
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-5-reveal.html#bar-plots",
    "href": "teaching/2023-2024/Programming Level-up/lecture-5-reveal.html#bar-plots",
    "title": "Introduction to Matplotlib",
    "section": "Bar plots",
    "text": "Bar plots\nBar plots are a simple plot that again takes an x and a y, where x is the numerical position of the bar’s centre, and y is the height of the bar.\n\nx = np.arange(0, 8)\ny = np.random.uniform(2, 7, len(x))\nplt.bar(x, y)\nplt.show()"
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-5-reveal.html#histograms",
    "href": "teaching/2023-2024/Programming Level-up/lecture-5-reveal.html#histograms",
    "title": "Introduction to Matplotlib",
    "section": "Histograms",
    "text": "Histograms\nHistograms allow us to visualise the distribution of values. In matplotlib, we can create a histogram of a vector by using the hist function that takes only the vector as its argument.\n\nx = np.random.randn(1000)\nplt.hist(x)\nplt.show()"
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-5-reveal.html#box-plots",
    "href": "teaching/2023-2024/Programming Level-up/lecture-5-reveal.html#box-plots",
    "title": "Introduction to Matplotlib",
    "section": "Box plots",
    "text": "Box plots\nBox plots also allow us to visualise the distribution, but the distribution of values within a group. In this example we’re visualising the distribution of 3 groups. Using the boxplot function, we pass a matrix.\n\nx = np.random.randn(10, 3)\nplt.boxplot(x)\nplt.show()"
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-5-reveal.html#image-plots",
    "href": "teaching/2023-2024/Programming Level-up/lecture-5-reveal.html#image-plots",
    "title": "Introduction to Matplotlib",
    "section": "Image plots",
    "text": "Image plots\nIn matplotlib, we can plot an ‘image’ – that is a 2D matrix – using the imshow function. For example:\n\nfig = plt.figure()\nx = np.random.randn(10, 10)\nplt.imshow(x)\nplt.show()\n\n\n\n\n\n\n\n\n\nOf course, given the name, we can then use imshow to plot an image as well, as long as we have the image loaded as a 2D array of values.\n\nfrom PIL import Image  # using the PIL module to read an image\nimg = np.array(Image.open(\"images/Lenna.png\"))\nplt.imshow(img)\nplt.show()"
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-5-reveal.html#dimensional-plots",
    "href": "teaching/2023-2024/Programming Level-up/lecture-5-reveal.html#dimensional-plots",
    "title": "Introduction to Matplotlib",
    "section": "3 dimensional plots",
    "text": "3 dimensional plots\n3 dimensional plots require us to import another module from matplotlib.\n\nfrom mpl_toolkits import mplot3d\n\nAfter importing this module, we can using the projection=“3d” and carry on plotting as normal.\n\nfig = plt.figure()\n# older matplotlib\n# ax = fig.gca(projection='3d')\n# newest version\nax = fig.add_subplot(projection='3d')\ntheta = np.linspace(-4 * np.pi, 4 * np.pi, 100)\nz = np.linspace(-2, 2, 100)\nr = z**2 + 1\nx = r * np.sin(theta)\ny = r * np.cos(theta)\nax.plot(x, y, z, label='parametric curve')\nax.legend()\nplt.show()"
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-5-reveal.html#other-types-of-plots",
    "href": "teaching/2023-2024/Programming Level-up/lecture-5-reveal.html#other-types-of-plots",
    "title": "Introduction to Matplotlib",
    "section": "Other types of Plots",
    "text": "Other types of Plots\nThere are many more different types of plots you can make using matplotlib. You can find a comprehensive list at:\nhttps://matplotlib.org/stable/plot_types/index.html"
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-5-reveal.html#subplots",
    "href": "teaching/2023-2024/Programming Level-up/lecture-5-reveal.html#subplots",
    "title": "Introduction to Matplotlib",
    "section": "Subplots",
    "text": "Subplots\nWhat if we wanted to create many plots side-by-side? For this we can use the subplots function. This function takes the number of rows, and number of columns to create. It returns two values, the first is the figure (entire figure), and the second value is a list of sub figures. Using this list, we can place a plot of each of them.\n\nx = np.linspace(-10, 10, 100)\ny = np.sin(x)\nz = np.cos(y)\n\nfig, ax = plt.subplots(1, 2)\n# ax is a list of sub figures\nax[0].plot(x, y)\nax[1].plot(x, z)\nplt.show()"
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-5-reveal.html#adding-a-legend",
    "href": "teaching/2023-2024/Programming Level-up/lecture-5-reveal.html#adding-a-legend",
    "title": "Introduction to Matplotlib",
    "section": "Adding a legend",
    "text": "Adding a legend\nOr we could put them onto the same plot. Matplotlib will automatically give them a different colour. If we use the label argument to plot, we can also give them a name that will appear when we call legend().\n\nx = np.linspace(-10, 10, 100)\ny = np.sin(x)\nz = np.tan(y)\nfig, ax = plt.subplots()\nax.plot(x, y, label=\"sin(x)\")\nax.plot(x, z, label=\"tan(x)\")\nax.legend()\nplt.show()"
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-5-reveal.html#position-the-legend-in-different-places",
    "href": "teaching/2023-2024/Programming Level-up/lecture-5-reveal.html#position-the-legend-in-different-places",
    "title": "Introduction to Matplotlib",
    "section": "Position the legend in different places",
    "text": "Position the legend in different places\nWe can change the position of the legend by specifying a different integer value for the loc argument (or string values such as ‘upper left’, ‘upper right’, …). Additionally, we can change the number of columns the legend has with the ncol argument.\n\nx = np.linspace(-10, 10, 100)\ny = np.sin(x)\nz = np.tan(y)\n\nfig, ax = plt.subplots()\nax.plot(x, y, label=\"sin(x)\")\nax.plot(x, z, label=\"tan(x)\")\nax.legend(loc=1, ncol=2)\nplt.show()\n\n\n\n\n\n\n\n\nYou can find the API reference for the different arguments to legend at: https://matplotlib.org/stable/api/legend_api.html?highlight=legend#module-matplotlib.legend"
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-5-reveal.html#modifying-the-xy-axis",
    "href": "teaching/2023-2024/Programming Level-up/lecture-5-reveal.html#modifying-the-xy-axis",
    "title": "Introduction to Matplotlib",
    "section": "Modifying the x/y axis",
    "text": "Modifying the x/y axis\nGood graphs always have their axis’s labelled. To do this in matplotlib, if we have a subplot object, we use set_xlabel, or we can use plt.xlabel(...). Here is an example with an subplot object:\n\nx = np.linspace(-10, 10, 100)\ny = np.sin(x)\nz = np.tan(y)\n\nfig, ax = plt.subplots()\nax.plot(x, y, label=\"sin(x)\")\nax.plot(x, z, label=\"tan(x)\")\nax.legend(loc=1, ncol=2)\nax.set_xlabel(\"x\")\nax.set_ylabel(\"y\")\nplt.show()"
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-5-reveal.html#changing-figure-size",
    "href": "teaching/2023-2024/Programming Level-up/lecture-5-reveal.html#changing-figure-size",
    "title": "Introduction to Matplotlib",
    "section": "Changing figure size",
    "text": "Changing figure size\nA common change you may want to make to your figure is to change its size or aspect ratio. figure() or subplots() take an optional argument called figsize. This argument expects a tuple representing the width and height of the figure in inches.\n\nfig = plt.figure(figsize=(8, 2.5))\n\n# or most likely\nfig, ax = plt.subplots(figsize=(8, 2.5))\nx = np.linspace(-10, 10, 100)\ny = np.sin(x)\nz = np.tan(y)\nax.plot(x, y, label=\"sin(x)\")\nax.plot(x, z, label=\"tan(x)\")\nax.legend(loc=1, ncol=2)\nax.set_xlabel(\"x\")\nax.set_ylabel(\"y\")\nplt.show()\n\n&lt;Figure size 768x240 with 0 Axes&gt;\n\n\n\n\n\n\n\n\n\nHere we are creating a figure with 8 inches of width, and 2.5 inches of height.\n\nThis is especially useful when you have many sub-figures, as by default, they will be ‘squashed’ into the default aspect ratio. We can ‘give them more space’ by modifying this figsize argument when creating the many sub-figures.\n\nfig, ax = plt.subplots(1, 2, figsize=(8, 2.5))\nx = np.linspace(-10, 10, 100)\ny = np.sin(x)\nz = np.tan(y)\nax[0].plot(x, y, label=\"sin(x)\")\nax[1].plot(x, z, label=\"tan(x)\")\nplt.show()"
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-5-reveal.html#line-properties",
    "href": "teaching/2023-2024/Programming Level-up/lecture-5-reveal.html#line-properties",
    "title": "Introduction to Matplotlib",
    "section": "Line properties",
    "text": "Line properties\nWhen creating a plot, there are many different properties you can change. Some of these include:\n\ncolor – the colour of the line\nalpha – the amount of transparency (1.0 is opaque, 0.0 is transparent)\nlinewidth, lw – the width of the stroke width\nlinestyle, ls – the style of the line (i.e. a dotted line)\n\nThere are also some properties for the markers, i.e. the circles in the scatter plot. These properties are:\n\nmarker – the type of marker (you can use different shapes instead of a circle\nmarkersize – the size of the mark\nmarkerfacecolor – colour of the marker\nmarkeredgewidth – outline width of the marker.\n\nIf this example we are modifying some of the line properties that include the color (c), setting it to a string value of “green”. The linewidth (lw) to be thicker, and making the line to be a dotted line by specifying the linestyle (ls) to “=–={”.\n\nfig = plt.figure()\nx = np.linspace(-5, 5, 100)\ny = np.sin(x)\nplt.plot(x, y,\n         c=\"green\", # or color\n         lw=3, # or linewidth\n         ls=\"--\")\nplt.show()"
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-5-reveal.html#colourmaps",
    "href": "teaching/2023-2024/Programming Level-up/lecture-5-reveal.html#colourmaps",
    "title": "Introduction to Matplotlib",
    "section": "Colourmaps",
    "text": "Colourmaps\nWhen we create a heatmap using imshow, the gradients of colour are automatically set. Yet, we can control the colour gradient using a colour map. First we must import cm from matplotlib:\n\nfrom matplotlib import cm\n\nThen we can get a colour map with 10 levels using get_cmap:\n\nblues = cm.get_cmap(\"Blues\", 10) # 10 levels\nreds = cm.get_cmap(\"Reds\", 2) # 2 levels\n\n/var/folders/fk/z5hmt4c13pv884phdfytrwsh0000gn/T/ipykernel_29774/226750876.py:1: MatplotlibDeprecationWarning: The get_cmap function was deprecated in Matplotlib 3.7 and will be removed in 3.11. Use ``matplotlib.colormaps[name]`` or ``matplotlib.colormaps.get_cmap()`` or ``pyplot.get_cmap()`` instead.\n  blues = cm.get_cmap(\"Blues\", 10) # 10 levels\n/var/folders/fk/z5hmt4c13pv884phdfytrwsh0000gn/T/ipykernel_29774/226750876.py:2: MatplotlibDeprecationWarning: The get_cmap function was deprecated in Matplotlib 3.7 and will be removed in 3.11. Use ``matplotlib.colormaps[name]`` or ``matplotlib.colormaps.get_cmap()`` or ``pyplot.get_cmap()`` instead.\n  reds = cm.get_cmap(\"Reds\", 2) # 2 levels\n\n\nYou can find a full list of different colour maps at: https://matplotlib.org/stable/tutorials/colors/colormaps.html\nNow that we have our new colour maps, we can pass it as an cmap argument when we create a plot.\n\nx = np.random.randn(10, 10)\ny = np.random.randn(10, 10)\nfig, ax = plt.subplots(1, 2, figsize=(8, 3))\np1 = ax[0].imshow(x, cmap=blues)\np2 = ax[1].imshow(y, cmap=reds)\nfig.colorbar(p1, ax=ax[0])\nfig.colorbar(p2, ax=ax[1])\nplt.show()"
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-5-reveal.html#ticks",
    "href": "teaching/2023-2024/Programming Level-up/lecture-5-reveal.html#ticks",
    "title": "Introduction to Matplotlib",
    "section": "Ticks",
    "text": "Ticks\nIf we want to customise the numbers along each axis, we use the set_xticks for the x-axis and set_yticks for the y-axis. These functions take the list of locations for each ‘tick’, and optionally a list of labels to use instead of the numbers.\n\nx = np.linspace(-2, 2, 100)\ny = np.sin(x)\n\nbx = np.arange(2, 7)\nby = np.random.uniform(2, 7, len(bx))\n\nfig, ax = plt.subplots(1, 2, figsize=(8, 3))\nax[0].plot(x, y)\nax[0].set_xticks([-2, 0, 2])\nax[1].bar(bx, by)\nax[1].set_xticks(bx, [\"a\", \"b\", \"c\", \"d\", \"e\"])\nplt.show()"
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-5-reveal.html#grids",
    "href": "teaching/2023-2024/Programming Level-up/lecture-5-reveal.html#grids",
    "title": "Introduction to Matplotlib",
    "section": "Grids",
    "text": "Grids\nIn all of the previous plots, the background has no grids, they are simply white. If we wanted to add grid lines to the plot we use the .grid() method. This function, by default, adds the major grid lines.\n\nx = np.linspace(-2, 2, 100)\ny = np.sin(x)\nz = np.tan(x)\nfig, ax = plt.subplots(1, 2, figsize=(8, 3))\nax[0].plot(x, y)\nax[0].grid()\nax[1].plot(x, z)\nax[1].grid(which=\"both\", color=\"r\")\nplt.show()"
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-5-reveal.html#scale",
    "href": "teaching/2023-2024/Programming Level-up/lecture-5-reveal.html#scale",
    "title": "Introduction to Matplotlib",
    "section": "Scale",
    "text": "Scale\nThe default behaviour of matplotlib is to plot using a linear scale. In certain situations, we want view the plot using a different scale. For this we can use set_yscale.\n\nx = np.linspace(-2, 10, 100)\ny = np.exp(x)\nfig, ax = plt.subplots(1, 2, figsize=(8, 3))\nax[0].plot(x, y)\nax[0].grid()\nax[1].plot(x, y)\nax[1].set_yscale('log')\nax[1].grid()\nplt.show()"
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-5-reveal.html#setting-the-plot-limits",
    "href": "teaching/2023-2024/Programming Level-up/lecture-5-reveal.html#setting-the-plot-limits",
    "title": "Introduction to Matplotlib",
    "section": "Setting the plot limits",
    "text": "Setting the plot limits\nBy default, matplotlib will calculate the minimum and maximum values of the data, and use those values to set the limits of the plot. Using set_xlim and set_ylim we can change this default behaviour.\n\nx = np.linspace(-2, 2, 100)\ny = np.sin(x)\nfig, ax = plt.subplots(1, 2, figsize=(8,3))\nax[0].plot(x, y)\nax[0].set_ylim(-1, 2)\nax[1].plot(x, y)\nax[1].set_xlim(-3, 3)\nplt.show()"
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-5-reveal.html#annotations",
    "href": "teaching/2023-2024/Programming Level-up/lecture-5-reveal.html#annotations",
    "title": "Introduction to Matplotlib",
    "section": "Annotations",
    "text": "Annotations\nWe can annotate our plot in a number of way:\n\n.axhline – plot a horizontal line (axvline for vertical lines)/\n.annotate – add text to the plot at a certain position.\n\n\nx = np.linspace(-2, 2, 100)\ny = np.sin(x)\nfig, ax = plt.subplots()\nax.plot(x, y)\nax.axhline(0, c='gray', ls='--')\nax.annotate(\"0th line\", \n            (-2, 0), \n            xytext=(-1.5, 0.25),\n            arrowprops=dict(\n                facecolor='black', \n                shrink=0.05,\n                width=0.5, \n                headwidth=5.0))\nplt.show()"
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-5-reveal.html#creating-a-twin-axes-plot",
    "href": "teaching/2023-2024/Programming Level-up/lecture-5-reveal.html#creating-a-twin-axes-plot",
    "title": "Introduction to Matplotlib",
    "section": "Creating a twin axes plot",
    "text": "Creating a twin axes plot\nSometimes you will want to display multiple sub-plots on the same plot, but where each have a very different range in values. Instead of having a single y-axis, with twinx() we can create a two y-axis plot.\n\nx = np.arange(10, 100)\ny = np.exp(x)\nz = np.log(x)\n\nfig, ax = plt.subplots(1, 2)\nax[0].plot(x, y, label=\"exp(x)\")\nax[0].plot(x, z, label=\"log(x)\")\nax[0].legend()\n\nax2 = ax[1].twinx()\nax[1].plot(x, y)\nax2.plot(x, z, color=\"orange\")\nax2.tick_params(axis=\"y\", labelcolor=\"orange\")\nplt.show()"
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-5.html",
    "href": "teaching/2023-2024/Programming Level-up/lecture-5.html",
    "title": "Introduction to Matplotlib",
    "section": "",
    "text": "In summary:\n\nMatplotlib is one of the defacto plotting libraries for Python. While there are many others and certainly some that are built for specific plot types, Matplotlib continues to pervade scientific plotting.\nYou can create basic plots (such as line or scatter plots) to more complicated plots that include interactivity.\n\n\n\n\nMatplotlib can be installed via conda:\nconda install matplotlib\nor with pip:\npip install matplotlib\nRemember! You can install packages in ipython REPL/juypter notebook by inserting a ‘!’ to the beginning of a shell command.\n\n\n\nFirst, we will import the matplotlib module. The plotting function is located within the pyplot package within matplotlib. The use of this package is so common that 99% of Python users will alias this import as plt:\n\nimport matplotlib.pyplot as plt\n\nWith this package now imported, we can now use the plot function. To begin with, let’s just plot a simple line chart. In this case, the plot function takes an x and y argument, where x denotes the values along the x-axis and y are the values along the y-axis.\n\nimport numpy as np\nx = np.linspace(-10, 10, 100)\ny = np.sin(x)\nplt.plot(x, y)\nplt.show()\n\n\n\n\n\n\n\n\nIn this example, we have created two vectors. The first x, creates a vector of 100 values from -10 to 10. y is the sin function applied to x. Finally, in the third line, we plot the sin wave using these two vectors."
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-5.html#what-is-matplotlib",
    "href": "teaching/2023-2024/Programming Level-up/lecture-5.html#what-is-matplotlib",
    "title": "Introduction to Matplotlib",
    "section": "",
    "text": "In summary:\n\nMatplotlib is one of the defacto plotting libraries for Python. While there are many others and certainly some that are built for specific plot types, Matplotlib continues to pervade scientific plotting.\nYou can create basic plots (such as line or scatter plots) to more complicated plots that include interactivity."
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-5.html#installing-and-importing-matplotlib",
    "href": "teaching/2023-2024/Programming Level-up/lecture-5.html#installing-and-importing-matplotlib",
    "title": "Introduction to Matplotlib",
    "section": "",
    "text": "Matplotlib can be installed via conda:\nconda install matplotlib\nor with pip:\npip install matplotlib\nRemember! You can install packages in ipython REPL/juypter notebook by inserting a ‘!’ to the beginning of a shell command."
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-5.html#basic-plotting",
    "href": "teaching/2023-2024/Programming Level-up/lecture-5.html#basic-plotting",
    "title": "Introduction to Matplotlib",
    "section": "",
    "text": "First, we will import the matplotlib module. The plotting function is located within the pyplot package within matplotlib. The use of this package is so common that 99% of Python users will alias this import as plt:\n\nimport matplotlib.pyplot as plt\n\nWith this package now imported, we can now use the plot function. To begin with, let’s just plot a simple line chart. In this case, the plot function takes an x and y argument, where x denotes the values along the x-axis and y are the values along the y-axis.\n\nimport numpy as np\nx = np.linspace(-10, 10, 100)\ny = np.sin(x)\nplt.plot(x, y)\nplt.show()\n\n\n\n\n\n\n\n\nIn this example, we have created two vectors. The first x, creates a vector of 100 values from -10 to 10. y is the sin function applied to x. Finally, in the third line, we plot the sin wave using these two vectors."
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-5.html#different-types-of-plots",
    "href": "teaching/2023-2024/Programming Level-up/lecture-5.html#different-types-of-plots",
    "title": "Introduction to Matplotlib",
    "section": "Different types of Plots",
    "text": "Different types of Plots\n\nThere are many different types of plots that one can make using matplotlib. These include the most popular:\n\nLine plots\nScatter plots\nBar plots\nHistograms\nBox plots\nImage plots\n\nWe’re going to take a look at how we create each type of plot, examining what type of inputs they require."
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-5.html#line-plots",
    "href": "teaching/2023-2024/Programming Level-up/lecture-5.html#line-plots",
    "title": "Introduction to Matplotlib",
    "section": "Line plots",
    "text": "Line plots\nWe’ve already seen one example of a line plot. This plot draws a line between each x,y point. For instance in the previous example, we created a sin wave by ‘sampling’ such wave using 100 samples from -10 to 10. Let’s see what happens when we sample only 10 points:\n\nx = np.linspace(-10, 10, 10)\ny = np.sin(x)\nplt.plot(x, y)\nplt.show()\n\n\n\n\n\n\n\n\nWe see the results are a less than ideal representation of a sin wave as plot will simply draw a straight line from each point."
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-5.html#scatter-plots",
    "href": "teaching/2023-2024/Programming Level-up/lecture-5.html#scatter-plots",
    "title": "Introduction to Matplotlib",
    "section": "Scatter plots",
    "text": "Scatter plots\nIf we want to see where each sample of the sin wave is, we could use instead the scatter plot, which will (by default) place a small circle at every x,y value. To create a scatter plot, we use scatter instead of the plot function. The arguments to this function are the same, however.\n\nx = np.linspace(-10, 10, 10)\ny = np.sin(x)\nplt.scatter(x, y)\nplt.show()\n\n\n\n\n\n\n\n\nNow we can see the position of each individual sample from the sin wave. If we, once again, sample 100 points from this curve, we will see better results.\n\n\nx = np.linspace(-10, 10, 100)\ny = np.sin(x)\nplt.scatter(x, y)\nplt.show()"
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-5.html#bar-plots",
    "href": "teaching/2023-2024/Programming Level-up/lecture-5.html#bar-plots",
    "title": "Introduction to Matplotlib",
    "section": "Bar plots",
    "text": "Bar plots\nBar plots are a simple plot that again takes an x and a y, where x is the numerical position of the bar’s centre, and y is the height of the bar.\n\nx = np.arange(0, 8)\ny = np.random.uniform(2, 7, len(x))\nplt.bar(x, y)\nplt.show()"
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-5.html#histograms",
    "href": "teaching/2023-2024/Programming Level-up/lecture-5.html#histograms",
    "title": "Introduction to Matplotlib",
    "section": "Histograms",
    "text": "Histograms\nHistograms allow us to visualise the distribution of values. In matplotlib, we can create a histogram of a vector by using the hist function that takes only the vector as its argument.\n\nx = np.random.randn(1000)\nplt.hist(x)\nplt.show()"
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-5.html#box-plots",
    "href": "teaching/2023-2024/Programming Level-up/lecture-5.html#box-plots",
    "title": "Introduction to Matplotlib",
    "section": "Box plots",
    "text": "Box plots\nBox plots also allow us to visualise the distribution, but the distribution of values within a group. In this example we’re visualising the distribution of 3 groups. Using the boxplot function, we pass a matrix.\n\nx = np.random.randn(10, 3)\nplt.boxplot(x)\nplt.show()"
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-5.html#image-plots",
    "href": "teaching/2023-2024/Programming Level-up/lecture-5.html#image-plots",
    "title": "Introduction to Matplotlib",
    "section": "Image plots",
    "text": "Image plots\nIn matplotlib, we can plot an ‘image’ – that is a 2D matrix – using the imshow function. For example:\n\nfig = plt.figure()\nx = np.random.randn(10, 10)\nplt.imshow(x)\nplt.show()\n\n\n\n\n\n\n\n\n\nOf course, given the name, we can then use imshow to plot an image as well, as long as we have the image loaded as a 2D array of values.\n\nfrom PIL import Image  # using the PIL module to read an image\nimg = np.array(Image.open(\"images/Lenna.png\"))\nplt.imshow(img)\nplt.show()"
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-5.html#dimensional-plots",
    "href": "teaching/2023-2024/Programming Level-up/lecture-5.html#dimensional-plots",
    "title": "Introduction to Matplotlib",
    "section": "3 dimensional plots",
    "text": "3 dimensional plots\n3 dimensional plots require us to import another module from matplotlib.\n\nfrom mpl_toolkits import mplot3d\n\nAfter importing this module, we can using the projection=“3d” and carry on plotting as normal.\n\nfig = plt.figure()\n# older matplotlib\n# ax = fig.gca(projection='3d')\n# newest version\nax = fig.add_subplot(projection='3d')\ntheta = np.linspace(-4 * np.pi, 4 * np.pi, 100)\nz = np.linspace(-2, 2, 100)\nr = z**2 + 1\nx = r * np.sin(theta)\ny = r * np.cos(theta)\nax.plot(x, y, z, label='parametric curve')\nax.legend()\nplt.show()"
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-5.html#other-types-of-plots",
    "href": "teaching/2023-2024/Programming Level-up/lecture-5.html#other-types-of-plots",
    "title": "Introduction to Matplotlib",
    "section": "Other types of Plots",
    "text": "Other types of Plots\nThere are many more different types of plots you can make using matplotlib. You can find a comprehensive list at:\nhttps://matplotlib.org/stable/plot_types/index.html"
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-5.html#subplots",
    "href": "teaching/2023-2024/Programming Level-up/lecture-5.html#subplots",
    "title": "Introduction to Matplotlib",
    "section": "Subplots",
    "text": "Subplots\nWhat if we wanted to create many plots side-by-side? For this we can use the subplots function. This function takes the number of rows, and number of columns to create. It returns two values, the first is the figure (entire figure), and the second value is a list of sub figures. Using this list, we can place a plot of each of them.\n\nx = np.linspace(-10, 10, 100)\ny = np.sin(x)\nz = np.cos(y)\n\nfig, ax = plt.subplots(1, 2)\n# ax is a list of sub figures\nax[0].plot(x, y)\nax[1].plot(x, z)\nplt.show()"
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-5.html#adding-a-legend",
    "href": "teaching/2023-2024/Programming Level-up/lecture-5.html#adding-a-legend",
    "title": "Introduction to Matplotlib",
    "section": "Adding a legend",
    "text": "Adding a legend\nOr we could put them onto the same plot. Matplotlib will automatically give them a different colour. If we use the label argument to plot, we can also give them a name that will appear when we call legend().\n\nx = np.linspace(-10, 10, 100)\ny = np.sin(x)\nz = np.tan(y)\nfig, ax = plt.subplots()\nax.plot(x, y, label=\"sin(x)\")\nax.plot(x, z, label=\"tan(x)\")\nax.legend()\nplt.show()"
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-5.html#position-the-legend-in-different-places",
    "href": "teaching/2023-2024/Programming Level-up/lecture-5.html#position-the-legend-in-different-places",
    "title": "Introduction to Matplotlib",
    "section": "Position the legend in different places",
    "text": "Position the legend in different places\nWe can change the position of the legend by specifying a different integer value for the loc argument (or string values such as ‘upper left’, ‘upper right’, …). Additionally, we can change the number of columns the legend has with the ncol argument.\n\nx = np.linspace(-10, 10, 100)\ny = np.sin(x)\nz = np.tan(y)\n\nfig, ax = plt.subplots()\nax.plot(x, y, label=\"sin(x)\")\nax.plot(x, z, label=\"tan(x)\")\nax.legend(loc=1, ncol=2)\nplt.show()\n\n\n\n\n\n\n\n\nYou can find the API reference for the different arguments to legend at: https://matplotlib.org/stable/api/legend_api.html?highlight=legend#module-matplotlib.legend"
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-5.html#modifying-the-xy-axis",
    "href": "teaching/2023-2024/Programming Level-up/lecture-5.html#modifying-the-xy-axis",
    "title": "Introduction to Matplotlib",
    "section": "Modifying the x/y axis",
    "text": "Modifying the x/y axis\nGood graphs always have their axis’s labelled. To do this in matplotlib, if we have a subplot object, we use set_xlabel, or we can use plt.xlabel(...). Here is an example with an subplot object:\n\nx = np.linspace(-10, 10, 100)\ny = np.sin(x)\nz = np.tan(y)\n\nfig, ax = plt.subplots()\nax.plot(x, y, label=\"sin(x)\")\nax.plot(x, z, label=\"tan(x)\")\nax.legend(loc=1, ncol=2)\nax.set_xlabel(\"x\")\nax.set_ylabel(\"y\")\nplt.show()"
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-5.html#changing-figure-size",
    "href": "teaching/2023-2024/Programming Level-up/lecture-5.html#changing-figure-size",
    "title": "Introduction to Matplotlib",
    "section": "Changing figure size",
    "text": "Changing figure size\nA common change you may want to make to your figure is to change its size or aspect ratio. figure() or subplots() take an optional argument called figsize. This argument expects a tuple representing the width and height of the figure in inches.\n\nfig = plt.figure(figsize=(8, 2.5))\n\n# or most likely\nfig, ax = plt.subplots(figsize=(8, 2.5))\nx = np.linspace(-10, 10, 100)\ny = np.sin(x)\nz = np.tan(y)\nax.plot(x, y, label=\"sin(x)\")\nax.plot(x, z, label=\"tan(x)\")\nax.legend(loc=1, ncol=2)\nax.set_xlabel(\"x\")\nax.set_ylabel(\"y\")\nplt.show()\n\n&lt;Figure size 768x240 with 0 Axes&gt;\n\n\n\n\n\n\n\n\n\nHere we are creating a figure with 8 inches of width, and 2.5 inches of height.\n\nThis is especially useful when you have many sub-figures, as by default, they will be ‘squashed’ into the default aspect ratio. We can ‘give them more space’ by modifying this figsize argument when creating the many sub-figures.\n\nfig, ax = plt.subplots(1, 2, figsize=(8, 2.5))\nx = np.linspace(-10, 10, 100)\ny = np.sin(x)\nz = np.tan(y)\nax[0].plot(x, y, label=\"sin(x)\")\nax[1].plot(x, z, label=\"tan(x)\")\nplt.show()"
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-5.html#line-properties",
    "href": "teaching/2023-2024/Programming Level-up/lecture-5.html#line-properties",
    "title": "Introduction to Matplotlib",
    "section": "Line properties",
    "text": "Line properties\nWhen creating a plot, there are many different properties you can change. Some of these include:\n\ncolor – the colour of the line\nalpha – the amount of transparency (1.0 is opaque, 0.0 is transparent)\nlinewidth, lw – the width of the stroke width\nlinestyle, ls – the style of the line (i.e. a dotted line)\n\nThere are also some properties for the markers, i.e. the circles in the scatter plot. These properties are:\n\nmarker – the type of marker (you can use different shapes instead of a circle\nmarkersize – the size of the mark\nmarkerfacecolor – colour of the marker\nmarkeredgewidth – outline width of the marker.\n\nIf this example we are modifying some of the line properties that include the color (c), setting it to a string value of “green”. The linewidth (lw) to be thicker, and making the line to be a dotted line by specifying the linestyle (ls) to “=–={”.\n\nfig = plt.figure()\nx = np.linspace(-5, 5, 100)\ny = np.sin(x)\nplt.plot(x, y,\n         c=\"green\", # or color\n         lw=3, # or linewidth\n         ls=\"--\")\nplt.show()"
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-5.html#colourmaps",
    "href": "teaching/2023-2024/Programming Level-up/lecture-5.html#colourmaps",
    "title": "Introduction to Matplotlib",
    "section": "Colourmaps",
    "text": "Colourmaps\nWhen we create a heatmap using imshow, the gradients of colour are automatically set. Yet, we can control the colour gradient using a colour map. First we must import cm from matplotlib:\n\nfrom matplotlib import cm\n\nThen we can get a colour map with 10 levels using get_cmap:\n\nblues = cm.get_cmap(\"Blues\", 10) # 10 levels\nreds = cm.get_cmap(\"Reds\", 2) # 2 levels\n\n/var/folders/fk/z5hmt4c13pv884phdfytrwsh0000gn/T/ipykernel_29774/226750876.py:1: MatplotlibDeprecationWarning: The get_cmap function was deprecated in Matplotlib 3.7 and will be removed in 3.11. Use ``matplotlib.colormaps[name]`` or ``matplotlib.colormaps.get_cmap()`` or ``pyplot.get_cmap()`` instead.\n  blues = cm.get_cmap(\"Blues\", 10) # 10 levels\n/var/folders/fk/z5hmt4c13pv884phdfytrwsh0000gn/T/ipykernel_29774/226750876.py:2: MatplotlibDeprecationWarning: The get_cmap function was deprecated in Matplotlib 3.7 and will be removed in 3.11. Use ``matplotlib.colormaps[name]`` or ``matplotlib.colormaps.get_cmap()`` or ``pyplot.get_cmap()`` instead.\n  reds = cm.get_cmap(\"Reds\", 2) # 2 levels\n\n\nYou can find a full list of different colour maps at: https://matplotlib.org/stable/tutorials/colors/colormaps.html\nNow that we have our new colour maps, we can pass it as an cmap argument when we create a plot.\n\nx = np.random.randn(10, 10)\ny = np.random.randn(10, 10)\nfig, ax = plt.subplots(1, 2, figsize=(8, 3))\np1 = ax[0].imshow(x, cmap=blues)\np2 = ax[1].imshow(y, cmap=reds)\nfig.colorbar(p1, ax=ax[0])\nfig.colorbar(p2, ax=ax[1])\nplt.show()"
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-5.html#ticks",
    "href": "teaching/2023-2024/Programming Level-up/lecture-5.html#ticks",
    "title": "Introduction to Matplotlib",
    "section": "Ticks",
    "text": "Ticks\nIf we want to customise the numbers along each axis, we use the set_xticks for the x-axis and set_yticks for the y-axis. These functions take the list of locations for each ‘tick’, and optionally a list of labels to use instead of the numbers.\n\nx = np.linspace(-2, 2, 100)\ny = np.sin(x)\n\nbx = np.arange(2, 7)\nby = np.random.uniform(2, 7, len(bx))\n\nfig, ax = plt.subplots(1, 2, figsize=(8, 3))\nax[0].plot(x, y)\nax[0].set_xticks([-2, 0, 2])\nax[1].bar(bx, by)\nax[1].set_xticks(bx, [\"a\", \"b\", \"c\", \"d\", \"e\"])\nplt.show()"
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-5.html#grids",
    "href": "teaching/2023-2024/Programming Level-up/lecture-5.html#grids",
    "title": "Introduction to Matplotlib",
    "section": "Grids",
    "text": "Grids\nIn all of the previous plots, the background has no grids, they are simply white. If we wanted to add grid lines to the plot we use the .grid() method. This function, by default, adds the major grid lines.\n\nx = np.linspace(-2, 2, 100)\ny = np.sin(x)\nz = np.tan(x)\nfig, ax = plt.subplots(1, 2, figsize=(8, 3))\nax[0].plot(x, y)\nax[0].grid()\nax[1].plot(x, z)\nax[1].grid(which=\"both\", color=\"r\")\nplt.show()"
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-5.html#scale",
    "href": "teaching/2023-2024/Programming Level-up/lecture-5.html#scale",
    "title": "Introduction to Matplotlib",
    "section": "Scale",
    "text": "Scale\nThe default behaviour of matplotlib is to plot using a linear scale. In certain situations, we want view the plot using a different scale. For this we can use set_yscale.\n\nx = np.linspace(-2, 10, 100)\ny = np.exp(x)\nfig, ax = plt.subplots(1, 2, figsize=(8, 3))\nax[0].plot(x, y)\nax[0].grid()\nax[1].plot(x, y)\nax[1].set_yscale('log')\nax[1].grid()\nplt.show()"
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-5.html#setting-the-plot-limits",
    "href": "teaching/2023-2024/Programming Level-up/lecture-5.html#setting-the-plot-limits",
    "title": "Introduction to Matplotlib",
    "section": "Setting the plot limits",
    "text": "Setting the plot limits\nBy default, matplotlib will calculate the minimum and maximum values of the data, and use those values to set the limits of the plot. Using set_xlim and set_ylim we can change this default behaviour.\n\nx = np.linspace(-2, 2, 100)\ny = np.sin(x)\nfig, ax = plt.subplots(1, 2, figsize=(8,3))\nax[0].plot(x, y)\nax[0].set_ylim(-1, 2)\nax[1].plot(x, y)\nax[1].set_xlim(-3, 3)\nplt.show()"
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-5.html#annotations",
    "href": "teaching/2023-2024/Programming Level-up/lecture-5.html#annotations",
    "title": "Introduction to Matplotlib",
    "section": "Annotations",
    "text": "Annotations\nWe can annotate our plot in a number of way:\n\n.axhline – plot a horizontal line (axvline for vertical lines)/\n.annotate – add text to the plot at a certain position.\n\n\nx = np.linspace(-2, 2, 100)\ny = np.sin(x)\nfig, ax = plt.subplots()\nax.plot(x, y)\nax.axhline(0, c='gray', ls='--')\nax.annotate(\"0th line\", \n            (-2, 0), \n            xytext=(-1.5, 0.25),\n            arrowprops=dict(\n                facecolor='black', \n                shrink=0.05,\n                width=0.5, \n                headwidth=5.0))\nplt.show()"
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-5.html#creating-a-twin-axes-plot",
    "href": "teaching/2023-2024/Programming Level-up/lecture-5.html#creating-a-twin-axes-plot",
    "title": "Introduction to Matplotlib",
    "section": "Creating a twin axes plot",
    "text": "Creating a twin axes plot\nSometimes you will want to display multiple sub-plots on the same plot, but where each have a very different range in values. Instead of having a single y-axis, with twinx() we can create a two y-axis plot.\n\nx = np.arange(10, 100)\ny = np.exp(x)\nz = np.log(x)\n\nfig, ax = plt.subplots(1, 2)\nax[0].plot(x, y, label=\"exp(x)\")\nax[0].plot(x, z, label=\"log(x)\")\nax[0].legend()\n\nax2 = ax[1].twinx()\nax[1].plot(x, y)\nax2.plot(x, z, color=\"orange\")\nax2.tick_params(axis=\"y\", labelcolor=\"orange\")\nplt.show()"
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-6-reveal.html#what-is-pandas",
    "href": "teaching/2023-2024/Programming Level-up/lecture-6-reveal.html#what-is-pandas",
    "title": "Introduction to Pandas",
    "section": "What is Pandas?",
    "text": "What is Pandas?\n\n\nPandas a library to make the representation and manipulation of tabular data easier in Python.\nA table of data is called a ‘Dataframe’ that consists of named columns and (optionally) named rows.\nhttps://pandas.pydata.org/"
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-6-reveal.html#installing-and-importing-pandas",
    "href": "teaching/2023-2024/Programming Level-up/lecture-6-reveal.html#installing-and-importing-pandas",
    "title": "Introduction to Pandas",
    "section": "Installing and importing pandas",
    "text": "Installing and importing pandas\nTo install pandas, we can either use conda:\nconda install pandas\nor with pip:\npip install pandas\nAfter pandas has been installed. We shall import it into our scripts (using the common convention of aliasing the library as pd):\nimport pandas as pd"
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-6-reveal.html#creating-a-dataframe",
    "href": "teaching/2023-2024/Programming Level-up/lecture-6-reveal.html#creating-a-dataframe",
    "title": "Introduction to Pandas",
    "section": "Creating a dataframe",
    "text": "Creating a dataframe\nNow that pandas has been successfully imported, we’re ready to create and manipulate our own dataframes. To create a dataframe, we first need to organise our data in appropriate format. Perhaps one of the most simple formats for this data is a dictionary, where each value is a list:\ndata = {\"col1\": [1, 2], \"col2\": [3, 4]}\nWe see that each ‘key’ is the representation of a column of data, and the value of this key is a list of data for this column. To convert this data to a dataframe, we need only to call the DataFrame class:\ndf = pd.DataFrame(data)\ndf (dataframe for short) is now our representation of the dataframe:\n\nWe see that each column is named using the keys in our data dictionary, and the values of the column correspond to the elements in the list. To the left of the dataframe we have a numerical index starting at 0.\nExtracting particular values from this dataframe can be accomplished using the loc and iloc class methods. First let’s look at using loc, and later on we’ll investigate the differences between these two methods.\nLet’s say we want to get all the data for the first row of our dataframe:\ndf.loc[0]\n\nThis returns a ‘Series’, which is just a representation of a vector of data."
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-6-reveal.html#access-elements-in-our-dataframe",
    "href": "teaching/2023-2024/Programming Level-up/lecture-6-reveal.html#access-elements-in-our-dataframe",
    "title": "Introduction to Pandas",
    "section": "Access elements in our dataframe",
    "text": "Access elements in our dataframe\nTo access a single value from this series, we can specify the column name:\ndf.loc[0][\"col1\"]  # returns one\nOr, we can more simply add the column name into the loc:\ndf.loc[0, \"col1\"]\nIf we wanted to retrieve a subset of columns, we supply a list of column names:\ndf.loc[0, [\"col1\", \"col2\"]]\nWe can also use the slice notation to access multiple rows:\ndf.loc[0:2, \"col1\"]\nThis retrieves the values in col1.\nOr if we just wanted to get the entire column of data, we could instead do:\ndf[\"col1\"]"
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-6-reveal.html#reading-a-csv-file",
    "href": "teaching/2023-2024/Programming Level-up/lecture-6-reveal.html#reading-a-csv-file",
    "title": "Introduction to Pandas",
    "section": "Reading a CSV file",
    "text": "Reading a CSV file\nInstead of manually constructing our data and then passing it to a DataFrame, we can use pandas to read directly from a CSV file and return a DataFrame:\nLet’s say we have a CSV file of measurements of Iris flowers called iris.csv. We can read this CSV file using the pd.read_csv method.\ndf = pd.read_csv(\"iris.csv\")"
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-6-reveal.html#selecting-a-subset-of-data",
    "href": "teaching/2023-2024/Programming Level-up/lecture-6-reveal.html#selecting-a-subset-of-data",
    "title": "Introduction to Pandas",
    "section": "Selecting a subset of data",
    "text": "Selecting a subset of data\nWith this more complex dataset, we can use more fancy methods of indexing. For example, let’s select all the rows where the sepal length is less than 5 cm.\ndf[df[\"sepal length (cm)\"] &lt; 5]\n\nInstead of the 150 rows we had before, this returns just 22. We can also specify only the columns we want with this conditional expression:\ndf[df[\"sepal length (cm)\"] &lt; 5][\"sepal width (cm)\"]"
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-6-reveal.html#creating-new-columns",
    "href": "teaching/2023-2024/Programming Level-up/lecture-6-reveal.html#creating-new-columns",
    "title": "Introduction to Pandas",
    "section": "Creating new columns",
    "text": "Creating new columns\nWe can add new columns to this dataset by using the assignment operator. In this example, we’re creating a new column called ‘sepal sum’ to be the sum of both the ‘sepal width’ and ‘sepal length’:\ndf[\"sepal sum\"] = df[\"sepal width (cm)\"] + df[\"sepal length (cm)\"]"
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-6-reveal.html#shape-of-the-data",
    "href": "teaching/2023-2024/Programming Level-up/lecture-6-reveal.html#shape-of-the-data",
    "title": "Introduction to Pandas",
    "section": "Shape of the data",
    "text": "Shape of the data\nWe can also further see that our new column has been added by inspecting the shape of the data.\ndf.shape\n(150, 5)\nThis returns a tuple corresponding to the number of rows (150) and the number of columns (5)."
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-6-reveal.html#getting-the-names-of-columns",
    "href": "teaching/2023-2024/Programming Level-up/lecture-6-reveal.html#getting-the-names-of-columns",
    "title": "Introduction to Pandas",
    "section": "Getting the names of columns",
    "text": "Getting the names of columns\nTo find out what the names of the columns are we can use the columns attribute:\ndf.columns\nIndex(['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)',\n       'petal width (cm)', 'sepal sum'],\n      dtype='object')\nThis returns an Index that can itself be indexed in the usual way:\ndf.columns[0]\n'sepal length (cm)'"
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-6-reveal.html#headtail",
    "href": "teaching/2023-2024/Programming Level-up/lecture-6-reveal.html#headtail",
    "title": "Introduction to Pandas",
    "section": "Head/tail",
    "text": "Head/tail\nWe can get the first/last few rows of the data using the .head() or .tail() methods. These take an optional argument specifying the number of rows to view. By default, it will show 10 rows.\ndf.head()  # shows the first 10 rows\ndf.head(5) # shows the first 5 rows\n\ndf.tail()  # shows the last 10 rows\ndf.tail(5) # shows the last 5 rows"
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-6-reveal.html#operations-on-data",
    "href": "teaching/2023-2024/Programming Level-up/lecture-6-reveal.html#operations-on-data",
    "title": "Introduction to Pandas",
    "section": "Operations on data",
    "text": "Operations on data\nPandas comes with a few standard methods to perform some basic operations. For example, you can calculate the mean of a column:\ndf[\"sepal length (cm)\"].mean()\nAnd you can use the apply() method to apply a function to every element (i.e. map a function to every element):\ndf[\"sepal length (cm)\"].apply(lambda x: x * 2)\nApply takes a function as an argument, and here we’re using an anonymous (unnamed function) using a lambda expression https://docs.python.org/3/tutorial/controlflow.html#lambda-expressions\nThis lambda expression will double its input, and therefore applying this function to every element will double all values in ‘sepal length (cm)’."
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-6-reveal.html#apply-operation-to-entire-row",
    "href": "teaching/2023-2024/Programming Level-up/lecture-6-reveal.html#apply-operation-to-entire-row",
    "title": "Introduction to Pandas",
    "section": "Apply operation to entire row",
    "text": "Apply operation to entire row\nIn the previous example, we saw the use of .apply, where a function is applied to each individual element in a column. With apply, it’s also possible to apply a function to each row of a dataframe, by specifying axis=1 in the call to apply:\n# some df with value column defined here\n\ndef window_sum(row, window=5):\n    \"\"\"Take a sum of rows within a window\"\"\"\n    curr_index = row.name  # access the row index number using .name\n    row[\"moving_avg\"] = df.loc[curr_index-window:curr_index, \"value\"].sum()\n    return row  # return the updated row\n\nupdated_df = df.apply(moving_avg, axis=1)"
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-6-reveal.html#merge",
    "href": "teaching/2023-2024/Programming Level-up/lecture-6-reveal.html#merge",
    "title": "Introduction to Pandas",
    "section": "Merge",
    "text": "Merge\nMany pandas dataframes can be combined together using the concat method that requires a list of dataframes as input.\ndata1 = pd.DataFrame({\"col1\": [0, 1], \"col2\": [0, 1]})\ndata2 = pd.DataFrame({\"col1\": [2, 3], \"col2\": [2, 3]})\n\ncombined = pd.concat([data1, data2])"
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-6-reveal.html#more-on-indexing",
    "href": "teaching/2023-2024/Programming Level-up/lecture-6-reveal.html#more-on-indexing",
    "title": "Introduction to Pandas",
    "section": "More on indexing",
    "text": "More on indexing\n\nNotice how the indexes are repeated. We can also verify this using the .index attribute:\ncombined.index\nInt64Index([0, 1, 0, 1], dtype='int64')\nWe can see two ’0’s and two ’1’s. Normally, this is not a problem, but it does have an effect on when we index our data with loc.\ncombined.loc[1]\n\nNotice how loc has returned two rows because it sees two rows with the index label of 1. If instead we simply meant: give me the second row we should use iloc:\ncombined.iloc[1]\nWhich will give us the desired outcome."
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-6-reveal.html#resetting-indexes",
    "href": "teaching/2023-2024/Programming Level-up/lecture-6-reveal.html#resetting-indexes",
    "title": "Introduction to Pandas",
    "section": "Resetting indexes",
    "text": "Resetting indexes\nAlternatively we can reset the index labels:\ncombined.reset_index()\n\nThis will compute a new series of indexes for our data, and then using loc again will only return the one row.\nTo save the result of reset_index() we need to overwrite our original data:\ncombined = combined.reset_index()\nOr specify inplace:\ncombined.reset_index(inplace=True)"
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-6-reveal.html#categorical-data",
    "href": "teaching/2023-2024/Programming Level-up/lecture-6-reveal.html#categorical-data",
    "title": "Introduction to Pandas",
    "section": "Categorical data",
    "text": "Categorical data\nSo far, we’ve only seen numerical data. One of the advantages of using pandas for tabular data is that we can represent various other types of data that makes our manipulation and operations on different data types simpler. For example, we can represent ‘categorical data’ where there is a finite set of values or categories.\ndf = pd.DataFrame({\"col1\": [\"a\", \"b\", \"c\", \"a\"],\n                    \"col2\": [1, 2, 5, 4]})\nRight now, df is simply representing ‘col1’ as strings, but we can change the representation to categorical elements with:\ndf[\"col1\"] = df[\"col1\"].astype(\"category\")\nWith categorical data, we can perform operations on these groups a lot quicker than if we were just to represent them on strings. For instance, lets compute the sum of ‘col2’ for each group.\ndf.groupby(\"col1\").sum()\n\nIf we have lots of data, having ‘col1’ astype('category') will be a lot more computationally efficient than leaving them as strings."
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-6-reveal.html#dates-and-times",
    "href": "teaching/2023-2024/Programming Level-up/lecture-6-reveal.html#dates-and-times",
    "title": "Introduction to Pandas",
    "section": "Dates and times",
    "text": "Dates and times\nIf you have a column that represents a date or time, you can convert that column to a true datetime representation with pd.to_datetime\ndf = pd.DataFrame({\"col1\": [\"2002/01/30\", \"2010/05/16\"]})\ndf[\"col1\"] = pd.to_datetime(df[\"col1\"])\nIn addition to make indexing by dates a lot faster, it also provides us with some convienant methods to extract particular components from the data. Such as the year:\ndf[\"col1\"].dt.year # or df[\"col1\"].dt.month etc"
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-6.html",
    "href": "teaching/2023-2024/Programming Level-up/lecture-6.html",
    "title": "Introduction to Pandas",
    "section": "",
    "text": "Pandas a library to make the representation and manipulation of tabular data easier in Python.\nA table of data is called a ‘Dataframe’ that consists of named columns and (optionally) named rows.\nhttps://pandas.pydata.org/\n\n\n\n\nTo install pandas, we can either use conda:\nconda install pandas\nor with pip:\npip install pandas\nAfter pandas has been installed. We shall import it into our scripts (using the common convention of aliasing the library as pd):\nimport pandas as pd\n\n\n\nNow that pandas has been successfully imported, we’re ready to create and manipulate our own dataframes. To create a dataframe, we first need to organise our data in appropriate format. Perhaps one of the most simple formats for this data is a dictionary, where each value is a list:\ndata = {\"col1\": [1, 2], \"col2\": [3, 4]}\nWe see that each ‘key’ is the representation of a column of data, and the value of this key is a list of data for this column. To convert this data to a dataframe, we need only to call the DataFrame class:\ndf = pd.DataFrame(data)\ndf (dataframe for short) is now our representation of the dataframe:\n\nWe see that each column is named using the keys in our data dictionary, and the values of the column correspond to the elements in the list. To the left of the dataframe we have a numerical index starting at 0.\nExtracting particular values from this dataframe can be accomplished using the loc and iloc class methods. First let’s look at using loc, and later on we’ll investigate the differences between these two methods.\nLet’s say we want to get all the data for the first row of our dataframe:\ndf.loc[0]\n\nThis returns a ‘Series’, which is just a representation of a vector of data.\n\n\n\nTo access a single value from this series, we can specify the column name:\ndf.loc[0][\"col1\"]  # returns one\nOr, we can more simply add the column name into the loc:\ndf.loc[0, \"col1\"]\nIf we wanted to retrieve a subset of columns, we supply a list of column names:\ndf.loc[0, [\"col1\", \"col2\"]]\nWe can also use the slice notation to access multiple rows:\ndf.loc[0:2, \"col1\"]\nThis retrieves the values in col1.\nOr if we just wanted to get the entire column of data, we could instead do:\ndf[\"col1\"]"
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-6.html#what-is-pandas",
    "href": "teaching/2023-2024/Programming Level-up/lecture-6.html#what-is-pandas",
    "title": "Introduction to Pandas",
    "section": "",
    "text": "Pandas a library to make the representation and manipulation of tabular data easier in Python.\nA table of data is called a ‘Dataframe’ that consists of named columns and (optionally) named rows.\nhttps://pandas.pydata.org/"
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-6.html#installing-and-importing-pandas",
    "href": "teaching/2023-2024/Programming Level-up/lecture-6.html#installing-and-importing-pandas",
    "title": "Introduction to Pandas",
    "section": "",
    "text": "To install pandas, we can either use conda:\nconda install pandas\nor with pip:\npip install pandas\nAfter pandas has been installed. We shall import it into our scripts (using the common convention of aliasing the library as pd):\nimport pandas as pd"
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-6.html#creating-a-dataframe",
    "href": "teaching/2023-2024/Programming Level-up/lecture-6.html#creating-a-dataframe",
    "title": "Introduction to Pandas",
    "section": "",
    "text": "Now that pandas has been successfully imported, we’re ready to create and manipulate our own dataframes. To create a dataframe, we first need to organise our data in appropriate format. Perhaps one of the most simple formats for this data is a dictionary, where each value is a list:\ndata = {\"col1\": [1, 2], \"col2\": [3, 4]}\nWe see that each ‘key’ is the representation of a column of data, and the value of this key is a list of data for this column. To convert this data to a dataframe, we need only to call the DataFrame class:\ndf = pd.DataFrame(data)\ndf (dataframe for short) is now our representation of the dataframe:\n\nWe see that each column is named using the keys in our data dictionary, and the values of the column correspond to the elements in the list. To the left of the dataframe we have a numerical index starting at 0.\nExtracting particular values from this dataframe can be accomplished using the loc and iloc class methods. First let’s look at using loc, and later on we’ll investigate the differences between these two methods.\nLet’s say we want to get all the data for the first row of our dataframe:\ndf.loc[0]\n\nThis returns a ‘Series’, which is just a representation of a vector of data."
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-6.html#access-elements-in-our-dataframe",
    "href": "teaching/2023-2024/Programming Level-up/lecture-6.html#access-elements-in-our-dataframe",
    "title": "Introduction to Pandas",
    "section": "",
    "text": "To access a single value from this series, we can specify the column name:\ndf.loc[0][\"col1\"]  # returns one\nOr, we can more simply add the column name into the loc:\ndf.loc[0, \"col1\"]\nIf we wanted to retrieve a subset of columns, we supply a list of column names:\ndf.loc[0, [\"col1\", \"col2\"]]\nWe can also use the slice notation to access multiple rows:\ndf.loc[0:2, \"col1\"]\nThis retrieves the values in col1.\nOr if we just wanted to get the entire column of data, we could instead do:\ndf[\"col1\"]"
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-6.html#reading-a-csv-file",
    "href": "teaching/2023-2024/Programming Level-up/lecture-6.html#reading-a-csv-file",
    "title": "Introduction to Pandas",
    "section": "Reading a CSV file",
    "text": "Reading a CSV file\nInstead of manually constructing our data and then passing it to a DataFrame, we can use pandas to read directly from a CSV file and return a DataFrame:\nLet’s say we have a CSV file of measurements of Iris flowers called iris.csv. We can read this CSV file using the pd.read_csv method.\ndf = pd.read_csv(\"iris.csv\")"
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-6.html#selecting-a-subset-of-data",
    "href": "teaching/2023-2024/Programming Level-up/lecture-6.html#selecting-a-subset-of-data",
    "title": "Introduction to Pandas",
    "section": "Selecting a subset of data",
    "text": "Selecting a subset of data\nWith this more complex dataset, we can use more fancy methods of indexing. For example, let’s select all the rows where the sepal length is less than 5 cm.\ndf[df[\"sepal length (cm)\"] &lt; 5]\n\nInstead of the 150 rows we had before, this returns just 22. We can also specify only the columns we want with this conditional expression:\ndf[df[\"sepal length (cm)\"] &lt; 5][\"sepal width (cm)\"]"
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-6.html#creating-new-columns",
    "href": "teaching/2023-2024/Programming Level-up/lecture-6.html#creating-new-columns",
    "title": "Introduction to Pandas",
    "section": "Creating new columns",
    "text": "Creating new columns\nWe can add new columns to this dataset by using the assignment operator. In this example, we’re creating a new column called ‘sepal sum’ to be the sum of both the ‘sepal width’ and ‘sepal length’:\ndf[\"sepal sum\"] = df[\"sepal width (cm)\"] + df[\"sepal length (cm)\"]"
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-6.html#shape-of-the-data",
    "href": "teaching/2023-2024/Programming Level-up/lecture-6.html#shape-of-the-data",
    "title": "Introduction to Pandas",
    "section": "Shape of the data",
    "text": "Shape of the data\nWe can also further see that our new column has been added by inspecting the shape of the data.\ndf.shape\n(150, 5)\nThis returns a tuple corresponding to the number of rows (150) and the number of columns (5)."
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-6.html#getting-the-names-of-columns",
    "href": "teaching/2023-2024/Programming Level-up/lecture-6.html#getting-the-names-of-columns",
    "title": "Introduction to Pandas",
    "section": "Getting the names of columns",
    "text": "Getting the names of columns\nTo find out what the names of the columns are we can use the columns attribute:\ndf.columns\nIndex(['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)',\n       'petal width (cm)', 'sepal sum'],\n      dtype='object')\nThis returns an Index that can itself be indexed in the usual way:\ndf.columns[0]\n'sepal length (cm)'"
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-6.html#headtail",
    "href": "teaching/2023-2024/Programming Level-up/lecture-6.html#headtail",
    "title": "Introduction to Pandas",
    "section": "Head/tail",
    "text": "Head/tail\nWe can get the first/last few rows of the data using the .head() or .tail() methods. These take an optional argument specifying the number of rows to view. By default, it will show 10 rows.\ndf.head()  # shows the first 10 rows\ndf.head(5) # shows the first 5 rows\n\ndf.tail()  # shows the last 10 rows\ndf.tail(5) # shows the last 5 rows"
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-6.html#operations-on-data",
    "href": "teaching/2023-2024/Programming Level-up/lecture-6.html#operations-on-data",
    "title": "Introduction to Pandas",
    "section": "Operations on data",
    "text": "Operations on data\nPandas comes with a few standard methods to perform some basic operations. For example, you can calculate the mean of a column:\ndf[\"sepal length (cm)\"].mean()\nAnd you can use the apply() method to apply a function to every element (i.e. map a function to every element):\ndf[\"sepal length (cm)\"].apply(lambda x: x * 2)\nApply takes a function as an argument, and here we’re using an anonymous (unnamed function) using a lambda expression https://docs.python.org/3/tutorial/controlflow.html#lambda-expressions\nThis lambda expression will double its input, and therefore applying this function to every element will double all values in ‘sepal length (cm)’."
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-6.html#apply-operation-to-entire-row",
    "href": "teaching/2023-2024/Programming Level-up/lecture-6.html#apply-operation-to-entire-row",
    "title": "Introduction to Pandas",
    "section": "Apply operation to entire row",
    "text": "Apply operation to entire row\nIn the previous example, we saw the use of .apply, where a function is applied to each individual element in a column. With apply, it’s also possible to apply a function to each row of a dataframe, by specifying axis=1 in the call to apply:\n# some df with value column defined here\n\ndef window_sum(row, window=5):\n    \"\"\"Take a sum of rows within a window\"\"\"\n    curr_index = row.name  # access the row index number using .name\n    row[\"moving_avg\"] = df.loc[curr_index-window:curr_index, \"value\"].sum()\n    return row  # return the updated row\n\nupdated_df = df.apply(moving_avg, axis=1)"
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-6.html#merge",
    "href": "teaching/2023-2024/Programming Level-up/lecture-6.html#merge",
    "title": "Introduction to Pandas",
    "section": "Merge",
    "text": "Merge\nMany pandas dataframes can be combined together using the concat method that requires a list of dataframes as input.\ndata1 = pd.DataFrame({\"col1\": [0, 1], \"col2\": [0, 1]})\ndata2 = pd.DataFrame({\"col1\": [2, 3], \"col2\": [2, 3]})\n\ncombined = pd.concat([data1, data2])"
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-6.html#more-on-indexing",
    "href": "teaching/2023-2024/Programming Level-up/lecture-6.html#more-on-indexing",
    "title": "Introduction to Pandas",
    "section": "More on indexing",
    "text": "More on indexing\n\nNotice how the indexes are repeated. We can also verify this using the .index attribute:\ncombined.index\nInt64Index([0, 1, 0, 1], dtype='int64')\nWe can see two ’0’s and two ’1’s. Normally, this is not a problem, but it does have an effect on when we index our data with loc.\ncombined.loc[1]\n\nNotice how loc has returned two rows because it sees two rows with the index label of 1. If instead we simply meant: give me the second row we should use iloc:\ncombined.iloc[1]\nWhich will give us the desired outcome."
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-6.html#resetting-indexes",
    "href": "teaching/2023-2024/Programming Level-up/lecture-6.html#resetting-indexes",
    "title": "Introduction to Pandas",
    "section": "Resetting indexes",
    "text": "Resetting indexes\nAlternatively we can reset the index labels:\ncombined.reset_index()\n\nThis will compute a new series of indexes for our data, and then using loc again will only return the one row.\nTo save the result of reset_index() we need to overwrite our original data:\ncombined = combined.reset_index()\nOr specify inplace:\ncombined.reset_index(inplace=True)"
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-6.html#categorical-data",
    "href": "teaching/2023-2024/Programming Level-up/lecture-6.html#categorical-data",
    "title": "Introduction to Pandas",
    "section": "Categorical data",
    "text": "Categorical data\nSo far, we’ve only seen numerical data. One of the advantages of using pandas for tabular data is that we can represent various other types of data that makes our manipulation and operations on different data types simpler. For example, we can represent ‘categorical data’ where there is a finite set of values or categories.\ndf = pd.DataFrame({\"col1\": [\"a\", \"b\", \"c\", \"a\"],\n                    \"col2\": [1, 2, 5, 4]})\nRight now, df is simply representing ‘col1’ as strings, but we can change the representation to categorical elements with:\ndf[\"col1\"] = df[\"col1\"].astype(\"category\")\nWith categorical data, we can perform operations on these groups a lot quicker than if we were just to represent them on strings. For instance, lets compute the sum of ‘col2’ for each group.\ndf.groupby(\"col1\").sum()\n\nIf we have lots of data, having ‘col1’ astype('category') will be a lot more computationally efficient than leaving them as strings."
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-6.html#dates-and-times",
    "href": "teaching/2023-2024/Programming Level-up/lecture-6.html#dates-and-times",
    "title": "Introduction to Pandas",
    "section": "Dates and times",
    "text": "Dates and times\nIf you have a column that represents a date or time, you can convert that column to a true datetime representation with pd.to_datetime\ndf = pd.DataFrame({\"col1\": [\"2002/01/30\", \"2010/05/16\"]})\ndf[\"col1\"] = pd.to_datetime(df[\"col1\"])\nIn addition to make indexing by dates a lot faster, it also provides us with some convienant methods to extract particular components from the data. Such as the year:\ndf[\"col1\"].dt.year # or df[\"col1\"].dt.month etc"
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-3-reveal.html#importing-in-python",
    "href": "teaching/2023-2024/Programming Level-up/lecture-3-reveal.html#importing-in-python",
    "title": "Python Modules",
    "section": "Importing in python",
    "text": "Importing in python\n\nhttps://xkcd.com/353/"
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-3-reveal.html#the-basic-structure-of-importing",
    "href": "teaching/2023-2024/Programming Level-up/lecture-3-reveal.html#the-basic-structure-of-importing",
    "title": "Python Modules",
    "section": "The basic structure of importing",
    "text": "The basic structure of importing\nModules or packages are other scripts or programs that can be imported into other scripts. This definition is very general, but we shall see how flexible importing in Python can be.\nThe basic syntax of importing is:\nimport &lt;package_name&gt;\n\n&lt;package_name&gt;.&lt;function/class/variable/etc&gt;\nIf we import &lt;package_name&gt; using this syntax, we always have to use the dot . syntax to refer to something within this package.\nLet’s take a look at a very basic example.\nimport math\n\nradius = 6.4  # cm\ncircum = 2 * math.pi * radius\nIn this example, we are importing the built-in math package. This package contains a bunch of useful functions and variables. We’re not going to take a look at them here, as we’re focusing on importing, but you can see we’re referring to a variable called pi to calculate the circumference of a circle."
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-3-reveal.html#importing-specific-items",
    "href": "teaching/2023-2024/Programming Level-up/lecture-3-reveal.html#importing-specific-items",
    "title": "Python Modules",
    "section": "Importing specific items",
    "text": "Importing specific items\nIf we didn’t always want to specify the package name when we only want to use something specific from a package, we can directly import that something.\nfrom &lt;package_name&gt; import &lt;function/class/variable/etc&gt;\n\n&lt;function/class/variable/etc&gt;\nAs you can see, we’re using the from ... import ... syntax.\nfrom math import pi\n\ncircumference = 2 * pi * radius"
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-3-reveal.html#dont-do-this",
    "href": "teaching/2023-2024/Programming Level-up/lecture-3-reveal.html#dont-do-this",
    "title": "Python Modules",
    "section": "Don’t do this!",
    "text": "Don’t do this!\nWhen using from ... import ..., there is a wildcard * that we could use. You may sometimes see this style of importing when looking at documentation online:\nfrom &lt;package_name&gt; import *\n\n&lt;function/class/variable/etc&gt;\nHowever, this can create many problems with reading your program code\nWhich module does my_function() originate? Are there are common names between the two? Which would be used?\nfrom my_module import *\nfrom my_second_module import *\n\nmy_function()"
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-3-reveal.html#alias",
    "href": "teaching/2023-2024/Programming Level-up/lecture-3-reveal.html#alias",
    "title": "Python Modules",
    "section": "Alias",
    "text": "Alias\nWhen importing, we can optionally create an alias to a symbol. Here we’re creating an alias to the existing pi in math.\nfrom math import pi as decilious_pi\n\ncircumference = 2 * delicious_pi * radius\nThere are some very common conventions of aliasing very highly used packages that we will definitely revisit in another lecture!\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt"
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-3-reveal.html#importing-local-libraries",
    "href": "teaching/2023-2024/Programming Level-up/lecture-3-reveal.html#importing-local-libraries",
    "title": "Python Modules",
    "section": "Importing local libraries",
    "text": "Importing local libraries\nlet’s consider a hypothetical local directory:\n    main.py\n    src/\n     |-- my_module.py\n     |-- module_1/\n            |-- cats.py\n            |-- dogs.py\nIf we wanted to import something from my_module.py we would do:\nfrom src.my_module import MyAwesomeClass\n\nmy_class = MyAwesomeclass()\nHere is another example for increased nesting of directories:\n    main.py\n    src/\n     |-- my_module.py\n     |-- module_1/\n            |-- cats.py\n            |-- dogs.py\nfrom src.module_1 import cats\nfrom src.module_1.dogs import Dog\n\ncat = cats.Cat()\ndog = Dog()"
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-3-reveal.html#quick-exercise-imports",
    "href": "teaching/2023-2024/Programming Level-up/lecture-3-reveal.html#quick-exercise-imports",
    "title": "Python Modules",
    "section": "Quick exercise – imports",
    "text": "Quick exercise – imports\n\nCreate a directory to store your scripts\nIn this directory, create a file called main.py.\nCreate a sub-directory called src. In src create another file called library.py.\nIn library.py create a class (that doesn’t do anything right now) called Database.\nIn main.py, create an instance of Database."
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-3-reveal.html#shortcuts-with-__init__.py",
    "href": "teaching/2023-2024/Programming Level-up/lecture-3-reveal.html#shortcuts-with-__init__.py",
    "title": "Python Modules",
    "section": "Shortcuts with __init__.py",
    "text": "Shortcuts with __init__.py\nLet’s say you often import Cat and Dog. We can use a file called __init__.py to help us and make the imports shorter. This fill gets executed when its module is imported.\n    main.py\n    src/\n     |-- my_module.py\n     |-- module_1/\n            |-- __init__.py\n            |-- cats.py\n            |-- dogs.py\nIn __init__.py:\nfrom cats import Cat\nfrom dogs import Dog\nIn main.py:\nfrom src.module_1 import Cat, Dog"
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-3-reveal.html#what-is-__main__",
    "href": "teaching/2023-2024/Programming Level-up/lecture-3-reveal.html#what-is-__main__",
    "title": "Python Modules",
    "section": "What is __main__?",
    "text": "What is __main__?\nConsider a file with the following:\nx = 2\ny = 1\nz = x + y\n\nclass MyAwesomeClass:\n...\nIf we import this file in another script, x, y, and z will be computed. In this very simple case this will have very little impact. But what if the computation of these takes a very long time?\nHere we are wrapping any global computations into a appropriate functions. This prevents the global variables being computed as soon as the script is imported.\nNow, if we wanted to compute x, y, and z if this script is run, we could use:\nif __name__ == \"__main__\":\n# do something\nAnything within the scope of the if function will only be run if the current file is the script that is being run directly (i.e. python &lt;the-file&gt;.py). If the script is being imported, the statements within this if scope will not be run.\nSo if we wanted to run compute() if this file is being run directly, we would write:\ndef compute():\n    x = 2\n    y = 1\n    z = x + y\n\nclass MyAwesomeClass:\n    ...\n    \nif __name__ == \"__main__\":\n    compute()\n    # we can of course use MyAwesomeClass as well\n    my_class = MyAwesomeClass()\n    my_class.do_something()"
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-3-reveal.html#current-working-directory",
    "href": "teaching/2023-2024/Programming Level-up/lecture-3-reveal.html#current-working-directory",
    "title": "Python Modules",
    "section": "Current working directory",
    "text": "Current working directory\nThe folder in which you run Python will be the current working directory (CWD). We can print this value with the os.getcwd() function, or change the directory with os.chdir(...). Its important to know what your CWD is as all relative paths (paths that do not start with a ‘/’) will be relative to your CWD.\nimport os\n\nprint(os.getcwd())\nos.chdir(\"../\")\nprint(os.getcwd())\nos.chdir(\"week-3\")`\nResults: \n# =&gt; [...]/Programming Level-up/week-3\n# =&gt; [...]/Programming Level-up\nI’ve replaced the full path printed by Python with [...] so you can see the differences in the paths!"
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-3-reveal.html#listing-directories",
    "href": "teaching/2023-2024/Programming Level-up/lecture-3-reveal.html#listing-directories",
    "title": "Python Modules",
    "section": "Listing directories",
    "text": "Listing directories\nContinuing with our usage of the os package, we can use the listdir function to list all files within a directory.\nprint(os.listdir())\nprint(os.listdir(\"images/\"))\nResults: \n# =&gt; ['images', '__pycache__', 'lecture.pdf', 'lecture.tex', 'data', 'test_file_1.py', 'lecture.org', '_minted-lecture', 'test_file_2.py']\n# =&gt; ['legend-2.png', 'fig-size.png', 'basic.png', 'subplots.png', 'python.png', 'pycharm01.png', 'installing-scikit-learn.png', 'pycharm02.png', 'PyCharm_Icon.png', 'axis.png', 'legend.png', 'complex-pycharm.jpg']\nThis returns a list of files and directory relative to your current working directory. Notice how from this list you cannot tell if something is a file or directory (though the filename does provide some hint)."
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-3-reveal.html#testing-for-files-or-directories",
    "href": "teaching/2023-2024/Programming Level-up/lecture-3-reveal.html#testing-for-files-or-directories",
    "title": "Python Modules",
    "section": "Testing for files or directories",
    "text": "Testing for files or directories\nIn the previous example we saw that the items returned by listdir does not specify if the item is a file or directory. However, os provides an isfile function in the path submodule to test if the argument is a file, else it will be a directory.\nfor path in os.listdir():\n    print(f\"{path} =&gt; is file: {os.path.isfile(path)}\")\nResults: \n# =&gt; images =&gt; is file: False\n# =&gt; __pycache__ =&gt; is file: False\n# =&gt; lecture.pdf =&gt; is file: True\n# =&gt; lecture.tex =&gt; is file: True\n# =&gt; data =&gt; is file: False\n# =&gt; test_file_1.py =&gt; is file: True\n# =&gt; lecture.org =&gt; is file: True\n# =&gt; _minted-lecture =&gt; is file: False\n# =&gt; test_file_2.py =&gt; is file: True"
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-3-reveal.html#using-wildcards",
    "href": "teaching/2023-2024/Programming Level-up/lecture-3-reveal.html#using-wildcards",
    "title": "Python Modules",
    "section": "Using wildcards",
    "text": "Using wildcards\nIf we wanted to get all files within a directory, we could use the glob function from the glob package. glob allows us to use the * wildcard. E.g. *.png will list all files that end with .png. test-* will list all files that start with test-*.\nfrom glob import glob\n\nfor fn in glob(\"images/*\"):\n    print(fn)\nResults: \n# =&gt; images/legend-2.png\n# =&gt; images/fig-size.png\n# =&gt; images/basic.png\n# =&gt; images/subplots.png\n# =&gt; images/python.png\n# =&gt; images/pycharm01.png\n# =&gt; images/installing-scikit-learn.png\n# =&gt; images/pycharm02.png\n# =&gt; images/PyCharm_Icon.png\n# =&gt; images/axis.png\n# =&gt; images/legend.png\n# =&gt; images/complex-pycharm.jpg"
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-3-reveal.html#pathlib-a-newer-way",
    "href": "teaching/2023-2024/Programming Level-up/lecture-3-reveal.html#pathlib-a-newer-way",
    "title": "Python Modules",
    "section": "Pathlib – a newer way",
    "text": "Pathlib – a newer way\npathlib is a somewhat recent addition to the Python standard library which makes working with files a little easier. Firstly, we can create a Path object, allowing us to concatenate paths with the /. Instead of using the glob module, a Path object has a glob class method.\nfrom pathlib import Path\n\ndata_dir = Path(\"data\")\nprocessed_data = data_dir / \"processed\"\n\ndata_files = processed_data.glob(\"*.txt\")\n\nfor data_file in data_files:\n    print(data_file)\nResults: \n# =&gt; data/processed/data-2.txt\n# =&gt; data/processed/data.txt"
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-3-reveal.html#pathlib-convenient-functions",
    "href": "teaching/2023-2024/Programming Level-up/lecture-3-reveal.html#pathlib-convenient-functions",
    "title": "Python Modules",
    "section": "Pathlib – convenient functions",
    "text": "Pathlib – convenient functions\npathlib allows us to easily decompose a path into different components. Take for example getting the filename of a path with .name.\nfrom pathlib import Path\n\nsome_file = Path(\"data/processed/data.txt\")\n\nprint(some_file.parts)  # get component parts\nprint(some_file.parents[0])  # list of parent dirs\nprint(some_file.name)   # only filename\nprint(some_file.suffix) # extension\nResults: \n# =&gt; ('data', 'processed', 'data.txt')\n# =&gt; data/processed\n# =&gt; data.txt\n# =&gt; .txt"
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-3-reveal.html#converting-path-into-a-string",
    "href": "teaching/2023-2024/Programming Level-up/lecture-3-reveal.html#converting-path-into-a-string",
    "title": "Python Modules",
    "section": "Converting Path into a string",
    "text": "Converting Path into a string\nAs pathlib is a recent addition to Python, some functions/classes are expecting a str representation of the path, not a Path object. Therefore, you may want to use the str function to convert a Path object to a string.\nstr(Path(\"data/\"))\nResults: \n# =&gt; 'data'"
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-3-reveal.html#quick-exercise-locating-files",
    "href": "teaching/2023-2024/Programming Level-up/lecture-3-reveal.html#quick-exercise-locating-files",
    "title": "Python Modules",
    "section": "Quick exercise – locating files",
    "text": "Quick exercise – locating files\n\nIn the same directory of scripts you created in the last exercise, create another directory called data.\nIn data, create 3 text files, calling them &lt;book_name&gt;.txt.\nThese each text file should contain the information from table below in the format:\nName:  Author:  Release Year: \n\n\n\n\n\n\n\n\n\n\nTitle\n\n\nAuthor\n\n\nRelease Date\n\n\n\n\n\n\nMoby Dick\n\n\nHerman Melville\n\n\n1851\n\n\n\n\nA Study in Scarlet\n\n\nSir Arthur Conan Doyle\n\n\n1887\n\n\n\n\nFrankenstein\n\n\nMary Shelley\n\n\n1818\n\n\n\n\nHitchhikers Guide to the Galaxy\n\n\nDouglas Adams\n\n\n1979\n\n\n\n\n\nFrom main.py, print out all of the text files in the directory."
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-3-reveal.html#reading-files",
    "href": "teaching/2023-2024/Programming Level-up/lecture-3-reveal.html#reading-files",
    "title": "Python Modules",
    "section": "Reading files",
    "text": "Reading files\nTo read a file, we must first open it with the open function. This returns a file stream to which we can call the read() class method.\nYou should always make sure to call the close() class method on this stream to close the file.\nread() reads the entire contents of the file and places it into a string.\nopen_file = open(str(Path(\"data\") / \"processed\" / \"data.txt\"))\ncontents_of_file = open_file.read()\nopen_file.close()  # should always happen!\nprint(contents_of_file)\nResults: \n# =&gt; this is some data\n# =&gt; on another line"
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-3-reveal.html#reading-files-lines-or-entire-file",
    "href": "teaching/2023-2024/Programming Level-up/lecture-3-reveal.html#reading-files-lines-or-entire-file",
    "title": "Python Modules",
    "section": "Reading files – lines or entire file?",
    "text": "Reading files – lines or entire file?\nWhile read works for the last example, you may want to read files in different ways. Luckily there are a number of methods you could use.\nopen_file.read()       # read entire file\nopen_file.readline()   # read a single line\nopen_file.readline(5)  # read 5 lines\nopen_file.readlines()  # returns all lines as a list\n\nfor line in open_file:  # read one line at a time\n    do_something(line)"
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-3-reveal.html#the-with-keyword",
    "href": "teaching/2023-2024/Programming Level-up/lecture-3-reveal.html#the-with-keyword",
    "title": "Python Modules",
    "section": "The with keyword",
    "text": "The with keyword\nIt can be a pain to remember to use the .close() every time you open a file. In Python, we can use open() as a context with the with keyword. This context will handle the closing of the file as soon as the scope is exited.\nThe syntax for opening a file is as follows:\nwith open(\"data/processed/data.txt\", \"r\") as open_file:\n    contents = open_file.read()\n\n# the file is automatically closed at this point\n\n    print(contents)\nResults: \n# =&gt; this is some data\n# =&gt; on another line"
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-3-reveal.html#writing-files",
    "href": "teaching/2023-2024/Programming Level-up/lecture-3-reveal.html#writing-files",
    "title": "Python Modules",
    "section": "Writing files",
    "text": "Writing files\nThe syntax for writing a file is similar to reading a file. The main difference is the use \"w\" instead of \"r\" in the second argument of open. Also, instead of read(), we use write().\ndata = [\"this is some data\", \"on another line\", \"with another line\"]\nnew_filename = \"data/processed/new-data.txt\"\n\nwith open(new_filename, \"w\") as open_file:\n    for line in data:\n        open_file.write(line + \"\\n\")\n\nwith open(new_filename, \"r\") as open_file:\n    new_contents = open_file.read()\n\nprint(new_contents)\nResults: \n# =&gt; this is some data\n# =&gt; on another line\n# =&gt; with another line"
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-3-reveal.html#appending-to-files",
    "href": "teaching/2023-2024/Programming Level-up/lecture-3-reveal.html#appending-to-files",
    "title": "Python Modules",
    "section": "Appending to files",
    "text": "Appending to files\nEvery time we write to a file, the entire contents is deleted and replaced. If we want to just append to the file instead, we use \"a\".\ndata = [\"this is some appended data\"]\nnew_filename = \"data/processed/new-data.txt\"\n\nwith open(new_filename, \"a\") as open_file:\n    for line in data:\n        open_file.write(line + \"\\n\")\n\nwith open(new_filename, \"r\") as open_file:\n    new_contents = open_file.read()\n\nprint(new_contents)\nResults: \n# =&gt; this is some data\n# =&gt; on another line\n# =&gt; with another line\n# =&gt; this is some appended data"
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-3-reveal.html#quick-exercise-readingwriting-files",
    "href": "teaching/2023-2024/Programming Level-up/lecture-3-reveal.html#quick-exercise-readingwriting-files",
    "title": "Python Modules",
    "section": "Quick exercise – reading/writing files",
    "text": "Quick exercise – reading/writing files\n\nUsing the same text files from the previous exercise, we will want to be able to read each text file, and parse the information contained in the file.\nThe output of reading each of the text files should be a list of dictionaries, like we have seen in previous lectures.\nWe will go through a sample solution together once you’ve had the chance to try it for yourself."
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-3-reveal.html#reading-csv-files-builtin",
    "href": "teaching/2023-2024/Programming Level-up/lecture-3-reveal.html#reading-csv-files-builtin",
    "title": "Python Modules",
    "section": "Reading CSV files – builtin",
    "text": "Reading CSV files – builtin\nWhen working with common file types, Python has built-in modules to make the process a little easier. Take, for example, reading and writing a CSV file. Here we are importing the csv module and in the context of reading the file, we are creating a CSV reader object. When reading, every line of the CSV file is returned as a list, thus an entire CSV file is a list of lists.\nimport csv  # built-in library\n\ndata_path = \"data/processed/data.csv\"\n\n# read a csv\nwith open(data_path, \"r\") as csv_file:\n    csv_reader = csv.reader(csv_file, delimiter=\",\")\n    for line in csv_reader:\n        print(line)\nResults: \n# =&gt; ['name', 'id', 'age']\n# =&gt; ['jane', '01', '35']\n# =&gt; ['james', '02', '50']"
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-3-reveal.html#writing-a-csv-file-builtin",
    "href": "teaching/2023-2024/Programming Level-up/lecture-3-reveal.html#writing-a-csv-file-builtin",
    "title": "Python Modules",
    "section": "Writing a CSV file – builtin",
    "text": "Writing a CSV file – builtin\nWriting a CSV file is similar except we are creating a CSV writer object, and are using writerow instead.\n# write a csv file\nnew_data_file = \"data/processed/new-data.csv\"\nnew_data = [[\"name\", \"age\", \"height\"], [\"jane\", \"35\", \"6\"]]\n\nwith open(new_data_file, \"w\") as csv_file:\n  csv_writer = csv.writer(csv_file, delimiter=\",\")\n  for row in new_data:\n      csv_writer.writerow(row)"
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-3-reveal.html#quick-exercise-readingwriting-csv-files",
    "href": "teaching/2023-2024/Programming Level-up/lecture-3-reveal.html#quick-exercise-readingwriting-csv-files",
    "title": "Python Modules",
    "section": "Quick exercise – reading/writing CSV files",
    "text": "Quick exercise – reading/writing CSV files\n\nGiven the parsed data from the previous exercise, write a new CSV file in the data directory.\nThis CSV file should contain the headings: name, author, releasedata.\nThe data in the CSV file should be the 3 books with data in the correct columns.\nTest that you can read this same CSV file in python."
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-3-reveal.html#read-json-files-builtin",
    "href": "teaching/2023-2024/Programming Level-up/lecture-3-reveal.html#read-json-files-builtin",
    "title": "Python Modules",
    "section": "Read JSON files – builtin",
    "text": "Read JSON files – builtin\nLike CSV, json is a common format for storing data. Python includes a package called json that enables us to read/write to json files with ease.\nLet’s first tackle the process of reading:\nimport json\n\njson_file_path = \"data/processed/data.json\"\n\n# read a json file\nwith open(json_file_path, \"r\") as json_file:\n    data = json.load(json_file)\n    print(data)\n    print(data.keys())\n    print(data[\"names\"])\nResults: \n# =&gt; {'names': ['jane', 'james'], 'ages': [35, 50]}\n# =&gt; dict_keys(['names', 'ages'])\n# =&gt; ['jane', 'james']"
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-3-reveal.html#write-json-files-builtin",
    "href": "teaching/2023-2024/Programming Level-up/lecture-3-reveal.html#write-json-files-builtin",
    "title": "Python Modules",
    "section": "Write JSON files – builtin",
    "text": "Write JSON files – builtin\nWhile we used json.load to read the file, we use json.dump to write the data to a json file.\nnew_data = {\"names\": [\"someone-new\"], \"ages\": [\"NA\"]}\n\n# write a json file\nwith open(\"data/processed/new-data.json\", \"w\") as json_file:\n    json.dump(new_data, json_file)\n\nwith open(\"data/processed/new-data.json\", \"r\") as json_file:\n    print(json.load(json_file))`\nResults: \n# =&gt; {'names': ['someone-new'], 'ages': ['NA']}"
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-3-reveal.html#virtual-environments",
    "href": "teaching/2023-2024/Programming Level-up/lecture-3-reveal.html#virtual-environments",
    "title": "Python Modules",
    "section": "Virtual Environments",
    "text": "Virtual Environments\nWhen installing packages, by default, the packages are going to be installed into the system-level Python. This can be a problem, for example, if you’re working on multiple projects that require different versions of packages.\nVirtual environments are ‘containerised’ versions of Python that can be created for each different project you’re working on.\nWe will take a look at package management and virtual environments in Python."
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-3-reveal.html#anaconda",
    "href": "teaching/2023-2024/Programming Level-up/lecture-3-reveal.html#anaconda",
    "title": "Python Modules",
    "section": "Anaconda",
    "text": "Anaconda\n\n\nDistribution of Python and R designed for scientific computing.\nWe’re going to focus on Conda, a package manager in the Anaconda ecosystem.\nHelps with package management and deployment.\nCreate virtual environments to install packages to avoid conflicts with other projects"
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-3-reveal.html#installing-anaconda",
    "href": "teaching/2023-2024/Programming Level-up/lecture-3-reveal.html#installing-anaconda",
    "title": "Python Modules",
    "section": "Installing Anaconda",
    "text": "Installing Anaconda\nWe’re going to install miniconda (a minimal installation of anaconda). https://docs.conda.io/en/latest/miniconda.html\nThe steps to install Miniconda are roughly:\n\nDownload Miniconda3 Linux 64-bit\nSave the file to the disk\nOpen up a terminal and run the following commands:\n\n    chmod +x &lt;miniconda-file&gt;.sh\n    ./&lt;miniconda-file&gt;.sh\nFollow the installation instructions (most of the time the defaults are sensible)."
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-3-reveal.html#creating-an-environment",
    "href": "teaching/2023-2024/Programming Level-up/lecture-3-reveal.html#creating-an-environment",
    "title": "Python Modules",
    "section": "Creating an environment",
    "text": "Creating an environment\nConda is a command line tool to manage environments. We’re going to highlight some of the most used commands. But for the full list of management, you can use the instructions at: https://conda.io/projects/conda/en/latest/user-guide/tasks/manage-environments.html\nIf you’re creating a brand new environment, use:\nconda create --name &lt;name-of-env&gt;\nThis will prompt you to confirm you want to create a new environment, whereupon you enter either a y or n. If y your new environment will be created, but start using the environment, you will first have to activate it."
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-3-reveal.html#activating-an-environment",
    "href": "teaching/2023-2024/Programming Level-up/lecture-3-reveal.html#activating-an-environment",
    "title": "Python Modules",
    "section": "Activating an environment",
    "text": "Activating an environment\nOnce you’ve created a new environment, you can activate it. This is as simple as:\nconda activate &lt;name-of-env&gt;\nYou will notice that your command line prompt has changed from (base) to (&lt;name-of-env&gt;). And whenever you start a new terminal it will always be (base)."
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-3-reveal.html#de-activating-an-environment",
    "href": "teaching/2023-2024/Programming Level-up/lecture-3-reveal.html#de-activating-an-environment",
    "title": "Python Modules",
    "section": "De-activating an environment",
    "text": "De-activating an environment\nTo deactivate an environment, just use:\nconda deactivate\nor:\nconda activate base"
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-3-reveal.html#installing-using-conda",
    "href": "teaching/2023-2024/Programming Level-up/lecture-3-reveal.html#installing-using-conda",
    "title": "Python Modules",
    "section": "Installing using conda",
    "text": "Installing using conda\nLet’s say we want to install a package, say scikit-learn (if we’re doing some data processing or machine learning). To install this package in conda, use:\nconda install scikit-learn\nConda will then check what packages are needed for scikit-learn to work, and figure out if anything needs to be upgraded/downgraded to match the required dependencies of other packages.\nWhen Conda has finalised what packages need to change, it will tell you these changes and ask to confirm. If everything seems okay type y, and enter.\nscikit-learn is a package in the anaconda repository. For a list of packages, you can use: https://anaconda.org/anaconda/repo"
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-3-reveal.html#package-versions",
    "href": "teaching/2023-2024/Programming Level-up/lecture-3-reveal.html#package-versions",
    "title": "Python Modules",
    "section": "Package versions",
    "text": "Package versions\nconda install &lt;package-name&gt;=&lt;version-number&gt;"
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-3-reveal.html#installing-a-specific-version-of-python",
    "href": "teaching/2023-2024/Programming Level-up/lecture-3-reveal.html#installing-a-specific-version-of-python",
    "title": "Python Modules",
    "section": "Installing a specific version of Python",
    "text": "Installing a specific version of Python\nIf we wanted to, we could also change the python version being used in the virtual environment.\nconda install python=3.9\nThis will try to install Python version 3.9 providing that the packages you already have installed support it."
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-3-reveal.html#conda-forge-and-other-repositories",
    "href": "teaching/2023-2024/Programming Level-up/lecture-3-reveal.html#conda-forge-and-other-repositories",
    "title": "Python Modules",
    "section": "Conda-forge and other repositories",
    "text": "Conda-forge and other repositories\nLet’s say that the package is not within the basic anaconda repository. You can specify another repository or channel using the -c flag.\nconda install -c &lt;channel&gt; &lt;package&gt;\nFor example, PyTorch (https://pytorch.org/) uses their own channel:\nconda install -c pytorch pytorch"
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-3-reveal.html#exporting-an-environment",
    "href": "teaching/2023-2024/Programming Level-up/lecture-3-reveal.html#exporting-an-environment",
    "title": "Python Modules",
    "section": "Exporting an environment",
    "text": "Exporting an environment\nWe will want to share our research and work with others. To allow others to use the exact same packages and especially the versions of packages we’re using, we want to export a snapshot of our environment. Conda includes an export command to do just this:\nconda env export --no-builds &gt; environment.yml\nHere we exporting our currently activated environment to a file called environment.yml (common convention) file. I am using the --no-builds flag to improve compatibility with other operating systems such as Mac OS."
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-3-reveal.html#reproducing-an-environment",
    "href": "teaching/2023-2024/Programming Level-up/lecture-3-reveal.html#reproducing-an-environment",
    "title": "Python Modules",
    "section": "Reproducing an environment",
    "text": "Reproducing an environment\nTo create an environment from an existing environment.yml file, you can use the following command:\nconda env create -f environment.yml\nThis will create an environment with the same name and install the same versions of the packages."
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-3-reveal.html#deleting-an-environment",
    "href": "teaching/2023-2024/Programming Level-up/lecture-3-reveal.html#deleting-an-environment",
    "title": "Python Modules",
    "section": "Deleting an Environment",
    "text": "Deleting an Environment\nAt later points in our project life-cycle – we have finished our project and we don’t want to have the environment installed anymore (besides we already have the environment.yml to recreate it from if we need to!).\nWe can remove an environment using:\nconda env remove --name &lt;name-of-env&gt;\nThis will remove the environment from Anaconda."
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-3-reveal.html#cleaning-up",
    "href": "teaching/2023-2024/Programming Level-up/lecture-3-reveal.html#cleaning-up",
    "title": "Python Modules",
    "section": "Cleaning up",
    "text": "Cleaning up\nIf you use Anaconda for a long time, you may start to see that a lot of memory is being used, this is because for every version of the package you install, a download of that package is cached to disk. Having these caches can make reinstalling these packages quicker as you won’t need to download the package again. But if you’re running out of hard drive space, cleaning up these cached downloads is an instant space saver:\nconda clean --all\nThis command will clean up the cache files for all environments, but doesn’t necessarily affect what’s already installed in the environments – so nothing should be broken by running this command."
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-3-reveal.html#pip",
    "href": "teaching/2023-2024/Programming Level-up/lecture-3-reveal.html#pip",
    "title": "Python Modules",
    "section": "Pip",
    "text": "Pip\nPip is another package installer for python. If you’re reading documentation online about how to install a certain Python package, the documentation will normally refer to pip.\nPip, like conda, uses a package repository to locate packages. For pip it is called Pypi (https://pypi.org)\nWe’re going to take a look at the most commonly used commands with pip."
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-3-reveal.html#installing-packages-with-pip",
    "href": "teaching/2023-2024/Programming Level-up/lecture-3-reveal.html#installing-packages-with-pip",
    "title": "Python Modules",
    "section": "Installing packages with pip",
    "text": "Installing packages with pip\nIf you want to install a package, its as simple as pip install.\npip install &lt;package-name&gt;"
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-3-reveal.html#installing-specific-versions",
    "href": "teaching/2023-2024/Programming Level-up/lecture-3-reveal.html#installing-specific-versions",
    "title": "Python Modules",
    "section": "Installing specific versions",
    "text": "Installing specific versions\nSometimes, though, you will want to install a specific package version. For this use ‘==’ after the name of the package.\npip install &lt;package-name&gt;==&lt;version-number&gt;"
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-3-reveal.html#upgrade-packages-with-pip",
    "href": "teaching/2023-2024/Programming Level-up/lecture-3-reveal.html#upgrade-packages-with-pip",
    "title": "Python Modules",
    "section": "Upgrade packages with pip",
    "text": "Upgrade packages with pip\nIf you want upgrade/install the package to the latest version, use the --upgrade flag.\npip install &lt;package-name&gt; --upgrade"
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-3-reveal.html#export-requirements-file",
    "href": "teaching/2023-2024/Programming Level-up/lecture-3-reveal.html#export-requirements-file",
    "title": "Python Modules",
    "section": "Export requirements file",
    "text": "Export requirements file\nLike exporting with conda, pip also includes a method to capture the currently installed environment. In pip, this is called freeze.\nThe common convention is to call the file requirements.txt.\npip freeze &gt; requirements.txt"
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-3-reveal.html#installing-multiple-packages-from-a-requirements-file",
    "href": "teaching/2023-2024/Programming Level-up/lecture-3-reveal.html#installing-multiple-packages-from-a-requirements-file",
    "title": "Python Modules",
    "section": "Installing multiple packages from a requirements file",
    "text": "Installing multiple packages from a requirements file\nIf we want to recreate the environment, we can install multiple packages with specific versions from a requirements file with:\npip install -r requirements.txt"
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-3-reveal.html#anaconda-handles-both-conda-and-pip",
    "href": "teaching/2023-2024/Programming Level-up/lecture-3-reveal.html#anaconda-handles-both-conda-and-pip",
    "title": "Python Modules",
    "section": "Anaconda handles both conda and pip",
    "text": "Anaconda handles both conda and pip\nConda encompasses pip, which means that when you create a virtual environment with conda, it can also include pip. So I would recommend using conda to create the virtual environment and to install packages when you can. But if the package is only available via pip, then it will be okay to install it using pip as well. When you export the environment with conda, it will specify what is installed with pip and what is installed via conda.\nconda env create -f environment.yml\nWhen the environment is re-created with conda, it will install the packages from the correct places, whether that is conda or pip."
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-3-reveal.html#pycharm",
    "href": "teaching/2023-2024/Programming Level-up/lecture-3-reveal.html#pycharm",
    "title": "Python Modules",
    "section": "PyCharm",
    "text": "PyCharm\n\nSo far we have been using a very basic text editor. This editor is only providing us with syntax highlighting (the colouring of keywords, etc) and helping with indentation.\nPyCharm is not a text editor. PyCharm is an Integrated Development Environment (IDE). An IDE is a fully fledged environment for programming in a specific programming language and offers a suite of features that makes programming in a particular language (Python in this case), a lot easier.\nSome of the features of an IDE are typically:\n\nDebugging support with breakpoints and variable inspection.\nPrompts and auto-completion with documentation support.\nBuild tools to run and test programs in various configurations.\n\nWe will use PyCharm for the rest of this course."
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-3-reveal.html#installing-pycharm",
    "href": "teaching/2023-2024/Programming Level-up/lecture-3-reveal.html#installing-pycharm",
    "title": "Python Modules",
    "section": "Installing PyCharm",
    "text": "Installing PyCharm\nUsing Ubuntu snaps:\nsnap install pycharm-community --classic\nOr we can download an archive with the executable. The steps to run goes something like:\ntar xvf pycharm-community-&lt;version&gt;.tar.gz\nbash pycharm-community-&lt;version&gt;/bin/pycharm.sh"
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-3-reveal.html#using-pycharm",
    "href": "teaching/2023-2024/Programming Level-up/lecture-3-reveal.html#using-pycharm",
    "title": "Python Modules",
    "section": "Using PyCharm",
    "text": "Using PyCharm\nWe shall take a look at the following:\n\nCreating a new project.\nSpecifying the conda environment.\nCreating build/run instructions.\nAdding new files/folders.\nDebugging with breakpoints."
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-3-reveal.html#jupyter",
    "href": "teaching/2023-2024/Programming Level-up/lecture-3-reveal.html#jupyter",
    "title": "Python Modules",
    "section": "Jupyter",
    "text": "Jupyter\n\nJupyter notebooks are environments where code is split into cells, where each cell can be executed independently and immediate results can be inspected.\nNotebooks can be very useful for data science projects and exploratory work where the process cannot be clearly defined (and therefore cannot be immediately programmed)."
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-3-reveal.html#installing-jupyter",
    "href": "teaching/2023-2024/Programming Level-up/lecture-3-reveal.html#installing-jupyter",
    "title": "Python Modules",
    "section": "Installing Jupyter",
    "text": "Installing Jupyter\nWe first need to install Jupyter. In you conda environment type:\nconda install jupyter\n# or pip install jupyter"
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-3-reveal.html#starting-the-server",
    "href": "teaching/2023-2024/Programming Level-up/lecture-3-reveal.html#starting-the-server",
    "title": "Python Modules",
    "section": "Starting the server",
    "text": "Starting the server\nWith Jupyter installed, we can now start the notebook server using:\njupyter notebook\nA new browser window will appear. This is the Jupyter interface.\nIf you want to stop the server, press Ctrl+c in the terminal window."
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-3-reveal.html#using-the-interface",
    "href": "teaching/2023-2024/Programming Level-up/lecture-3-reveal.html#using-the-interface",
    "title": "Python Modules",
    "section": "Using the interface",
    "text": "Using the interface\nWe shall take a look at the following:\n\nCreating a new notebook\nDifferent cell types\nExecuting code cells\nMarkdown cells\nExporting to a different format\nHow the notebook gets stored"
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-3-reveal.html#markdown-101",
    "href": "teaching/2023-2024/Programming Level-up/lecture-3-reveal.html#markdown-101",
    "title": "Python Modules",
    "section": "Markdown 101",
    "text": "Markdown 101\nWe will revisit markdown in a later lecture, but since we’re using notebooks, some of the cells can be of a type markdown. In these cells, we can style the text using markdown syntax.\nhttps://www.markdownguide.org/basic-syntax/"
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-3-reveal.html#a-slightly-better-environment-jupyterlab",
    "href": "teaching/2023-2024/Programming Level-up/lecture-3-reveal.html#a-slightly-better-environment-jupyterlab",
    "title": "Python Modules",
    "section": "A slightly better environment – jupyterlab",
    "text": "A slightly better environment – jupyterlab\nThe notebook environment is fine, but there exists another package called jupyter-lab that enhances the environment to include a separate file browser, etc.\nconda install jupyterlab -c conda-forge\n\njupyter-lab"
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-3-reveal.html#a-sense-of-style",
    "href": "teaching/2023-2024/Programming Level-up/lecture-3-reveal.html#a-sense-of-style",
    "title": "Python Modules",
    "section": "A sense of style",
    "text": "A sense of style\nNow that we have looked at syntax you will need to create Python projects, I want to take a minute to talk about the style of writing Python code.\nThis style can help you create projects that can be maintained and understood by others but also yourself.\nPython itself also advocates for an adherence to a particular style of writing Python code with the PEP8 style guide: https://www.python.org/dev/peps/pep-0008/. Though, I will talk through some of the most important ones, in my opinion."
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-3-reveal.html#meaningful-names",
    "href": "teaching/2023-2024/Programming Level-up/lecture-3-reveal.html#meaningful-names",
    "title": "Python Modules",
    "section": "Meaningful names",
    "text": "Meaningful names\n\n\n\nWhat does this code do?\ndef f(l):\n    x = 0\n    y = 0\n    for i in l:\n        x += i\n        y += 1\n    return x / y\n\na = range(100)\nr = f(a)\n\n\n\nWhat about this one?\ndef compute_average(list_of_data):\n    sum = 0\n    num_elements = 0\n    for element in list_of_data:\n        sum += element\n        num_elements += 1\n    return sum / num_elements\n\ndataset = range(100)\naverage_value = compute_average(dataset)\n\n\n\nThey are both the same code, but the second version is a lot more readable and understandable because we have used meaningful names for things!"
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-3-reveal.html#use-builtins-where-possible",
    "href": "teaching/2023-2024/Programming Level-up/lecture-3-reveal.html#use-builtins-where-possible",
    "title": "Python Modules",
    "section": "Use builtins where possible",
    "text": "Use builtins where possible\nDon’t re-invent the wheel. Try to use Python’s built-in functions/classes if they exist, they will normally be quicker and more accurate than what you could make in Python itself. For example:\ndataset = range(100)\naverage_value = sum(dataset) / len(dataset)\n\nor maybe even:\nimport numpy as np\ndataset = range(100)\naverage_value = np.mean(dataset)"
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-3-reveal.html#use-docstrings-and-comments",
    "href": "teaching/2023-2024/Programming Level-up/lecture-3-reveal.html#use-docstrings-and-comments",
    "title": "Python Modules",
    "section": "Use docstrings and comments",
    "text": "Use docstrings and comments\ndef compute_average(list_of_data, exclude=None):\n    \"\"\"\n    Compute and return the average value of an iterable list. \n    This average excludes any value if specified by exclude\n\n    params: \n    - list_of_data: data for which the average is computed \n    - exclude: numeric value of values that should not be taken \n        into account\n\n    returns: \n    The computed average, possibly excluding a value.\n    \"\"\"\n    sum = 0\n    num_elements = 0\n    for element in list_of_data:\n        if exclude is not None and element == exclude:\n            continue  # skip this element\n        sum += element\n        num_elements += 1\n    return sum / num_elements"
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-3-reveal.html#using-agreed-upon-casing",
    "href": "teaching/2023-2024/Programming Level-up/lecture-3-reveal.html#using-agreed-upon-casing",
    "title": "Python Modules",
    "section": "Using agreed upon casing",
    "text": "Using agreed upon casing\n\nsnake_casing for functions and variables\nClasses should use CamelCasing\n\ndef this_if_a_function(data_x, data_y):\nclass BookEntry:"
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-3-reveal.html#use-type-annotations-if-possible",
    "href": "teaching/2023-2024/Programming Level-up/lecture-3-reveal.html#use-type-annotations-if-possible",
    "title": "Python Modules",
    "section": "Use type-annotations if possible",
    "text": "Use type-annotations if possible\nType annotations can helper your editor (such as PyCharm) find potential issues in your code. If you use type annotations, the editor can spot types that are not compatible. For example, a string being used with a division.\nhttps://docs.python.org/3/library/typing.html https://realpython.com/python-type-checking/\ndef compute_average(list_of_data: list[int],\n                    exclude: Optional[int] = None) -&gt; float:\n    ..."
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-3-reveal.html#organise-your-imports",
    "href": "teaching/2023-2024/Programming Level-up/lecture-3-reveal.html#organise-your-imports",
    "title": "Python Modules",
    "section": "Organise your imports",
    "text": "Organise your imports\nMake the distinction between standard library imports, externally installed imports, and your own custom imports.\n# internal imports\nimport os\nfrom math import pi\n\n# external imports\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\n# custom imports\nfrom src.my_module import DAGs"
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-3-reveal.html#functions-should-do-one-thing-only",
    "href": "teaching/2023-2024/Programming Level-up/lecture-3-reveal.html#functions-should-do-one-thing-only",
    "title": "Python Modules",
    "section": "Functions should do one thing only",
    "text": "Functions should do one thing only\nDo one thing and do it well. Docstrings can help you understand what your function is doing, especially if you use the word ‘and’ in the docstring, you might want to think about breaking your single function into many parts."
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-3-reveal.html#functions-as-re-usability",
    "href": "teaching/2023-2024/Programming Level-up/lecture-3-reveal.html#functions-as-re-usability",
    "title": "Python Modules",
    "section": "Functions as re-usability",
    "text": "Functions as re-usability\nIf you find yourself doing something over and over, a function call help consolidate duplication and potentially reduce the chance of getting things wrong.\n\nprint(\"The result is \", w * x1 + b)\nprint(\"The result is \", w * x2 + b)\nprint(\"The result is \", w * x3 + b)\n\n\ndef compute(var):\n    return w * var + b\n\ndef print_result(res):\n    print(\"The result is \", res)\n\nfor var in [x1, x2, x3]:\n    print_result(compute(var))"
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-3-reveal.html#be-wary-of-god-classes",
    "href": "teaching/2023-2024/Programming Level-up/lecture-3-reveal.html#be-wary-of-god-classes",
    "title": "Python Modules",
    "section": "Be wary of God classes",
    "text": "Be wary of God classes\nGod classes/God object is a class that is doing too many things or ‘knows’ about too much. When designing a class, remember that like a function, in general, it should manage one thing or concept.\n\n\n\nclass Game:\n    def __init__(self):\n        ...\n    def create_character(self):\n        ...\n    def move_character(self):\n        ...\n    def update_score(self):\n        ...\n    def reset_score(self):\n        ...\n    def start_game(self):\n        ...\n    def end_game(self):\n        ...\n    def start_boat(self):\n        ...\n    def stop_boat(self):\n        ...\n    ...\n\n\n\nclass Game:\n    def __init__(self):\n        ...\n    def start_game(self):\n        ...\n    def end_game(self):\n        ...\n\nclass Character:\n    def __init__(self):\n        ...\n    def create_character(self):\n        ...\n    def move_character(self):\n        ...\n\nclass ScoreBoard:\n    ..."
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-3-reveal.html#documentation",
    "href": "teaching/2023-2024/Programming Level-up/lecture-3-reveal.html#documentation",
    "title": "Python Modules",
    "section": "Documentation",
    "text": "Documentation\n\nComments that contradict the code are worse than no comments. Always make a priority of keeping the comments up-to-date when the code changes!\n\nPEP 8 Style Guide\n\nEnsure that comments are correct.\nDon’t over document (i.e. if something is self explanatory, then comments will distract rather than inform). An example from PEP 8:\n\nx = x + 1                 # Increment x\nx = x + 1                 # Compensate for border\n\nDocument what you think will be difficult to understand without some prior knowledge, such as why a particular decision was made to do something a certain way. Don’t explain, educate the reader."
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-3-reveal.html#perform-testing",
    "href": "teaching/2023-2024/Programming Level-up/lecture-3-reveal.html#perform-testing",
    "title": "Python Modules",
    "section": "Perform testing!",
    "text": "Perform testing!\nMake sure to write tests, for example, using unittest (https://docs.python.org/3/library/unittest.html). Writing tests can help find source of bugs/mistakes in your code, and if you change something in the future, you want to make sure that it still works. Writing tests can automate the process of testing your code."
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-3.html",
    "href": "teaching/2023-2024/Programming Level-up/lecture-3.html",
    "title": "Python Modules",
    "section": "",
    "text": "https://xkcd.com/353/\n\n\n\nModules or packages are other scripts or programs that can be imported into other scripts. This definition is very general, but we shall see how flexible importing in Python can be.\nThe basic syntax of importing is:\nimport &lt;package_name&gt;\n\n&lt;package_name&gt;.&lt;function/class/variable/etc&gt;\nIf we import &lt;package_name&gt; using this syntax, we always have to use the dot . syntax to refer to something within this package.\nLet’s take a look at a very basic example.\nimport math\n\nradius = 6.4  # cm\ncircum = 2 * math.pi * radius\nIn this example, we are importing the built-in math package. This package contains a bunch of useful functions and variables. We’re not going to take a look at them here, as we’re focusing on importing, but you can see we’re referring to a variable called pi to calculate the circumference of a circle.\n\n\n\nIf we didn’t always want to specify the package name when we only want to use something specific from a package, we can directly import that something.\nfrom &lt;package_name&gt; import &lt;function/class/variable/etc&gt;\n\n&lt;function/class/variable/etc&gt;\nAs you can see, we’re using the from ... import ... syntax.\nfrom math import pi\n\ncircumference = 2 * pi * radius\n\n\n\nWhen using from ... import ..., there is a wildcard * that we could use. You may sometimes see this style of importing when looking at documentation online:\nfrom &lt;package_name&gt; import *\n\n&lt;function/class/variable/etc&gt;\nHowever, this can create many problems with reading your program code\nWhich module does my_function() originate? Are there are common names between the two? Which would be used?\nfrom my_module import *\nfrom my_second_module import *\n\nmy_function()\n\n\n\nWhen importing, we can optionally create an alias to a symbol. Here we’re creating an alias to the existing pi in math.\nfrom math import pi as decilious_pi\n\ncircumference = 2 * delicious_pi * radius\nThere are some very common conventions of aliasing very highly used packages that we will definitely revisit in another lecture!\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\n\n\nlet’s consider a hypothetical local directory:\n    main.py\n    src/\n     |-- my_module.py\n     |-- module_1/\n            |-- cats.py\n            |-- dogs.py\nIf we wanted to import something from my_module.py we would do:\nfrom src.my_module import MyAwesomeClass\n\nmy_class = MyAwesomeclass()\nHere is another example for increased nesting of directories:\n    main.py\n    src/\n     |-- my_module.py\n     |-- module_1/\n            |-- cats.py\n            |-- dogs.py\nfrom src.module_1 import cats\nfrom src.module_1.dogs import Dog\n\ncat = cats.Cat()\ndog = Dog()\n\n\n\n\nCreate a directory to store your scripts\nIn this directory, create a file called main.py.\nCreate a sub-directory called src. In src create another file called library.py.\nIn library.py create a class (that doesn’t do anything right now) called Database.\nIn main.py, create an instance of Database.\n\n\n\n\nLet’s say you often import Cat and Dog. We can use a file called __init__.py to help us and make the imports shorter. This fill gets executed when its module is imported.\n    main.py\n    src/\n     |-- my_module.py\n     |-- module_1/\n            |-- __init__.py\n            |-- cats.py\n            |-- dogs.py\nIn __init__.py:\nfrom cats import Cat\nfrom dogs import Dog\nIn main.py:\nfrom src.module_1 import Cat, Dog\n\n\n\nConsider a file with the following:\nx = 2\ny = 1\nz = x + y\n\nclass MyAwesomeClass:\n...\nIf we import this file in another script, x, y, and z will be computed. In this very simple case this will have very little impact. But what if the computation of these takes a very long time?\nHere we are wrapping any global computations into a appropriate functions. This prevents the global variables being computed as soon as the script is imported.\nNow, if we wanted to compute x, y, and z if this script is run, we could use:\nif __name__ == \"__main__\":\n# do something\nAnything within the scope of the if function will only be run if the current file is the script that is being run directly (i.e. python &lt;the-file&gt;.py). If the script is being imported, the statements within this if scope will not be run.\nSo if we wanted to run compute() if this file is being run directly, we would write:\ndef compute():\n    x = 2\n    y = 1\n    z = x + y\n\nclass MyAwesomeClass:\n    ...\n    \nif __name__ == \"__main__\":\n    compute()\n    # we can of course use MyAwesomeClass as well\n    my_class = MyAwesomeClass()\n    my_class.do_something()"
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-3.html#importing-in-python",
    "href": "teaching/2023-2024/Programming Level-up/lecture-3.html#importing-in-python",
    "title": "Python Modules",
    "section": "",
    "text": "https://xkcd.com/353/"
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-3.html#the-basic-structure-of-importing",
    "href": "teaching/2023-2024/Programming Level-up/lecture-3.html#the-basic-structure-of-importing",
    "title": "Python Modules",
    "section": "",
    "text": "Modules or packages are other scripts or programs that can be imported into other scripts. This definition is very general, but we shall see how flexible importing in Python can be.\nThe basic syntax of importing is:\nimport &lt;package_name&gt;\n\n&lt;package_name&gt;.&lt;function/class/variable/etc&gt;\nIf we import &lt;package_name&gt; using this syntax, we always have to use the dot . syntax to refer to something within this package.\nLet’s take a look at a very basic example.\nimport math\n\nradius = 6.4  # cm\ncircum = 2 * math.pi * radius\nIn this example, we are importing the built-in math package. This package contains a bunch of useful functions and variables. We’re not going to take a look at them here, as we’re focusing on importing, but you can see we’re referring to a variable called pi to calculate the circumference of a circle."
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-3.html#importing-specific-items",
    "href": "teaching/2023-2024/Programming Level-up/lecture-3.html#importing-specific-items",
    "title": "Python Modules",
    "section": "",
    "text": "If we didn’t always want to specify the package name when we only want to use something specific from a package, we can directly import that something.\nfrom &lt;package_name&gt; import &lt;function/class/variable/etc&gt;\n\n&lt;function/class/variable/etc&gt;\nAs you can see, we’re using the from ... import ... syntax.\nfrom math import pi\n\ncircumference = 2 * pi * radius"
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-3.html#dont-do-this",
    "href": "teaching/2023-2024/Programming Level-up/lecture-3.html#dont-do-this",
    "title": "Python Modules",
    "section": "",
    "text": "When using from ... import ..., there is a wildcard * that we could use. You may sometimes see this style of importing when looking at documentation online:\nfrom &lt;package_name&gt; import *\n\n&lt;function/class/variable/etc&gt;\nHowever, this can create many problems with reading your program code\nWhich module does my_function() originate? Are there are common names between the two? Which would be used?\nfrom my_module import *\nfrom my_second_module import *\n\nmy_function()"
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-3.html#alias",
    "href": "teaching/2023-2024/Programming Level-up/lecture-3.html#alias",
    "title": "Python Modules",
    "section": "",
    "text": "When importing, we can optionally create an alias to a symbol. Here we’re creating an alias to the existing pi in math.\nfrom math import pi as decilious_pi\n\ncircumference = 2 * delicious_pi * radius\nThere are some very common conventions of aliasing very highly used packages that we will definitely revisit in another lecture!\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt"
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-3.html#importing-local-libraries",
    "href": "teaching/2023-2024/Programming Level-up/lecture-3.html#importing-local-libraries",
    "title": "Python Modules",
    "section": "",
    "text": "let’s consider a hypothetical local directory:\n    main.py\n    src/\n     |-- my_module.py\n     |-- module_1/\n            |-- cats.py\n            |-- dogs.py\nIf we wanted to import something from my_module.py we would do:\nfrom src.my_module import MyAwesomeClass\n\nmy_class = MyAwesomeclass()\nHere is another example for increased nesting of directories:\n    main.py\n    src/\n     |-- my_module.py\n     |-- module_1/\n            |-- cats.py\n            |-- dogs.py\nfrom src.module_1 import cats\nfrom src.module_1.dogs import Dog\n\ncat = cats.Cat()\ndog = Dog()"
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-3.html#quick-exercise-imports",
    "href": "teaching/2023-2024/Programming Level-up/lecture-3.html#quick-exercise-imports",
    "title": "Python Modules",
    "section": "",
    "text": "Create a directory to store your scripts\nIn this directory, create a file called main.py.\nCreate a sub-directory called src. In src create another file called library.py.\nIn library.py create a class (that doesn’t do anything right now) called Database.\nIn main.py, create an instance of Database."
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-3.html#shortcuts-with-__init__.py",
    "href": "teaching/2023-2024/Programming Level-up/lecture-3.html#shortcuts-with-__init__.py",
    "title": "Python Modules",
    "section": "",
    "text": "Let’s say you often import Cat and Dog. We can use a file called __init__.py to help us and make the imports shorter. This fill gets executed when its module is imported.\n    main.py\n    src/\n     |-- my_module.py\n     |-- module_1/\n            |-- __init__.py\n            |-- cats.py\n            |-- dogs.py\nIn __init__.py:\nfrom cats import Cat\nfrom dogs import Dog\nIn main.py:\nfrom src.module_1 import Cat, Dog"
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-3.html#what-is-__main__",
    "href": "teaching/2023-2024/Programming Level-up/lecture-3.html#what-is-__main__",
    "title": "Python Modules",
    "section": "",
    "text": "Consider a file with the following:\nx = 2\ny = 1\nz = x + y\n\nclass MyAwesomeClass:\n...\nIf we import this file in another script, x, y, and z will be computed. In this very simple case this will have very little impact. But what if the computation of these takes a very long time?\nHere we are wrapping any global computations into a appropriate functions. This prevents the global variables being computed as soon as the script is imported.\nNow, if we wanted to compute x, y, and z if this script is run, we could use:\nif __name__ == \"__main__\":\n# do something\nAnything within the scope of the if function will only be run if the current file is the script that is being run directly (i.e. python &lt;the-file&gt;.py). If the script is being imported, the statements within this if scope will not be run.\nSo if we wanted to run compute() if this file is being run directly, we would write:\ndef compute():\n    x = 2\n    y = 1\n    z = x + y\n\nclass MyAwesomeClass:\n    ...\n    \nif __name__ == \"__main__\":\n    compute()\n    # we can of course use MyAwesomeClass as well\n    my_class = MyAwesomeClass()\n    my_class.do_something()"
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-3.html#current-working-directory",
    "href": "teaching/2023-2024/Programming Level-up/lecture-3.html#current-working-directory",
    "title": "Python Modules",
    "section": "Current working directory",
    "text": "Current working directory\nThe folder in which you run Python will be the current working directory (CWD). We can print this value with the os.getcwd() function, or change the directory with os.chdir(...). Its important to know what your CWD is as all relative paths (paths that do not start with a ‘/’) will be relative to your CWD.\nimport os\n\nprint(os.getcwd())\nos.chdir(\"../\")\nprint(os.getcwd())\nos.chdir(\"week-3\")`\nResults: \n# =&gt; [...]/Programming Level-up/week-3\n# =&gt; [...]/Programming Level-up\nI’ve replaced the full path printed by Python with [...] so you can see the differences in the paths!"
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-3.html#listing-directories",
    "href": "teaching/2023-2024/Programming Level-up/lecture-3.html#listing-directories",
    "title": "Python Modules",
    "section": "Listing directories",
    "text": "Listing directories\nContinuing with our usage of the os package, we can use the listdir function to list all files within a directory.\nprint(os.listdir())\nprint(os.listdir(\"images/\"))\nResults: \n# =&gt; ['images', '__pycache__', 'lecture.pdf', 'lecture.tex', 'data', 'test_file_1.py', 'lecture.org', '_minted-lecture', 'test_file_2.py']\n# =&gt; ['legend-2.png', 'fig-size.png', 'basic.png', 'subplots.png', 'python.png', 'pycharm01.png', 'installing-scikit-learn.png', 'pycharm02.png', 'PyCharm_Icon.png', 'axis.png', 'legend.png', 'complex-pycharm.jpg']\nThis returns a list of files and directory relative to your current working directory. Notice how from this list you cannot tell if something is a file or directory (though the filename does provide some hint)."
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-3.html#testing-for-files-or-directories",
    "href": "teaching/2023-2024/Programming Level-up/lecture-3.html#testing-for-files-or-directories",
    "title": "Python Modules",
    "section": "Testing for files or directories",
    "text": "Testing for files or directories\nIn the previous example we saw that the items returned by listdir does not specify if the item is a file or directory. However, os provides an isfile function in the path submodule to test if the argument is a file, else it will be a directory.\nfor path in os.listdir():\n    print(f\"{path} =&gt; is file: {os.path.isfile(path)}\")\nResults: \n# =&gt; images =&gt; is file: False\n# =&gt; __pycache__ =&gt; is file: False\n# =&gt; lecture.pdf =&gt; is file: True\n# =&gt; lecture.tex =&gt; is file: True\n# =&gt; data =&gt; is file: False\n# =&gt; test_file_1.py =&gt; is file: True\n# =&gt; lecture.org =&gt; is file: True\n# =&gt; _minted-lecture =&gt; is file: False\n# =&gt; test_file_2.py =&gt; is file: True"
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-3.html#using-wildcards",
    "href": "teaching/2023-2024/Programming Level-up/lecture-3.html#using-wildcards",
    "title": "Python Modules",
    "section": "Using wildcards",
    "text": "Using wildcards\nIf we wanted to get all files within a directory, we could use the glob function from the glob package. glob allows us to use the * wildcard. E.g. *.png will list all files that end with .png. test-* will list all files that start with test-*.\nfrom glob import glob\n\nfor fn in glob(\"images/*\"):\n    print(fn)\nResults: \n# =&gt; images/legend-2.png\n# =&gt; images/fig-size.png\n# =&gt; images/basic.png\n# =&gt; images/subplots.png\n# =&gt; images/python.png\n# =&gt; images/pycharm01.png\n# =&gt; images/installing-scikit-learn.png\n# =&gt; images/pycharm02.png\n# =&gt; images/PyCharm_Icon.png\n# =&gt; images/axis.png\n# =&gt; images/legend.png\n# =&gt; images/complex-pycharm.jpg"
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-3.html#pathlib-a-newer-way",
    "href": "teaching/2023-2024/Programming Level-up/lecture-3.html#pathlib-a-newer-way",
    "title": "Python Modules",
    "section": "Pathlib – a newer way",
    "text": "Pathlib – a newer way\npathlib is a somewhat recent addition to the Python standard library which makes working with files a little easier. Firstly, we can create a Path object, allowing us to concatenate paths with the /. Instead of using the glob module, a Path object has a glob class method.\nfrom pathlib import Path\n\ndata_dir = Path(\"data\")\nprocessed_data = data_dir / \"processed\"\n\ndata_files = processed_data.glob(\"*.txt\")\n\nfor data_file in data_files:\n    print(data_file)\nResults: \n# =&gt; data/processed/data-2.txt\n# =&gt; data/processed/data.txt"
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-3.html#pathlib-convenient-functions",
    "href": "teaching/2023-2024/Programming Level-up/lecture-3.html#pathlib-convenient-functions",
    "title": "Python Modules",
    "section": "Pathlib – convenient functions",
    "text": "Pathlib – convenient functions\npathlib allows us to easily decompose a path into different components. Take for example getting the filename of a path with .name.\nfrom pathlib import Path\n\nsome_file = Path(\"data/processed/data.txt\")\n\nprint(some_file.parts)  # get component parts\nprint(some_file.parents[0])  # list of parent dirs\nprint(some_file.name)   # only filename\nprint(some_file.suffix) # extension\nResults: \n# =&gt; ('data', 'processed', 'data.txt')\n# =&gt; data/processed\n# =&gt; data.txt\n# =&gt; .txt"
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-3.html#converting-path-into-a-string",
    "href": "teaching/2023-2024/Programming Level-up/lecture-3.html#converting-path-into-a-string",
    "title": "Python Modules",
    "section": "Converting Path into a string",
    "text": "Converting Path into a string\nAs pathlib is a recent addition to Python, some functions/classes are expecting a str representation of the path, not a Path object. Therefore, you may want to use the str function to convert a Path object to a string.\nstr(Path(\"data/\"))\nResults: \n# =&gt; 'data'"
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-3.html#quick-exercise-locating-files",
    "href": "teaching/2023-2024/Programming Level-up/lecture-3.html#quick-exercise-locating-files",
    "title": "Python Modules",
    "section": "Quick exercise – locating files",
    "text": "Quick exercise – locating files\n\nIn the same directory of scripts you created in the last exercise, create another directory called data.\nIn data, create 3 text files, calling them &lt;book_name&gt;.txt.\nThese each text file should contain the information from table below in the format:\nName:  Author:  Release Year: \n\n\n\n\n\n\n\n\n\n\nTitle\n\n\nAuthor\n\n\nRelease Date\n\n\n\n\n\n\nMoby Dick\n\n\nHerman Melville\n\n\n1851\n\n\n\n\nA Study in Scarlet\n\n\nSir Arthur Conan Doyle\n\n\n1887\n\n\n\n\nFrankenstein\n\n\nMary Shelley\n\n\n1818\n\n\n\n\nHitchhikers Guide to the Galaxy\n\n\nDouglas Adams\n\n\n1979\n\n\n\n\n\nFrom main.py, print out all of the text files in the directory."
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-3.html#reading-files",
    "href": "teaching/2023-2024/Programming Level-up/lecture-3.html#reading-files",
    "title": "Python Modules",
    "section": "Reading files",
    "text": "Reading files\nTo read a file, we must first open it with the open function. This returns a file stream to which we can call the read() class method.\nYou should always make sure to call the close() class method on this stream to close the file.\nread() reads the entire contents of the file and places it into a string.\nopen_file = open(str(Path(\"data\") / \"processed\" / \"data.txt\"))\ncontents_of_file = open_file.read()\nopen_file.close()  # should always happen!\nprint(contents_of_file)\nResults: \n# =&gt; this is some data\n# =&gt; on another line"
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-3.html#reading-files-lines-or-entire-file",
    "href": "teaching/2023-2024/Programming Level-up/lecture-3.html#reading-files-lines-or-entire-file",
    "title": "Python Modules",
    "section": "Reading files – lines or entire file?",
    "text": "Reading files – lines or entire file?\nWhile read works for the last example, you may want to read files in different ways. Luckily there are a number of methods you could use.\nopen_file.read()       # read entire file\nopen_file.readline()   # read a single line\nopen_file.readline(5)  # read 5 lines\nopen_file.readlines()  # returns all lines as a list\n\nfor line in open_file:  # read one line at a time\n    do_something(line)"
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-3.html#the-with-keyword",
    "href": "teaching/2023-2024/Programming Level-up/lecture-3.html#the-with-keyword",
    "title": "Python Modules",
    "section": "The with keyword",
    "text": "The with keyword\nIt can be a pain to remember to use the .close() every time you open a file. In Python, we can use open() as a context with the with keyword. This context will handle the closing of the file as soon as the scope is exited.\nThe syntax for opening a file is as follows:\nwith open(\"data/processed/data.txt\", \"r\") as open_file:\n    contents = open_file.read()\n\n# the file is automatically closed at this point\n\n    print(contents)\nResults: \n# =&gt; this is some data\n# =&gt; on another line"
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-3.html#writing-files",
    "href": "teaching/2023-2024/Programming Level-up/lecture-3.html#writing-files",
    "title": "Python Modules",
    "section": "Writing files",
    "text": "Writing files\nThe syntax for writing a file is similar to reading a file. The main difference is the use \"w\" instead of \"r\" in the second argument of open. Also, instead of read(), we use write().\ndata = [\"this is some data\", \"on another line\", \"with another line\"]\nnew_filename = \"data/processed/new-data.txt\"\n\nwith open(new_filename, \"w\") as open_file:\n    for line in data:\n        open_file.write(line + \"\\n\")\n\nwith open(new_filename, \"r\") as open_file:\n    new_contents = open_file.read()\n\nprint(new_contents)\nResults: \n# =&gt; this is some data\n# =&gt; on another line\n# =&gt; with another line"
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-3.html#appending-to-files",
    "href": "teaching/2023-2024/Programming Level-up/lecture-3.html#appending-to-files",
    "title": "Python Modules",
    "section": "Appending to files",
    "text": "Appending to files\nEvery time we write to a file, the entire contents is deleted and replaced. If we want to just append to the file instead, we use \"a\".\ndata = [\"this is some appended data\"]\nnew_filename = \"data/processed/new-data.txt\"\n\nwith open(new_filename, \"a\") as open_file:\n    for line in data:\n        open_file.write(line + \"\\n\")\n\nwith open(new_filename, \"r\") as open_file:\n    new_contents = open_file.read()\n\nprint(new_contents)\nResults: \n# =&gt; this is some data\n# =&gt; on another line\n# =&gt; with another line\n# =&gt; this is some appended data"
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-3.html#quick-exercise-readingwriting-files",
    "href": "teaching/2023-2024/Programming Level-up/lecture-3.html#quick-exercise-readingwriting-files",
    "title": "Python Modules",
    "section": "Quick exercise – reading/writing files",
    "text": "Quick exercise – reading/writing files\n\nUsing the same text files from the previous exercise, we will want to be able to read each text file, and parse the information contained in the file.\nThe output of reading each of the text files should be a list of dictionaries, like we have seen in previous lectures.\nWe will go through a sample solution together once you’ve had the chance to try it for yourself."
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-3.html#reading-csv-files-builtin",
    "href": "teaching/2023-2024/Programming Level-up/lecture-3.html#reading-csv-files-builtin",
    "title": "Python Modules",
    "section": "Reading CSV files – builtin",
    "text": "Reading CSV files – builtin\nWhen working with common file types, Python has built-in modules to make the process a little easier. Take, for example, reading and writing a CSV file. Here we are importing the csv module and in the context of reading the file, we are creating a CSV reader object. When reading, every line of the CSV file is returned as a list, thus an entire CSV file is a list of lists.\nimport csv  # built-in library\n\ndata_path = \"data/processed/data.csv\"\n\n# read a csv\nwith open(data_path, \"r\") as csv_file:\n    csv_reader = csv.reader(csv_file, delimiter=\",\")\n    for line in csv_reader:\n        print(line)\nResults: \n# =&gt; ['name', 'id', 'age']\n# =&gt; ['jane', '01', '35']\n# =&gt; ['james', '02', '50']"
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-3.html#writing-a-csv-file-builtin",
    "href": "teaching/2023-2024/Programming Level-up/lecture-3.html#writing-a-csv-file-builtin",
    "title": "Python Modules",
    "section": "Writing a CSV file – builtin",
    "text": "Writing a CSV file – builtin\nWriting a CSV file is similar except we are creating a CSV writer object, and are using writerow instead.\n# write a csv file\nnew_data_file = \"data/processed/new-data.csv\"\nnew_data = [[\"name\", \"age\", \"height\"], [\"jane\", \"35\", \"6\"]]\n\nwith open(new_data_file, \"w\") as csv_file:\n  csv_writer = csv.writer(csv_file, delimiter=\",\")\n  for row in new_data:\n      csv_writer.writerow(row)"
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-3.html#quick-exercise-readingwriting-csv-files",
    "href": "teaching/2023-2024/Programming Level-up/lecture-3.html#quick-exercise-readingwriting-csv-files",
    "title": "Python Modules",
    "section": "Quick exercise – reading/writing CSV files",
    "text": "Quick exercise – reading/writing CSV files\n\nGiven the parsed data from the previous exercise, write a new CSV file in the data directory.\nThis CSV file should contain the headings: name, author, releasedata.\nThe data in the CSV file should be the 3 books with data in the correct columns.\nTest that you can read this same CSV file in python."
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-3.html#read-json-files-builtin",
    "href": "teaching/2023-2024/Programming Level-up/lecture-3.html#read-json-files-builtin",
    "title": "Python Modules",
    "section": "Read JSON files – builtin",
    "text": "Read JSON files – builtin\nLike CSV, json is a common format for storing data. Python includes a package called json that enables us to read/write to json files with ease.\nLet’s first tackle the process of reading:\nimport json\n\njson_file_path = \"data/processed/data.json\"\n\n# read a json file\nwith open(json_file_path, \"r\") as json_file:\n    data = json.load(json_file)\n    print(data)\n    print(data.keys())\n    print(data[\"names\"])\nResults: \n# =&gt; {'names': ['jane', 'james'], 'ages': [35, 50]}\n# =&gt; dict_keys(['names', 'ages'])\n# =&gt; ['jane', 'james']"
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-3.html#write-json-files-builtin",
    "href": "teaching/2023-2024/Programming Level-up/lecture-3.html#write-json-files-builtin",
    "title": "Python Modules",
    "section": "Write JSON files – builtin",
    "text": "Write JSON files – builtin\nWhile we used json.load to read the file, we use json.dump to write the data to a json file.\nnew_data = {\"names\": [\"someone-new\"], \"ages\": [\"NA\"]}\n\n# write a json file\nwith open(\"data/processed/new-data.json\", \"w\") as json_file:\n    json.dump(new_data, json_file)\n\nwith open(\"data/processed/new-data.json\", \"r\") as json_file:\n    print(json.load(json_file))`\nResults: \n# =&gt; {'names': ['someone-new'], 'ages': ['NA']}"
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-3.html#virtual-environments",
    "href": "teaching/2023-2024/Programming Level-up/lecture-3.html#virtual-environments",
    "title": "Python Modules",
    "section": "Virtual Environments",
    "text": "Virtual Environments\nWhen installing packages, by default, the packages are going to be installed into the system-level Python. This can be a problem, for example, if you’re working on multiple projects that require different versions of packages.\nVirtual environments are ‘containerised’ versions of Python that can be created for each different project you’re working on.\nWe will take a look at package management and virtual environments in Python."
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-3.html#anaconda",
    "href": "teaching/2023-2024/Programming Level-up/lecture-3.html#anaconda",
    "title": "Python Modules",
    "section": "Anaconda",
    "text": "Anaconda\n\n\n\n\n\n\nDistribution of Python and R designed for scientific computing.\nWe’re going to focus on Conda, a package manager in the Anaconda ecosystem.\nHelps with package management and deployment.\nCreate virtual environments to install packages to avoid conflicts with other projects"
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-3.html#installing-anaconda",
    "href": "teaching/2023-2024/Programming Level-up/lecture-3.html#installing-anaconda",
    "title": "Python Modules",
    "section": "Installing Anaconda",
    "text": "Installing Anaconda\nWe’re going to install miniconda (a minimal installation of anaconda). https://docs.conda.io/en/latest/miniconda.html\nThe steps to install Miniconda are roughly:\n\nDownload Miniconda3 Linux 64-bit\nSave the file to the disk\nOpen up a terminal and run the following commands:\n\n    chmod +x &lt;miniconda-file&gt;.sh\n    ./&lt;miniconda-file&gt;.sh\nFollow the installation instructions (most of the time the defaults are sensible)."
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-3.html#creating-an-environment",
    "href": "teaching/2023-2024/Programming Level-up/lecture-3.html#creating-an-environment",
    "title": "Python Modules",
    "section": "Creating an environment",
    "text": "Creating an environment\nConda is a command line tool to manage environments. We’re going to highlight some of the most used commands. But for the full list of management, you can use the instructions at: https://conda.io/projects/conda/en/latest/user-guide/tasks/manage-environments.html\nIf you’re creating a brand new environment, use:\nconda create --name &lt;name-of-env&gt;\nThis will prompt you to confirm you want to create a new environment, whereupon you enter either a y or n. If y your new environment will be created, but start using the environment, you will first have to activate it."
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-3.html#activating-an-environment",
    "href": "teaching/2023-2024/Programming Level-up/lecture-3.html#activating-an-environment",
    "title": "Python Modules",
    "section": "Activating an environment",
    "text": "Activating an environment\nOnce you’ve created a new environment, you can activate it. This is as simple as:\nconda activate &lt;name-of-env&gt;\nYou will notice that your command line prompt has changed from (base) to (&lt;name-of-env&gt;). And whenever you start a new terminal it will always be (base)."
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-3.html#de-activating-an-environment",
    "href": "teaching/2023-2024/Programming Level-up/lecture-3.html#de-activating-an-environment",
    "title": "Python Modules",
    "section": "De-activating an environment",
    "text": "De-activating an environment\nTo deactivate an environment, just use:\nconda deactivate\nor:\nconda activate base"
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-3.html#installing-using-conda",
    "href": "teaching/2023-2024/Programming Level-up/lecture-3.html#installing-using-conda",
    "title": "Python Modules",
    "section": "Installing using conda",
    "text": "Installing using conda\nLet’s say we want to install a package, say scikit-learn (if we’re doing some data processing or machine learning). To install this package in conda, use:\nconda install scikit-learn\nConda will then check what packages are needed for scikit-learn to work, and figure out if anything needs to be upgraded/downgraded to match the required dependencies of other packages.\nWhen Conda has finalised what packages need to change, it will tell you these changes and ask to confirm. If everything seems okay type y, and enter.\nscikit-learn is a package in the anaconda repository. For a list of packages, you can use: https://anaconda.org/anaconda/repo"
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-3.html#package-versions",
    "href": "teaching/2023-2024/Programming Level-up/lecture-3.html#package-versions",
    "title": "Python Modules",
    "section": "Package versions",
    "text": "Package versions\nconda install &lt;package-name&gt;=&lt;version-number&gt;"
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-3.html#installing-a-specific-version-of-python",
    "href": "teaching/2023-2024/Programming Level-up/lecture-3.html#installing-a-specific-version-of-python",
    "title": "Python Modules",
    "section": "Installing a specific version of Python",
    "text": "Installing a specific version of Python\nIf we wanted to, we could also change the python version being used in the virtual environment.\nconda install python=3.9\nThis will try to install Python version 3.9 providing that the packages you already have installed support it."
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-3.html#conda-forge-and-other-repositories",
    "href": "teaching/2023-2024/Programming Level-up/lecture-3.html#conda-forge-and-other-repositories",
    "title": "Python Modules",
    "section": "Conda-forge and other repositories",
    "text": "Conda-forge and other repositories\nLet’s say that the package is not within the basic anaconda repository. You can specify another repository or channel using the -c flag.\nconda install -c &lt;channel&gt; &lt;package&gt;\nFor example, PyTorch (https://pytorch.org/) uses their own channel:\nconda install -c pytorch pytorch"
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-3.html#exporting-an-environment",
    "href": "teaching/2023-2024/Programming Level-up/lecture-3.html#exporting-an-environment",
    "title": "Python Modules",
    "section": "Exporting an environment",
    "text": "Exporting an environment\nWe will want to share our research and work with others. To allow others to use the exact same packages and especially the versions of packages we’re using, we want to export a snapshot of our environment. Conda includes an export command to do just this:\nconda env export --no-builds &gt; environment.yml\nHere we exporting our currently activated environment to a file called environment.yml (common convention) file. I am using the --no-builds flag to improve compatibility with other operating systems such as Mac OS."
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-3.html#reproducing-an-environment",
    "href": "teaching/2023-2024/Programming Level-up/lecture-3.html#reproducing-an-environment",
    "title": "Python Modules",
    "section": "Reproducing an environment",
    "text": "Reproducing an environment\nTo create an environment from an existing environment.yml file, you can use the following command:\nconda env create -f environment.yml\nThis will create an environment with the same name and install the same versions of the packages."
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-3.html#deleting-an-environment",
    "href": "teaching/2023-2024/Programming Level-up/lecture-3.html#deleting-an-environment",
    "title": "Python Modules",
    "section": "Deleting an Environment",
    "text": "Deleting an Environment\nAt later points in our project life-cycle – we have finished our project and we don’t want to have the environment installed anymore (besides we already have the environment.yml to recreate it from if we need to!).\nWe can remove an environment using:\nconda env remove --name &lt;name-of-env&gt;\nThis will remove the environment from Anaconda."
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-3.html#cleaning-up",
    "href": "teaching/2023-2024/Programming Level-up/lecture-3.html#cleaning-up",
    "title": "Python Modules",
    "section": "Cleaning up",
    "text": "Cleaning up\nIf you use Anaconda for a long time, you may start to see that a lot of memory is being used, this is because for every version of the package you install, a download of that package is cached to disk. Having these caches can make reinstalling these packages quicker as you won’t need to download the package again. But if you’re running out of hard drive space, cleaning up these cached downloads is an instant space saver:\nconda clean --all\nThis command will clean up the cache files for all environments, but doesn’t necessarily affect what’s already installed in the environments – so nothing should be broken by running this command."
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-3.html#pip",
    "href": "teaching/2023-2024/Programming Level-up/lecture-3.html#pip",
    "title": "Python Modules",
    "section": "Pip",
    "text": "Pip\nPip is another package installer for python. If you’re reading documentation online about how to install a certain Python package, the documentation will normally refer to pip.\nPip, like conda, uses a package repository to locate packages. For pip it is called Pypi (https://pypi.org)\nWe’re going to take a look at the most commonly used commands with pip."
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-3.html#installing-packages-with-pip",
    "href": "teaching/2023-2024/Programming Level-up/lecture-3.html#installing-packages-with-pip",
    "title": "Python Modules",
    "section": "Installing packages with pip",
    "text": "Installing packages with pip\nIf you want to install a package, its as simple as pip install.\npip install &lt;package-name&gt;"
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-3.html#installing-specific-versions",
    "href": "teaching/2023-2024/Programming Level-up/lecture-3.html#installing-specific-versions",
    "title": "Python Modules",
    "section": "Installing specific versions",
    "text": "Installing specific versions\nSometimes, though, you will want to install a specific package version. For this use ‘==’ after the name of the package.\npip install &lt;package-name&gt;==&lt;version-number&gt;"
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-3.html#upgrade-packages-with-pip",
    "href": "teaching/2023-2024/Programming Level-up/lecture-3.html#upgrade-packages-with-pip",
    "title": "Python Modules",
    "section": "Upgrade packages with pip",
    "text": "Upgrade packages with pip\nIf you want upgrade/install the package to the latest version, use the --upgrade flag.\npip install &lt;package-name&gt; --upgrade"
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-3.html#export-requirements-file",
    "href": "teaching/2023-2024/Programming Level-up/lecture-3.html#export-requirements-file",
    "title": "Python Modules",
    "section": "Export requirements file",
    "text": "Export requirements file\nLike exporting with conda, pip also includes a method to capture the currently installed environment. In pip, this is called freeze.\nThe common convention is to call the file requirements.txt.\npip freeze &gt; requirements.txt"
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-3.html#installing-multiple-packages-from-a-requirements-file",
    "href": "teaching/2023-2024/Programming Level-up/lecture-3.html#installing-multiple-packages-from-a-requirements-file",
    "title": "Python Modules",
    "section": "Installing multiple packages from a requirements file",
    "text": "Installing multiple packages from a requirements file\nIf we want to recreate the environment, we can install multiple packages with specific versions from a requirements file with:\npip install -r requirements.txt"
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-3.html#anaconda-handles-both-conda-and-pip",
    "href": "teaching/2023-2024/Programming Level-up/lecture-3.html#anaconda-handles-both-conda-and-pip",
    "title": "Python Modules",
    "section": "Anaconda handles both conda and pip",
    "text": "Anaconda handles both conda and pip\nConda encompasses pip, which means that when you create a virtual environment with conda, it can also include pip. So I would recommend using conda to create the virtual environment and to install packages when you can. But if the package is only available via pip, then it will be okay to install it using pip as well. When you export the environment with conda, it will specify what is installed with pip and what is installed via conda.\nconda env create -f environment.yml\nWhen the environment is re-created with conda, it will install the packages from the correct places, whether that is conda or pip."
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-3.html#pycharm",
    "href": "teaching/2023-2024/Programming Level-up/lecture-3.html#pycharm",
    "title": "Python Modules",
    "section": "PyCharm",
    "text": "PyCharm\n\n\n\n\n\nSo far we have been using a very basic text editor. This editor is only providing us with syntax highlighting (the colouring of keywords, etc) and helping with indentation.\nPyCharm is not a text editor. PyCharm is an Integrated Development Environment (IDE). An IDE is a fully fledged environment for programming in a specific programming language and offers a suite of features that makes programming in a particular language (Python in this case), a lot easier.\nSome of the features of an IDE are typically:\n\nDebugging support with breakpoints and variable inspection.\nPrompts and auto-completion with documentation support.\nBuild tools to run and test programs in various configurations.\n\nWe will use PyCharm for the rest of this course."
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-3.html#installing-pycharm",
    "href": "teaching/2023-2024/Programming Level-up/lecture-3.html#installing-pycharm",
    "title": "Python Modules",
    "section": "Installing PyCharm",
    "text": "Installing PyCharm\nUsing Ubuntu snaps:\nsnap install pycharm-community --classic\nOr we can download an archive with the executable. The steps to run goes something like:\ntar xvf pycharm-community-&lt;version&gt;.tar.gz\nbash pycharm-community-&lt;version&gt;/bin/pycharm.sh"
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-3.html#using-pycharm",
    "href": "teaching/2023-2024/Programming Level-up/lecture-3.html#using-pycharm",
    "title": "Python Modules",
    "section": "Using PyCharm",
    "text": "Using PyCharm\nWe shall take a look at the following:\n\nCreating a new project.\nSpecifying the conda environment.\nCreating build/run instructions.\nAdding new files/folders.\nDebugging with breakpoints."
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-3.html#jupyter",
    "href": "teaching/2023-2024/Programming Level-up/lecture-3.html#jupyter",
    "title": "Python Modules",
    "section": "Jupyter",
    "text": "Jupyter\n\n\n\n\n\nJupyter notebooks are environments where code is split into cells, where each cell can be executed independently and immediate results can be inspected.\nNotebooks can be very useful for data science projects and exploratory work where the process cannot be clearly defined (and therefore cannot be immediately programmed)."
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-3.html#installing-jupyter",
    "href": "teaching/2023-2024/Programming Level-up/lecture-3.html#installing-jupyter",
    "title": "Python Modules",
    "section": "Installing Jupyter",
    "text": "Installing Jupyter\nWe first need to install Jupyter. In you conda environment type:\nconda install jupyter\n# or pip install jupyter"
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-3.html#starting-the-server",
    "href": "teaching/2023-2024/Programming Level-up/lecture-3.html#starting-the-server",
    "title": "Python Modules",
    "section": "Starting the server",
    "text": "Starting the server\nWith Jupyter installed, we can now start the notebook server using:\njupyter notebook\nA new browser window will appear. This is the Jupyter interface.\nIf you want to stop the server, press Ctrl+c in the terminal window."
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-3.html#using-the-interface",
    "href": "teaching/2023-2024/Programming Level-up/lecture-3.html#using-the-interface",
    "title": "Python Modules",
    "section": "Using the interface",
    "text": "Using the interface\nWe shall take a look at the following:\n\nCreating a new notebook\nDifferent cell types\nExecuting code cells\nMarkdown cells\nExporting to a different format\nHow the notebook gets stored"
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-3.html#markdown-101",
    "href": "teaching/2023-2024/Programming Level-up/lecture-3.html#markdown-101",
    "title": "Python Modules",
    "section": "Markdown 101",
    "text": "Markdown 101\nWe will revisit markdown in a later lecture, but since we’re using notebooks, some of the cells can be of a type markdown. In these cells, we can style the text using markdown syntax.\nhttps://www.markdownguide.org/basic-syntax/"
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-3.html#a-slightly-better-environment-jupyterlab",
    "href": "teaching/2023-2024/Programming Level-up/lecture-3.html#a-slightly-better-environment-jupyterlab",
    "title": "Python Modules",
    "section": "A slightly better environment – jupyterlab",
    "text": "A slightly better environment – jupyterlab\nThe notebook environment is fine, but there exists another package called jupyter-lab that enhances the environment to include a separate file browser, etc.\nconda install jupyterlab -c conda-forge\n\njupyter-lab"
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-3.html#a-sense-of-style",
    "href": "teaching/2023-2024/Programming Level-up/lecture-3.html#a-sense-of-style",
    "title": "Python Modules",
    "section": "A sense of style",
    "text": "A sense of style\nNow that we have looked at syntax you will need to create Python projects, I want to take a minute to talk about the style of writing Python code.\nThis style can help you create projects that can be maintained and understood by others but also yourself.\nPython itself also advocates for an adherence to a particular style of writing Python code with the PEP8 style guide: https://www.python.org/dev/peps/pep-0008/. Though, I will talk through some of the most important ones, in my opinion."
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-3.html#meaningful-names",
    "href": "teaching/2023-2024/Programming Level-up/lecture-3.html#meaningful-names",
    "title": "Python Modules",
    "section": "Meaningful names",
    "text": "Meaningful names\n\n\n\nWhat does this code do?\ndef f(l):\n    x = 0\n    y = 0\n    for i in l:\n        x += i\n        y += 1\n    return x / y\n\na = range(100)\nr = f(a)\n\n\n\nWhat about this one?\ndef compute_average(list_of_data):\n    sum = 0\n    num_elements = 0\n    for element in list_of_data:\n        sum += element\n        num_elements += 1\n    return sum / num_elements\n\ndataset = range(100)\naverage_value = compute_average(dataset)\n\n\n\n\nThey are both the same code, but the second version is a lot more readable and understandable because we have used meaningful names for things!"
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-3.html#use-builtins-where-possible",
    "href": "teaching/2023-2024/Programming Level-up/lecture-3.html#use-builtins-where-possible",
    "title": "Python Modules",
    "section": "Use builtins where possible",
    "text": "Use builtins where possible\nDon’t re-invent the wheel. Try to use Python’s built-in functions/classes if they exist, they will normally be quicker and more accurate than what you could make in Python itself. For example:\ndataset = range(100)\naverage_value = sum(dataset) / len(dataset)\n. . .\nor maybe even:\nimport numpy as np\ndataset = range(100)\naverage_value = np.mean(dataset)"
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-3.html#use-docstrings-and-comments",
    "href": "teaching/2023-2024/Programming Level-up/lecture-3.html#use-docstrings-and-comments",
    "title": "Python Modules",
    "section": "Use docstrings and comments",
    "text": "Use docstrings and comments\ndef compute_average(list_of_data, exclude=None):\n    \"\"\"\n    Compute and return the average value of an iterable list. \n    This average excludes any value if specified by exclude\n\n    params: \n    - list_of_data: data for which the average is computed \n    - exclude: numeric value of values that should not be taken \n        into account\n\n    returns: \n    The computed average, possibly excluding a value.\n    \"\"\"\n    sum = 0\n    num_elements = 0\n    for element in list_of_data:\n        if exclude is not None and element == exclude:\n            continue  # skip this element\n        sum += element\n        num_elements += 1\n    return sum / num_elements"
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-3.html#using-agreed-upon-casing",
    "href": "teaching/2023-2024/Programming Level-up/lecture-3.html#using-agreed-upon-casing",
    "title": "Python Modules",
    "section": "Using agreed upon casing",
    "text": "Using agreed upon casing\n\nsnake_casing for functions and variables\nClasses should use CamelCasing\n\ndef this_if_a_function(data_x, data_y):\nclass BookEntry:"
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-3.html#use-type-annotations-if-possible",
    "href": "teaching/2023-2024/Programming Level-up/lecture-3.html#use-type-annotations-if-possible",
    "title": "Python Modules",
    "section": "Use type-annotations if possible",
    "text": "Use type-annotations if possible\nType annotations can helper your editor (such as PyCharm) find potential issues in your code. If you use type annotations, the editor can spot types that are not compatible. For example, a string being used with a division.\nhttps://docs.python.org/3/library/typing.html https://realpython.com/python-type-checking/\ndef compute_average(list_of_data: list[int],\n                    exclude: Optional[int] = None) -&gt; float:\n    ..."
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-3.html#organise-your-imports",
    "href": "teaching/2023-2024/Programming Level-up/lecture-3.html#organise-your-imports",
    "title": "Python Modules",
    "section": "Organise your imports",
    "text": "Organise your imports\nMake the distinction between standard library imports, externally installed imports, and your own custom imports.\n# internal imports\nimport os\nfrom math import pi\n\n# external imports\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\n# custom imports\nfrom src.my_module import DAGs"
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-3.html#functions-should-do-one-thing-only",
    "href": "teaching/2023-2024/Programming Level-up/lecture-3.html#functions-should-do-one-thing-only",
    "title": "Python Modules",
    "section": "Functions should do one thing only",
    "text": "Functions should do one thing only\nDo one thing and do it well. Docstrings can help you understand what your function is doing, especially if you use the word ‘and’ in the docstring, you might want to think about breaking your single function into many parts."
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-3.html#functions-as-re-usability",
    "href": "teaching/2023-2024/Programming Level-up/lecture-3.html#functions-as-re-usability",
    "title": "Python Modules",
    "section": "Functions as re-usability",
    "text": "Functions as re-usability\nIf you find yourself doing something over and over, a function call help consolidate duplication and potentially reduce the chance of getting things wrong.\n\nprint(\"The result is \", w * x1 + b)\nprint(\"The result is \", w * x2 + b)\nprint(\"The result is \", w * x3 + b)\n\n\ndef compute(var):\n    return w * var + b\n\ndef print_result(res):\n    print(\"The result is \", res)\n\nfor var in [x1, x2, x3]:\n    print_result(compute(var))"
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-3.html#be-wary-of-god-classes",
    "href": "teaching/2023-2024/Programming Level-up/lecture-3.html#be-wary-of-god-classes",
    "title": "Python Modules",
    "section": "Be wary of God classes",
    "text": "Be wary of God classes\nGod classes/God object is a class that is doing too many things or ‘knows’ about too much. When designing a class, remember that like a function, in general, it should manage one thing or concept.\n\n\n\nclass Game:\n    def __init__(self):\n        ...\n    def create_character(self):\n        ...\n    def move_character(self):\n        ...\n    def update_score(self):\n        ...\n    def reset_score(self):\n        ...\n    def start_game(self):\n        ...\n    def end_game(self):\n        ...\n    def start_boat(self):\n        ...\n    def stop_boat(self):\n        ...\n    ...\n\n\n\nclass Game:\n    def __init__(self):\n        ...\n    def start_game(self):\n        ...\n    def end_game(self):\n        ...\n\nclass Character:\n    def __init__(self):\n        ...\n    def create_character(self):\n        ...\n    def move_character(self):\n        ...\n\nclass ScoreBoard:\n    ..."
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-3.html#documentation",
    "href": "teaching/2023-2024/Programming Level-up/lecture-3.html#documentation",
    "title": "Python Modules",
    "section": "Documentation",
    "text": "Documentation\n\nComments that contradict the code are worse than no comments. Always make a priority of keeping the comments up-to-date when the code changes!\n\nPEP 8 Style Guide\n\nEnsure that comments are correct.\nDon’t over document (i.e. if something is self explanatory, then comments will distract rather than inform). An example from PEP 8:\n\nx = x + 1                 # Increment x\nx = x + 1                 # Compensate for border\n\nDocument what you think will be difficult to understand without some prior knowledge, such as why a particular decision was made to do something a certain way. Don’t explain, educate the reader."
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/lecture-3.html#perform-testing",
    "href": "teaching/2023-2024/Programming Level-up/lecture-3.html#perform-testing",
    "title": "Python Modules",
    "section": "Perform testing!",
    "text": "Perform testing!\nMake sure to write tests, for example, using unittest (https://docs.python.org/3/library/unittest.html). Writing tests can help find source of bugs/mistakes in your code, and if you change something in the future, you want to make sure that it still works. Writing tests can automate the process of testing your code."
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/index.html",
    "href": "teaching/2023-2024/Programming Level-up/index.html",
    "title": "Programming Level-up",
    "section": "",
    "text": "Welcome to the Programming Level-up Course. In this series of lectures, we will cover everything we need to be able to program in a Linux-based environment, and use the high performance computers (also called cluster/supercomputers) to run experiments.\n\n\nYou can find my personal page over at: https://pageperso.lis-lab.fr/jay.morgan/\nAs we progress through the lectures, I will also make the course publicly available. These lectures will be hosted at: https://pageperso.lis-lab.fr/jay.morgan/teaching.html in a variety of formats (i.e. PDF, HTML).\nIf you have any questions please email me directly. My email address is jay.morgan@univ-tln.fr. Other modes of contact can be found on my personal website listed above.\n\n\n\nThis course aims to deliver everything you need. If you attend each lecture, you will know what you need for the following lectures. Despite this design, however, I have included a list of additional resources below. These resources are optional, but they will take you beyond what you’re taught in these sessions and enable you to become a Programming Master!\nThere is nothing like a good book to learn from. They are usually rich in content, but also provide reasonable enough depth to the subject matter to not only learn how things work, but also why they work the way they do.\n\nThink Python: An Introduction to Software Design - Livre d’Allen B. Downey\nNumerical Python: Scientific Computing and Data Science Applications with Numpy, SciPy and Matplotlib - Livre de Robert Johansson.\nClassic Shell Scripting - Livre de Arnold Robbins, Nelson H F Beebe\n\n\n\n\nThe course will cover a broad spectrum of skills used when programming for scientific research. This includes the programming and scripting itself (in our case, Python programming), managing the environment in which we work (i.e. working in a Linux-based environment and managing our projects with version control), and interacting with the supercomputers to perform intensive computations.\n\n\n\nAll of my lectures are available online, including the source code that was used in the lectures, and the source code used to generate the slides themselves. You can find this source code here:\nMirrors:\n\nhttps://git.sr.ht/~jaymorgan/teaching\nhttps://gitlab.com/jaymorgan/teaching.git\nhttps://github.com/jaypmorgan/teaching.git"
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/index.html#contact-information",
    "href": "teaching/2023-2024/Programming Level-up/index.html#contact-information",
    "title": "Programming Level-up",
    "section": "",
    "text": "You can find my personal page over at: https://pageperso.lis-lab.fr/jay.morgan/\nAs we progress through the lectures, I will also make the course publicly available. These lectures will be hosted at: https://pageperso.lis-lab.fr/jay.morgan/teaching.html in a variety of formats (i.e. PDF, HTML).\nIf you have any questions please email me directly. My email address is jay.morgan@univ-tln.fr. Other modes of contact can be found on my personal website listed above."
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/index.html#resources",
    "href": "teaching/2023-2024/Programming Level-up/index.html#resources",
    "title": "Programming Level-up",
    "section": "",
    "text": "This course aims to deliver everything you need. If you attend each lecture, you will know what you need for the following lectures. Despite this design, however, I have included a list of additional resources below. These resources are optional, but they will take you beyond what you’re taught in these sessions and enable you to become a Programming Master!\nThere is nothing like a good book to learn from. They are usually rich in content, but also provide reasonable enough depth to the subject matter to not only learn how things work, but also why they work the way they do.\n\nThink Python: An Introduction to Software Design - Livre d’Allen B. Downey\nNumerical Python: Scientific Computing and Data Science Applications with Numpy, SciPy and Matplotlib - Livre de Robert Johansson.\nClassic Shell Scripting - Livre de Arnold Robbins, Nelson H F Beebe"
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/index.html#what-will-be-taught",
    "href": "teaching/2023-2024/Programming Level-up/index.html#what-will-be-taught",
    "title": "Programming Level-up",
    "section": "",
    "text": "The course will cover a broad spectrum of skills used when programming for scientific research. This includes the programming and scripting itself (in our case, Python programming), managing the environment in which we work (i.e. working in a Linux-based environment and managing our projects with version control), and interacting with the supercomputers to perform intensive computations."
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/index.html#source-code",
    "href": "teaching/2023-2024/Programming Level-up/index.html#source-code",
    "title": "Programming Level-up",
    "section": "",
    "text": "All of my lectures are available online, including the source code that was used in the lectures, and the source code used to generate the slides themselves. You can find this source code here:\nMirrors:\n\nhttps://git.sr.ht/~jaymorgan/teaching\nhttps://gitlab.com/jaymorgan/teaching.git\nhttps://github.com/jaypmorgan/teaching.git"
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/0.course-introduction.html",
    "href": "teaching/2023-2024/Programming Level-up/0.course-introduction.html",
    "title": "Course Introduction",
    "section": "",
    "text": "Welcome to the Progamming Level-up course. In this series of lectures, we’ll be delving into the broad world of programming for research!"
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/0.course-introduction.html#what-why",
    "href": "teaching/2023-2024/Programming Level-up/0.course-introduction.html#what-why",
    "title": "Course Introduction",
    "section": "What…? Why…?",
    "text": "What…? Why…?\n\nProgramming is much more than the act of programming a small script. Even if you’ve programmed before, doing so for a research project requires a lot of rigour to ensure the results you’re reporting are correct, and reproducible.\nThere is so much surrounding the act of programming that it can get a little overwhelming. Things from setting up a programming environment to managing multiple experiments on the supercomputers can involve many languages and understanding of technologies.\nThis course is designed to take you from not being able to program at all to being able to do it comfortably for your research and work."
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/0.course-introduction.html#what-is-this-course-going-to-teach-me",
    "href": "teaching/2023-2024/Programming Level-up/0.course-introduction.html#what-is-this-course-going-to-teach-me",
    "title": "Course Introduction",
    "section": "What is this course going to teach me?",
    "text": "What is this course going to teach me?\n\nProgramming with the Python Programming Language.\n\nBasic syntax.\nIntroduction to the basics of object oriented programming (OOP).\nNumerical computing with numpy/pandas/scipy.\n\nDoing your programming in a Linux-based Environment (GNU/Linux) and being comfortable with the organisation of this Linux environment.\n\nSetting up a research (reproducible) environment.\nExecuting experiments.\n\nInteracting with the Super-computers/clusters.\n\nInteraction with SLURM (management of jobs).\n\nTaking the results from a program you’ve created, be able to visualise them and include them in reports/papers.\n\nLaTeX/Markdown.\nPlotting."
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/0.course-introduction.html#how-the-course-will-be-delivered",
    "href": "teaching/2023-2024/Programming Level-up/0.course-introduction.html#how-the-course-will-be-delivered",
    "title": "Course Introduction",
    "section": "How the course will be delivered",
    "text": "How the course will be delivered\n\n2/3 hour sessions over the next 2 months.\nThroughout the lecture, there will be small exercises to try out what we’ve learnt. We will go through the answers to these exercises.\nAt the end of the lecture we will have a larger exercise that will become more challenging. These exercises are not marked, but again, just an opportunity to try out what you’ve learnt. The best way to learn how to program is to program."
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/0.course-introduction.html#rough-timeline",
    "href": "teaching/2023-2024/Programming Level-up/0.course-introduction.html#rough-timeline",
    "title": "Course Introduction",
    "section": "Rough timeline",
    "text": "Rough timeline\n\n\n\n\n\n\n\n\n\nLecture\n\n\nTopic\n\n\nDescription\n\n\n\n\n\n\n1\n\n\nIntroduction\n\n\n\nCourse introduction\n\n\n\n\n\n \n\n\n \n\n\n\nBasic Python programming\n\n\n\n\n\n2\n\n\nPython classes\n\n\n\nIntroduction to OOP\n\n\n\n\n\n3\n\n\nProject management\n\n\n\nCreating/importing modules\n\n\n\n\n\n \n\n\n \n\n\n\nAnaconda/pip\n\n\n\n\n\n4\n\n\nProgramming environments\n\n\n\nPyCharm\n\n\n\n\n\n \n\n\n \n\n\n\nJupyter notebooks\n\n\n\n\n\n5\n\n\nNumerical computing\n\n\n\nNumpy\n\n\n\n\n\n \n\n\n \n\n\n\nScipy\n\n\n\n\n\n6\n\n\nNumerical computing\n\n\n\nPandas\n\n\n\n\n\n \n\n\n \n\n\n\nVisualisations\n\n\n\n\n\n7\n\n\nBasics of GNU/Linux\n\n\n\nUsing the terminal\n\n\n\n\n\n8\n\n\nBash scripting\n\n\n\nBash scripting\n\n\n\n\n\n9\n\n\nHigh performance computing\n\n\n\nSLURM\n\n\n\n\n\n \n\n\n \n\n\n\nSingularity\n\n\n\n\n\n10\n\n\nReporting\n\n\n\nLaTeX\n\n\n\n\n\n \n\n\n \n\n\n\nMarkdown"
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/0.course-introduction.html#where-to-find-me",
    "href": "teaching/2023-2024/Programming Level-up/0.course-introduction.html#where-to-find-me",
    "title": "Course Introduction",
    "section": "Where to find me",
    "text": "Where to find me\nMy name is Dr Jay Paul Morgan. I am a researcher work on Deep Learning in Astrophysics.\n\nEmail: jay.morgan@univ-tln.fr\nLecture slides and other contact on my website: https://pageperso.lis-lab.fr/jay.morgan/"
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/0.course-introduction.html#setting-up-a-proxy-in-linux-environment-variables",
    "href": "teaching/2023-2024/Programming Level-up/0.course-introduction.html#setting-up-a-proxy-in-linux-environment-variables",
    "title": "Course Introduction",
    "section": "Setting up a proxy in Linux – environment variables",
    "text": "Setting up a proxy in Linux – environment variables\nEnvironment variables are variables that are set in the Linux environment and are used to configure some high-level details in Linux.\nThe command to create/set an environment is:\nexport VARIABLE_NAME=''\nExporting a variable in this way will mean VARIABLE_NAME will be accessible while you’re logged in. Every time you log in you will have to set this variable again."
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/0.course-introduction.html#univ-tln-specific-details",
    "href": "teaching/2023-2024/Programming Level-up/0.course-introduction.html#univ-tln-specific-details",
    "title": "Course Introduction",
    "section": "UNIV-TLN specific details",
    "text": "UNIV-TLN specific details\nIn the université de Toulon, you’re required to use the university’s proxy server to access the internet. Therefore, in Linux at least, you will have to tell the system where the proxy server is with an environment variable.\nexport HTTP_PROXY='&lt;username&gt;:&lt;password&gt;@proxy.univ-tln.fr:3128'\nexport HTTPS_PROXY='&lt;username&gt;:&lt;password&gt;@proxy.univ-tln.fr:3128'\nexport FTP_PROXY='&lt;username&gt;:&lt;password&gt;@proxy.univ-tln.fr:3128'\nNOTE: Watch out for special characters in your password! They will have to be URL encoded."
  },
  {
    "objectID": "teaching/2023-2024/Programming Level-up/0.course-introduction.html#setting-up-a-proxy-in-the-.bashrc",
    "href": "teaching/2023-2024/Programming Level-up/0.course-introduction.html#setting-up-a-proxy-in-the-.bashrc",
    "title": "Course Introduction",
    "section": "Setting up a proxy in the .bashrc",
    "text": "Setting up a proxy in the .bashrc\nIf you don’t wish to set the variable every time log in, you should enter the same commands into a .bashrc in your home directory.\nexport HTTP_PROXY='...'\nexport HTTPS_PROXY='...'\nexport FTP_PROXY='...'\nWhen you log in, the .bashrc file will be run and these variables will be set for you."
  }
]