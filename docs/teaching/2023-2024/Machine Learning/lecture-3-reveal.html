<!DOCTYPE html>
<html lang="en"><head>
<script src="../../../site_libs/clipboard/clipboard.min.js"></script>
<link rel="alternate" hreflang="en" href="https://morganwastaken.com/teaching/2023-2024/Machine Learning/lecture-3-reveal.html" />
<link rel="alternate" hreflang="cy" href="https://morganwastaken.com/cy/teaching/2023-2024/Machine Learning/lecture-3-reveal.cy.html" />
<script src="../../../site_libs/quarto-html/tabby.min.js"></script>
<script src="../../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../../site_libs/quarto-html/tippy.umd.min.js"></script>
<link href="../../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../../site_libs/quarto-html/light-border.css" rel="stylesheet">
<link href="../../../site_libs/quarto-html/quarto-syntax-highlighting-e26003cea8cd680ca0c55a263523d882.css" rel="stylesheet" id="quarto-text-highlighting-styles"><meta charset="utf-8">
  <meta name="generator" content="quarto-1.6.39">

  <meta name="author" content="Jay Paul Morgan">
  <title>Jay Paul Morgan – Model Performance</title>
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, minimal-ui">
  <link rel="stylesheet" href="../../../site_libs/revealjs/dist/reset.css">
  <link rel="stylesheet" href="../../../site_libs/revealjs/dist/reveal.css">
  <style>
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    ul.task-list{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      width: 0.8em;
      margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
      vertical-align: middle;
    }
  </style>
  <link rel="stylesheet" href="../../../site_libs/revealjs/dist/theme/quarto-bbe7401fe57d4b791b917637bb662036.css">
  <script async="" src="https://www.googletagmanager.com/gtag/js?id=G-Q1SQLS91HT"></script>

  <script type="text/javascript">

  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());
   
    gtag('consent', 'default', {
      'ad_storage': 'denied',
      'analytics_storage': 'denied'
    });
  gtag('config', 'G-Q1SQLS91HT', { 'anonymize_ip': true});
  </script>
  <link href="../../../site_libs/revealjs/plugin/quarto-line-highlight/line-highlight.css" rel="stylesheet">
  <link href="../../../site_libs/revealjs/plugin/reveal-menu/menu.css" rel="stylesheet">
  <link href="../../../site_libs/revealjs/plugin/reveal-menu/quarto-menu.css" rel="stylesheet">
  <link href="../../../site_libs/revealjs/plugin/quarto-support/footer.css" rel="stylesheet">
  <style type="text/css">
    .reveal div.sourceCode {
      margin: 0;
      overflow: auto;
    }
    .reveal div.hanging-indent {
      margin-left: 1em;
      text-indent: -1em;
    }
    .reveal .slide:not(.center) {
      height: 100%;
    }
    .reveal .slide.scrollable {
      overflow-y: auto;
    }
    .reveal .footnotes {
      height: 100%;
      overflow-y: auto;
    }
    .reveal .slide .absolute {
      position: absolute;
      display: block;
    }
    .reveal .footnotes ol {
      counter-reset: ol;
      list-style-type: none; 
      margin-left: 0;
    }
    .reveal .footnotes ol li:before {
      counter-increment: ol;
      content: counter(ol) ". "; 
    }
    .reveal .footnotes ol li > p:first-child {
      display: inline-block;
    }
    .reveal .slide ul,
    .reveal .slide ol {
      margin-bottom: 0.5em;
    }
    .reveal .slide ul li,
    .reveal .slide ol li {
      margin-top: 0.4em;
      margin-bottom: 0.2em;
    }
    .reveal .slide ul[role="tablist"] li {
      margin-bottom: 0;
    }
    .reveal .slide ul li > *:first-child,
    .reveal .slide ol li > *:first-child {
      margin-block-start: 0;
    }
    .reveal .slide ul li > *:last-child,
    .reveal .slide ol li > *:last-child {
      margin-block-end: 0;
    }
    .reveal .slide .columns:nth-child(3) {
      margin-block-start: 0.8em;
    }
    .reveal blockquote {
      box-shadow: none;
    }
    .reveal .tippy-content>* {
      margin-top: 0.2em;
      margin-bottom: 0.7em;
    }
    .reveal .tippy-content>*:last-child {
      margin-bottom: 0.2em;
    }
    .reveal .slide > img.stretch.quarto-figure-center,
    .reveal .slide > img.r-stretch.quarto-figure-center {
      display: block;
      margin-left: auto;
      margin-right: auto; 
    }
    .reveal .slide > img.stretch.quarto-figure-left,
    .reveal .slide > img.r-stretch.quarto-figure-left  {
      display: block;
      margin-left: 0;
      margin-right: auto; 
    }
    .reveal .slide > img.stretch.quarto-figure-right,
    .reveal .slide > img.r-stretch.quarto-figure-right  {
      display: block;
      margin-left: auto;
      margin-right: 0; 
    }
  </style>
<meta property="og:title" content="Model Performance – Jay Paul Morgan">
<meta property="og:description" content="Lecture 3">
<meta property="og:site_name" content="Jay Paul Morgan">
</head>
<body class="quarto-light">
  <div class="reveal">
    <div class="slides">

<section id="title-slide" class="quarto-title-block center">
  <h1 class="title">Model Performance</h1>
  <p class="subtitle">Lecture 3</p>

<div class="quarto-title-authors">
<div class="quarto-title-author">
<div class="quarto-title-author-name">
Jay Paul Morgan 
</div>
</div>
</div>

</section>
<section>
<section id="train-test" class="title-slide slide level1 center">
<h1>Train &amp; Test</h1>

</section>
<section id="why-do-we-have-different-sets-of-data" class="slide level2">
<h2>Why do we have different ‘sets’ of data?</h2>
<p>We’ve seen in the previous lecture how we can fit a linear regression model to a set of data, and we can measure the performance of this model.</p>
<p>But we do not understand how well this model works in the ‘real-world’, how well it performs on data that has not yet been ‘seen’, how well the model <strong>generalises</strong> to this unknown data.</p>
<p>So, when we want to create a machine learning model, we usually take our data, and split into two (sometimes three) sets of data. These different sets are named:</p>
<ul>
<li>training set,</li>
<li>testing set,</li>
<li>and (optionally) validation set.</li>
</ul>
</section>
<section id="training-set" class="slide level2">
<h2>Training Set</h2>
<p>The training dataset, is the set of data, that we’re allowing the model to `see’ or learn from.</p>
<p>In our example of the linear regression, this is the set of data points to which we find the optimal parameters of our model.</p>
<p>It is not very useful to evaluate our model’s performance with the training set as it doesn’t tell us how well it’s actually doing (we’ll come back to this when we talk about over-/under-fitting).</p>
</section>
<section id="testing-set" class="slide level2">
<h2>Testing Set</h2>
<p>The testing set is the set of data that we use to evaluate the <strong>generalisation</strong> of our machine learning model. The model is not allowed to use this set of data during training, but it is simply used for the evaluation of the model.</p>
<p>In general the testing set is between 10-30% of the overall available data, but this rule is not something dictated, and may vary depending on the amount of data available and the overall use case.</p>
<p>Once the 10-30% of the data has been sampled for the testing set, the rest of the data can be used for the training and validation sets.</p>
</section>
<section id="validation-set" class="slide level2">
<h2>Validation Set</h2>
<p>If we have an iterative optimisation process (such as what we saw with gradient descent), we might want to know how well our model is possibly generalising to unseen data.</p>
<p>The validation dataset, is the set of data that we use to measure the generalisation of our model during the course of its learning process. Like the test set, this validation data should not be used to train the model, but only used to measure the model’s generalisation during the lifetime of the learning process.</p>
</section></section>
<section>
<section id="over-underfitting" class="title-slide slide level1 center">
<h1>Over-/Underfitting</h1>

</section>
<section id="the-ability-of-the-model" class="slide level2">
<h2>The ability of the model</h2>
<p>When we created a linear regression model, we saw that it was not possible to predict the house price exactly, there was always some error that we could not overcome with the linear model.</p>
<p>If we have a model complicated model, such as polynomial regression (where we have polynomial terms in line equation), it may be possible to fit every training data point exactly. But <strong>is that what we want?</strong>.</p>
<p>In this section, we’ll explore the concept of over- and under-fitting, and how we can use the testing set to understanding if these processes are happening.</p>
</section>
<section id="over-fitting" class="slide level2">
<h2>Over-fitting</h2>
<p>We’ll begin with over-fitting. Over-fitting occurs when our model has a very high or perfect performance on the testing set, but does not perform well at all on the testing set.</p>
<p>There may be many reasons for this happening, such as the model being very complex, having too many variables.</p>

<img data-src="images/overfit.png" title="Example of a well-fit model (red dashed) and a model that has overfitted to each data point (blue solid)." class="r-stretch"></section>
<section id="under-fitting" class="slide level2">
<h2>Under-fitting</h2>
<p>Under-fitting, as the name suggests is what happens when we cannot fit the model to the data, it doesn’t even perform well on the training data, the data the model is allowed to learn from. This can happen when the model is too simple and cannot learn the intrinsic relationship between the input and output. For example, trying to use a linear model to learn from data that is not linear by nature.</p>

<img data-src="images/underfit.png" title="A linear model (blue line) is unable to properly capture the relationship of this polynomial and so will underfit the data." class="r-stretch"></section>
<section id="validation-curves" class="slide level2">
<h2>Validation Curves</h2>
<p>If we have an iterative learning process, we can use the training and validation datasets to measure whether our model is over-fitting, and stop training the model at an optimal point before it overfits.</p>
<p>To do this, at every iteration of the learning process, we evaluate the model’s performance using both the training and validation datasets. If the performance on both datasets is decreasing we can infer that the model is learning something useful that helps with it’s generalisation to unseen data.</p>
<p>However, if the performance on the training set is decreasing, while the performance on the validation dataset is no longer decreasing or indeed increasing, we know the model is over-fitting to the training data.</p>

<img data-src="images/validation_curves.png" title="Example of training and validation loss as the model iteratively trains. Both the train and validation loss decreases, up until a point where the model begins overfitting. This overfitting begins to occur when the training loss continues to decrease but the validation loss either stops decreasing or increases. Ideally, we would use the model parameters from the model with the lowest validation loss." class="r-stretch"></section>
<section id="biasvariance-tradeoff" class="slide level2">
<h2>Bias/Variance Tradeoff</h2>
<p>The Bias/Variance tradeoff is a property of machine learning models. It describes a model’s expected generalisation abilities based upon how the parameters are estimated across a dataset.</p>
<ul>
<li><strong>Bias</strong> - the model’s `flexibility’ to represent the true relationship in the data. Model’s with low bias have a tendency to underfit. An example would be a linear model model trying to fit against non-linear function.</li>
<li><strong>Variance</strong> - the impact that a single sample in the data has on the model. Model’s with high variance tend to overfit to the training data.</li>
</ul>
</section></section>
<section>
<section id="regression" class="title-slide slide level1 center">
<h1>Regression</h1>

</section>
<section id="metrics" class="slide level2">
<h2>Metrics</h2>
<p>Now that we’ve looked at the various sets of data, and the potential scenarios when we fit a model, we’ll now want to look at some actual methods of evaluating our model.</p>
<p>These we call <strong>metrics</strong>. Metrics are values that help us understand how well a model might perform in the real world. <strong>Metrics are helpful to explain the predictive power of a model with one value</strong>.</p>
<p>There are many different types of metrics that can be used depending on the class of problem that is being dealt with. For instance, there are different set of metrics for Regression and classification problems.</p>
<p>We’ll first look at some metrics we can use to evaluate a regression model (some of which we’ve already seen in the Linear models lecture), and then we’ll have a look at metrics for a classification task.</p>
</section>
<section id="mean-squared-error-mse" class="slide level2">
<h2>Mean Squared Error (MSE)</h2>
<p>A mean squared error (sometimes called the sum of squared residuals) is the measure of mean magnitude between two sets of points <span class="math inline">\(y, \overline{y}\)</span>.</p>
<p>The formula for MSE is:</p>
<p><span class="math inline">\(\text{MSE} = \frac{1}{N} \sum_i^N (y_i, \overline{y_i})^2\)</span></p>
<p>for <span class="math inline">\(N\)</span> points.</p>
<p>MSE is always non-negative, and the lower the MSE the better.</p>
</section>
<section id="root-mean-squared-error-rmse" class="slide level2">
<h2>Root Mean Squared Error (RMSE)</h2>
<p><span class="math display">\[
\text{RMSE} = \sqrt{\text{MSE}}
\]</span></p>
<p>Due to the squared error term, larger errors have a large effect on the outcome of the equation, so both RMSE and MSE is sensitive to outliers.</p>
<p>MSE’s error is measured in squared units, while RMSE is measured in the same unit as the target.</p>
</section>
<section id="mean-absolute-error-mae" class="slide level2">
<h2>Mean Absolute Error (MAE)</h2>
<p>Mean absolute error or MAE is one objective function for measure the <span class="math inline">\(L_1\)</span> between two sets of points.</p>
<p><span class="math inline">\(\text{MAE} = \frac{1}{N} \sum_i^N | y_i - \overline{y_i} |\)</span></p>
<p>for <span class="math inline">\(N\)</span> of points.</p>
<p>Like MSE, RMSE, the lower the MAE value, the better the fit on the statistical model.</p>
</section></section>
<section>
<section id="classification" class="title-slide slide level1 center">
<h1>Classification</h1>

</section>
<section id="binary-classification-labelling-as-positive-or-negative" class="slide level2">
<h2>Binary classification &amp; labelling as positive or negative</h2>
<p>We now move onto some of the more typical classification metrics. But first, we must first understand when our classifier predicts positive or negative in a binary classification task.</p>
<p>Let’s say we have a binary classifier <span class="math inline">\(\mathcal{M}\)</span> which predicts the positive class if the predicted probability is <span class="math inline">\(\geq 0.5\)</span>. I.e.:</p>
<p><span class="math display">\[
L(x)  = \begin{cases}
1 &amp; \text{if}, \; \mathcal{M}(x) \geq 0.5 \\
0 &amp; \text{otherwise}
\end{cases}
\]</span></p>
<p>where <span class="math inline">\(L\)</span> is our labelling function.</p>
<p>Here 0.5 is the <strong>threshold</strong> for predicting the positive class.</p>
</section>
<section id="tptnfpfn" class="slide level2">
<h2>TP/TN/FP/FN</h2>
<p>Before we look at other metrics to evaluate our classification metrics, I first want to describe these acronyms.</p>
<ul>
<li><p>List :B_column:BMCOL:</p>
<ul>
<li>TP - True-Positive – our model has predicted positive (it was correct) and the actual label is positive.</li>
<li>TN - True-Negative – our model has predicted negative (it was correct) and the actual label is negative.</li>
<li>FP - False-Positive – our model has predicted positive (it was wrong) the actual label was negative.</li>
<li>FN - False-Negative – our model has predicted negative (it was wrong) the actual label was positive.</li>
</ul></li>
<li><p>Diagram :B_column:BMCOL:</p>
<p><img data-src="images/Precisionrecall.png" title="By Walber - Own work, CC BY-SA 4.0, <https://commons.wikimedia.org/w/index.php?curid=36926283>"></p></li>
</ul>
</section>
<section id="accuracy" class="slide level2">
<h2>Accuracy</h2>
<p>In a binary classification task, accuracy is measured using:</p>
<p><span class="math display">\[
\text{Accuracy} = \frac{TP+TN}{TP+TN+FP+FN}
\]</span></p>
<p>or multi-classification:</p>
<p><span class="math display">\[
\text{Accuracy} = \frac{\text{number of correct}}{\text{number of samples}}
\]</span></p>
<p>The range of accuracy is in <span class="math inline">\([0, 1]\)</span>, the higher the value of accuracy the better. Accuracy is often presented in the form of a percentage i.e.&nbsp;<span class="math inline">\(100 \cdot \text{Accuracy}\)</span></p>
</section>
<section id="precision" class="slide level2">
<h2>Precision</h2>
<p>Measuring the precision tells us how many how accurate our model was in predicting positive cases. Here we have <span class="math inline">\(TP\)</span> or the number of True-Positive, divided by <span class="math inline">\(TP + FP\)</span> where <span class="math inline">\(FP\)</span> is the number of False-Positive cases.</p>
<p><span class="math display">\[
\frac{TP}{TP + FP}
\]</span></p>
<p>Valid values for the precision metric are in the range <span class="math inline">\([0, 1]\)</span> where the higher the value the better.</p>
</section>
<section id="recall" class="slide level2">
<h2>Recall</h2>
<p>Recall tells us: out of all the positive cases, how many of them were actually found/predicted to be positive. How many of these positive cases was our model able to <em>recall</em>?</p>
<p><span class="math display">\[
\frac{TP}{TP+FN}
\]</span></p>
<p>Like precision, recall is in the range <span class="math inline">\([0, 1]\)</span> where the higher the value the better the recall.</p>
</section>
<section id="confusion-matrix" class="slide level2">
<h2>Confusion Matrix</h2>
<p>A confusion matrix is a visual representation of these different type of predictive cases (TP/TN/FP/FN).</p>
<p>An optimal confusion matrix, is a diagonal matrix (all entries outside of the diagonal are zero). Here is one example of a confusion matrix.</p>
<table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides">
<colgroup>
<col class="org-left">
<col class="org-left">
<col class="org-right">
<col class="org-right">
</colgroup>
<tbody>
<tr>
<td class="org-left">
&nbsp;
</td>
<td class="org-left">
&nbsp;
</td>
<td class="org-right">
Predicted
</td>
<td class="org-right">
&nbsp;
</td>
</tr>
<tr>
<td class="org-left">
&nbsp;
</td>
<td class="org-left">
&nbsp;
</td>
<td class="org-right">
Positive
</td>
<td class="org-right">
Negative
</td>
</tr>
<tr>
<td class="org-left">
Actual
</td>
<td class="org-left">
Positive
</td>
<td class="org-right">
5
</td>
<td class="org-right">
2
</td>
</tr>
<tr>
<td class="org-left">
&nbsp;
</td>
<td class="org-left">
Negative
</td>
<td class="org-right">
3
</td>
<td class="org-right">
1
</td>
</tr>
</tbody>
</table>
<ul>
<li><p>Values :B_column:BMCOL:</p>
<ul>
<li>TP = 5</li>
<li>TN = 1</li>
<li>FP = 3</li>
<li>FN = 2</li>
</ul></li>
<li><p>Calculation :B_column:BMCOL:</p>
<ul>
<li>Precision = <span class="math inline">\(\frac{5}{5+3} = 0.625\)</span></li>
<li>Recall = <span class="math inline">\(\frac{5}{5+2}\)</span> <span class="math inline">\(= 0.714\)</span></li>
</ul></li>
</ul>
</section>
<section id="f_beta-f_1" class="slide level2">
<h2><span class="math inline">\(F_\beta\)</span> &amp; <span class="math inline">\(F_1\)</span></h2>
<p>With the precision/recall metrics, it is trivial to optimise for one over the over:</p>
<ul>
<li>We can achieve perfect precision (<span class="math inline">\(\text{precision} = 1\)</span>) by predicting everything is negative (no false positives)</li>
<li>We can achieve perfect recall (<span class="math inline">\(\text{recall} = 1\)</span>) by predicting that everything is positive (no false negatives).</li>
</ul>
<p>But predicting everything is negative, or everything is positive is not really a useful model. So we have another metric that is the <strong>harmonic combination</strong> of precision and recall: <span class="math inline">\(F_1\)</span> and <span class="math inline">\(F_\beta\)</span> score.</p>
<p><span class="math display">\[
F_\beta = (1 + \beta^2) \frac{p \cdot r}{\beta^2 p + r}
\]</span></p>
<p>where <span class="math inline">\(p, r\)</span> is the precision and recall metric respectively. For the <span class="math inline">\(F_1\)</span> score, we simple set <span class="math inline">\(\beta = 1\)</span>.</p>
</section>
<section id="receiver-operating-characteristic-roc" class="slide level2">
<h2>Receiver Operating Characteristic (ROC)</h2>
<p>In the previous slides, we have labelled our samples as positive if our classifier predicts <span class="math inline">\(\geq 0.5\)</span>, else it is labelled as negative. This <span class="math inline">\(0.5\)</span> is our threshold for our labelling function. But we can vary this threshold if we want. Lowering the threshold will typically mean our classifier labels positive cases more often. While increasing the threshold makes the classifier more conservative, and typically predicts labels positive cases less often.</p>
<p>If we vary this threshold from 0 to 1 and calculate the true- and false-positive rate, we can visualise something we call the <strong>Receiver Operating Characteristic</strong> or ROC for short.</p>

<img data-src="images/roc.png" class="r-stretch"><p>This ROC curve, with the dotted line directly in the centre, first shows us what a random classifier would look like. This random classifier randomly predicts positive or negative for any case.</p>
<p>We can say that our classifier is better than random, if the line is to the <strong>top-left</strong> of the random classifier. In general, the more to the top-left the line is, the better.</p>
</section>
<section id="area-under-curve-auc" class="slide level2">
<h2>Area Under Curve (AUC)</h2>
<p>We’ve just seen how the ROC curve can visually point to which model is better than others, and which threshold we may want to choose for our labelling function. However, we can also turn these types of curves in a number, a metric.</p>
<p>This next metric we’re going to look at does just that. The <strong>Area Under Curve</strong> or AUC for short, takes our ROC curve, and measures the area underneath the curve, giving us a single value for each model that we can use for comparison.</p>

<img data-src="images/auc.png" class="r-stretch"><p>One method to calculate this area is to use the trapezoid rule to approximate the region underneath the graph of a function:</p>
<p><span class="math display">\[
\text{Area} = 0.5 \frac{1}{N} \times \left[ \text{TP}_1 + 2 (\text{TP}_2 + ... + \text{TP}_{N-1}) + \text{TP}_N \right]
\]</span></p>
<p>If the AUC is close to one we know that the model at any threshold has very good discriminatory power.</p>
</section></section>
<section>
<section id="choosing-the-best-model" class="title-slide slide level1 center">
<h1>Choosing the best model</h1>

</section>
<section id="cross-validation-using-k-fold" class="slide level2">
<h2>Cross Validation using K-fold</h2>
<p>We have seen why having a separate set of data for training, testing, and validation is necessary – to give some indication as to the generalisation performance of our model, and to track possible over-fitting.</p>
<p>To create these separate sets of data, we may have just sampled randomly or using a stratified method (more on this in a few slides). However, this is only one test of the model’s generalisation abilities.</p>
<p>Cross-validation is a statistical method to test the model on many <strong>resamplings</strong> on the test set.</p>

<img data-src="images/K-fold_cross_validation_EN.png" title="K-fold cross-validation (By Gufosowa - Own work, CC BY-SA 4.0, <https://commons.wikimedia.org/w/index.php?curid=82298768>)" class="r-stretch"><p>Cross-validation works selecting a subset of the data for testing (leaving the rest for training), training the model, and then calculating the performance on this test set. Next, sample a different subset of data for a new testing set, training the model, and calculating the performance. Repeat this process until all data has been sampled for the testing set, and calculate the mean and standard deviation of model performance.</p>
<p><strong>K-fold</strong> cross-validation is this method where <span class="math inline">\(k\)</span> is the number of iterations it will take to have used the entire available data for testing. I.e., if you’re performing 5-fold cross-validation, you would have trained and tested your model 5 different types, on 5 different samples from your available data.</p>
</section>
<section id="random-stratified-sampling" class="slide level2">
<h2>Random &amp; Stratified Sampling</h2>
<p>When sampling data for our training and testing set, we could use two different methods:</p>
<ul>
<li>Random</li>
<li>Stratified</li>
</ul>
<p>To perform stratified sampling, we first split the dataset into stratas or distinct groups. For a classification problem, this could be splitting samplings by their respective class labels. Then, after splitting the data into their respective groups, we randomly sample from each group.</p>
<p>Let’s say we have 150 samples, where:</p>
<ul>
<li>40 samples are in group 1,</li>
<li>25 samples are in group 2,</li>
<li>85 samples are in group 3.</li>
</ul>
<p>And we want to sample from this dataset for our test set using stratified sampling. First, we calculate the proportion of each group in the overall data:</p>
<ul>
<li><span class="math inline">\(100 \times \frac{40}{150} = 26.\overline{6}\; \%\)</span>,</li>
<li><span class="math inline">\(100 \times \frac{25}{150} = 16.\overline{6}\; \%\)</span>,</li>
<li><span class="math inline">\(100 \times \frac{85}{150} = 56.\overline{6} \; \%\)</span>.</li>
</ul>
<p>Therefore, in our testing set, <span class="math inline">\(26.\overline{6} \; \%\)</span> of the data should be randomly sampled from group 1, and so on for all groups.</p>
<p>So if we want to use <span class="math inline">\(10 \; \%\)</span> of our data for testing, that means we would have 15 samples in our dataset (<span class="math inline">\(\frac{150}{10}\)</span>) sampled using:</p>
<ul>
<li>group 1: <span class="math inline">\(40 \times (\frac{15}{150}) = 4\)</span> samples,</li>
<li>group 2: <span class="math inline">\(25\times (\frac{15}{150}) = 2.5\)</span> samples,</li>
<li>group 3: <span class="math inline">\(85 \times ( \frac{15}{150}) = 8.5\)</span> samples.</li>
</ul>
<p>The proportion of samples in our test set from each group should roughly match the proportion of the overall available data. We can verify this by calculating the proportion of each group’s representation, i.e.&nbsp;: <span class="math inline">\(100 \times \frac{4}{15} =
26.\overline{6} \; \%\)</span> and we see that it matches the proportion of the overall data.</p>
<p>Stratified sampling is especially useful when we have a class-imbalance, and randomly sampling data could potentially lead to a situation where our test or training set only has one class label.</p>
</section></section>
<section id="summary" class="title-slide slide level1 center">
<h1>Summary</h1>
<p>In this lecture we have discussed the following things:</p>
<ul>
<li>The idea behind having different subsets of data dedicated to training, testing, and validation.</li>
<li>Different metrics that are used to evaluation regression and classification models.</li>
<li>Various methods to sample data using cross-validation, random, or stratified sampling.</li>
</ul>


</section>
    </div>
  <div class="quarto-auto-generated-content" style="display: none;">
<div class="footer footer-default">

</div>
</div></div>

  <script>window.backupDefine = window.define; window.define = undefined;</script>
  <script src="../../../site_libs/revealjs/dist/reveal.js"></script>
  <!-- reveal.js plugins -->
  <script src="../../../site_libs/revealjs/plugin/quarto-line-highlight/line-highlight.js"></script>
  <script src="../../../site_libs/revealjs/plugin/pdf-export/pdfexport.js"></script>
  <script src="../../../site_libs/revealjs/plugin/reveal-menu/menu.js"></script>
  <script src="../../../site_libs/revealjs/plugin/reveal-menu/quarto-menu.js"></script>
  <script src="../../../site_libs/revealjs/plugin/quarto-support/support.js"></script>
  

  <script src="../../../site_libs/revealjs/plugin/notes/notes.js"></script>
  <script src="../../../site_libs/revealjs/plugin/search/search.js"></script>
  <script src="../../../site_libs/revealjs/plugin/zoom/zoom.js"></script>
  <script src="../../../site_libs/revealjs/plugin/math/math.js"></script>
  <script>window.define = window.backupDefine; window.backupDefine = undefined;</script>

  <script>

      // Full list of configuration options available at:
      // https://revealjs.com/config/
      Reveal.initialize({
'controlsAuto': true,
'previewLinksAuto': false,
'pdfSeparateFragments': false,
'autoAnimateEasing': "ease",
'autoAnimateDuration': 1,
'autoAnimateUnmatched': true,
'jumpToSlide': true,
'menu': {"side":"left","useTextContentForMissingTitles":true,"markers":false,"loadIcons":false,"custom":[{"title":"Tools","icon":"<i class=\"fas fa-gear\"></i>","content":"<ul class=\"slide-menu-items\">\n<li class=\"slide-tool-item active\" data-item=\"0\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.fullscreen(event)\"><kbd>f</kbd> Fullscreen</a></li>\n<li class=\"slide-tool-item\" data-item=\"1\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.speakerMode(event)\"><kbd>s</kbd> Speaker View</a></li>\n<li class=\"slide-tool-item\" data-item=\"2\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.overview(event)\"><kbd>o</kbd> Slide Overview</a></li>\n<li class=\"slide-tool-item\" data-item=\"3\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.togglePdfExport(event)\"><kbd>e</kbd> PDF Export Mode</a></li>\n<li class=\"slide-tool-item\" data-item=\"4\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.toggleScrollView(event)\"><kbd>r</kbd> Scroll View Mode</a></li>\n<li class=\"slide-tool-item\" data-item=\"5\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.keyboardHelp(event)\"><kbd>?</kbd> Keyboard Help</a></li>\n</ul>"}],"openButton":true},
'smaller': false,
 
        // Display controls in the bottom right corner
        controls: false,

        // Help the user learn the controls by providing hints, for example by
        // bouncing the down arrow when they first encounter a vertical slide
        controlsTutorial: false,

        // Determines where controls appear, "edges" or "bottom-right"
        controlsLayout: 'edges',

        // Visibility rule for backwards navigation arrows; "faded", "hidden"
        // or "visible"
        controlsBackArrows: 'faded',

        // Display a presentation progress bar
        progress: true,

        // Display the page number of the current slide
        slideNumber: false,

        // 'all', 'print', or 'speaker'
        showSlideNumber: 'all',

        // Add the current slide number to the URL hash so that reloading the
        // page/copying the URL will return you to the same slide
        hash: true,

        // Start with 1 for the hash rather than 0
        hashOneBasedIndex: false,

        // Flags if we should monitor the hash and change slides accordingly
        respondToHashChanges: true,

        // Push each slide change to the browser history
        history: true,

        // Enable keyboard shortcuts for navigation
        keyboard: true,

        // Enable the slide overview mode
        overview: true,

        // Disables the default reveal.js slide layout (scaling and centering)
        // so that you can use custom CSS layout
        disableLayout: false,

        // Vertical centering of slides
        center: false,

        // Enables touch navigation on devices with touch input
        touch: true,

        // Loop the presentation
        loop: false,

        // Change the presentation direction to be RTL
        rtl: false,

        // see https://revealjs.com/vertical-slides/#navigation-mode
        navigationMode: 'linear',

        // Randomizes the order of slides each time the presentation loads
        shuffle: false,

        // Turns fragments on and off globally
        fragments: true,

        // Flags whether to include the current fragment in the URL,
        // so that reloading brings you to the same fragment position
        fragmentInURL: false,

        // Flags if the presentation is running in an embedded mode,
        // i.e. contained within a limited portion of the screen
        embedded: false,

        // Flags if we should show a help overlay when the questionmark
        // key is pressed
        help: true,

        // Flags if it should be possible to pause the presentation (blackout)
        pause: true,

        // Flags if speaker notes should be visible to all viewers
        showNotes: false,

        // Global override for autoplaying embedded media (null/true/false)
        autoPlayMedia: null,

        // Global override for preloading lazy-loaded iframes (null/true/false)
        preloadIframes: null,

        // Number of milliseconds between automatically proceeding to the
        // next slide, disabled when set to 0, this value can be overwritten
        // by using a data-autoslide attribute on your slides
        autoSlide: 0,

        // Stop auto-sliding after user input
        autoSlideStoppable: true,

        // Use this method for navigation when auto-sliding
        autoSlideMethod: null,

        // Specify the average time in seconds that you think you will spend
        // presenting each slide. This is used to show a pacing timer in the
        // speaker view
        defaultTiming: null,

        // Enable slide navigation via mouse wheel
        mouseWheel: false,

        // The display mode that will be used to show slides
        display: 'block',

        // Hide cursor if inactive
        hideInactiveCursor: true,

        // Time before the cursor is hidden (in ms)
        hideCursorTime: 5000,

        // Opens links in an iframe preview overlay
        previewLinks: false,

        // Transition style (none/fade/slide/convex/concave/zoom)
        transition: 'none',

        // Transition speed (default/fast/slow)
        transitionSpeed: 'default',

        // Transition style for full page slide backgrounds
        // (none/fade/slide/convex/concave/zoom)
        backgroundTransition: 'none',

        // Number of slides away from the current that are visible
        viewDistance: 3,

        // Number of slides away from the current that are visible on mobile
        // devices. It is advisable to set this to a lower number than
        // viewDistance in order to save resources.
        mobileViewDistance: 2,

        // The "normal" size of the presentation, aspect ratio will be preserved
        // when the presentation is scaled to fit different resolutions. Can be
        // specified using percentage units.
        width: 1050,

        height: 700,

        // Factor of the display size that should remain empty around the content
        margin: 0.1,

        math: {
          mathjax: 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/MathJax.js',
          config: 'TeX-AMS_HTML-full',
          tex2jax: {
            inlineMath: [['\\(','\\)']],
            displayMath: [['\\[','\\]']],
            balanceBraces: true,
            processEscapes: false,
            processRefs: true,
            processEnvironments: true,
            preview: 'TeX',
            skipTags: ['script','noscript','style','textarea','pre','code'],
            ignoreClass: 'tex2jax_ignore',
            processClass: 'tex2jax_process'
          },
        },

        // reveal.js plugins
        plugins: [QuartoLineHighlight, PdfExport, RevealMenu, QuartoSupport,

          RevealMath,
          RevealNotes,
          RevealSearch,
          RevealZoom
        ]
      });
    </script>
    <script id="quarto-html-after-body" type="application/javascript">
    window.document.addEventListener("DOMContentLoaded", function (event) {
      const toggleBodyColorMode = (bsSheetEl) => {
        const mode = bsSheetEl.getAttribute("data-mode");
        const bodyEl = window.document.querySelector("body");
        if (mode === "dark") {
          bodyEl.classList.add("quarto-dark");
          bodyEl.classList.remove("quarto-light");
        } else {
          bodyEl.classList.add("quarto-light");
          bodyEl.classList.remove("quarto-dark");
        }
      }
      const toggleBodyColorPrimary = () => {
        const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
        if (bsSheetEl) {
          toggleBodyColorMode(bsSheetEl);
        }
      }
      toggleBodyColorPrimary();  
      const tabsets =  window.document.querySelectorAll(".panel-tabset-tabby")
      tabsets.forEach(function(tabset) {
        const tabby = new Tabby('#' + tabset.id);
      });
      const isCodeAnnotation = (el) => {
        for (const clz of el.classList) {
          if (clz.startsWith('code-annotation-')) {                     
            return true;
          }
        }
        return false;
      }
      const onCopySuccess = function(e) {
        // button target
        const button = e.trigger;
        // don't keep focus
        button.blur();
        // flash "checked"
        button.classList.add('code-copy-button-checked');
        var currentTitle = button.getAttribute("title");
        button.setAttribute("title", "Copied!");
        let tooltip;
        if (window.bootstrap) {
          button.setAttribute("data-bs-toggle", "tooltip");
          button.setAttribute("data-bs-placement", "left");
          button.setAttribute("data-bs-title", "Copied!");
          tooltip = new bootstrap.Tooltip(button, 
            { trigger: "manual", 
              customClass: "code-copy-button-tooltip",
              offset: [0, -8]});
          tooltip.show();    
        }
        setTimeout(function() {
          if (tooltip) {
            tooltip.hide();
            button.removeAttribute("data-bs-title");
            button.removeAttribute("data-bs-toggle");
            button.removeAttribute("data-bs-placement");
          }
          button.setAttribute("title", currentTitle);
          button.classList.remove('code-copy-button-checked');
        }, 1000);
        // clear code selection
        e.clearSelection();
      }
      const getTextToCopy = function(trigger) {
          const codeEl = trigger.previousElementSibling.cloneNode(true);
          for (const childEl of codeEl.children) {
            if (isCodeAnnotation(childEl)) {
              childEl.remove();
            }
          }
          return codeEl.innerText;
      }
      const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
        text: getTextToCopy
      });
      clipboard.on('success', onCopySuccess);
      if (window.document.getElementById('quarto-embedded-source-code-modal')) {
        const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
          text: getTextToCopy,
          container: window.document.getElementById('quarto-embedded-source-code-modal')
        });
        clipboardModal.on('success', onCopySuccess);
      }
        var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
        var mailtoRegex = new RegExp(/^mailto:/);
          var filterRegex = new RegExp("https:\/\/morganwastaken\.com");
        var isInternal = (href) => {
            return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
        }
        // Inspect non-navigation links and adorn them if external
     	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
        for (var i=0; i<links.length; i++) {
          const link = links[i];
          if (!isInternal(link.href)) {
            // undo the damage that might have been done by quarto-nav.js in the case of
            // links that we want to consider external
            if (link.dataset.originalHref !== undefined) {
              link.href = link.dataset.originalHref;
            }
          }
        }
      function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
        const config = {
          allowHTML: true,
          maxWidth: 500,
          delay: 100,
          arrow: false,
          appendTo: function(el) {
              return el.closest('section.slide') || el.parentElement;
          },
          interactive: true,
          interactiveBorder: 10,
          theme: 'light-border',
          placement: 'bottom-start',
        };
        if (contentFn) {
          config.content = contentFn;
        }
        if (onTriggerFn) {
          config.onTrigger = onTriggerFn;
        }
        if (onUntriggerFn) {
          config.onUntrigger = onUntriggerFn;
        }
          config['offset'] = [0,0];
          config['maxWidth'] = 700;
        window.tippy(el, config); 
      }
      const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
      for (var i=0; i<noterefs.length; i++) {
        const ref = noterefs[i];
        tippyHover(ref, function() {
          // use id or data attribute instead here
          let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
          try { href = new URL(href).hash; } catch {}
          const id = href.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note) {
            return note.innerHTML;
          } else {
            return "";
          }
        });
      }
      const findCites = (el) => {
        const parentEl = el.parentElement;
        if (parentEl) {
          const cites = parentEl.dataset.cites;
          if (cites) {
            return {
              el,
              cites: cites.split(' ')
            };
          } else {
            return findCites(el.parentElement)
          }
        } else {
          return undefined;
        }
      };
      var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
      for (var i=0; i<bibliorefs.length; i++) {
        const ref = bibliorefs[i];
        const citeInfo = findCites(ref);
        if (citeInfo) {
          tippyHover(citeInfo.el, function() {
            var popup = window.document.createElement('div');
            citeInfo.cites.forEach(function(cite) {
              var citeDiv = window.document.createElement('div');
              citeDiv.classList.add('hanging-indent');
              citeDiv.classList.add('csl-entry');
              var biblioDiv = window.document.getElementById('ref-' + cite);
              if (biblioDiv) {
                citeDiv.innerHTML = biblioDiv.innerHTML;
              }
              popup.appendChild(citeDiv);
            });
            return popup.innerHTML;
          });
        }
      }
    });
    </script>
    

</body></html>
