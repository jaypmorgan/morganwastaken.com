[
  {
    "objectID": "lecture-5.html",
    "href": "lecture-5.html",
    "title": "K-Nearest Neighbour & K-Means",
    "section": "",
    "text": "The first algorithm we’re going to see today is a very simple one. Let’s image we have a feature space with labelled data points, such as this:\n\nWe want to use these labelled data points as our training data to be able to predict the classification of new data points (such as those from our testing set).\nThe algorithm we’re going to use to do this classification is called K-nearest neighbour, or kNN for short. This algorithm isn’t mathematically derived as some others we’ve seen, but rather based on intuition.\n\n\n\nkNN is a classification algorithm where, we as the user, get to set \\(K\\) ourselves. \\(K\\) is the number of neighbours that will be considered for the model’s classification.\nNeighbour’s of a new data point can be determined using the euclidean distance, and selecting \\(K\\) closest points.\n\nLet’s say we set \\(K=3\\), this means that when we have a new data point we want to classify, we’re going to find out where this new data point falls in the feature space, and find 3 of it’s closest neighbours. Using these closet neighbours, we will assign this new data point the same class as the class majority of it’s neighbours.\n\n\n\n\\(K\\) in the kNN algorithm is user defined, and the larger the number, the more neighbours will be used. One fun example of the effect of \\(K\\) is that if we were to set \\(K=N\\) where \\(N\\) is the number of data points in our training set, then we will always assign new data points the majority class.\n\n\n\n\nWhat if, when using \\(K=4\\), two neighbours are of class 1, while the other two neighbours are of class 2. Which class is assigned to our new data point? Well, since the k-NN algorithm is not a mathematically derived algorithm, but based on the intuition that with similar coordinates in a feature space should be similar classes, then it’s up to you to decide how to deal with ‘ties’. One example, would be to avoid them all together and only use an odd \\(K\\). Another option would be to weight the neighbours by the distance to the new point to be classified. So that closer points have a higher weight. In summary here are some options:\n\nOnly use odd valued \\(K\\).\nDecrease \\(K\\) until the tie is broken.\nWeight neighbours by the distance."
  },
  {
    "objectID": "lecture-5.html#problem-statement",
    "href": "lecture-5.html#problem-statement",
    "title": "K-Nearest Neighbour & K-Means",
    "section": "",
    "text": "The first algorithm we’re going to see today is a very simple one. Let’s image we have a feature space with labelled data points, such as this:\n\nWe want to use these labelled data points as our training data to be able to predict the classification of new data points (such as those from our testing set).\nThe algorithm we’re going to use to do this classification is called K-nearest neighbour, or kNN for short. This algorithm isn’t mathematically derived as some others we’ve seen, but rather based on intuition."
  },
  {
    "objectID": "lecture-5.html#example-solution",
    "href": "lecture-5.html#example-solution",
    "title": "K-Nearest Neighbour & K-Means",
    "section": "",
    "text": "kNN is a classification algorithm where, we as the user, get to set \\(K\\) ourselves. \\(K\\) is the number of neighbours that will be considered for the model’s classification.\nNeighbour’s of a new data point can be determined using the euclidean distance, and selecting \\(K\\) closest points.\n\nLet’s say we set \\(K=3\\), this means that when we have a new data point we want to classify, we’re going to find out where this new data point falls in the feature space, and find 3 of it’s closest neighbours. Using these closet neighbours, we will assign this new data point the same class as the class majority of it’s neighbours."
  },
  {
    "objectID": "lecture-5.html#the-effect-of-k",
    "href": "lecture-5.html#the-effect-of-k",
    "title": "K-Nearest Neighbour & K-Means",
    "section": "",
    "text": "\\(K\\) in the kNN algorithm is user defined, and the larger the number, the more neighbours will be used. One fun example of the effect of \\(K\\) is that if we were to set \\(K=N\\) where \\(N\\) is the number of data points in our training set, then we will always assign new data points the majority class."
  },
  {
    "objectID": "lecture-5.html#accounting-for-tiesdraws",
    "href": "lecture-5.html#accounting-for-tiesdraws",
    "title": "K-Nearest Neighbour & K-Means",
    "section": "",
    "text": "What if, when using \\(K=4\\), two neighbours are of class 1, while the other two neighbours are of class 2. Which class is assigned to our new data point? Well, since the k-NN algorithm is not a mathematically derived algorithm, but based on the intuition that with similar coordinates in a feature space should be similar classes, then it’s up to you to decide how to deal with ‘ties’. One example, would be to avoid them all together and only use an odd \\(K\\). Another option would be to weight the neighbours by the distance to the new point to be classified. So that closer points have a higher weight. In summary here are some options:\n\nOnly use odd valued \\(K\\).\nDecrease \\(K\\) until the tie is broken.\nWeight neighbours by the distance."
  },
  {
    "objectID": "lecture-5.html#problem-statement-1",
    "href": "lecture-5.html#problem-statement-1",
    "title": "K-Nearest Neighbour & K-Means",
    "section": "Problem statement",
    "text": "Problem statement\nSay we had a set of data, un-labelled data, and we wanted to separate them into groups or classes. Below we have an example where, as humans, we can see 3 distinct groups of data points. In today’s lecture, we’re going to look at an algorithm that can identify these same clusters or groups systematically."
  },
  {
    "objectID": "lecture-5.html#k-means-clustering",
    "href": "lecture-5.html#k-means-clustering",
    "title": "K-Nearest Neighbour & K-Means",
    "section": "K-Means clustering",
    "text": "K-Means clustering\nThis algorithm is called K-means. In essence, it is an algorithm that finds \\(K\\) different clusters or groups of points, where \\(K\\) is defined by the user.\n\nOf course, we have to, ourselves, pick a value of for \\(K\\). For data that has more than 3-dimensions, we might not know how many groups there are inherently in the data."
  },
  {
    "objectID": "lecture-5.html#starting-point",
    "href": "lecture-5.html#starting-point",
    "title": "K-Nearest Neighbour & K-Means",
    "section": "Starting point",
    "text": "Starting point\nK-means is an iterative algorithm, which means that the centroids of the clusters will be randomly assigned in the feature space. Let’s say that we initialise a K-means algorithm with \\(K = 3\\). We might have something that looks like:"
  },
  {
    "objectID": "lecture-5.html#iterative-process",
    "href": "lecture-5.html#iterative-process",
    "title": "K-Nearest Neighbour & K-Means",
    "section": "Iterative process",
    "text": "Iterative process\nAs mentioned, K-means is an iterative process of assigning the position of the cluster’s centroid. Therefore, after randomly assigning each centroid to a different point in the feature space, the algorithm will iteratively move the centroid to better match the true clustering of data points. We’ll get back to how this is mathematically done later in the lecture, but for now we want to understand this intuition."
  },
  {
    "objectID": "lecture-5.html#assigning-centroids",
    "href": "lecture-5.html#assigning-centroids",
    "title": "K-Nearest Neighbour & K-Means",
    "section": "Assigning centroids",
    "text": "Assigning centroids\nAfter the algorithm has converged or stopped, we will have 3 centroids, that will, hopefully, match the true clustering of data points.\nAfter we have these positioned centroids, they can be used to label new data points by determining to which cluster do the new data points fall under, or are closet to."
  },
  {
    "objectID": "lecture-5.html#initialisation",
    "href": "lecture-5.html#initialisation",
    "title": "K-Nearest Neighbour & K-Means",
    "section": "Initialisation",
    "text": "Initialisation\nLet \\(C\\) be the set of cluster centroids:\n\\[C = \\{c_1, c_2, ..., c_K\\}\\]\nAnd let \\(S(c_i)\\) be the set of all points \\(x_i\\) that are located within the cluster \\(c_i\\). The intersection of all \\(S\\) will be the null set (each point will be assigned to only one cluster):\n\\[ \\bigcap_{i=1}^{K} S(c_i) = \\emptyset \\]\nTo initialise the K-means algorithm, we randomly select \\(K\\) data points as the location of the centroids, i.e. \\(x_i = c_i\\).\nAfter, we compute \\(S(c_i)\\) by the minimum euclidean distance to each centroid. I.e., to determine whether a new point falls within the cluster of \\(c_i\\), we can use the euclidean distance between \\(x_i\\) and \\(c_i\\):\n\\[ \\arg \\min_{c_i \\in C} || x_i - c_i ||^2 \\]\nSo we select the cluster to which our new \\(x_i\\) data point is closest to.\nThe position of each centroid \\(c_i\\) is the geometric mean of the data points contained within the cluster:\n\\[ c_i = \\frac{1}{|S(c_i)|} \\sum_{x_j \\in S(c_i)} x_j \\]"
  },
  {
    "objectID": "lecture-5.html#iteration",
    "href": "lecture-5.html#iteration",
    "title": "K-Nearest Neighbour & K-Means",
    "section": "Iteration",
    "text": "Iteration\nClassic optimisation problem:\n\\[ \\arg \\min_c \\sum_{c_i \\in C} \\sum_{x_j \\in S(c_i)} || x_j - c_i ||^2 \\]\nThere are 3 criterions for stopping the iterative process:\n\nThere are no more changes in clusters by moving the centroids.\nPoints remain within the same cluster as before.\nA maximum number of steps/iterations has been reached."
  },
  {
    "objectID": "lecture-5.html#classification",
    "href": "lecture-5.html#classification",
    "title": "K-Nearest Neighbour & K-Means",
    "section": "Classification",
    "text": "Classification\nTo determine whether a new point falls within the cluster of \\(c_i\\), we can use the euclidean distance between \\(x_i\\) and \\(c_i\\):\n\\[ \\arg \\min_{c_i \\in C} || x_i - c_i ||^2 \\]\nSo we select the cluster to which our new \\(x_i\\) data point is closest to."
  },
  {
    "objectID": "lecture-5.html#evaluation-of-k-means",
    "href": "lecture-5.html#evaluation-of-k-means",
    "title": "K-Nearest Neighbour & K-Means",
    "section": "Evaluation of K-means",
    "text": "Evaluation of K-means\nSince we don’t have true labels with which to evaluate the k-means algorithm against, we must take a different tactic for evaluating the classifications or group of points it has clustered together. This works by evaluating the structure of the clusters.\nintra-cluster distance – the average distance between all data points in the same cluster.\n\nintra-cluster diameter – the distance between the two most remote objects in a cluster."
  },
  {
    "objectID": "lecture-5.html#inter-cluster-distance",
    "href": "lecture-5.html#inter-cluster-distance",
    "title": "K-Nearest Neighbour & K-Means",
    "section": "Inter-cluster distance",
    "text": "Inter-cluster distance\n\ninter-cluster distance – average smallest distance to a different cluster.\nsilhouette score – \\(\\frac{\\text{intra} - \\text{inter}}{\\max(\\text{intra}, \\text{inter})}\\)"
  },
  {
    "objectID": "lecture-5.html#the-effect-of-k-1",
    "href": "lecture-5.html#the-effect-of-k-1",
    "title": "K-Nearest Neighbour & K-Means",
    "section": "The effect of \\(K\\)",
    "text": "The effect of \\(K\\)\nThe \\(K\\) in k-means clustering determines how many clusters the algorithm will try to find. But if our data is un-labelled, how do we know what to set \\(K\\) equal to? The answer is that we don’t necessarily. So we might create several different clustering algorithms where we vary the value for \\(K\\) and evaluate the resulting model.\nThis may give us some indication as to how many clusters to use.\nOther times the value for \\(K\\) will be inherent to the problem you’re trying to solve. For example, if we’re trying to cluster and label the calls of different birds, we may know the number of different bird species that were recorded, thus providing some grounds for setting \\(K\\)."
  },
  {
    "objectID": "lecture-5-revealjs.html#problem-statement",
    "href": "lecture-5-revealjs.html#problem-statement",
    "title": "K-Nearest Neighbour & K-Means",
    "section": "Problem statement",
    "text": "Problem statement\nThe first algorithm we’re going to see today is a very simple one. Let’s image we have a feature space with labelled data points, such as this:\n\nWe want to use these labelled data points as our training data to be able to predict the classification of new data points (such as those from our testing set).\nThe algorithm we’re going to use to do this classification is called K-nearest neighbour, or kNN for short. This algorithm isn’t mathematically derived as some others we’ve seen, but rather based on intuition."
  },
  {
    "objectID": "lecture-5-revealjs.html#example-solution",
    "href": "lecture-5-revealjs.html#example-solution",
    "title": "K-Nearest Neighbour & K-Means",
    "section": "Example solution",
    "text": "Example solution\nkNN is a classification algorithm where, we as the user, get to set \\(K\\) ourselves. \\(K\\) is the number of neighbours that will be considered for the model’s classification.\nNeighbour’s of a new data point can be determined using the euclidean distance, and selecting \\(K\\) closest points.\n\nLet’s say we set \\(K=3\\), this means that when we have a new data point we want to classify, we’re going to find out where this new data point falls in the feature space, and find 3 of it’s closest neighbours. Using these closet neighbours, we will assign this new data point the same class as the class majority of it’s neighbours."
  },
  {
    "objectID": "lecture-5-revealjs.html#the-effect-of-k",
    "href": "lecture-5-revealjs.html#the-effect-of-k",
    "title": "K-Nearest Neighbour & K-Means",
    "section": "The effect of \\(K\\)",
    "text": "The effect of \\(K\\)\n\\(K\\) in the kNN algorithm is user defined, and the larger the number, the more neighbours will be used. One fun example of the effect of \\(K\\) is that if we were to set \\(K=N\\) where \\(N\\) is the number of data points in our training set, then we will always assign new data points the majority class."
  },
  {
    "objectID": "lecture-5-revealjs.html#accounting-for-tiesdraws",
    "href": "lecture-5-revealjs.html#accounting-for-tiesdraws",
    "title": "K-Nearest Neighbour & K-Means",
    "section": "Accounting for ‘ties’/‘draws’",
    "text": "Accounting for ‘ties’/‘draws’\nWhat if, when using \\(K=4\\), two neighbours are of class 1, while the other two neighbours are of class 2. Which class is assigned to our new data point? Well, since the k-NN algorithm is not a mathematically derived algorithm, but based on the intuition that with similar coordinates in a feature space should be similar classes, then it’s up to you to decide how to deal with ‘ties’. One example, would be to avoid them all together and only use an odd \\(K\\). Another option would be to weight the neighbours by the distance to the new point to be classified. So that closer points have a higher weight. In summary here are some options:\n\nOnly use odd valued \\(K\\).\nDecrease \\(K\\) until the tie is broken.\nWeight neighbours by the distance."
  },
  {
    "objectID": "lecture-5-revealjs.html#problem-statement-1",
    "href": "lecture-5-revealjs.html#problem-statement-1",
    "title": "K-Nearest Neighbour & K-Means",
    "section": "Problem statement",
    "text": "Problem statement\nSay we had a set of data, un-labelled data, and we wanted to separate them into groups or classes. Below we have an example where, as humans, we can see 3 distinct groups of data points. In today’s lecture, we’re going to look at an algorithm that can identify these same clusters or groups systematically."
  },
  {
    "objectID": "lecture-5-revealjs.html#k-means-clustering",
    "href": "lecture-5-revealjs.html#k-means-clustering",
    "title": "K-Nearest Neighbour & K-Means",
    "section": "K-Means clustering",
    "text": "K-Means clustering\nThis algorithm is called K-means. In essence, it is an algorithm that finds \\(K\\) different clusters or groups of points, where \\(K\\) is defined by the user.\n\nOf course, we have to, ourselves, pick a value of for \\(K\\). For data that has more than 3-dimensions, we might not know how many groups there are inherently in the data."
  },
  {
    "objectID": "lecture-5-revealjs.html#starting-point",
    "href": "lecture-5-revealjs.html#starting-point",
    "title": "K-Nearest Neighbour & K-Means",
    "section": "Starting point",
    "text": "Starting point\nK-means is an iterative algorithm, which means that the centroids of the clusters will be randomly assigned in the feature space. Let’s say that we initialise a K-means algorithm with \\(K = 3\\). We might have something that looks like:"
  },
  {
    "objectID": "lecture-5-revealjs.html#iterative-process",
    "href": "lecture-5-revealjs.html#iterative-process",
    "title": "K-Nearest Neighbour & K-Means",
    "section": "Iterative process",
    "text": "Iterative process\nAs mentioned, K-means is an iterative process of assigning the position of the cluster’s centroid. Therefore, after randomly assigning each centroid to a different point in the feature space, the algorithm will iteratively move the centroid to better match the true clustering of data points. We’ll get back to how this is mathematically done later in the lecture, but for now we want to understand this intuition."
  },
  {
    "objectID": "lecture-5-revealjs.html#assigning-centroids",
    "href": "lecture-5-revealjs.html#assigning-centroids",
    "title": "K-Nearest Neighbour & K-Means",
    "section": "Assigning centroids",
    "text": "Assigning centroids\nAfter the algorithm has converged or stopped, we will have 3 centroids, that will, hopefully, match the true clustering of data points.\nAfter we have these positioned centroids, they can be used to label new data points by determining to which cluster do the new data points fall under, or are closet to."
  },
  {
    "objectID": "lecture-5-revealjs.html#initialisation",
    "href": "lecture-5-revealjs.html#initialisation",
    "title": "K-Nearest Neighbour & K-Means",
    "section": "Initialisation",
    "text": "Initialisation\nLet \\(C\\) be the set of cluster centroids:\n\\[C = \\{c_1, c_2, ..., c_K\\}\\]\nAnd let \\(S(c_i)\\) be the set of all points \\(x_i\\) that are located within the cluster \\(c_i\\). The intersection of all \\(S\\) will be the null set (each point will be assigned to only one cluster):\n\\[ \\bigcap_{i=1}^{K} S(c_i) = \\emptyset \\]\nTo initialise the K-means algorithm, we randomly select \\(K\\) data points as the location of the centroids, i.e. \\(x_i = c_i\\).\nAfter, we compute \\(S(c_i)\\) by the minimum euclidean distance to each centroid. I.e., to determine whether a new point falls within the cluster of \\(c_i\\), we can use the euclidean distance between \\(x_i\\) and \\(c_i\\):\n\\[ \\arg \\min_{c_i \\in C} || x_i - c_i ||^2 \\]\nSo we select the cluster to which our new \\(x_i\\) data point is closest to.\nThe position of each centroid \\(c_i\\) is the geometric mean of the data points contained within the cluster:\n\\[ c_i = \\frac{1}{|S(c_i)|} \\sum_{x_j \\in S(c_i)} x_j \\]"
  },
  {
    "objectID": "lecture-5-revealjs.html#iteration",
    "href": "lecture-5-revealjs.html#iteration",
    "title": "K-Nearest Neighbour & K-Means",
    "section": "Iteration",
    "text": "Iteration\nClassic optimisation problem:\n\\[ \\arg \\min_c \\sum_{c_i \\in C} \\sum_{x_j \\in S(c_i)} || x_j - c_i ||^2 \\]\nThere are 3 criterions for stopping the iterative process:\n\nThere are no more changes in clusters by moving the centroids.\nPoints remain within the same cluster as before.\nA maximum number of steps/iterations has been reached."
  },
  {
    "objectID": "lecture-5-revealjs.html#classification",
    "href": "lecture-5-revealjs.html#classification",
    "title": "K-Nearest Neighbour & K-Means",
    "section": "Classification",
    "text": "Classification\nTo determine whether a new point falls within the cluster of \\(c_i\\), we can use the euclidean distance between \\(x_i\\) and \\(c_i\\):\n\\[ \\arg \\min_{c_i \\in C} || x_i - c_i ||^2 \\]\nSo we select the cluster to which our new \\(x_i\\) data point is closest to."
  },
  {
    "objectID": "lecture-5-revealjs.html#evaluation-of-k-means",
    "href": "lecture-5-revealjs.html#evaluation-of-k-means",
    "title": "K-Nearest Neighbour & K-Means",
    "section": "Evaluation of K-means",
    "text": "Evaluation of K-means\nSince we don’t have true labels with which to evaluate the k-means algorithm against, we must take a different tactic for evaluating the classifications or group of points it has clustered together. This works by evaluating the structure of the clusters.\nintra-cluster distance – the average distance between all data points in the same cluster.\n\nintra-cluster diameter – the distance between the two most remote objects in a cluster."
  },
  {
    "objectID": "lecture-5-revealjs.html#inter-cluster-distance",
    "href": "lecture-5-revealjs.html#inter-cluster-distance",
    "title": "K-Nearest Neighbour & K-Means",
    "section": "Inter-cluster distance",
    "text": "Inter-cluster distance\n\ninter-cluster distance – average smallest distance to a different cluster.\nsilhouette score – \\(\\frac{\\text{intra} - \\text{inter}}{\\max(\\text{intra}, \\text{inter})}\\)"
  },
  {
    "objectID": "lecture-5-revealjs.html#the-effect-of-k-1",
    "href": "lecture-5-revealjs.html#the-effect-of-k-1",
    "title": "K-Nearest Neighbour & K-Means",
    "section": "The effect of \\(K\\)",
    "text": "The effect of \\(K\\)\nThe \\(K\\) in k-means clustering determines how many clusters the algorithm will try to find. But if our data is un-labelled, how do we know what to set \\(K\\) equal to? The answer is that we don’t necessarily. So we might create several different clustering algorithms where we vary the value for \\(K\\) and evaluate the resulting model.\nThis may give us some indication as to how many clusters to use.\nOther times the value for \\(K\\) will be inherent to the problem you’re trying to solve. For example, if we’re trying to cluster and label the calls of different birds, we may know the number of different bird species that were recorded, thus providing some grounds for setting \\(K\\)."
  },
  {
    "objectID": "lecture-3.html",
    "href": "lecture-3.html",
    "title": "Model Performance",
    "section": "",
    "text": "We’ve seen in the previous lecture how we can fit a linear regression model to a set of data, and we can measure the performance of this model.\nBut we do not understand how well this model works in the ‘real-world’, how well it performs on data that has not yet been ‘seen’, how well the model generalises to this unknown data.\nSo, when we want to create a machine learning model, we usually take our data, and split into two (sometimes three) sets of data. These different sets are named:\n\ntraining set,\ntesting set,\nand (optionally) validation set.\n\n\n\n\nThe training dataset, is the set of data, that we’re allowing the model to `see’ or learn from.\nIn our example of the linear regression, this is the set of data points to which we find the optimal parameters of our model.\nIt is not very useful to evaluate our model’s performance with the training set as it doesn’t tell us how well it’s actually doing (we’ll come back to this when we talk about over-/under-fitting).\n\n\n\nThe testing set is the set of data that we use to evaluate the generalisation of our machine learning model. The model is not allowed to use this set of data during training, but it is simply used for the evaluation of the model.\nIn general the testing set is between 10-30% of the overall available data, but this rule is not something dictated, and may vary depending on the amount of data available and the overall use case.\nOnce the 10-30% of the data has been sampled for the testing set, the rest of the data can be used for the training and validation sets.\n\n\n\nIf we have an iterative optimisation process (such as what we saw with gradient descent), we might want to know how well our model is possibly generalising to unseen data.\nThe validation dataset, is the set of data that we use to measure the generalisation of our model during the course of its learning process. Like the test set, this validation data should not be used to train the model, but only used to measure the model’s generalisation during the lifetime of the learning process."
  },
  {
    "objectID": "lecture-3.html#why-do-we-have-different-sets-of-data",
    "href": "lecture-3.html#why-do-we-have-different-sets-of-data",
    "title": "Model Performance",
    "section": "",
    "text": "We’ve seen in the previous lecture how we can fit a linear regression model to a set of data, and we can measure the performance of this model.\nBut we do not understand how well this model works in the ‘real-world’, how well it performs on data that has not yet been ‘seen’, how well the model generalises to this unknown data.\nSo, when we want to create a machine learning model, we usually take our data, and split into two (sometimes three) sets of data. These different sets are named:\n\ntraining set,\ntesting set,\nand (optionally) validation set."
  },
  {
    "objectID": "lecture-3.html#training-set",
    "href": "lecture-3.html#training-set",
    "title": "Model Performance",
    "section": "",
    "text": "The training dataset, is the set of data, that we’re allowing the model to `see’ or learn from.\nIn our example of the linear regression, this is the set of data points to which we find the optimal parameters of our model.\nIt is not very useful to evaluate our model’s performance with the training set as it doesn’t tell us how well it’s actually doing (we’ll come back to this when we talk about over-/under-fitting)."
  },
  {
    "objectID": "lecture-3.html#testing-set",
    "href": "lecture-3.html#testing-set",
    "title": "Model Performance",
    "section": "",
    "text": "The testing set is the set of data that we use to evaluate the generalisation of our machine learning model. The model is not allowed to use this set of data during training, but it is simply used for the evaluation of the model.\nIn general the testing set is between 10-30% of the overall available data, but this rule is not something dictated, and may vary depending on the amount of data available and the overall use case.\nOnce the 10-30% of the data has been sampled for the testing set, the rest of the data can be used for the training and validation sets."
  },
  {
    "objectID": "lecture-3.html#validation-set",
    "href": "lecture-3.html#validation-set",
    "title": "Model Performance",
    "section": "",
    "text": "If we have an iterative optimisation process (such as what we saw with gradient descent), we might want to know how well our model is possibly generalising to unseen data.\nThe validation dataset, is the set of data that we use to measure the generalisation of our model during the course of its learning process. Like the test set, this validation data should not be used to train the model, but only used to measure the model’s generalisation during the lifetime of the learning process."
  },
  {
    "objectID": "lecture-3.html#the-ability-of-the-model",
    "href": "lecture-3.html#the-ability-of-the-model",
    "title": "Model Performance",
    "section": "The ability of the model",
    "text": "The ability of the model\nWhen we created a linear regression model, we saw that it was not possible to predict the house price exactly, there was always some error that we could not overcome with the linear model.\nIf we have a model complicated model, such as polynomial regression (where we have polynomial terms in line equation), it may be possible to fit every training data point exactly. But is that what we want?.\nIn this section, we’ll explore the concept of over- and under-fitting, and how we can use the testing set to understanding if these processes are happening."
  },
  {
    "objectID": "lecture-3.html#over-fitting",
    "href": "lecture-3.html#over-fitting",
    "title": "Model Performance",
    "section": "Over-fitting",
    "text": "Over-fitting\nWe’ll begin with over-fitting. Over-fitting occurs when our model has a very high or perfect performance on the testing set, but does not perform well at all on the testing set.\nThere may be many reasons for this happening, such as the model being very complex, having too many variables."
  },
  {
    "objectID": "lecture-3.html#under-fitting",
    "href": "lecture-3.html#under-fitting",
    "title": "Model Performance",
    "section": "Under-fitting",
    "text": "Under-fitting\nUnder-fitting, as the name suggests is what happens when we cannot fit the model to the data, it doesn’t even perform well on the training data, the data the model is allowed to learn from. This can happen when the model is too simple and cannot learn the intrinsic relationship between the input and output. For example, trying to use a linear model to learn from data that is not linear by nature."
  },
  {
    "objectID": "lecture-3.html#validation-curves",
    "href": "lecture-3.html#validation-curves",
    "title": "Model Performance",
    "section": "Validation Curves",
    "text": "Validation Curves\nIf we have an iterative learning process, we can use the training and validation datasets to measure whether our model is over-fitting, and stop training the model at an optimal point before it overfits.\nTo do this, at every iteration of the learning process, we evaluate the model’s performance using both the training and validation datasets. If the performance on both datasets is decreasing we can infer that the model is learning something useful that helps with it’s generalisation to unseen data.\nHowever, if the performance on the training set is decreasing, while the performance on the validation dataset is no longer decreasing or indeed increasing, we know the model is over-fitting to the training data."
  },
  {
    "objectID": "lecture-3.html#biasvariance-tradeoff",
    "href": "lecture-3.html#biasvariance-tradeoff",
    "title": "Model Performance",
    "section": "Bias/Variance Tradeoff",
    "text": "Bias/Variance Tradeoff\nThe Bias/Variance tradeoff is a property of machine learning models. It describes a model’s expected generalisation abilities based upon how the parameters are estimated across a dataset.\n\nBias - the model’s `flexibility’ to represent the true relationship in the data. Model’s with low bias have a tendency to underfit. An example would be a linear model model trying to fit against non-linear function.\nVariance - the impact that a single sample in the data has on the model. Model’s with high variance tend to overfit to the training data."
  },
  {
    "objectID": "lecture-3.html#metrics",
    "href": "lecture-3.html#metrics",
    "title": "Model Performance",
    "section": "Metrics",
    "text": "Metrics\nNow that we’ve looked at the various sets of data, and the potential scenarios when we fit a model, we’ll now want to look at some actual methods of evaluating our model.\nThese we call metrics. Metrics are values that help us understand how well a model might perform in the real world. Metrics are helpful to explain the predictive power of a model with one value.\nThere are many different types of metrics that can be used depending on the class of problem that is being dealt with. For instance, there are different set of metrics for Regression and classification problems.\nWe’ll first look at some metrics we can use to evaluate a regression model (some of which we’ve already seen in the Linear models lecture), and then we’ll have a look at metrics for a classification task."
  },
  {
    "objectID": "lecture-3.html#mean-squared-error-mse",
    "href": "lecture-3.html#mean-squared-error-mse",
    "title": "Model Performance",
    "section": "Mean Squared Error (MSE)",
    "text": "Mean Squared Error (MSE)\nA mean squared error (sometimes called the sum of squared residuals) is the measure of mean magnitude between two sets of points \\(y, \\overline{y}\\).\nThe formula for MSE is:\n\\(\\text{MSE} = \\frac{1}{N} \\sum_i^N (y_i, \\overline{y_i})^2\\)\nfor \\(N\\) points.\nMSE is always non-negative, and the lower the MSE the better."
  },
  {
    "objectID": "lecture-3.html#root-mean-squared-error-rmse",
    "href": "lecture-3.html#root-mean-squared-error-rmse",
    "title": "Model Performance",
    "section": "Root Mean Squared Error (RMSE)",
    "text": "Root Mean Squared Error (RMSE)\n\\[\n\\text{RMSE} = \\sqrt{\\text{MSE}}\n\\]\nDue to the squared error term, larger errors have a large effect on the outcome of the equation, so both RMSE and MSE is sensitive to outliers.\nMSE’s error is measured in squared units, while RMSE is measured in the same unit as the target."
  },
  {
    "objectID": "lecture-3.html#mean-absolute-error-mae",
    "href": "lecture-3.html#mean-absolute-error-mae",
    "title": "Model Performance",
    "section": "Mean Absolute Error (MAE)",
    "text": "Mean Absolute Error (MAE)\nMean absolute error or MAE is one objective function for measure the \\(L_1\\) between two sets of points.\n\\(\\text{MAE} = \\frac{1}{N} \\sum_i^N | y_i - \\overline{y_i} |\\)\nfor \\(N\\) of points.\nLike MSE, RMSE, the lower the MAE value, the better the fit on the statistical model."
  },
  {
    "objectID": "lecture-3.html#binary-classification-labelling-as-positive-or-negative",
    "href": "lecture-3.html#binary-classification-labelling-as-positive-or-negative",
    "title": "Model Performance",
    "section": "Binary classification & labelling as positive or negative",
    "text": "Binary classification & labelling as positive or negative\nWe now move onto some of the more typical classification metrics. But first, we must first understand when our classifier predicts positive or negative in a binary classification task.\nLet’s say we have a binary classifier \\(\\mathcal{M}\\) which predicts the positive class if the predicted probability is \\(\\geq 0.5\\). I.e.:\n\\[\nL(x)  = \\begin{cases}\n1 & \\text{if}, \\; \\mathcal{M}(x) \\geq 0.5 \\\\\n0 & \\text{otherwise}\n\\end{cases}\n\\]\nwhere \\(L\\) is our labelling function.\nHere 0.5 is the threshold for predicting the positive class."
  },
  {
    "objectID": "lecture-3.html#tptnfpfn",
    "href": "lecture-3.html#tptnfpfn",
    "title": "Model Performance",
    "section": "TP/TN/FP/FN",
    "text": "TP/TN/FP/FN\nBefore we look at other metrics to evaluate our classification metrics, I first want to describe these acronyms.\n\nList :B_column:BMCOL:\n\nTP - True-Positive – our model has predicted positive (it was correct) and the actual label is positive.\nTN - True-Negative – our model has predicted negative (it was correct) and the actual label is negative.\nFP - False-Positive – our model has predicted positive (it was wrong) the actual label was negative.\nFN - False-Negative – our model has predicted negative (it was wrong) the actual label was positive.\n\nDiagram :B_column:BMCOL:"
  },
  {
    "objectID": "lecture-3.html#accuracy",
    "href": "lecture-3.html#accuracy",
    "title": "Model Performance",
    "section": "Accuracy",
    "text": "Accuracy\nIn a binary classification task, accuracy is measured using:\n\\[\n\\text{Accuracy} = \\frac{TP+TN}{TP+TN+FP+FN}\n\\]\nor multi-classification:\n\\[\n\\text{Accuracy} = \\frac{\\text{number of correct}}{\\text{number of samples}}\n\\]\nThe range of accuracy is in \\([0, 1]\\), the higher the value of accuracy the better. Accuracy is often presented in the form of a percentage i.e. \\(100 \\cdot \\text{Accuracy}\\)"
  },
  {
    "objectID": "lecture-3.html#precision",
    "href": "lecture-3.html#precision",
    "title": "Model Performance",
    "section": "Precision",
    "text": "Precision\nMeasuring the precision tells us how many how accurate our model was in predicting positive cases. Here we have \\(TP\\) or the number of True-Positive, divided by \\(TP + FP\\) where \\(FP\\) is the number of False-Positive cases.\n\\[\n\\frac{TP}{TP + FP}\n\\]\nValid values for the precision metric are in the range \\([0, 1]\\) where the higher the value the better."
  },
  {
    "objectID": "lecture-3.html#recall",
    "href": "lecture-3.html#recall",
    "title": "Model Performance",
    "section": "Recall",
    "text": "Recall\nRecall tells us: out of all the positive cases, how many of them were actually found/predicted to be positive. How many of these positive cases was our model able to recall?\n\\[\n\\frac{TP}{TP+FN}\n\\]\nLike precision, recall is in the range \\([0, 1]\\) where the higher the value the better the recall."
  },
  {
    "objectID": "lecture-3.html#confusion-matrix",
    "href": "lecture-3.html#confusion-matrix",
    "title": "Model Performance",
    "section": "Confusion Matrix",
    "text": "Confusion Matrix\nA confusion matrix is a visual representation of these different type of predictive cases (TP/TN/FP/FN).\nAn optimal confusion matrix, is a diagonal matrix (all entries outside of the diagonal are zero). Here is one example of a confusion matrix.\n\n\n\n\n\n\n\n\n\n\n\n \n\n\n \n\n\nPredicted\n\n\n \n\n\n\n\n \n\n\n \n\n\nPositive\n\n\nNegative\n\n\n\n\nActual\n\n\nPositive\n\n\n5\n\n\n2\n\n\n\n\n \n\n\nNegative\n\n\n3\n\n\n1\n\n\n\n\n\n\nValues :B_column:BMCOL:\n\nTP = 5\nTN = 1\nFP = 3\nFN = 2\n\nCalculation :B_column:BMCOL:\n\nPrecision = \\(\\frac{5}{5+3} = 0.625\\)\nRecall = \\(\\frac{5}{5+2}\\) \\(= 0.714\\)"
  },
  {
    "objectID": "lecture-3.html#f_beta-f_1",
    "href": "lecture-3.html#f_beta-f_1",
    "title": "Model Performance",
    "section": "\\(F_\\beta\\) & \\(F_1\\)",
    "text": "\\(F_\\beta\\) & \\(F_1\\)\nWith the precision/recall metrics, it is trivial to optimise for one over the over:\n\nWe can achieve perfect precision (\\(\\text{precision} = 1\\)) by predicting everything is negative (no false positives)\nWe can achieve perfect recall (\\(\\text{recall} = 1\\)) by predicting that everything is positive (no false negatives).\n\nBut predicting everything is negative, or everything is positive is not really a useful model. So we have another metric that is the harmonic combination of precision and recall: \\(F_1\\) and \\(F_\\beta\\) score.\n\\[\nF_\\beta = (1 + \\beta^2) \\frac{p \\cdot r}{\\beta^2 p + r}\n\\]\nwhere \\(p, r\\) is the precision and recall metric respectively. For the \\(F_1\\) score, we simple set \\(\\beta = 1\\)."
  },
  {
    "objectID": "lecture-3.html#receiver-operating-characteristic-roc",
    "href": "lecture-3.html#receiver-operating-characteristic-roc",
    "title": "Model Performance",
    "section": "Receiver Operating Characteristic (ROC)",
    "text": "Receiver Operating Characteristic (ROC)\nIn the previous slides, we have labelled our samples as positive if our classifier predicts \\(\\geq 0.5\\), else it is labelled as negative. This \\(0.5\\) is our threshold for our labelling function. But we can vary this threshold if we want. Lowering the threshold will typically mean our classifier labels positive cases more often. While increasing the threshold makes the classifier more conservative, and typically predicts labels positive cases less often.\nIf we vary this threshold from 0 to 1 and calculate the true- and false-positive rate, we can visualise something we call the Receiver Operating Characteristic or ROC for short.\n\nThis ROC curve, with the dotted line directly in the centre, first shows us what a random classifier would look like. This random classifier randomly predicts positive or negative for any case.\nWe can say that our classifier is better than random, if the line is to the top-left of the random classifier. In general, the more to the top-left the line is, the better."
  },
  {
    "objectID": "lecture-3.html#area-under-curve-auc",
    "href": "lecture-3.html#area-under-curve-auc",
    "title": "Model Performance",
    "section": "Area Under Curve (AUC)",
    "text": "Area Under Curve (AUC)\nWe’ve just seen how the ROC curve can visually point to which model is better than others, and which threshold we may want to choose for our labelling function. However, we can also turn these types of curves in a number, a metric.\nThis next metric we’re going to look at does just that. The Area Under Curve or AUC for short, takes our ROC curve, and measures the area underneath the curve, giving us a single value for each model that we can use for comparison.\n\nOne method to calculate this area is to use the trapezoid rule to approximate the region underneath the graph of a function:\n\\[\n\\text{Area} = 0.5 \\frac{1}{N} \\times \\left[ \\text{TP}_1 + 2 (\\text{TP}_2 + ... + \\text{TP}_{N-1}) + \\text{TP}_N \\right]\n\\]\nIf the AUC is close to one we know that the model at any threshold has very good discriminatory power."
  },
  {
    "objectID": "lecture-3.html#cross-validation-using-k-fold",
    "href": "lecture-3.html#cross-validation-using-k-fold",
    "title": "Model Performance",
    "section": "Cross Validation using K-fold",
    "text": "Cross Validation using K-fold\nWe have seen why having a separate set of data for training, testing, and validation is necessary – to give some indication as to the generalisation performance of our model, and to track possible over-fitting.\nTo create these separate sets of data, we may have just sampled randomly or using a stratified method (more on this in a few slides). However, this is only one test of the model’s generalisation abilities.\nCross-validation is a statistical method to test the model on many resamplings on the test set.\n\nCross-validation works selecting a subset of the data for testing (leaving the rest for training), training the model, and then calculating the performance on this test set. Next, sample a different subset of data for a new testing set, training the model, and calculating the performance. Repeat this process until all data has been sampled for the testing set, and calculate the mean and standard deviation of model performance.\nK-fold cross-validation is this method where \\(k\\) is the number of iterations it will take to have used the entire available data for testing. I.e., if you’re performing 5-fold cross-validation, you would have trained and tested your model 5 different types, on 5 different samples from your available data."
  },
  {
    "objectID": "lecture-3.html#random-stratified-sampling",
    "href": "lecture-3.html#random-stratified-sampling",
    "title": "Model Performance",
    "section": "Random & Stratified Sampling",
    "text": "Random & Stratified Sampling\nWhen sampling data for our training and testing set, we could use two different methods:\n\nRandom\nStratified\n\nTo perform stratified sampling, we first split the dataset into stratas or distinct groups. For a classification problem, this could be splitting samplings by their respective class labels. Then, after splitting the data into their respective groups, we randomly sample from each group.\nLet’s say we have 150 samples, where:\n\n40 samples are in group 1,\n25 samples are in group 2,\n85 samples are in group 3.\n\nAnd we want to sample from this dataset for our test set using stratified sampling. First, we calculate the proportion of each group in the overall data:\n\n\\(100 \\times \\frac{40}{150} = 26.\\overline{6}\\; \\%\\),\n\\(100 \\times \\frac{25}{150} = 16.\\overline{6}\\; \\%\\),\n\\(100 \\times \\frac{85}{150} = 56.\\overline{6} \\; \\%\\).\n\nTherefore, in our testing set, \\(26.\\overline{6} \\; \\%\\) of the data should be randomly sampled from group 1, and so on for all groups.\nSo if we want to use \\(10 \\; \\%\\) of our data for testing, that means we would have 15 samples in our dataset (\\(\\frac{150}{10}\\)) sampled using:\n\ngroup 1: \\(40 \\times (\\frac{15}{150}) = 4\\) samples,\ngroup 2: \\(25\\times (\\frac{15}{150}) = 2.5\\) samples,\ngroup 3: \\(85 \\times ( \\frac{15}{150}) = 8.5\\) samples.\n\nThe proportion of samples in our test set from each group should roughly match the proportion of the overall available data. We can verify this by calculating the proportion of each group’s representation, i.e. : \\(100 \\times \\frac{4}{15} = 26.\\overline{6} \\; \\%\\) and we see that it matches the proportion of the overall data.\nStratified sampling is especially useful when we have a class-imbalance, and randomly sampling data could potentially lead to a situation where our test or training set only has one class label."
  },
  {
    "objectID": "lecture-3-reveal.html#why-do-we-have-different-sets-of-data",
    "href": "lecture-3-reveal.html#why-do-we-have-different-sets-of-data",
    "title": "Model Performance",
    "section": "Why do we have different ‘sets’ of data?",
    "text": "Why do we have different ‘sets’ of data?\nWe’ve seen in the previous lecture how we can fit a linear regression model to a set of data, and we can measure the performance of this model.\nBut we do not understand how well this model works in the ‘real-world’, how well it performs on data that has not yet been ‘seen’, how well the model generalises to this unknown data.\nSo, when we want to create a machine learning model, we usually take our data, and split into two (sometimes three) sets of data. These different sets are named:\n\ntraining set,\ntesting set,\nand (optionally) validation set."
  },
  {
    "objectID": "lecture-3-reveal.html#training-set",
    "href": "lecture-3-reveal.html#training-set",
    "title": "Model Performance",
    "section": "Training Set",
    "text": "Training Set\nThe training dataset, is the set of data, that we’re allowing the model to `see’ or learn from.\nIn our example of the linear regression, this is the set of data points to which we find the optimal parameters of our model.\nIt is not very useful to evaluate our model’s performance with the training set as it doesn’t tell us how well it’s actually doing (we’ll come back to this when we talk about over-/under-fitting)."
  },
  {
    "objectID": "lecture-3-reveal.html#testing-set",
    "href": "lecture-3-reveal.html#testing-set",
    "title": "Model Performance",
    "section": "Testing Set",
    "text": "Testing Set\nThe testing set is the set of data that we use to evaluate the generalisation of our machine learning model. The model is not allowed to use this set of data during training, but it is simply used for the evaluation of the model.\nIn general the testing set is between 10-30% of the overall available data, but this rule is not something dictated, and may vary depending on the amount of data available and the overall use case.\nOnce the 10-30% of the data has been sampled for the testing set, the rest of the data can be used for the training and validation sets."
  },
  {
    "objectID": "lecture-3-reveal.html#validation-set",
    "href": "lecture-3-reveal.html#validation-set",
    "title": "Model Performance",
    "section": "Validation Set",
    "text": "Validation Set\nIf we have an iterative optimisation process (such as what we saw with gradient descent), we might want to know how well our model is possibly generalising to unseen data.\nThe validation dataset, is the set of data that we use to measure the generalisation of our model during the course of its learning process. Like the test set, this validation data should not be used to train the model, but only used to measure the model’s generalisation during the lifetime of the learning process."
  },
  {
    "objectID": "lecture-3-reveal.html#the-ability-of-the-model",
    "href": "lecture-3-reveal.html#the-ability-of-the-model",
    "title": "Model Performance",
    "section": "The ability of the model",
    "text": "The ability of the model\nWhen we created a linear regression model, we saw that it was not possible to predict the house price exactly, there was always some error that we could not overcome with the linear model.\nIf we have a model complicated model, such as polynomial regression (where we have polynomial terms in line equation), it may be possible to fit every training data point exactly. But is that what we want?.\nIn this section, we’ll explore the concept of over- and under-fitting, and how we can use the testing set to understanding if these processes are happening."
  },
  {
    "objectID": "lecture-3-reveal.html#over-fitting",
    "href": "lecture-3-reveal.html#over-fitting",
    "title": "Model Performance",
    "section": "Over-fitting",
    "text": "Over-fitting\nWe’ll begin with over-fitting. Over-fitting occurs when our model has a very high or perfect performance on the testing set, but does not perform well at all on the testing set.\nThere may be many reasons for this happening, such as the model being very complex, having too many variables."
  },
  {
    "objectID": "lecture-3-reveal.html#under-fitting",
    "href": "lecture-3-reveal.html#under-fitting",
    "title": "Model Performance",
    "section": "Under-fitting",
    "text": "Under-fitting\nUnder-fitting, as the name suggests is what happens when we cannot fit the model to the data, it doesn’t even perform well on the training data, the data the model is allowed to learn from. This can happen when the model is too simple and cannot learn the intrinsic relationship between the input and output. For example, trying to use a linear model to learn from data that is not linear by nature."
  },
  {
    "objectID": "lecture-3-reveal.html#validation-curves",
    "href": "lecture-3-reveal.html#validation-curves",
    "title": "Model Performance",
    "section": "Validation Curves",
    "text": "Validation Curves\nIf we have an iterative learning process, we can use the training and validation datasets to measure whether our model is over-fitting, and stop training the model at an optimal point before it overfits.\nTo do this, at every iteration of the learning process, we evaluate the model’s performance using both the training and validation datasets. If the performance on both datasets is decreasing we can infer that the model is learning something useful that helps with it’s generalisation to unseen data.\nHowever, if the performance on the training set is decreasing, while the performance on the validation dataset is no longer decreasing or indeed increasing, we know the model is over-fitting to the training data."
  },
  {
    "objectID": "lecture-3-reveal.html#biasvariance-tradeoff",
    "href": "lecture-3-reveal.html#biasvariance-tradeoff",
    "title": "Model Performance",
    "section": "Bias/Variance Tradeoff",
    "text": "Bias/Variance Tradeoff\nThe Bias/Variance tradeoff is a property of machine learning models. It describes a model’s expected generalisation abilities based upon how the parameters are estimated across a dataset.\n\nBias - the model’s `flexibility’ to represent the true relationship in the data. Model’s with low bias have a tendency to underfit. An example would be a linear model model trying to fit against non-linear function.\nVariance - the impact that a single sample in the data has on the model. Model’s with high variance tend to overfit to the training data."
  },
  {
    "objectID": "lecture-3-reveal.html#metrics",
    "href": "lecture-3-reveal.html#metrics",
    "title": "Model Performance",
    "section": "Metrics",
    "text": "Metrics\nNow that we’ve looked at the various sets of data, and the potential scenarios when we fit a model, we’ll now want to look at some actual methods of evaluating our model.\nThese we call metrics. Metrics are values that help us understand how well a model might perform in the real world. Metrics are helpful to explain the predictive power of a model with one value.\nThere are many different types of metrics that can be used depending on the class of problem that is being dealt with. For instance, there are different set of metrics for Regression and classification problems.\nWe’ll first look at some metrics we can use to evaluate a regression model (some of which we’ve already seen in the Linear models lecture), and then we’ll have a look at metrics for a classification task."
  },
  {
    "objectID": "lecture-3-reveal.html#mean-squared-error-mse",
    "href": "lecture-3-reveal.html#mean-squared-error-mse",
    "title": "Model Performance",
    "section": "Mean Squared Error (MSE)",
    "text": "Mean Squared Error (MSE)\nA mean squared error (sometimes called the sum of squared residuals) is the measure of mean magnitude between two sets of points \\(y, \\overline{y}\\).\nThe formula for MSE is:\n\\(\\text{MSE} = \\frac{1}{N} \\sum_i^N (y_i, \\overline{y_i})^2\\)\nfor \\(N\\) points.\nMSE is always non-negative, and the lower the MSE the better."
  },
  {
    "objectID": "lecture-3-reveal.html#root-mean-squared-error-rmse",
    "href": "lecture-3-reveal.html#root-mean-squared-error-rmse",
    "title": "Model Performance",
    "section": "Root Mean Squared Error (RMSE)",
    "text": "Root Mean Squared Error (RMSE)\n\\[\n\\text{RMSE} = \\sqrt{\\text{MSE}}\n\\]\nDue to the squared error term, larger errors have a large effect on the outcome of the equation, so both RMSE and MSE is sensitive to outliers.\nMSE’s error is measured in squared units, while RMSE is measured in the same unit as the target."
  },
  {
    "objectID": "lecture-3-reveal.html#mean-absolute-error-mae",
    "href": "lecture-3-reveal.html#mean-absolute-error-mae",
    "title": "Model Performance",
    "section": "Mean Absolute Error (MAE)",
    "text": "Mean Absolute Error (MAE)\nMean absolute error or MAE is one objective function for measure the \\(L_1\\) between two sets of points.\n\\(\\text{MAE} = \\frac{1}{N} \\sum_i^N | y_i - \\overline{y_i} |\\)\nfor \\(N\\) of points.\nLike MSE, RMSE, the lower the MAE value, the better the fit on the statistical model."
  },
  {
    "objectID": "lecture-3-reveal.html#binary-classification-labelling-as-positive-or-negative",
    "href": "lecture-3-reveal.html#binary-classification-labelling-as-positive-or-negative",
    "title": "Model Performance",
    "section": "Binary classification & labelling as positive or negative",
    "text": "Binary classification & labelling as positive or negative\nWe now move onto some of the more typical classification metrics. But first, we must first understand when our classifier predicts positive or negative in a binary classification task.\nLet’s say we have a binary classifier \\(\\mathcal{M}\\) which predicts the positive class if the predicted probability is \\(\\geq 0.5\\). I.e.:\n\\[\nL(x)  = \\begin{cases}\n1 & \\text{if}, \\; \\mathcal{M}(x) \\geq 0.5 \\\\\n0 & \\text{otherwise}\n\\end{cases}\n\\]\nwhere \\(L\\) is our labelling function.\nHere 0.5 is the threshold for predicting the positive class."
  },
  {
    "objectID": "lecture-3-reveal.html#tptnfpfn",
    "href": "lecture-3-reveal.html#tptnfpfn",
    "title": "Model Performance",
    "section": "TP/TN/FP/FN",
    "text": "TP/TN/FP/FN\nBefore we look at other metrics to evaluate our classification metrics, I first want to describe these acronyms.\n\nList :B_column:BMCOL:\n\nTP - True-Positive – our model has predicted positive (it was correct) and the actual label is positive.\nTN - True-Negative – our model has predicted negative (it was correct) and the actual label is negative.\nFP - False-Positive – our model has predicted positive (it was wrong) the actual label was negative.\nFN - False-Negative – our model has predicted negative (it was wrong) the actual label was positive.\n\nDiagram :B_column:BMCOL:"
  },
  {
    "objectID": "lecture-3-reveal.html#accuracy",
    "href": "lecture-3-reveal.html#accuracy",
    "title": "Model Performance",
    "section": "Accuracy",
    "text": "Accuracy\nIn a binary classification task, accuracy is measured using:\n\\[\n\\text{Accuracy} = \\frac{TP+TN}{TP+TN+FP+FN}\n\\]\nor multi-classification:\n\\[\n\\text{Accuracy} = \\frac{\\text{number of correct}}{\\text{number of samples}}\n\\]\nThe range of accuracy is in \\([0, 1]\\), the higher the value of accuracy the better. Accuracy is often presented in the form of a percentage i.e. \\(100 \\cdot \\text{Accuracy}\\)"
  },
  {
    "objectID": "lecture-3-reveal.html#precision",
    "href": "lecture-3-reveal.html#precision",
    "title": "Model Performance",
    "section": "Precision",
    "text": "Precision\nMeasuring the precision tells us how many how accurate our model was in predicting positive cases. Here we have \\(TP\\) or the number of True-Positive, divided by \\(TP + FP\\) where \\(FP\\) is the number of False-Positive cases.\n\\[\n\\frac{TP}{TP + FP}\n\\]\nValid values for the precision metric are in the range \\([0, 1]\\) where the higher the value the better."
  },
  {
    "objectID": "lecture-3-reveal.html#recall",
    "href": "lecture-3-reveal.html#recall",
    "title": "Model Performance",
    "section": "Recall",
    "text": "Recall\nRecall tells us: out of all the positive cases, how many of them were actually found/predicted to be positive. How many of these positive cases was our model able to recall?\n\\[\n\\frac{TP}{TP+FN}\n\\]\nLike precision, recall is in the range \\([0, 1]\\) where the higher the value the better the recall."
  },
  {
    "objectID": "lecture-3-reveal.html#confusion-matrix",
    "href": "lecture-3-reveal.html#confusion-matrix",
    "title": "Model Performance",
    "section": "Confusion Matrix",
    "text": "Confusion Matrix\nA confusion matrix is a visual representation of these different type of predictive cases (TP/TN/FP/FN).\nAn optimal confusion matrix, is a diagonal matrix (all entries outside of the diagonal are zero). Here is one example of a confusion matrix.\n\n\n\n\n\n\n\n\n\n\n\n \n\n\n \n\n\nPredicted\n\n\n \n\n\n\n\n \n\n\n \n\n\nPositive\n\n\nNegative\n\n\n\n\nActual\n\n\nPositive\n\n\n5\n\n\n2\n\n\n\n\n \n\n\nNegative\n\n\n3\n\n\n1\n\n\n\n\n\n\nValues :B_column:BMCOL:\n\nTP = 5\nTN = 1\nFP = 3\nFN = 2\n\nCalculation :B_column:BMCOL:\n\nPrecision = \\(\\frac{5}{5+3} = 0.625\\)\nRecall = \\(\\frac{5}{5+2}\\) \\(= 0.714\\)"
  },
  {
    "objectID": "lecture-3-reveal.html#f_beta-f_1",
    "href": "lecture-3-reveal.html#f_beta-f_1",
    "title": "Model Performance",
    "section": "\\(F_\\beta\\) & \\(F_1\\)",
    "text": "\\(F_\\beta\\) & \\(F_1\\)\nWith the precision/recall metrics, it is trivial to optimise for one over the over:\n\nWe can achieve perfect precision (\\(\\text{precision} = 1\\)) by predicting everything is negative (no false positives)\nWe can achieve perfect recall (\\(\\text{recall} = 1\\)) by predicting that everything is positive (no false negatives).\n\nBut predicting everything is negative, or everything is positive is not really a useful model. So we have another metric that is the harmonic combination of precision and recall: \\(F_1\\) and \\(F_\\beta\\) score.\n\\[\nF_\\beta = (1 + \\beta^2) \\frac{p \\cdot r}{\\beta^2 p + r}\n\\]\nwhere \\(p, r\\) is the precision and recall metric respectively. For the \\(F_1\\) score, we simple set \\(\\beta = 1\\)."
  },
  {
    "objectID": "lecture-3-reveal.html#receiver-operating-characteristic-roc",
    "href": "lecture-3-reveal.html#receiver-operating-characteristic-roc",
    "title": "Model Performance",
    "section": "Receiver Operating Characteristic (ROC)",
    "text": "Receiver Operating Characteristic (ROC)\nIn the previous slides, we have labelled our samples as positive if our classifier predicts \\(\\geq 0.5\\), else it is labelled as negative. This \\(0.5\\) is our threshold for our labelling function. But we can vary this threshold if we want. Lowering the threshold will typically mean our classifier labels positive cases more often. While increasing the threshold makes the classifier more conservative, and typically predicts labels positive cases less often.\nIf we vary this threshold from 0 to 1 and calculate the true- and false-positive rate, we can visualise something we call the Receiver Operating Characteristic or ROC for short.\n\nThis ROC curve, with the dotted line directly in the centre, first shows us what a random classifier would look like. This random classifier randomly predicts positive or negative for any case.\nWe can say that our classifier is better than random, if the line is to the top-left of the random classifier. In general, the more to the top-left the line is, the better."
  },
  {
    "objectID": "lecture-3-reveal.html#area-under-curve-auc",
    "href": "lecture-3-reveal.html#area-under-curve-auc",
    "title": "Model Performance",
    "section": "Area Under Curve (AUC)",
    "text": "Area Under Curve (AUC)\nWe’ve just seen how the ROC curve can visually point to which model is better than others, and which threshold we may want to choose for our labelling function. However, we can also turn these types of curves in a number, a metric.\nThis next metric we’re going to look at does just that. The Area Under Curve or AUC for short, takes our ROC curve, and measures the area underneath the curve, giving us a single value for each model that we can use for comparison.\n\nOne method to calculate this area is to use the trapezoid rule to approximate the region underneath the graph of a function:\n\\[\n\\text{Area} = 0.5 \\frac{1}{N} \\times \\left[ \\text{TP}_1 + 2 (\\text{TP}_2 + ... + \\text{TP}_{N-1}) + \\text{TP}_N \\right]\n\\]\nIf the AUC is close to one we know that the model at any threshold has very good discriminatory power."
  },
  {
    "objectID": "lecture-3-reveal.html#cross-validation-using-k-fold",
    "href": "lecture-3-reveal.html#cross-validation-using-k-fold",
    "title": "Model Performance",
    "section": "Cross Validation using K-fold",
    "text": "Cross Validation using K-fold\nWe have seen why having a separate set of data for training, testing, and validation is necessary – to give some indication as to the generalisation performance of our model, and to track possible over-fitting.\nTo create these separate sets of data, we may have just sampled randomly or using a stratified method (more on this in a few slides). However, this is only one test of the model’s generalisation abilities.\nCross-validation is a statistical method to test the model on many resamplings on the test set.\n\nCross-validation works selecting a subset of the data for testing (leaving the rest for training), training the model, and then calculating the performance on this test set. Next, sample a different subset of data for a new testing set, training the model, and calculating the performance. Repeat this process until all data has been sampled for the testing set, and calculate the mean and standard deviation of model performance.\nK-fold cross-validation is this method where \\(k\\) is the number of iterations it will take to have used the entire available data for testing. I.e., if you’re performing 5-fold cross-validation, you would have trained and tested your model 5 different types, on 5 different samples from your available data."
  },
  {
    "objectID": "lecture-3-reveal.html#random-stratified-sampling",
    "href": "lecture-3-reveal.html#random-stratified-sampling",
    "title": "Model Performance",
    "section": "Random & Stratified Sampling",
    "text": "Random & Stratified Sampling\nWhen sampling data for our training and testing set, we could use two different methods:\n\nRandom\nStratified\n\nTo perform stratified sampling, we first split the dataset into stratas or distinct groups. For a classification problem, this could be splitting samplings by their respective class labels. Then, after splitting the data into their respective groups, we randomly sample from each group.\nLet’s say we have 150 samples, where:\n\n40 samples are in group 1,\n25 samples are in group 2,\n85 samples are in group 3.\n\nAnd we want to sample from this dataset for our test set using stratified sampling. First, we calculate the proportion of each group in the overall data:\n\n\\(100 \\times \\frac{40}{150} = 26.\\overline{6}\\; \\%\\),\n\\(100 \\times \\frac{25}{150} = 16.\\overline{6}\\; \\%\\),\n\\(100 \\times \\frac{85}{150} = 56.\\overline{6} \\; \\%\\).\n\nTherefore, in our testing set, \\(26.\\overline{6} \\; \\%\\) of the data should be randomly sampled from group 1, and so on for all groups.\nSo if we want to use \\(10 \\; \\%\\) of our data for testing, that means we would have 15 samples in our dataset (\\(\\frac{150}{10}\\)) sampled using:\n\ngroup 1: \\(40 \\times (\\frac{15}{150}) = 4\\) samples,\ngroup 2: \\(25\\times (\\frac{15}{150}) = 2.5\\) samples,\ngroup 3: \\(85 \\times ( \\frac{15}{150}) = 8.5\\) samples.\n\nThe proportion of samples in our test set from each group should roughly match the proportion of the overall available data. We can verify this by calculating the proportion of each group’s representation, i.e. : \\(100 \\times \\frac{4}{15} = 26.\\overline{6} \\; \\%\\) and we see that it matches the proportion of the overall data.\nStratified sampling is especially useful when we have a class-imbalance, and randomly sampling data could potentially lead to a situation where our test or training set only has one class label."
  },
  {
    "objectID": "lecture-1.html",
    "href": "lecture-1.html",
    "title": "Introduction",
    "section": "",
    "text": "Welcome to all the new students! Here I am going to be talking about Machine Learning and all of the great things that this “technology” has to offer. To begin our course, I shall start with a bit of house keeping – more specifically, I will be talking about what exactly we’ll be learning about in the course (Machine Learning is a broad subject after-all). In addition, I will tell you where you can find the resources related to the course and how you can contact me, should you have any questions.\n\n\n\nIn this course, we will be learning about Machine Learning: firstly, what Machine Learning actually is; secondly, we’ll take a look at some of the algorithms within the scope of Machine Learning, and develop an intuition about how these algorithms work and when they would be useful; and finally, how we can compare and evaluate the algorithms we’ve learnt about.\n\n\n\nI intended to deliver this course via a series of lectures. These lectures will be accompanied by the PDF lecture slides, in which I will provide the definitions and provide reference links should you wish to do some extra reading.\n\n\n\n\n\n\n\n\n\n\n\n\n\nLecture\n\n\nType\n\n\nTopic\n\n\n\n\n\n\n1\n\n\nTheory\n\n\nIntroduction\n\n\n\n\n2\n\n\nTheory\n\n\nLinear models\n\n\n\n\n3\n\n\nLab\n\n\nLab on Linear models\n\n\n\n\n4\n\n\nTheory/Lab\n\n\nEvaluation of models\n\n\n\n\n5\n\n\nTheory/Lab\n\n\nSupport Vector Machines\n\n\n\n\n6\n\n\nTheory/Lab\n\n\nKernel methods"
  },
  {
    "objectID": "lecture-1.html#welcome",
    "href": "lecture-1.html#welcome",
    "title": "Introduction",
    "section": "",
    "text": "Welcome to all the new students! Here I am going to be talking about Machine Learning and all of the great things that this “technology” has to offer. To begin our course, I shall start with a bit of house keeping – more specifically, I will be talking about what exactly we’ll be learning about in the course (Machine Learning is a broad subject after-all). In addition, I will tell you where you can find the resources related to the course and how you can contact me, should you have any questions."
  },
  {
    "objectID": "lecture-1.html#what-this-course-is-about",
    "href": "lecture-1.html#what-this-course-is-about",
    "title": "Introduction",
    "section": "",
    "text": "In this course, we will be learning about Machine Learning: firstly, what Machine Learning actually is; secondly, we’ll take a look at some of the algorithms within the scope of Machine Learning, and develop an intuition about how these algorithms work and when they would be useful; and finally, how we can compare and evaluate the algorithms we’ve learnt about."
  },
  {
    "objectID": "lecture-1.html#how-this-course-will-be-taught",
    "href": "lecture-1.html#how-this-course-will-be-taught",
    "title": "Introduction",
    "section": "",
    "text": "I intended to deliver this course via a series of lectures. These lectures will be accompanied by the PDF lecture slides, in which I will provide the definitions and provide reference links should you wish to do some extra reading."
  },
  {
    "objectID": "lecture-1.html#outline-of-the-course",
    "href": "lecture-1.html#outline-of-the-course",
    "title": "Introduction",
    "section": "",
    "text": "Lecture\n\n\nType\n\n\nTopic\n\n\n\n\n\n\n1\n\n\nTheory\n\n\nIntroduction\n\n\n\n\n2\n\n\nTheory\n\n\nLinear models\n\n\n\n\n3\n\n\nLab\n\n\nLab on Linear models\n\n\n\n\n4\n\n\nTheory/Lab\n\n\nEvaluation of models\n\n\n\n\n5\n\n\nTheory/Lab\n\n\nSupport Vector Machines\n\n\n\n\n6\n\n\nTheory/Lab\n\n\nKernel methods"
  },
  {
    "objectID": "lecture-1.html#source-code",
    "href": "lecture-1.html#source-code",
    "title": "Introduction",
    "section": "Source code",
    "text": "Source code\nDuring the course, I would also like to supplement my algorithmic definitions and explanations with some programming code – for this I will use the Python programming language. The code snippets would look something like:\nimport random\nx = [1, 2, 3, 4]\ny = [random.random() + xi for xi in x]\nprint(y)\n\n[1.4898241502582414, 2.4805286156642175, 3.065379052563245, 4.05328483072365]"
  },
  {
    "objectID": "lecture-1.html#running-the-source-code-yourself",
    "href": "lecture-1.html#running-the-source-code-yourself",
    "title": "Introduction",
    "section": "Running the source code yourself",
    "text": "Running the source code yourself\nAll of the source can be run by yourselves if you use the same python environment (i.e. that you have installed all the appropriate libraries). On the git repository, I’ve included the environment.yml file used in the production of these lectures.\nTo run the code:\n    wget https://git.sr.ht/~jaymorgan/teaching/blob/master/2022-2023/Machine%20Learning/environment.yml\n    conda env create -f environment.yml  # recreate the conda env\n    conda activate ml-lectures           # activate the new env\n    python &lt;scripts&gt;"
  },
  {
    "objectID": "lecture-1.html#references",
    "href": "lecture-1.html#references",
    "title": "Introduction",
    "section": "References",
    "text": "References\nIn some cases, and is the norm with academic traditions, we’ll want to include a reference, a link to previous written works.\nHere is an example of a sentence that includes a reference:\n“This is a very important sentence which I assert to be true, to convince you of this fact I shall appeal to authority and include a reference: (Shalev-Shwartz, Shai and Ben-David, Shai, 2014)”\nMore information on the referenced material (such as title, publishing date) will be found in the bibliography slide (or bottom of the webpage if you’re viewing the HTML version of the lectures)."
  },
  {
    "objectID": "lecture-1.html#about-me",
    "href": "lecture-1.html#about-me",
    "title": "Introduction",
    "section": "About Me",
    "text": "About Me\nMy name is Dr Jay Paul Morgan. I am a researcher at the Université de Toulon, where I am developing Deep Learning models (a sub-field of Machine Learning research) for the study of astrophysical phenomenon.\nYou can find more information and links on my personal (LIS-Lab) website: https://pageperso.lis-lab.fr/jay.morgan/\nI also publish libraries and source code online:\n\nGithub: https://github.com/jaypmorgan\nGitlab: https://gitlab.com/jaymorgan\nSource Hut: https://sr.ht/~jaymorgan/\n\nIf you have any questions, you can email me at jay.morgan@univ-tln.fr"
  },
  {
    "objectID": "lecture-1.html#where-you-can-find-the-resources",
    "href": "lecture-1.html#where-you-can-find-the-resources",
    "title": "Introduction",
    "section": "Where you can find the resources",
    "text": "Where you can find the resources\nI try to make this course as accessible as possible, which means that I host these slides in a variety of ways to suit you.\nFirstly, you can find the links to all my courses on my personal website at: https://pageperso.lis-lab.fr/jay.morgan/teaching.html\nHere you can find the links to each lecture in a PDF or HTML format. Additionally, you can view the source code used to make these lectures on source hut: https://git.sr.ht/~jaymorgan/teaching. On this git repository you can find all my lectures from all years."
  },
  {
    "objectID": "lecture-1.html#lets-answer-the-question-of-learning",
    "href": "lecture-1.html#lets-answer-the-question-of-learning",
    "title": "Introduction",
    "section": "Let’s answer the question of learning",
    "text": "Let’s answer the question of learning\nWe’ll begin our journey into the world of Machine Learning by tackling the question of what it means to ‘learn’ – how may a machine actually learn anything?"
  },
  {
    "objectID": "lecture-1.html#bait-shyness",
    "href": "lecture-1.html#bait-shyness",
    "title": "Introduction",
    "section": "Bait-shyness",
    "text": "Bait-shyness\n\nTo begin to answer the question of learning, we may turn to nature for advice. Principally, if we look at the studies conducted with Mice we find some idea to notion of learning (Shalev-Shwartz, Shai and Ben-David, Shai, 2014). (Image by brgfx on Freepik)\nWhen a rat encounters a novel source of food, it will first eat a little bit of it. If the food is edible for the rat, it will continue to eat the food, even in future encounters. If, however, on the initial contact with the food, the rat deems the food poisonous, it will ignore and not eat the food in future encounters. This process we call ‘bait-shyness’.\nHere then we see the rat, on finding something new, learn from its experience, and use that knowledge of the experience for future encounters.\nOur initial understanding of rat’s bait-shyness was limited, but we’ve come to understand more about it. For instance, we learn that their learning process is more complex than originally thought. In a later experiment, where the ‘poison’ in the food is replaced by a different unpleasant stimulus such as a electric shock – i.e. when a rat eats a food, it is then shocked. It was found that this did not deter the rat from eating the food in future encounters, unlike the poison.\nIt is presumed that the rat’s have some ‘prior knowledge’ about the world and do not infer a temporal relationship between the food and being shocked, while they can infer the same relationship with food and illness."
  },
  {
    "objectID": "lecture-1.html#computer-programs",
    "href": "lecture-1.html#computer-programs",
    "title": "Introduction",
    "section": "Computer Programs",
    "text": "Computer Programs\nFrom these two examples of how rats may learn we see: the rat will make a guess about something now (i.e. that the food is not poisonous), it will find out how good this guess is (i.e. it either gets ill or it does not), and learn from how well its guess was for the future. We also see that its learning can be impacted by the rat’s prior knowledge about how the world may work.\nBut how does this framework for the process of learning translate to computers? For a more formal definition of how computer programs could be said to learn, we have a similar idea:\n\nA computer program is said to learn from experience \\(E\\) with respect to some class of tasks \\(T\\) and performance measure \\(P\\), if its performance a tasks in \\(T\\), as measured by \\(P\\), improves with experience \\(E\\).\n\n(Mitchell, Tom M, 1997)"
  },
  {
    "objectID": "lecture-1.html#quiz",
    "href": "lecture-1.html#quiz",
    "title": "Introduction",
    "section": "Quiz!",
    "text": "Quiz!\nWhat function is being used here?\n    8 ? 5   =   13\n    9 ? 1   =   10\n    1 ? 2   =    3"
  },
  {
    "objectID": "lecture-1.html#something-more-difficult",
    "href": "lecture-1.html#something-more-difficult",
    "title": "Introduction",
    "section": "Something more difficult…",
    "text": "Something more difficult…\nWhat values are being used here?\n    x * 1 + y   =   4\n    x * 3 + y   =   8\n    x * 5 + y   =  12"
  },
  {
    "objectID": "lecture-1.html#when-might-we-need-machine-learning",
    "href": "lecture-1.html#when-might-we-need-machine-learning",
    "title": "Introduction",
    "section": "When might we need Machine Learning",
    "text": "When might we need Machine Learning\n\nWhy do we need computer programs that ‘learn’ anyway? We already have programming languages, why can’t we just use them?\nLet’s suppose we’re creating a very simple Optical Character Recognition (OCR) program.\nThis program looks at a PDF document and converts the text into something we can copy and paste. Part of this program’s task is to take an individual character, say the number ‘8’, and recognise that it’s an 8 and add that to the already scanned text.\nHow would we go about creating a program where we can define how to identify ‘8’ or ‘1’ or ‘l’ – with all the varieties of lighting conditions, handwriting, fonts, sizes. We could find the process of encompassing all different variations tiresome – if not impossible, and that’s only for a single character!\nWith Machine Learning, instead of enumerating all possible solutions within a programming language, we collect a bunch of examples of ’8’s and give them to the algorithm to learn from.\nThrough looking at these many different examples, the algorithm will/should be able to recognise what an 8 generally looks like."
  },
  {
    "objectID": "lecture-1.html#different-types-of-learning",
    "href": "lecture-1.html#different-types-of-learning",
    "title": "Introduction",
    "section": "Different types of Learning",
    "text": "Different types of Learning\nWhat we have just demonstrated by way of the OCR example, is the type of learning we call ‘Supervised Learning’. We have many examples of input (lots of different kinds of handwritten 8’s), and we tell the learning algorithm, that they are indeed the number 8.\nBut there are other kind of different learning frameworks. Specifically we have the following:\n\nSupervised Learning\nUnsupervised, or sometimes called self-supervised Learning\nReinforcement Learning"
  },
  {
    "objectID": "lecture-1.html#supervised-learning",
    "href": "lecture-1.html#supervised-learning",
    "title": "Introduction",
    "section": "Supervised Learning",
    "text": "Supervised Learning\nTo better formalise Supervised Learning from our previous OCR example, Supervised Learning is when the learning algorithm “see’s” or has access to both the input and output.\nLet’s have a dataset \\(X\\), which is a set consisting of tuple pairs \\(x_i, y_i\\). \\(x_i\\) is an input, i.e. a single image with an ‘8’, and \\(y_i\\) is a label which tells the learning algorithm if the input is indeed an ‘8’ or something else. Mathematically we have:\n\\(X = \\{(x_1, y_1), (x_2, y_2), ..., (x_n, y_n)\\}\\)"
  },
  {
    "objectID": "lecture-1.html#unsupervised-learning",
    "href": "lecture-1.html#unsupervised-learning",
    "title": "Introduction",
    "section": "Unsupervised Learning",
    "text": "Unsupervised Learning\nIn Unsupervised learning, we have again have a dataset \\(X\\), who’s elements are only inputs. In other words, there are no corresponding labels for each input. Instead, the learning algorithm must learn inherent patterns in the data and create labels itself. Throughout the course, we’ll see examples of Unsupervised Learning in action.\nOne thing to note: Recent methodologies have started to call Unsupervised Learning, self-supervised. As we have just discussed, the labels are inherent to the data from the discovered patterns, it’s just we are not explicitly giving them to the learning algorithm ourselves. So it’s sort of like a supervised learning setup, except the learning algorithm is providing the labels itself – hence the self-supervised."
  },
  {
    "objectID": "lecture-1.html#reinforcement-learning",
    "href": "lecture-1.html#reinforcement-learning",
    "title": "Introduction",
    "section": "Reinforcement Learning",
    "text": "Reinforcement Learning\nReinforcement Learning is very different to both Supervised and Unsupervised Learning. Here is the type of learning you might be familiar with if you’ve seen ‘AI’ that learns to play video games. In this type of learning, we have the following elements:\n\nAn agent\nAn environment\nA set of allowed actions the agent can make within its environment.\n\nIn this situation, an agent will interact with it’s environment, and when it does something it can receive a reward (a reward can be positive or negative). The agent will remember what it has done to receive the reward. The objective for the agent is to maximise the reward score, and learns to do this through many iterations or play-through."
  },
  {
    "objectID": "lecture-1.html#what-will-our-data-look-like",
    "href": "lecture-1.html#what-will-our-data-look-like",
    "title": "Introduction",
    "section": "What will our data look like?",
    "text": "What will our data look like?\nIn this section we shall take a look at the different types of data we might expect and the different terminology used to name them.\nData in Machine Learning applications can come in a variety of different formats. The most typical data formats we might see are:\n\nTables\nImages/Videos\nText\nSound\n\nThese are the initial formats, though, before actually doing any learning, we will want to transform them into a different representation that we can use."
  },
  {
    "objectID": "lecture-1.html#tables",
    "href": "lecture-1.html#tables",
    "title": "Introduction",
    "section": "Tables",
    "text": "Tables\nA table, or tabular, format is a \\(n \\times m\\) set of data with \\(n\\) samples or examples, and \\(m\\) features for each sample. For example, suppose we have a table consisting the price of 100 different houses:\n\n\n\n\n\n\n\n\n\n\n\nNumber of bedrooms\n\n\nGarden size (ft)\n\n\n…\n\n\nPrice ($)\n\n\n\n\n\n\n3\n\n\n0\n\n\n…\n\n\n150,000\n\n\n\n\n5\n\n\n10\n\n\n…\n\n\n200,000\n\n\n\n\n…\n\n\n…\n\n\n…\n\n\n \n\n\n\n\n10\n\n\n1000\n\n\n…\n\n\n2,000,000\n\n\n\n\n\nIn a supervised learning setting, where we want to predict the price of a house we may then have the following dataset:\n\\(X = \\{([3, 0, ...], 150,000), ([5, 10, ...], 200,000), \\\\..., ([10, 1000, ...], 2,000,000)\\}\\)"
  },
  {
    "objectID": "lecture-1.html#imagesvideos",
    "href": "lecture-1.html#imagesvideos",
    "title": "Introduction",
    "section": "Images/Videos",
    "text": "Images/Videos\nImages are composed of 2D or 3D arrays of numeric values. For example, in a RGB image that is 1024x500 pixels, we would have the array of size 1024x500x3 – where 3 is the red, green, and blue channel, respectively. If we have just a grayscale image, we could represent it as either 1024x500x1 or 1024x500 as the channel ‘dimension’ of the array is singular.\nWe may already know that videos are simply a sequence of images that are iterated through 24+ times a second. For a 24 frames per second video, we would have an array size of 1024x500x3x24 – a 4-dimensional array."
  },
  {
    "objectID": "lecture-1.html#text",
    "href": "lecture-1.html#text",
    "title": "Introduction",
    "section": "Text",
    "text": "Text\nText and language data is perhaps one of the most flexible formats of data, in terms of the person implementing the Machine Learning algorithm is somewhat free in determining how to represent the language to the algorithm.\nWith text data, we have a series of ‘tokens’ – these tokens could be words, groups of words, parts of words, and even just characters. For example, consider:\n“this is a sentence, that shouldn’t be misunderstood.”"
  },
  {
    "objectID": "lecture-1.html#tokenisation-of-text",
    "href": "lecture-1.html#tokenisation-of-text",
    "title": "Introduction",
    "section": "Tokenisation of text",
    "text": "Tokenisation of text\n“this is a sentence, that shouldn’t be misunderstood.”\nWe could ‘tokenise’ (the process of converting a string into a series of tokens that represent the original string) this sentence by splitting at white-space:\n{\"this\", \"is\", \"a\", \"sentence,\", \"that\" \"shouldn't\", \"be\", \"misunderstood.\"}\nNotice how with the words “sentence” and “misunderstood”, the punctuation is considered part of the word and so “misunderstood.” != “misunderstood”.\nThese kinds of questions of how to best represent text and language we will talk more about in later lectures!"
  },
  {
    "objectID": "lecture-1.html#time-series",
    "href": "lecture-1.html#time-series",
    "title": "Introduction",
    "section": "Time-series",
    "text": "Time-series\nI named this section time-series to be as general as possible. Within the type ‘time-series’, we could have the following types of information:\n\nSound waves\nStock prices\nNetwork messaging\n\nThese types of data all share a property in that the ‘time’ component is important in their meaning."
  },
  {
    "objectID": "lecture-1.html#types-of-outputs-regression-classification",
    "href": "lecture-1.html#types-of-outputs-regression-classification",
    "title": "Introduction",
    "section": "Types of Outputs – Regression & Classification",
    "text": "Types of Outputs – Regression & Classification\nFirst, however, I wish to explain the difference between the terms Regression and Classification.\n\nRegression: the prediction of a continuous quantity, i.e. how much does this house cost?\nClassification: the prediction of a discrete value or class label, i.e. dog or cat?\n\nIn the following toy datasets, we’ll see different types of predictions that fall under the regression/classification output type."
  },
  {
    "objectID": "lecture-1.html#boston-house-prices-dataset-tabular-regression",
    "href": "lecture-1.html#boston-house-prices-dataset-tabular-regression",
    "title": "Introduction",
    "section": "Boston House Prices Dataset – Tabular Regression",
    "text": "Boston House Prices Dataset – Tabular Regression\nA dataset of 506 houses in Boston, USA, collected during US Census.\n\n13 features/properties about each house\n1 target property: the price of the house\n\nMore information about each of the features can be found at: https://www.cs.toronto.edu/~delve/data/boston/bostonDetail.html\n(Harrison Jr, David and Rubinfeld, Daniel L, 1978)"
  },
  {
    "objectID": "lecture-1.html#boston-house-prices-example-rows",
    "href": "lecture-1.html#boston-house-prices-example-rows",
    "title": "Introduction",
    "section": "Boston House Prices – example rows",
    "text": "Boston House Prices – example rows\nimport warnings\nfrom sklearn.datasets import load_boston\nwith warnings.catch_warnings():\n    warnings.filterwarnings(\"ignore\")\n    boston = load_boston()\nboston = pd.DataFrame(\n    data=np.c_[boston['data'], boston['target']],\n    columns=boston['feature_names'].tolist() + ['target'])\nprint(boston[:2])\n      CRIM    ZN  INDUS  CHAS    NOX     RM  ...  RAD    TAX  PTRATIO      B  LSTAT  target\n0  0.00632  18.0   2.31   0.0  0.538  6.575  ...  1.0  296.0     15.3  396.9   4.98    24.0\n1  0.02731   0.0   7.07   0.0  0.469  6.421  ...  2.0  242.0     17.8  396.9   9.14    21.6\n\n[2 rows x 14 columns]"
  },
  {
    "objectID": "lecture-1.html#boston-house-prices-concerns",
    "href": "lecture-1.html#boston-house-prices-concerns",
    "title": "Introduction",
    "section": "Boston House Prices – concerns",
    "text": "Boston House Prices – concerns\nThe Boston dataset is an excellent dataset in the fact that it contains some ethical issues when it comes to Machine Learning. More specifically, some of the features in the data are ‘dummy’ variables for racial attributes (Carlisle, M., 2020). Moreover, these features show a racial segregation has a positive impact on house prices.\nScikit-Learn (scikit-learn, 2022), one of the most prolific Machine Learning framework in the Python ecosystem, has decided to depreciate and remove the Boston dataset from their repository following these concerns.\nWe will continue to use the dataset here as it is an easy to understand regression problem, and to demonstrate how easy it is to be accidentally unethical if you’re not thinking about the data carefully enough."
  },
  {
    "objectID": "lecture-1.html#iris-dataset-tabular-classification",
    "href": "lecture-1.html#iris-dataset-tabular-classification",
    "title": "Introduction",
    "section": "Iris Dataset – Tabular Classification",
    "text": "Iris Dataset – Tabular Classification"
  },
  {
    "objectID": "lecture-1.html#iris-dataset-features",
    "href": "lecture-1.html#iris-dataset-features",
    "title": "Introduction",
    "section": "Iris Dataset – features",
    "text": "Iris Dataset – features\n\n150 examples\n4 features: Petal length/width, sepal length/width\n1 classification: type of flower: {viriginica, setosa, veriscolor}\nhttps://archive.ics.uci.edu/ml/datasets/iris (Fisher, Ronald A, 1936)"
  },
  {
    "objectID": "lecture-1.html#iris-dataset-example-rows",
    "href": "lecture-1.html#iris-dataset-example-rows",
    "title": "Introduction",
    "section": "Iris Dataset – example rows",
    "text": "Iris Dataset – example rows\nfrom sklearn.datasets import load_iris\niris = load_iris()\niris = pd.DataFrame(\n    data = np.c_[iris['data'], iris['target']],\n    columns = iris['feature_names'] + ['target'])\nprint(iris.head(2))\n   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  target\n0                5.1               3.5                1.4               0.2     0.0\n1                4.9               3.0                1.4               0.2     0.0"
  },
  {
    "objectID": "lecture-1.html#mnist-dataset-image-classification",
    "href": "lecture-1.html#mnist-dataset-image-classification",
    "title": "Introduction",
    "section": "MNIST Dataset – Image Classification",
    "text": "MNIST Dataset – Image Classification\n\nA dataset of images (of size 28x28) containing handwritten digits from 0 - 9.\nhttp://yann.lecun.com/exdb/mnist/\n(LeCun, Yann and Bottou, L{\\’e}on and Bengio, Yoshua and Haffner, Patrick, 1998)"
  },
  {
    "objectID": "lecture-1.html#mnist-dataset-features",
    "href": "lecture-1.html#mnist-dataset-features",
    "title": "Introduction",
    "section": "MNIST Dataset – Features",
    "text": "MNIST Dataset – Features\n\n60,000 images in the training dataset\n10,000 images in the test dataset\n28x28 pixels (grayscale)"
  },
  {
    "objectID": "lecture-1.html#mnist-dataset-example-rows",
    "href": "lecture-1.html#mnist-dataset-example-rows",
    "title": "Introduction",
    "section": "MNIST Dataset – Example Rows",
    "text": "MNIST Dataset – Example Rows\nfrom sklearn.datasets import fetch_openml\nmnist = fetch_openml(\"mnist_784\").data[:2]\npixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  pixel8  pixel9  \\\n0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n1     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n\npixel10  ...  pixel775  pixel776  pixel777  pixel778  pixel779  pixel780  \\\n0      0.0  ...       0.0       0.0       0.0       0.0       0.0       0.0   \n1      0.0  ...       0.0       0.0       0.0       0.0       0.0       0.0   \n\npixel781  pixel782  pixel783  pixel784  \n0       0.0       0.0       0.0       0.0  \n1       0.0       0.0       0.0       0.0  \n\n[2 rows x 784 columns]"
  },
  {
    "objectID": "lecture-1.html#large-movie-review-dataset-text-classificationregression",
    "href": "lecture-1.html#large-movie-review-dataset-text-classificationregression",
    "title": "Introduction",
    "section": "Large Movie Review Dataset – Text Classification/Regression",
    "text": "Large Movie Review Dataset – Text Classification/Regression\n\nStory of a man who has unnatural feelings for a pig. Starts out with a opening scene that is a terrific example of absurd comedy. A formal orchestra audience is turned into an insane, violent mob by the crazy chantings of it’s singers. Unfortunately it stays absurd the WHOLE time with no general narrative eventually making it just too off putting. Even those from the era should be turned off. The cryptic dialogue would make Shakespeare seem easy to a third grader. On a technical level it’s better than you might think with some good cinematography by future great Vilmos Zsigmond. Future stars Sally Kirkland and Frederic Forrest can be seen briefly.\n\nReview from: train/neg/0_3.txt\n\n50,000 movie reviews (25,000 for training and testing).\nEach review is labelled with a binary label of sentiment – a positive or negative review was towards the movie in question.\n\nhttps://ai.stanford.edu/~amaas/data/sentiment/\n(Maas, Andrew L. and Daly, Raymond E. and Pham, Peter T. and Huang, Dan and Ng, Andrew Y. and Potts, Christopher, 2011)"
  },
  {
    "objectID": "lecture-1.html#ham-or-spam-text-classification",
    "href": "lecture-1.html#ham-or-spam-text-classification",
    "title": "Introduction",
    "section": "Ham or Spam – Text Classification",
    "text": "Ham or Spam – Text Classification\n    Message-ID: &lt;8701134.1075856113926.JavaMail.evans@thyme&gt;\n    Date: Mon, 30 Oct 2000 02:06:00 -0800 (PST)\n    From: shona.wilson@enron.com\n    To: eugenio.perez@enron.com\n    Subject: meeting deadlines\n    Mime-Version: 1.0\n    Content-Type: text/plain; charset=us-ascii\n    Content-Transfer-Encoding: 7bit\n    X-From: Shona Wilson\n    X-To: Eugenio Perez\n    X-cc: \n    X-bcc: \n    X-Origin: Beck-S\n    X-FileName: sbeck.nsf\n    \n    Dear Eugenio,\n    \n    I did not want to say this when everyone else was around, but I am concerned \n    that no attempt was made to meet the deadline of this morning that we \n    discussed last Friday. (to decide on a name for the database).  Only Maria \n    Teresa had her information to me this am as requested. The deadline could \n    have been easily met by working diligently this morning, but Jennifer did not \n    come in until 8:30 and MT until 8:15.\n    \n    I thought we had discussed the urgency of this - to have something to present \n    at the 10am meeting.  We need to discuss this to ensure it does not happen \n    again.\n    \n    Best regards\n    \n    Shona\n\nEnron Spam classification of email messages.\nIs the email Spam – each email is labelled with a binary label, spam or not spam (ham).\nThe dataset contains 17,171 spam and 16,545 ham email messages.\n\nhttps://www2.aueb.gr/users/ion/data/enron-spam/\n(Metsis, Vangelis and Androutsopoulos, Ion and Paliouras, Georgios, 2006)"
  },
  {
    "objectID": "lecture-1.html#compute-resources-environmental-concerns",
    "href": "lecture-1.html#compute-resources-environmental-concerns",
    "title": "Introduction",
    "section": "Compute resources – environmental concerns",
    "text": "Compute resources – environmental concerns\n\nLarge-scale deployment of AI could also have both positive and negative impacts on the environment. Negative impacts include increased use of natural resources, such as rare earth metals, pollution and waste, as well as energy consumption. However, AI could help with waste management and conservation offering environmental benefits.\n\n\n[…] In the United States, data centres already account for about 2 percent of all electricity used. In one estimation, DeepMind’s AlphaGo – which beat Go Champion Lee Sedol in 2016 – took 50,000 times as much power as the human brain to do so.\n\n({European Parliament. Directorate General for Parliamentary Research Services.}, 2020)"
  },
  {
    "objectID": "lecture-1.html#bias-in-language-models",
    "href": "lecture-1.html#bias-in-language-models",
    "title": "Introduction",
    "section": "Bias in language models",
    "text": "Bias in language models\n\nBiases exist in language models trained on news articles (Bolukbasi, Tolga and Chang, Kai-Wei and Zou, James Y and Saligrama, Venkatesh and Kalai, Adam T, 2016)."
  },
  {
    "objectID": "lecture-1.html#personal-information",
    "href": "lecture-1.html#personal-information",
    "title": "Introduction",
    "section": "Personal information",
    "text": "Personal information\nIn Machine Learning applications where data is generated (such as generating faces that don’t exist), there is a possibility to expose personal information. For example, in a situation where these generative Machine Learning models create synthetic patient data, the model may be trained on real medical data. The output of the Machine Learning model could possibly leak personal information.\n(Arora, Anmol and Arora, Ananya, 2022)"
  },
  {
    "objectID": "lecture-1.html#mental-health-of-optimisation-algorithms",
    "href": "lecture-1.html#mental-health-of-optimisation-algorithms",
    "title": "Introduction",
    "section": "Mental health of optimisation algorithms",
    "text": "Mental health of optimisation algorithms\nThis example is more specific to how algorithms are used as opposed to their specific design. Yet, this should still be highlighted. We have seen increasing discussion surrounding the use of optimisation algorithms that try to increase the amount of ‘screen time’ or engagement from users of social media, and it’s no secret that spending lots of time of social media has a measurable effect on one’s mental health."
  },
  {
    "objectID": "lecture-1.html#copyright-concerns",
    "href": "lecture-1.html#copyright-concerns",
    "title": "Introduction",
    "section": "Copyright Concerns",
    "text": "Copyright Concerns\nA more recent addition to the concerns is that of Github’s co-pilot application that helps users write programming code. This application has been developed on open-source software – some of which includes licensing that specifies how this open-source code may be used (for example, with attribution or copy-left). Yet, Github’s co-pilot may insert code that its been trained on verbatim (though recent additions have been addressing these concerns), resulting in a situation of ‘code laundering’. https://twitter.com/mitsuhiko/status/1410886329924194309\n    float Q_rsqrt( float number )\n    {\n            long i;\n            float x2, y;\n            const float threehalfs = 1.5F;\n    \n            x2 = number * 0.5F;\n            y  = number;\n            i  = * ( long * ) &y;                       // evil floating point bit level hacking\n            i  = 0x5f3759df - ( i &gt;&gt; 1 );               // what the fuck? \n            y  = * ( float * ) &i;\n            y  = y * ( threehalfs - ( x2 * y * y ) );   // 1st iteration\n    //  y  = y * ( threehalfs - ( x2 * y * y ) );   // 2nd iteration, this can be removed\n    \n            return y;\n    }\n    \n    // Implementation from Quake III Arena under the GPL license."
  },
  {
    "objectID": "lecture-1.html#what-is-machine-learning",
    "href": "lecture-1.html#what-is-machine-learning",
    "title": "Introduction",
    "section": "What is Machine Learning",
    "text": "What is Machine Learning\n\nWe’ve taken a look at the different kinds of frameworks for learning – animal behaviour with bait-shyness, and how that translates in computer programs.\nWe’ve identified the different types of learning: supervised, unsupervised, and reinforcement learning.\nWe’ve looked at the different types of data we may encounter, from tabular to text data, and have also seen examples of some toy datasets we will be using in the course.\nFinally, we’ve highlighted some of the ethical concerns that can arise in Machine Learning."
  },
  {
    "objectID": "lecture-1.html#bibliography-1",
    "href": "lecture-1.html#bibliography-1",
    "title": "Introduction",
    "section": "Bibliography",
    "text": "Bibliography\nArora, Anmol and Arora, Ananya (2022). Generative Adversarial Networks and Synthetic Patient Data: Current Challenges and Future Perspectives, {Royal College of Physicians}.\nBolukbasi, Tolga and Chang, Kai-Wei and Zou, James Y and Saligrama, Venkatesh and Kalai, Adam T (2016). Man is to computer programmer as woman is to homemaker? debiasing word embeddings, Advances in neural information processing systems.\nCarlisle, M. (2020). Racist Data Destruction?, Medium.\nDiliff (2014). Iris germanica (Purple bearded Iris), Wakehurst Place, UK - Diliff.jpg.\nEric Guinther (2005). Image of a primrose willowherb Ludwigia octovalvis (family Onagraceae), flower showing petals and sepals.\nFisher, Ronald A (1936). The use of multiple measurements in taxonomic problems, Wiley Online Library.\nGonen, Hila and Goldberg, Yoav (2019). Lipstick on a {{Pig}}: {{Debiasing Methods Cover}} up {{Systematic Gender Biases}} in {{Word Embeddings But}} Do Not {{Remove Them}}, {arXiv}.\nHarrison Jr, David and Rubinfeld, Daniel L (1978). Hedonic housing prices and the demand for clean air, Elsevier.\nLeCun, Yann and Bottou, L{\\’e}on and Bengio, Yoshua and Haffner, Patrick (1998). Gradient-based learning applied to document recognition, Ieee.\nMaas, Andrew L. and Daly, Raymond E. and Pham, Peter T. and Huang, Dan and Ng, Andrew Y. and Potts, Christopher (2011). Learning Word Vectors for Sentiment Analysis, Association for Computational Linguistics.\nMetsis, Vangelis and Androutsopoulos, Ion and Paliouras, Georgios (2006). Spam filtering with naive bayes-which naive bayes?.\nMitchell, Tom M (1997). Machine learning, McGraw-hill New York.\nShalev-Shwartz, Shai and Ben-David, Shai (2014). Understanding machine learning: From theory to algorithms, Cambridge university press.\nscikit-learn (2022). Sklearn.Datasets.Load\\_boston, scikit-learn.\n{European Parliament. Directorate General for Parliamentary Research Services.} (2020). The Ethics of Artificial Intelligence: Issues and Initiatives., {Publications Office}."
  },
  {
    "objectID": "lecture-1-reveal.html#welcome",
    "href": "lecture-1-reveal.html#welcome",
    "title": "Introduction",
    "section": "Welcome!",
    "text": "Welcome!\nWelcome to all the new students! Here I am going to be talking about Machine Learning and all of the great things that this “technology” has to offer. To begin our course, I shall start with a bit of house keeping – more specifically, I will be talking about what exactly we’ll be learning about in the course (Machine Learning is a broad subject after-all). In addition, I will tell you where you can find the resources related to the course and how you can contact me, should you have any questions."
  },
  {
    "objectID": "lecture-1-reveal.html#what-this-course-is-about",
    "href": "lecture-1-reveal.html#what-this-course-is-about",
    "title": "Introduction",
    "section": "What this course is about?",
    "text": "What this course is about?\nIn this course, we will be learning about Machine Learning: firstly, what Machine Learning actually is; secondly, we’ll take a look at some of the algorithms within the scope of Machine Learning, and develop an intuition about how these algorithms work and when they would be useful; and finally, how we can compare and evaluate the algorithms we’ve learnt about."
  },
  {
    "objectID": "lecture-1-reveal.html#how-this-course-will-be-taught",
    "href": "lecture-1-reveal.html#how-this-course-will-be-taught",
    "title": "Introduction",
    "section": "How this course will be taught",
    "text": "How this course will be taught\nI intended to deliver this course via a series of lectures. These lectures will be accompanied by the PDF lecture slides, in which I will provide the definitions and provide reference links should you wish to do some extra reading."
  },
  {
    "objectID": "lecture-1-reveal.html#outline-of-the-course",
    "href": "lecture-1-reveal.html#outline-of-the-course",
    "title": "Introduction",
    "section": "Outline of the course",
    "text": "Outline of the course\n\n\n\n\n\n\n\n\n\n\nLecture\n\n\nType\n\n\nTopic\n\n\n\n\n\n\n1\n\n\nTheory\n\n\nIntroduction\n\n\n\n\n2\n\n\nTheory\n\n\nLinear models\n\n\n\n\n3\n\n\nLab\n\n\nLab on Linear models\n\n\n\n\n4\n\n\nTheory/Lab\n\n\nEvaluation of models\n\n\n\n\n5\n\n\nTheory/Lab\n\n\nSupport Vector Machines\n\n\n\n\n6\n\n\nTheory/Lab\n\n\nKernel methods"
  },
  {
    "objectID": "lecture-1-reveal.html#source-code",
    "href": "lecture-1-reveal.html#source-code",
    "title": "Introduction",
    "section": "Source code",
    "text": "Source code\nDuring the course, I would also like to supplement my algorithmic definitions and explanations with some programming code – for this I will use the Python programming language. The code snippets would look something like:\nimport random\nx = [1, 2, 3, 4]\ny = [random.random() + xi for xi in x]\nprint(y)\n\n[1.4898241502582414, 2.4805286156642175, 3.065379052563245, 4.05328483072365]"
  },
  {
    "objectID": "lecture-1-reveal.html#running-the-source-code-yourself",
    "href": "lecture-1-reveal.html#running-the-source-code-yourself",
    "title": "Introduction",
    "section": "Running the source code yourself",
    "text": "Running the source code yourself\nAll of the source can be run by yourselves if you use the same python environment (i.e. that you have installed all the appropriate libraries). On the git repository, I’ve included the environment.yml file used in the production of these lectures.\nTo run the code:\n    wget https://git.sr.ht/~jaymorgan/teaching/blob/master/2022-2023/Machine%20Learning/environment.yml\n    conda env create -f environment.yml  # recreate the conda env\n    conda activate ml-lectures           # activate the new env\n    python &lt;scripts&gt;"
  },
  {
    "objectID": "lecture-1-reveal.html#references",
    "href": "lecture-1-reveal.html#references",
    "title": "Introduction",
    "section": "References",
    "text": "References\nIn some cases, and is the norm with academic traditions, we’ll want to include a reference, a link to previous written works.\nHere is an example of a sentence that includes a reference:\n“This is a very important sentence which I assert to be true, to convince you of this fact I shall appeal to authority and include a reference: (Shalev-Shwartz, Shai and Ben-David, Shai, 2014)”\nMore information on the referenced material (such as title, publishing date) will be found in the bibliography slide (or bottom of the webpage if you’re viewing the HTML version of the lectures)."
  },
  {
    "objectID": "lecture-1-reveal.html#about-me",
    "href": "lecture-1-reveal.html#about-me",
    "title": "Introduction",
    "section": "About Me",
    "text": "About Me\nMy name is Dr Jay Paul Morgan. I am a researcher at the Université de Toulon, where I am developing Deep Learning models (a sub-field of Machine Learning research) for the study of astrophysical phenomenon.\nYou can find more information and links on my personal (LIS-Lab) website: https://pageperso.lis-lab.fr/jay.morgan/\nI also publish libraries and source code online:\n\nGithub: https://github.com/jaypmorgan\nGitlab: https://gitlab.com/jaymorgan\nSource Hut: https://sr.ht/~jaymorgan/\n\nIf you have any questions, you can email me at jay.morgan@univ-tln.fr"
  },
  {
    "objectID": "lecture-1-reveal.html#where-you-can-find-the-resources",
    "href": "lecture-1-reveal.html#where-you-can-find-the-resources",
    "title": "Introduction",
    "section": "Where you can find the resources",
    "text": "Where you can find the resources\nI try to make this course as accessible as possible, which means that I host these slides in a variety of ways to suit you.\nFirstly, you can find the links to all my courses on my personal website at: https://pageperso.lis-lab.fr/jay.morgan/teaching.html\nHere you can find the links to each lecture in a PDF or HTML format. Additionally, you can view the source code used to make these lectures on source hut: https://git.sr.ht/~jaymorgan/teaching. On this git repository you can find all my lectures from all years."
  },
  {
    "objectID": "lecture-1-reveal.html#lets-answer-the-question-of-learning",
    "href": "lecture-1-reveal.html#lets-answer-the-question-of-learning",
    "title": "Introduction",
    "section": "Let’s answer the question of learning",
    "text": "Let’s answer the question of learning\nWe’ll begin our journey into the world of Machine Learning by tackling the question of what it means to ‘learn’ – how may a machine actually learn anything?"
  },
  {
    "objectID": "lecture-1-reveal.html#bait-shyness",
    "href": "lecture-1-reveal.html#bait-shyness",
    "title": "Introduction",
    "section": "Bait-shyness",
    "text": "Bait-shyness\n\nTo begin to answer the question of learning, we may turn to nature for advice. Principally, if we look at the studies conducted with Mice we find some idea to notion of learning (Shalev-Shwartz, Shai and Ben-David, Shai, 2014). (Image by brgfx on Freepik)\nWhen a rat encounters a novel source of food, it will first eat a little bit of it. If the food is edible for the rat, it will continue to eat the food, even in future encounters. If, however, on the initial contact with the food, the rat deems the food poisonous, it will ignore and not eat the food in future encounters. This process we call ‘bait-shyness’.\nHere then we see the rat, on finding something new, learn from its experience, and use that knowledge of the experience for future encounters.\nOur initial understanding of rat’s bait-shyness was limited, but we’ve come to understand more about it. For instance, we learn that their learning process is more complex than originally thought. In a later experiment, where the ‘poison’ in the food is replaced by a different unpleasant stimulus such as a electric shock – i.e. when a rat eats a food, it is then shocked. It was found that this did not deter the rat from eating the food in future encounters, unlike the poison.\nIt is presumed that the rat’s have some ‘prior knowledge’ about the world and do not infer a temporal relationship between the food and being shocked, while they can infer the same relationship with food and illness."
  },
  {
    "objectID": "lecture-1-reveal.html#computer-programs",
    "href": "lecture-1-reveal.html#computer-programs",
    "title": "Introduction",
    "section": "Computer Programs",
    "text": "Computer Programs\nFrom these two examples of how rats may learn we see: the rat will make a guess about something now (i.e. that the food is not poisonous), it will find out how good this guess is (i.e. it either gets ill or it does not), and learn from how well its guess was for the future. We also see that its learning can be impacted by the rat’s prior knowledge about how the world may work.\nBut how does this framework for the process of learning translate to computers? For a more formal definition of how computer programs could be said to learn, we have a similar idea:\n\nA computer program is said to learn from experience \\(E\\) with respect to some class of tasks \\(T\\) and performance measure \\(P\\), if its performance a tasks in \\(T\\), as measured by \\(P\\), improves with experience \\(E\\).\n\n(Mitchell, Tom M, 1997)"
  },
  {
    "objectID": "lecture-1-reveal.html#quiz",
    "href": "lecture-1-reveal.html#quiz",
    "title": "Introduction",
    "section": "Quiz!",
    "text": "Quiz!\nWhat function is being used here?\n    8 ? 5   =   13\n    9 ? 1   =   10\n    1 ? 2   =    3"
  },
  {
    "objectID": "lecture-1-reveal.html#something-more-difficult",
    "href": "lecture-1-reveal.html#something-more-difficult",
    "title": "Introduction",
    "section": "Something more difficult…",
    "text": "Something more difficult…\nWhat values are being used here?\n    x * 1 + y   =   4\n    x * 3 + y   =   8\n    x * 5 + y   =  12"
  },
  {
    "objectID": "lecture-1-reveal.html#when-might-we-need-machine-learning",
    "href": "lecture-1-reveal.html#when-might-we-need-machine-learning",
    "title": "Introduction",
    "section": "When might we need Machine Learning",
    "text": "When might we need Machine Learning\n\nWhy do we need computer programs that ‘learn’ anyway? We already have programming languages, why can’t we just use them?\nLet’s suppose we’re creating a very simple Optical Character Recognition (OCR) program.\nThis program looks at a PDF document and converts the text into something we can copy and paste. Part of this program’s task is to take an individual character, say the number ‘8’, and recognise that it’s an 8 and add that to the already scanned text.\nHow would we go about creating a program where we can define how to identify ‘8’ or ‘1’ or ‘l’ – with all the varieties of lighting conditions, handwriting, fonts, sizes. We could find the process of encompassing all different variations tiresome – if not impossible, and that’s only for a single character!\nWith Machine Learning, instead of enumerating all possible solutions within a programming language, we collect a bunch of examples of ’8’s and give them to the algorithm to learn from.\nThrough looking at these many different examples, the algorithm will/should be able to recognise what an 8 generally looks like."
  },
  {
    "objectID": "lecture-1-reveal.html#different-types-of-learning",
    "href": "lecture-1-reveal.html#different-types-of-learning",
    "title": "Introduction",
    "section": "Different types of Learning",
    "text": "Different types of Learning\nWhat we have just demonstrated by way of the OCR example, is the type of learning we call ‘Supervised Learning’. We have many examples of input (lots of different kinds of handwritten 8’s), and we tell the learning algorithm, that they are indeed the number 8.\nBut there are other kind of different learning frameworks. Specifically we have the following:\n\nSupervised Learning\nUnsupervised, or sometimes called self-supervised Learning\nReinforcement Learning"
  },
  {
    "objectID": "lecture-1-reveal.html#supervised-learning",
    "href": "lecture-1-reveal.html#supervised-learning",
    "title": "Introduction",
    "section": "Supervised Learning",
    "text": "Supervised Learning\nTo better formalise Supervised Learning from our previous OCR example, Supervised Learning is when the learning algorithm “see’s” or has access to both the input and output.\nLet’s have a dataset \\(X\\), which is a set consisting of tuple pairs \\(x_i, y_i\\). \\(x_i\\) is an input, i.e. a single image with an ‘8’, and \\(y_i\\) is a label which tells the learning algorithm if the input is indeed an ‘8’ or something else. Mathematically we have:\n\\(X = \\{(x_1, y_1), (x_2, y_2), ..., (x_n, y_n)\\}\\)"
  },
  {
    "objectID": "lecture-1-reveal.html#unsupervised-learning",
    "href": "lecture-1-reveal.html#unsupervised-learning",
    "title": "Introduction",
    "section": "Unsupervised Learning",
    "text": "Unsupervised Learning\nIn Unsupervised learning, we have again have a dataset \\(X\\), who’s elements are only inputs. In other words, there are no corresponding labels for each input. Instead, the learning algorithm must learn inherent patterns in the data and create labels itself. Throughout the course, we’ll see examples of Unsupervised Learning in action.\nOne thing to note: Recent methodologies have started to call Unsupervised Learning, self-supervised. As we have just discussed, the labels are inherent to the data from the discovered patterns, it’s just we are not explicitly giving them to the learning algorithm ourselves. So it’s sort of like a supervised learning setup, except the learning algorithm is providing the labels itself – hence the self-supervised."
  },
  {
    "objectID": "lecture-1-reveal.html#reinforcement-learning",
    "href": "lecture-1-reveal.html#reinforcement-learning",
    "title": "Introduction",
    "section": "Reinforcement Learning",
    "text": "Reinforcement Learning\nReinforcement Learning is very different to both Supervised and Unsupervised Learning. Here is the type of learning you might be familiar with if you’ve seen ‘AI’ that learns to play video games. In this type of learning, we have the following elements:\n\nAn agent\nAn environment\nA set of allowed actions the agent can make within its environment.\n\nIn this situation, an agent will interact with it’s environment, and when it does something it can receive a reward (a reward can be positive or negative). The agent will remember what it has done to receive the reward. The objective for the agent is to maximise the reward score, and learns to do this through many iterations or play-through."
  },
  {
    "objectID": "lecture-1-reveal.html#what-will-our-data-look-like",
    "href": "lecture-1-reveal.html#what-will-our-data-look-like",
    "title": "Introduction",
    "section": "What will our data look like?",
    "text": "What will our data look like?\nIn this section we shall take a look at the different types of data we might expect and the different terminology used to name them.\nData in Machine Learning applications can come in a variety of different formats. The most typical data formats we might see are:\n\nTables\nImages/Videos\nText\nSound\n\nThese are the initial formats, though, before actually doing any learning, we will want to transform them into a different representation that we can use."
  },
  {
    "objectID": "lecture-1-reveal.html#tables",
    "href": "lecture-1-reveal.html#tables",
    "title": "Introduction",
    "section": "Tables",
    "text": "Tables\nA table, or tabular, format is a \\(n \\times m\\) set of data with \\(n\\) samples or examples, and \\(m\\) features for each sample. For example, suppose we have a table consisting the price of 100 different houses:\n\n\n\n\n\n\n\n\n\n\n\nNumber of bedrooms\n\n\nGarden size (ft)\n\n\n…\n\n\nPrice ($)\n\n\n\n\n\n\n3\n\n\n0\n\n\n…\n\n\n150,000\n\n\n\n\n5\n\n\n10\n\n\n…\n\n\n200,000\n\n\n\n\n…\n\n\n…\n\n\n…\n\n\n \n\n\n\n\n10\n\n\n1000\n\n\n…\n\n\n2,000,000\n\n\n\n\n\nIn a supervised learning setting, where we want to predict the price of a house we may then have the following dataset:\n\\(X = \\{([3, 0, ...], 150,000), ([5, 10, ...], 200,000), \\\\..., ([10, 1000, ...], 2,000,000)\\}\\)"
  },
  {
    "objectID": "lecture-1-reveal.html#imagesvideos",
    "href": "lecture-1-reveal.html#imagesvideos",
    "title": "Introduction",
    "section": "Images/Videos",
    "text": "Images/Videos\nImages are composed of 2D or 3D arrays of numeric values. For example, in a RGB image that is 1024x500 pixels, we would have the array of size 1024x500x3 – where 3 is the red, green, and blue channel, respectively. If we have just a grayscale image, we could represent it as either 1024x500x1 or 1024x500 as the channel ‘dimension’ of the array is singular.\nWe may already know that videos are simply a sequence of images that are iterated through 24+ times a second. For a 24 frames per second video, we would have an array size of 1024x500x3x24 – a 4-dimensional array."
  },
  {
    "objectID": "lecture-1-reveal.html#text",
    "href": "lecture-1-reveal.html#text",
    "title": "Introduction",
    "section": "Text",
    "text": "Text\nText and language data is perhaps one of the most flexible formats of data, in terms of the person implementing the Machine Learning algorithm is somewhat free in determining how to represent the language to the algorithm.\nWith text data, we have a series of ‘tokens’ – these tokens could be words, groups of words, parts of words, and even just characters. For example, consider:\n“this is a sentence, that shouldn’t be misunderstood.”"
  },
  {
    "objectID": "lecture-1-reveal.html#tokenisation-of-text",
    "href": "lecture-1-reveal.html#tokenisation-of-text",
    "title": "Introduction",
    "section": "Tokenisation of text",
    "text": "Tokenisation of text\n“this is a sentence, that shouldn’t be misunderstood.”\nWe could ‘tokenise’ (the process of converting a string into a series of tokens that represent the original string) this sentence by splitting at white-space:\n{\"this\", \"is\", \"a\", \"sentence,\", \"that\" \"shouldn't\", \"be\", \"misunderstood.\"}\nNotice how with the words “sentence” and “misunderstood”, the punctuation is considered part of the word and so “misunderstood.” != “misunderstood”.\nThese kinds of questions of how to best represent text and language we will talk more about in later lectures!"
  },
  {
    "objectID": "lecture-1-reveal.html#time-series",
    "href": "lecture-1-reveal.html#time-series",
    "title": "Introduction",
    "section": "Time-series",
    "text": "Time-series\nI named this section time-series to be as general as possible. Within the type ‘time-series’, we could have the following types of information:\n\nSound waves\nStock prices\nNetwork messaging\n\nThese types of data all share a property in that the ‘time’ component is important in their meaning."
  },
  {
    "objectID": "lecture-1-reveal.html#types-of-outputs-regression-classification",
    "href": "lecture-1-reveal.html#types-of-outputs-regression-classification",
    "title": "Introduction",
    "section": "Types of Outputs – Regression & Classification",
    "text": "Types of Outputs – Regression & Classification\nFirst, however, I wish to explain the difference between the terms Regression and Classification.\n\nRegression: the prediction of a continuous quantity, i.e. how much does this house cost?\nClassification: the prediction of a discrete value or class label, i.e. dog or cat?\n\nIn the following toy datasets, we’ll see different types of predictions that fall under the regression/classification output type."
  },
  {
    "objectID": "lecture-1-reveal.html#boston-house-prices-dataset-tabular-regression",
    "href": "lecture-1-reveal.html#boston-house-prices-dataset-tabular-regression",
    "title": "Introduction",
    "section": "Boston House Prices Dataset – Tabular Regression",
    "text": "Boston House Prices Dataset – Tabular Regression\nA dataset of 506 houses in Boston, USA, collected during US Census.\n\n13 features/properties about each house\n1 target property: the price of the house\n\nMore information about each of the features can be found at: https://www.cs.toronto.edu/~delve/data/boston/bostonDetail.html\n(Harrison Jr, David and Rubinfeld, Daniel L, 1978)"
  },
  {
    "objectID": "lecture-1-reveal.html#boston-house-prices-example-rows",
    "href": "lecture-1-reveal.html#boston-house-prices-example-rows",
    "title": "Introduction",
    "section": "Boston House Prices – example rows",
    "text": "Boston House Prices – example rows\nimport warnings\nfrom sklearn.datasets import load_boston\nwith warnings.catch_warnings():\n    warnings.filterwarnings(\"ignore\")\n    boston = load_boston()\nboston = pd.DataFrame(\n    data=np.c_[boston['data'], boston['target']],\n    columns=boston['feature_names'].tolist() + ['target'])\nprint(boston[:2])\n      CRIM    ZN  INDUS  CHAS    NOX     RM  ...  RAD    TAX  PTRATIO      B  LSTAT  target\n0  0.00632  18.0   2.31   0.0  0.538  6.575  ...  1.0  296.0     15.3  396.9   4.98    24.0\n1  0.02731   0.0   7.07   0.0  0.469  6.421  ...  2.0  242.0     17.8  396.9   9.14    21.6\n\n[2 rows x 14 columns]"
  },
  {
    "objectID": "lecture-1-reveal.html#boston-house-prices-concerns",
    "href": "lecture-1-reveal.html#boston-house-prices-concerns",
    "title": "Introduction",
    "section": "Boston House Prices – concerns",
    "text": "Boston House Prices – concerns\nThe Boston dataset is an excellent dataset in the fact that it contains some ethical issues when it comes to Machine Learning. More specifically, some of the features in the data are ‘dummy’ variables for racial attributes (Carlisle, M., 2020). Moreover, these features show a racial segregation has a positive impact on house prices.\nScikit-Learn (scikit-learn, 2022), one of the most prolific Machine Learning framework in the Python ecosystem, has decided to depreciate and remove the Boston dataset from their repository following these concerns.\nWe will continue to use the dataset here as it is an easy to understand regression problem, and to demonstrate how easy it is to be accidentally unethical if you’re not thinking about the data carefully enough."
  },
  {
    "objectID": "lecture-1-reveal.html#iris-dataset-tabular-classification",
    "href": "lecture-1-reveal.html#iris-dataset-tabular-classification",
    "title": "Introduction",
    "section": "Iris Dataset – Tabular Classification",
    "text": "Iris Dataset – Tabular Classification"
  },
  {
    "objectID": "lecture-1-reveal.html#iris-dataset-features",
    "href": "lecture-1-reveal.html#iris-dataset-features",
    "title": "Introduction",
    "section": "Iris Dataset – features",
    "text": "Iris Dataset – features\n\n150 examples\n4 features: Petal length/width, sepal length/width\n1 classification: type of flower: {viriginica, setosa, veriscolor}\nhttps://archive.ics.uci.edu/ml/datasets/iris (Fisher, Ronald A, 1936)"
  },
  {
    "objectID": "lecture-1-reveal.html#iris-dataset-example-rows",
    "href": "lecture-1-reveal.html#iris-dataset-example-rows",
    "title": "Introduction",
    "section": "Iris Dataset – example rows",
    "text": "Iris Dataset – example rows\nfrom sklearn.datasets import load_iris\niris = load_iris()\niris = pd.DataFrame(\n    data = np.c_[iris['data'], iris['target']],\n    columns = iris['feature_names'] + ['target'])\nprint(iris.head(2))\n   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  target\n0                5.1               3.5                1.4               0.2     0.0\n1                4.9               3.0                1.4               0.2     0.0"
  },
  {
    "objectID": "lecture-1-reveal.html#mnist-dataset-image-classification",
    "href": "lecture-1-reveal.html#mnist-dataset-image-classification",
    "title": "Introduction",
    "section": "MNIST Dataset – Image Classification",
    "text": "MNIST Dataset – Image Classification\n\nA dataset of images (of size 28x28) containing handwritten digits from 0 - 9.\nhttp://yann.lecun.com/exdb/mnist/\n(LeCun, Yann and Bottou, L{\\’e}on and Bengio, Yoshua and Haffner, Patrick, 1998)"
  },
  {
    "objectID": "lecture-1-reveal.html#mnist-dataset-features",
    "href": "lecture-1-reveal.html#mnist-dataset-features",
    "title": "Introduction",
    "section": "MNIST Dataset – Features",
    "text": "MNIST Dataset – Features\n\n60,000 images in the training dataset\n10,000 images in the test dataset\n28x28 pixels (grayscale)"
  },
  {
    "objectID": "lecture-1-reveal.html#mnist-dataset-example-rows",
    "href": "lecture-1-reveal.html#mnist-dataset-example-rows",
    "title": "Introduction",
    "section": "MNIST Dataset – Example Rows",
    "text": "MNIST Dataset – Example Rows\nfrom sklearn.datasets import fetch_openml\nmnist = fetch_openml(\"mnist_784\").data[:2]\npixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  pixel8  pixel9  \\\n0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n1     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n\npixel10  ...  pixel775  pixel776  pixel777  pixel778  pixel779  pixel780  \\\n0      0.0  ...       0.0       0.0       0.0       0.0       0.0       0.0   \n1      0.0  ...       0.0       0.0       0.0       0.0       0.0       0.0   \n\npixel781  pixel782  pixel783  pixel784  \n0       0.0       0.0       0.0       0.0  \n1       0.0       0.0       0.0       0.0  \n\n[2 rows x 784 columns]"
  },
  {
    "objectID": "lecture-1-reveal.html#large-movie-review-dataset-text-classificationregression",
    "href": "lecture-1-reveal.html#large-movie-review-dataset-text-classificationregression",
    "title": "Introduction",
    "section": "Large Movie Review Dataset – Text Classification/Regression",
    "text": "Large Movie Review Dataset – Text Classification/Regression\n\nStory of a man who has unnatural feelings for a pig. Starts out with a opening scene that is a terrific example of absurd comedy. A formal orchestra audience is turned into an insane, violent mob by the crazy chantings of it’s singers. Unfortunately it stays absurd the WHOLE time with no general narrative eventually making it just too off putting. Even those from the era should be turned off. The cryptic dialogue would make Shakespeare seem easy to a third grader. On a technical level it’s better than you might think with some good cinematography by future great Vilmos Zsigmond. Future stars Sally Kirkland and Frederic Forrest can be seen briefly.\n\nReview from: train/neg/0_3.txt\n\n50,000 movie reviews (25,000 for training and testing).\nEach review is labelled with a binary label of sentiment – a positive or negative review was towards the movie in question.\n\nhttps://ai.stanford.edu/~amaas/data/sentiment/\n(Maas, Andrew L. and Daly, Raymond E. and Pham, Peter T. and Huang, Dan and Ng, Andrew Y. and Potts, Christopher, 2011)"
  },
  {
    "objectID": "lecture-1-reveal.html#ham-or-spam-text-classification",
    "href": "lecture-1-reveal.html#ham-or-spam-text-classification",
    "title": "Introduction",
    "section": "Ham or Spam – Text Classification",
    "text": "Ham or Spam – Text Classification\n    Message-ID: &lt;8701134.1075856113926.JavaMail.evans@thyme&gt;\n    Date: Mon, 30 Oct 2000 02:06:00 -0800 (PST)\n    From: shona.wilson@enron.com\n    To: eugenio.perez@enron.com\n    Subject: meeting deadlines\n    Mime-Version: 1.0\n    Content-Type: text/plain; charset=us-ascii\n    Content-Transfer-Encoding: 7bit\n    X-From: Shona Wilson\n    X-To: Eugenio Perez\n    X-cc: \n    X-bcc: \n    X-Origin: Beck-S\n    X-FileName: sbeck.nsf\n    \n    Dear Eugenio,\n    \n    I did not want to say this when everyone else was around, but I am concerned \n    that no attempt was made to meet the deadline of this morning that we \n    discussed last Friday. (to decide on a name for the database).  Only Maria \n    Teresa had her information to me this am as requested. The deadline could \n    have been easily met by working diligently this morning, but Jennifer did not \n    come in until 8:30 and MT until 8:15.\n    \n    I thought we had discussed the urgency of this - to have something to present \n    at the 10am meeting.  We need to discuss this to ensure it does not happen \n    again.\n    \n    Best regards\n    \n    Shona\n\nEnron Spam classification of email messages.\nIs the email Spam – each email is labelled with a binary label, spam or not spam (ham).\nThe dataset contains 17,171 spam and 16,545 ham email messages.\n\nhttps://www2.aueb.gr/users/ion/data/enron-spam/\n(Metsis, Vangelis and Androutsopoulos, Ion and Paliouras, Georgios, 2006)"
  },
  {
    "objectID": "lecture-1-reveal.html#compute-resources-environmental-concerns",
    "href": "lecture-1-reveal.html#compute-resources-environmental-concerns",
    "title": "Introduction",
    "section": "Compute resources – environmental concerns",
    "text": "Compute resources – environmental concerns\n\nLarge-scale deployment of AI could also have both positive and negative impacts on the environment. Negative impacts include increased use of natural resources, such as rare earth metals, pollution and waste, as well as energy consumption. However, AI could help with waste management and conservation offering environmental benefits.\n\n\n[…] In the United States, data centres already account for about 2 percent of all electricity used. In one estimation, DeepMind’s AlphaGo – which beat Go Champion Lee Sedol in 2016 – took 50,000 times as much power as the human brain to do so.\n\n({European Parliament. Directorate General for Parliamentary Research Services.}, 2020)"
  },
  {
    "objectID": "lecture-1-reveal.html#bias-in-language-models",
    "href": "lecture-1-reveal.html#bias-in-language-models",
    "title": "Introduction",
    "section": "Bias in language models",
    "text": "Bias in language models\n\nBiases exist in language models trained on news articles (Bolukbasi, Tolga and Chang, Kai-Wei and Zou, James Y and Saligrama, Venkatesh and Kalai, Adam T, 2016)."
  },
  {
    "objectID": "lecture-1-reveal.html#personal-information",
    "href": "lecture-1-reveal.html#personal-information",
    "title": "Introduction",
    "section": "Personal information",
    "text": "Personal information\nIn Machine Learning applications where data is generated (such as generating faces that don’t exist), there is a possibility to expose personal information. For example, in a situation where these generative Machine Learning models create synthetic patient data, the model may be trained on real medical data. The output of the Machine Learning model could possibly leak personal information.\n(Arora, Anmol and Arora, Ananya, 2022)"
  },
  {
    "objectID": "lecture-1-reveal.html#mental-health-of-optimisation-algorithms",
    "href": "lecture-1-reveal.html#mental-health-of-optimisation-algorithms",
    "title": "Introduction",
    "section": "Mental health of optimisation algorithms",
    "text": "Mental health of optimisation algorithms\nThis example is more specific to how algorithms are used as opposed to their specific design. Yet, this should still be highlighted. We have seen increasing discussion surrounding the use of optimisation algorithms that try to increase the amount of ‘screen time’ or engagement from users of social media, and it’s no secret that spending lots of time of social media has a measurable effect on one’s mental health."
  },
  {
    "objectID": "lecture-1-reveal.html#copyright-concerns",
    "href": "lecture-1-reveal.html#copyright-concerns",
    "title": "Introduction",
    "section": "Copyright Concerns",
    "text": "Copyright Concerns\nA more recent addition to the concerns is that of Github’s co-pilot application that helps users write programming code. This application has been developed on open-source software – some of which includes licensing that specifies how this open-source code may be used (for example, with attribution or copy-left). Yet, Github’s co-pilot may insert code that its been trained on verbatim (though recent additions have been addressing these concerns), resulting in a situation of ‘code laundering’. https://twitter.com/mitsuhiko/status/1410886329924194309\n    float Q_rsqrt( float number )\n    {\n            long i;\n            float x2, y;\n            const float threehalfs = 1.5F;\n    \n            x2 = number * 0.5F;\n            y  = number;\n            i  = * ( long * ) &y;                       // evil floating point bit level hacking\n            i  = 0x5f3759df - ( i &gt;&gt; 1 );               // what the fuck? \n            y  = * ( float * ) &i;\n            y  = y * ( threehalfs - ( x2 * y * y ) );   // 1st iteration\n    //  y  = y * ( threehalfs - ( x2 * y * y ) );   // 2nd iteration, this can be removed\n    \n            return y;\n    }\n    \n    // Implementation from Quake III Arena under the GPL license."
  },
  {
    "objectID": "lecture-1-reveal.html#what-is-machine-learning",
    "href": "lecture-1-reveal.html#what-is-machine-learning",
    "title": "Introduction",
    "section": "What is Machine Learning",
    "text": "What is Machine Learning\n\nWe’ve taken a look at the different kinds of frameworks for learning – animal behaviour with bait-shyness, and how that translates in computer programs.\nWe’ve identified the different types of learning: supervised, unsupervised, and reinforcement learning.\nWe’ve looked at the different types of data we may encounter, from tabular to text data, and have also seen examples of some toy datasets we will be using in the course.\nFinally, we’ve highlighted some of the ethical concerns that can arise in Machine Learning."
  },
  {
    "objectID": "lecture-1-reveal.html#bibliography-1",
    "href": "lecture-1-reveal.html#bibliography-1",
    "title": "Introduction",
    "section": "Bibliography",
    "text": "Bibliography\nArora, Anmol and Arora, Ananya (2022). Generative Adversarial Networks and Synthetic Patient Data: Current Challenges and Future Perspectives, {Royal College of Physicians}.\nBolukbasi, Tolga and Chang, Kai-Wei and Zou, James Y and Saligrama, Venkatesh and Kalai, Adam T (2016). Man is to computer programmer as woman is to homemaker? debiasing word embeddings, Advances in neural information processing systems.\nCarlisle, M. (2020). Racist Data Destruction?, Medium.\nDiliff (2014). Iris germanica (Purple bearded Iris), Wakehurst Place, UK - Diliff.jpg.\nEric Guinther (2005). Image of a primrose willowherb Ludwigia octovalvis (family Onagraceae), flower showing petals and sepals.\nFisher, Ronald A (1936). The use of multiple measurements in taxonomic problems, Wiley Online Library.\nGonen, Hila and Goldberg, Yoav (2019). Lipstick on a {{Pig}}: {{Debiasing Methods Cover}} up {{Systematic Gender Biases}} in {{Word Embeddings But}} Do Not {{Remove Them}}, {arXiv}.\nHarrison Jr, David and Rubinfeld, Daniel L (1978). Hedonic housing prices and the demand for clean air, Elsevier.\nLeCun, Yann and Bottou, L{\\’e}on and Bengio, Yoshua and Haffner, Patrick (1998). Gradient-based learning applied to document recognition, Ieee.\nMaas, Andrew L. and Daly, Raymond E. and Pham, Peter T. and Huang, Dan and Ng, Andrew Y. and Potts, Christopher (2011). Learning Word Vectors for Sentiment Analysis, Association for Computational Linguistics.\nMetsis, Vangelis and Androutsopoulos, Ion and Paliouras, Georgios (2006). Spam filtering with naive bayes-which naive bayes?.\nMitchell, Tom M (1997). Machine learning, McGraw-hill New York.\nShalev-Shwartz, Shai and Ben-David, Shai (2014). Understanding machine learning: From theory to algorithms, Cambridge university press.\nscikit-learn (2022). Sklearn.Datasets.Load\\_boston, scikit-learn.\n{European Parliament. Directorate General for Parliamentary Research Services.} (2020). The Ethics of Artificial Intelligence: Issues and Initiatives., {Publications Office}."
  },
  {
    "objectID": "lab-2.html",
    "href": "lab-2.html",
    "title": "Evaluation of Models",
    "section": "",
    "text": "Welcome to the second lab for the Machine Learning course. In this lab we’re going to be implementing various methods to evaluate a logistic regressor.\nThis lab will build on what we created in the last lab, transforming the linear regressor into a logistic regressor.\n\n\nIn these lab sessions we will implement what we’ve learn during the theory lectures. These implementation will need to be using the Python Programming Language. You’re allowed to use 3rd party libraries such as pandas, matplotlib, numpy. But it is not allowed to use a library that implements exactly machine learning model we’re learning about. For example, in this lab, we’re learning about linear models, so you cannot use a library that provides functionality for computing a linear model. If you’re uncertain about whether a library can be used, please do ask!\nI am going to give you the maximum flexibility with how you want to program these linear models: you can create a Python script, or if you like, you can use jupyter notebooks. In both cases, You should preface your implementation with which question you’re answering with a comment (if you’re writing a python script), or markdown (if you want to use jupyter) like this:\n# Q1. Download, parse, and load the data into a pandas dataframe,\n# print the first 5 rows to ensure the data is formated correctly\nimport pandas as pd\n\ndef load_data(filepath: str) -&gt; pd.DataFrame:\n    # load_data logic\n    return df\nYou are to work individually.\nIn summary:\n\nWork individually.\nImplementation should be using the Python programming language.\nYou can use supplementary libraries such as pandas, matplotlib, numpy, but cannot use a library that provides a function call for the assignment.\n\n\n\n\nTo hand in your assignment, please zip all of your source code (do not include the data) into a zip-archive named using the following format:\n&lt;first-name&gt;-&lt;surname&gt;-machine-learning-lab-2.zip\nreplacing &lt;first-name&gt; and &lt;surname&gt; with your name. Please send this assignment to my email address: jay.morgan@univ-tln.fr using the subject Machine Learning Assignment 2 by the end of the lab session. I will accept late assignments, but will be deducted score accordingly."
  },
  {
    "objectID": "lab-2.html#how-to-answer-the-questions",
    "href": "lab-2.html#how-to-answer-the-questions",
    "title": "Evaluation of Models",
    "section": "",
    "text": "In these lab sessions we will implement what we’ve learn during the theory lectures. These implementation will need to be using the Python Programming Language. You’re allowed to use 3rd party libraries such as pandas, matplotlib, numpy. But it is not allowed to use a library that implements exactly machine learning model we’re learning about. For example, in this lab, we’re learning about linear models, so you cannot use a library that provides functionality for computing a linear model. If you’re uncertain about whether a library can be used, please do ask!\nI am going to give you the maximum flexibility with how you want to program these linear models: you can create a Python script, or if you like, you can use jupyter notebooks. In both cases, You should preface your implementation with which question you’re answering with a comment (if you’re writing a python script), or markdown (if you want to use jupyter) like this:\n# Q1. Download, parse, and load the data into a pandas dataframe,\n# print the first 5 rows to ensure the data is formated correctly\nimport pandas as pd\n\ndef load_data(filepath: str) -&gt; pd.DataFrame:\n    # load_data logic\n    return df\nYou are to work individually.\nIn summary:\n\nWork individually.\nImplementation should be using the Python programming language.\nYou can use supplementary libraries such as pandas, matplotlib, numpy, but cannot use a library that provides a function call for the assignment."
  },
  {
    "objectID": "lab-2.html#submission-procedure",
    "href": "lab-2.html#submission-procedure",
    "title": "Evaluation of Models",
    "section": "",
    "text": "To hand in your assignment, please zip all of your source code (do not include the data) into a zip-archive named using the following format:\n&lt;first-name&gt;-&lt;surname&gt;-machine-learning-lab-2.zip\nreplacing &lt;first-name&gt; and &lt;surname&gt; with your name. Please send this assignment to my email address: jay.morgan@univ-tln.fr using the subject Machine Learning Assignment 2 by the end of the lab session. I will accept late assignments, but will be deducted score accordingly."
  },
  {
    "objectID": "lab-2.html#question-1",
    "href": "lab-2.html#question-1",
    "title": "Evaluation of Models",
    "section": "Question 1",
    "text": "Question 1\nCopy the existing code from Lab 1, creating a new folder for this lab and pasting in the code for the linear regressor."
  },
  {
    "objectID": "lab-2.html#question-2",
    "href": "lab-2.html#question-2",
    "title": "Evaluation of Models",
    "section": "Question 2",
    "text": "Question 2\nDownload the Iris dataset from https://archive.ics.uci.edu/dataset/53/iris. The dataset can be downloaded from iris.data. Load the data into a pandas dataframe.\nFor this lab, we’re going to be performing a binary classification problem, but this dataset has 3 classes: setosa, virginica, and versicolor. So we want to take this multi-class problem and transform it into a binary classification.\nCreate a new column for the dataset called target. The value of target will be 1 if the row contains a setosa flower, else the value is 0. There should be \\(\\frac{1}{3}\\) rows with the value of 1, the rest should be 0."
  },
  {
    "objectID": "lab-2.html#question-3",
    "href": "lab-2.html#question-3",
    "title": "Evaluation of Models",
    "section": "Question 3",
    "text": "Question 3\nFor this question we want to take this dataset of 150 rows, and split it into a train, test, and validation dataset, using the following proportions for each split:\n\nTraining: 70%\nValidation: 10%\nTesting: 20%\n\nSample data for each subset using stratified sampling. I.e. the training data should have roughly \\(\\frac{1}{3}\\) positive samples, the testing and validation dataset should also have roughly \\(\\frac{1}{3}\\) positive samples."
  },
  {
    "objectID": "lab-2.html#question-4",
    "href": "lab-2.html#question-4",
    "title": "Evaluation of Models",
    "section": "Question 4",
    "text": "Question 4\nUsing the linear regression model you created in the previous lecture, transform it into a logistic regressor by applying the logistic function to the output of the model. The loss function for this model should be binary cross entropy.\nSelect two columns from the Iris dataset (i.e. petal length and petal width), and using these two columns, train a logistic regressor using gradient descent, measuring the gradient using finite differences approximation. This means that instead of having a single slope variable, we have multiple:\n\\[\n\\hat{y} = \\sigma(\\beta_0 + \\sum_{i=1}^m x_i \\beta_i)\n\\]\nwhere \\(\\hat{y}\\) is the model’s probability prediction, \\(\\sigma\\) is the logistic/sigmoid function, \\(\\beta_0\\) is the intercept, \\(\\beta_i\\) is the coefficient that modulates the \\(x_i\\) variable.\nI’ve made a start for you, please fill in the ‘#TODOs’:\nimport numpy as np\n\ndef bce(y, yhat):\n    # TODO: apply the binary cross entropy function returning the loss\n    return loss\n\nclass LogisticRegressor:\n    def __init__(self, n_features: int = 2):\n        self.params = np.random.randn(n_features + 1)\n\n    def logistic(self, x):\n        # TODO: apply the logistic function\n        return x\n\n    def __call__(self, x, logits=False):\n        y = self.params[0] + self.params[1:] @ x.T\n        if not logits:\n            y = self.logistic(y)\n        return y\n\n    def fit(train_x, train_y, valid_x, valid_y, epochs: int = 100, lr: float = 0.01):\n        # TODO: train the model using gradient descent and finite-differences\n        for epoch in range(1, epochs+1):\n            for xi, yi in zip(train_x, train_y):\n                # calculate loss and update model parameters using gradient descent\n            for xi, yi in zip(valid_x, valid_y):\n                # calculate validation loss (BUT DON'T UPDATE MODEL PARAMETERS!)\n\n    def predict(x, logits):\n        return self(x, logits=logits)"
  },
  {
    "objectID": "lab-2.html#question-5",
    "href": "lab-2.html#question-5",
    "title": "Evaluation of Models",
    "section": "Question 5",
    "text": "Question 5\nAs gradient descent is iterating, store (using class variables), the training and validation loss.\nVisualise the training and validation loss. Is there a point at which the model begins to over fit? How do you know that the model is beginning to overfit by looking at these curves?"
  },
  {
    "objectID": "lab-2.html#question-6",
    "href": "lab-2.html#question-6",
    "title": "Evaluation of Models",
    "section": "Question 6",
    "text": "Question 6\nPredict the class labels for the testing set.\nFor the testing set, calculate the:\n\nTP – number of true positives\nTN – number of true negatives\nFP – number of false positives\nFN – number of false negatives"
  },
  {
    "objectID": "lab-2.html#question-7",
    "href": "lab-2.html#question-7",
    "title": "Evaluation of Models",
    "section": "Question 7",
    "text": "Question 7\nCalculate the precision and recall and \\(F_1\\) score.\ndef precision(y, yhat):\n    # calculate the precision and return it\n    return\n\ndef recall(y, yhat):\n    # calculate the recall and return it\n    return\n\ndef f_beta(y, yhat, beta=1):\n    pr = precision(y, yhat)\n    rc = recall(y, yhat)\n    # calculate the f_beta score and return it\n    return\n\n\npr = precision(y, yhat&gt;=0.5)\nrc = recall(y, yhat&gt;=0.5)\n# ..."
  },
  {
    "objectID": "lab-2.html#question-8",
    "href": "lab-2.html#question-8",
    "title": "Evaluation of Models",
    "section": "Question 8",
    "text": "Question 8\nGenerate a report using the precision, recall and \\(F_1\\) and confusion matrix. The report should be printed like:\n    |        |          | Predicted |          |\n    |        |          |  Positive | Negative |\n    | Actual | Positive |         5 |        2 |\n    |        | Negative |         3 |        1 |\n    \n    - Precision: 0.6\n    - Recall: 0.6\n    - F_1 Score: 0.6\nReplacing the scores with the correct numbers."
  },
  {
    "objectID": "lab-2.html#question-9",
    "href": "lab-2.html#question-9",
    "title": "Evaluation of Models",
    "section": "Question 9",
    "text": "Question 9\nCalculate the true-positive and false positive rate, and from these values generate a ROC curve.\n    def roc(y, yhat, threshold_step=0.01):\n        # iteratively increase the threshold by threshold_step,\n        # calculating the TP and FP rate for each iteration. This function\n        # should return two lists, a list of TP rates, and a list of FP\n        # rates.\n        return tp, fp\n    \n    tp, fp = roc(y, yhat)\n    # visualise the ROC curve here"
  },
  {
    "objectID": "lab-2.html#question-10",
    "href": "lab-2.html#question-10",
    "title": "Evaluation of Models",
    "section": "Question 10",
    "text": "Question 10\nNow that you’ve created a logistic regressor for two features of the Iris dataset and have created some analytic results. Select another two columns (i.e. petal width and sepal length, or petal length and sepal width). Create a different logistic regressor using these new columns and create the same results as you did with questions 8 and 9.\nCompare these two models trained with different columns. Which model is best, and why do we know that it’s the best?"
  },
  {
    "objectID": "lab-2-reveal.html#how-to-answer-the-questions",
    "href": "lab-2-reveal.html#how-to-answer-the-questions",
    "title": "Evaluation of Models",
    "section": "How to answer the questions",
    "text": "How to answer the questions\nIn these lab sessions we will implement what we’ve learn during the theory lectures. These implementation will need to be using the Python Programming Language. You’re allowed to use 3rd party libraries such as pandas, matplotlib, numpy. But it is not allowed to use a library that implements exactly machine learning model we’re learning about. For example, in this lab, we’re learning about linear models, so you cannot use a library that provides functionality for computing a linear model. If you’re uncertain about whether a library can be used, please do ask!\nI am going to give you the maximum flexibility with how you want to program these linear models: you can create a Python script, or if you like, you can use jupyter notebooks. In both cases, You should preface your implementation with which question you’re answering with a comment (if you’re writing a python script), or markdown (if you want to use jupyter) like this:\n# Q1. Download, parse, and load the data into a pandas dataframe,\n# print the first 5 rows to ensure the data is formated correctly\nimport pandas as pd\n\ndef load_data(filepath: str) -&gt; pd.DataFrame:\n    # load_data logic\n    return df\nYou are to work individually.\nIn summary:\n\nWork individually.\nImplementation should be using the Python programming language.\nYou can use supplementary libraries such as pandas, matplotlib, numpy, but cannot use a library that provides a function call for the assignment."
  },
  {
    "objectID": "lab-2-reveal.html#submission-procedure",
    "href": "lab-2-reveal.html#submission-procedure",
    "title": "Evaluation of Models",
    "section": "Submission Procedure",
    "text": "Submission Procedure\nTo hand in your assignment, please zip all of your source code (do not include the data) into a zip-archive named using the following format:\n&lt;first-name&gt;-&lt;surname&gt;-machine-learning-lab-2.zip\nreplacing &lt;first-name&gt; and &lt;surname&gt; with your name. Please send this assignment to my email address: jay.morgan@univ-tln.fr using the subject Machine Learning Assignment 2 by the end of the lab session. I will accept late assignments, but will be deducted score accordingly."
  },
  {
    "objectID": "lab-2-reveal.html#question-1",
    "href": "lab-2-reveal.html#question-1",
    "title": "Evaluation of Models",
    "section": "Question 1",
    "text": "Question 1\nCopy the existing code from Lab 1, creating a new folder for this lab and pasting in the code for the linear regressor."
  },
  {
    "objectID": "lab-2-reveal.html#question-2",
    "href": "lab-2-reveal.html#question-2",
    "title": "Evaluation of Models",
    "section": "Question 2",
    "text": "Question 2\nDownload the Iris dataset from https://archive.ics.uci.edu/dataset/53/iris. The dataset can be downloaded from iris.data. Load the data into a pandas dataframe.\nFor this lab, we’re going to be performing a binary classification problem, but this dataset has 3 classes: setosa, virginica, and versicolor. So we want to take this multi-class problem and transform it into a binary classification.\nCreate a new column for the dataset called target. The value of target will be 1 if the row contains a setosa flower, else the value is 0. There should be \\(\\frac{1}{3}\\) rows with the value of 1, the rest should be 0."
  },
  {
    "objectID": "lab-2-reveal.html#question-3",
    "href": "lab-2-reveal.html#question-3",
    "title": "Evaluation of Models",
    "section": "Question 3",
    "text": "Question 3\nFor this question we want to take this dataset of 150 rows, and split it into a train, test, and validation dataset, using the following proportions for each split:\n\nTraining: 70%\nValidation: 10%\nTesting: 20%\n\nSample data for each subset using stratified sampling. I.e. the training data should have roughly \\(\\frac{1}{3}\\) positive samples, the testing and validation dataset should also have roughly \\(\\frac{1}{3}\\) positive samples."
  },
  {
    "objectID": "lab-2-reveal.html#question-4",
    "href": "lab-2-reveal.html#question-4",
    "title": "Evaluation of Models",
    "section": "Question 4",
    "text": "Question 4\nUsing the linear regression model you created in the previous lecture, transform it into a logistic regressor by applying the logistic function to the output of the model. The loss function for this model should be binary cross entropy.\nSelect two columns from the Iris dataset (i.e. petal length and petal width), and using these two columns, train a logistic regressor using gradient descent, measuring the gradient using finite differences approximation. This means that instead of having a single slope variable, we have multiple:\n\\[\n\\hat{y} = \\sigma(\\beta_0 + \\sum_{i=1}^m x_i \\beta_i)\n\\]\nwhere \\(\\hat{y}\\) is the model’s probability prediction, \\(\\sigma\\) is the logistic/sigmoid function, \\(\\beta_0\\) is the intercept, \\(\\beta_i\\) is the coefficient that modulates the \\(x_i\\) variable.\nI’ve made a start for you, please fill in the ‘#TODOs’:\nimport numpy as np\n\ndef bce(y, yhat):\n    # TODO: apply the binary cross entropy function returning the loss\n    return loss\n\nclass LogisticRegressor:\n    def __init__(self, n_features: int = 2):\n        self.params = np.random.randn(n_features + 1)\n\n    def logistic(self, x):\n        # TODO: apply the logistic function\n        return x\n\n    def __call__(self, x, logits=False):\n        y = self.params[0] + self.params[1:] @ x.T\n        if not logits:\n            y = self.logistic(y)\n        return y\n\n    def fit(train_x, train_y, valid_x, valid_y, epochs: int = 100, lr: float = 0.01):\n        # TODO: train the model using gradient descent and finite-differences\n        for epoch in range(1, epochs+1):\n            for xi, yi in zip(train_x, train_y):\n                # calculate loss and update model parameters using gradient descent\n            for xi, yi in zip(valid_x, valid_y):\n                # calculate validation loss (BUT DON'T UPDATE MODEL PARAMETERS!)\n\n    def predict(x, logits):\n        return self(x, logits=logits)"
  },
  {
    "objectID": "lab-2-reveal.html#question-5",
    "href": "lab-2-reveal.html#question-5",
    "title": "Evaluation of Models",
    "section": "Question 5",
    "text": "Question 5\nAs gradient descent is iterating, store (using class variables), the training and validation loss.\nVisualise the training and validation loss. Is there a point at which the model begins to over fit? How do you know that the model is beginning to overfit by looking at these curves?"
  },
  {
    "objectID": "lab-2-reveal.html#question-6",
    "href": "lab-2-reveal.html#question-6",
    "title": "Evaluation of Models",
    "section": "Question 6",
    "text": "Question 6\nPredict the class labels for the testing set.\nFor the testing set, calculate the:\n\nTP – number of true positives\nTN – number of true negatives\nFP – number of false positives\nFN – number of false negatives"
  },
  {
    "objectID": "lab-2-reveal.html#question-7",
    "href": "lab-2-reveal.html#question-7",
    "title": "Evaluation of Models",
    "section": "Question 7",
    "text": "Question 7\nCalculate the precision and recall and \\(F_1\\) score.\ndef precision(y, yhat):\n    # calculate the precision and return it\n    return\n\ndef recall(y, yhat):\n    # calculate the recall and return it\n    return\n\ndef f_beta(y, yhat, beta=1):\n    pr = precision(y, yhat)\n    rc = recall(y, yhat)\n    # calculate the f_beta score and return it\n    return\n\n\npr = precision(y, yhat&gt;=0.5)\nrc = recall(y, yhat&gt;=0.5)\n# ..."
  },
  {
    "objectID": "lab-2-reveal.html#question-8",
    "href": "lab-2-reveal.html#question-8",
    "title": "Evaluation of Models",
    "section": "Question 8",
    "text": "Question 8\nGenerate a report using the precision, recall and \\(F_1\\) and confusion matrix. The report should be printed like:\n    |        |          | Predicted |          |\n    |        |          |  Positive | Negative |\n    | Actual | Positive |         5 |        2 |\n    |        | Negative |         3 |        1 |\n    \n    - Precision: 0.6\n    - Recall: 0.6\n    - F_1 Score: 0.6\nReplacing the scores with the correct numbers."
  },
  {
    "objectID": "lab-2-reveal.html#question-9",
    "href": "lab-2-reveal.html#question-9",
    "title": "Evaluation of Models",
    "section": "Question 9",
    "text": "Question 9\nCalculate the true-positive and false positive rate, and from these values generate a ROC curve.\n    def roc(y, yhat, threshold_step=0.01):\n        # iteratively increase the threshold by threshold_step,\n        # calculating the TP and FP rate for each iteration. This function\n        # should return two lists, a list of TP rates, and a list of FP\n        # rates.\n        return tp, fp\n    \n    tp, fp = roc(y, yhat)\n    # visualise the ROC curve here"
  },
  {
    "objectID": "lab-2-reveal.html#question-10",
    "href": "lab-2-reveal.html#question-10",
    "title": "Evaluation of Models",
    "section": "Question 10",
    "text": "Question 10\nNow that you’ve created a logistic regressor for two features of the Iris dataset and have created some analytic results. Select another two columns (i.e. petal width and sepal length, or petal length and sepal width). Create a different logistic regressor using these new columns and create the same results as you did with questions 8 and 9.\nCompare these two models trained with different columns. Which model is best, and why do we know that it’s the best?"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Machine Learning",
    "section": "",
    "text": "Welcome to the Machine Learning course developed for the MIR Masters Engineering and Complex Systems. In this series of lectures, we’re going to learn about how to learn! Specifically, we’re going to learn about how computers learn using Machine Learning algorithms. We’ll learn about the basic understanding of learning algorithms, as well as specific algorithms that include: linear models, support vector machines, and clustering methods. In addition to these algorithms, we will also look at a key part of using any learning algorithm – evaluating it!\nBelow you can find the lectures presented in this course, in a HTML or PDF format. If you have any questions or concerns, you can contact me using my email address jay.morgan@univ-tln.fr"
  },
  {
    "objectID": "index.html#lectures",
    "href": "index.html#lectures",
    "title": "Machine Learning",
    "section": "Lectures",
    "text": "Lectures\n\nLecture 1 - Introduction\nLecture 2 - Linear Models\nLecture 3 - Evaluation of Models\nLecture 4 - Support Vector Machines\nLecture 5 - K-Nearest Neighbours & K-Means"
  },
  {
    "objectID": "index.html#labs",
    "href": "index.html#labs",
    "title": "Machine Learning",
    "section": "Labs",
    "text": "Labs\n\nLab 1 - Linear Models\nLab 2 - Evaluation of Models\nLab 3 - K-Nearest Neighbours"
  },
  {
    "objectID": "lab-1-reveal.html#how-to-answer-the-questions",
    "href": "lab-1-reveal.html#how-to-answer-the-questions",
    "title": "Linear Models",
    "section": "How to answer the questions",
    "text": "How to answer the questions\nIn these lab sessions we will implement what we’ve learn during the theory lectures. These implementation will need to be using the Python Programming Language. You’re allowed to use 3rd party libraries such as pandas, matplotlib, numpy. But it is not allowed to use a library that implements exactly machine learning model we’re learning about. For example, in this lab, we’re learning about linear models, so you cannot use a library that provides functionality for computing a linear model. If you’re uncertain about whether a library can be used, please do ask!\nI am going to give you the maximum flexibility with how you want to program these linear models: you can create a Python script, or if you like, you can use jupyter notebooks. In both cases, You should preface your implementation with which question you’re answering with a comment (if you’re writing a python script), or markdown (if you want to use jupyter) like this:\n# Q1. Download, parse, and load the data into a pandas dataframe,\n# print the first 5 rows to ensure the data is formated correctly\nimport pandas as pd\n\ndef load_data(filepath: str) -&gt; pd.DataFrame:\n    # load_data logic\n    return df\nYou are to work individually.\nIn summary:\n\nWork individually.\nImplementation should be using the Python programming language.\nYou can use supplementary libraries such as pandas, matplotlib, numpy, but cannot use a library that provides a function call for the assignment."
  },
  {
    "objectID": "lab-1-reveal.html#submission-procedure",
    "href": "lab-1-reveal.html#submission-procedure",
    "title": "Linear Models",
    "section": "Submission Procedure",
    "text": "Submission Procedure\nTo hand in your assignment, please zip all of your source code (do not include the data) into a zip-archive named using the following format:\n&lt;first-name&gt;-&lt;surname&gt;-machine-learning-lab-1.zip\nreplacing &lt;first-name&gt; and &lt;surname&gt; with your name. Please send this assignment to my email address: jay.morgan@univ-tln.fr using the subject Machine Learning Assignment 1 by the end of the lab session. I will accept late assignments, but will be deducted score accordingly."
  },
  {
    "objectID": "lab-1-reveal.html#question-1",
    "href": "lab-1-reveal.html#question-1",
    "title": "Linear Models",
    "section": "Question 1",
    "text": "Question 1\nTo start this lab session we want to setup our project. For this question, do the following:\n\nCreate a new directory for this lab.\nCreate a new conda environment.\nIn this new conda environment, install python, pandas, matplotlib, and numpy.\nExport this conda environment to an environment.yml into the root of the directory."
  },
  {
    "objectID": "lab-1-reveal.html#question-2",
    "href": "lab-1-reveal.html#question-2",
    "title": "Linear Models",
    "section": "Question 2",
    "text": "Question 2\nTo implement a linear regression model, we will be using a toy dataset to ensure we’ve implemented the model correctly. To begin with this lab, we will want to download the boston dataset from https://www.cs.toronto.edu/~delve/data/boston/bostonDetail.html. Download and save the dataset exactly as it is, and save it as a CSV.\nAfter we’ve downloaded the CSV file, we will want to parse and load the data into a pandas DataFrame.\nCreate a load_boston_data(filepath: str) -&gt; pd.DataFrame function.\nThis may require iterating through each line in the file until you read the data, at this point you will need to parse the data. Finally, return the data as a dataframe."
  },
  {
    "objectID": "lab-1-reveal.html#question-3",
    "href": "lab-1-reveal.html#question-3",
    "title": "Linear Models",
    "section": "Question 3",
    "text": "Question 3\nVisualise some scatter plots of the columns of your choice against the target house price column (i.e. the column of your choice will be on the x-axis, will house price will be the y-axis).\nDecide what you think will be the singular best column to use for using a linear model to predict the house price.\nWhat is this column?"
  },
  {
    "objectID": "lab-1-reveal.html#question-4",
    "href": "lab-1-reveal.html#question-4",
    "title": "Linear Models",
    "section": "Question 4",
    "text": "Question 4\nCreate a function called lm, that takes an x, and y, and returns the random m and b variables in the linear equation:\n\\[\ny = m x + b\n\\]\ndef lm(x, y) -&gt; tuple[float, float]:\n    # create random m, b\n    return m, b"
  },
  {
    "objectID": "lab-1-reveal.html#question-5",
    "href": "lab-1-reveal.html#question-5",
    "title": "Linear Models",
    "section": "Question 5",
    "text": "Question 5\nUsing these m, b variables, create a housing price prediction for each row of data."
  },
  {
    "objectID": "lab-1-reveal.html#question-6",
    "href": "lab-1-reveal.html#question-6",
    "title": "Linear Models",
    "section": "Question 6",
    "text": "Question 6\nCreate a function mae that calculate the mean absolute error of the true house price value and the predicted value. What is the error?\ndef mae(y, y_pred) -&gt; float:\n    # calculate the mean absolute error\n    return error"
  },
  {
    "objectID": "lab-1-reveal.html#question-7",
    "href": "lab-1-reveal.html#question-7",
    "title": "Linear Models",
    "section": "Question 7",
    "text": "Question 7\nVisualise the linear model returned from lm on top of the scatter plot of the input and target data."
  },
  {
    "objectID": "lab-1-reveal.html#question-8",
    "href": "lab-1-reveal.html#question-8",
    "title": "Linear Models",
    "section": "Question 8",
    "text": "Question 8\nRe-make the lm function. This time, when called with an x, y it returns the optimal m and b.\nYou are free to either implement least-squares regression, or the gradient descent method.\ndef lm(x, y) -&gt; tuple[float, float]:\n    # create the optimal values for m, b\n    return m, b"
  },
  {
    "objectID": "lab-1-reveal.html#question-9",
    "href": "lab-1-reveal.html#question-9",
    "title": "Linear Models",
    "section": "Question 9",
    "text": "Question 9\nRe-plot this linear model against the scatter plot."
  },
  {
    "objectID": "lab-1-reveal.html#question-10",
    "href": "lab-1-reveal.html#question-10",
    "title": "Linear Models",
    "section": "Question 10",
    "text": "Question 10\nRe-calculate the mean absolute error for these optimal m, b variables. What is the error now?"
  },
  {
    "objectID": "lab-1.html",
    "href": "lab-1.html",
    "title": "Linear Models",
    "section": "",
    "text": "Welcome to the first Machine Learning lab session! For this first session, we will be implementing and using linear models. In the following session we will be answering the questions below, of which will be marked using the marking criteria on the last page.\n\n\nIn these lab sessions we will implement what we’ve learn during the theory lectures. These implementation will need to be using the Python Programming Language. You’re allowed to use 3rd party libraries such as pandas, matplotlib, numpy. But it is not allowed to use a library that implements exactly machine learning model we’re learning about. For example, in this lab, we’re learning about linear models, so you cannot use a library that provides functionality for computing a linear model. If you’re uncertain about whether a library can be used, please do ask!\nI am going to give you the maximum flexibility with how you want to program these linear models: you can create a Python script, or if you like, you can use jupyter notebooks. In both cases, You should preface your implementation with which question you’re answering with a comment (if you’re writing a python script), or markdown (if you want to use jupyter) like this:\n# Q1. Download, parse, and load the data into a pandas dataframe,\n# print the first 5 rows to ensure the data is formated correctly\nimport pandas as pd\n\ndef load_data(filepath: str) -&gt; pd.DataFrame:\n    # load_data logic\n    return df\nYou are to work individually.\nIn summary:\n\nWork individually.\nImplementation should be using the Python programming language.\nYou can use supplementary libraries such as pandas, matplotlib, numpy, but cannot use a library that provides a function call for the assignment.\n\n\n\n\nTo hand in your assignment, please zip all of your source code (do not include the data) into a zip-archive named using the following format:\n&lt;first-name&gt;-&lt;surname&gt;-machine-learning-lab-1.zip\nreplacing &lt;first-name&gt; and &lt;surname&gt; with your name. Please send this assignment to my email address: jay.morgan@univ-tln.fr using the subject Machine Learning Assignment 1 by the end of the lab session. I will accept late assignments, but will be deducted score accordingly."
  },
  {
    "objectID": "lab-1.html#how-to-answer-the-questions",
    "href": "lab-1.html#how-to-answer-the-questions",
    "title": "Linear Models",
    "section": "",
    "text": "In these lab sessions we will implement what we’ve learn during the theory lectures. These implementation will need to be using the Python Programming Language. You’re allowed to use 3rd party libraries such as pandas, matplotlib, numpy. But it is not allowed to use a library that implements exactly machine learning model we’re learning about. For example, in this lab, we’re learning about linear models, so you cannot use a library that provides functionality for computing a linear model. If you’re uncertain about whether a library can be used, please do ask!\nI am going to give you the maximum flexibility with how you want to program these linear models: you can create a Python script, or if you like, you can use jupyter notebooks. In both cases, You should preface your implementation with which question you’re answering with a comment (if you’re writing a python script), or markdown (if you want to use jupyter) like this:\n# Q1. Download, parse, and load the data into a pandas dataframe,\n# print the first 5 rows to ensure the data is formated correctly\nimport pandas as pd\n\ndef load_data(filepath: str) -&gt; pd.DataFrame:\n    # load_data logic\n    return df\nYou are to work individually.\nIn summary:\n\nWork individually.\nImplementation should be using the Python programming language.\nYou can use supplementary libraries such as pandas, matplotlib, numpy, but cannot use a library that provides a function call for the assignment."
  },
  {
    "objectID": "lab-1.html#submission-procedure",
    "href": "lab-1.html#submission-procedure",
    "title": "Linear Models",
    "section": "",
    "text": "To hand in your assignment, please zip all of your source code (do not include the data) into a zip-archive named using the following format:\n&lt;first-name&gt;-&lt;surname&gt;-machine-learning-lab-1.zip\nreplacing &lt;first-name&gt; and &lt;surname&gt; with your name. Please send this assignment to my email address: jay.morgan@univ-tln.fr using the subject Machine Learning Assignment 1 by the end of the lab session. I will accept late assignments, but will be deducted score accordingly."
  },
  {
    "objectID": "lab-1.html#question-1",
    "href": "lab-1.html#question-1",
    "title": "Linear Models",
    "section": "Question 1",
    "text": "Question 1\nTo start this lab session we want to setup our project. For this question, do the following:\n\nCreate a new directory for this lab.\nCreate a new conda environment.\nIn this new conda environment, install python, pandas, matplotlib, and numpy.\nExport this conda environment to an environment.yml into the root of the directory."
  },
  {
    "objectID": "lab-1.html#question-2",
    "href": "lab-1.html#question-2",
    "title": "Linear Models",
    "section": "Question 2",
    "text": "Question 2\nTo implement a linear regression model, we will be using a toy dataset to ensure we’ve implemented the model correctly. To begin with this lab, we will want to download the boston dataset from https://www.cs.toronto.edu/~delve/data/boston/bostonDetail.html. Download and save the dataset exactly as it is, and save it as a CSV.\nAfter we’ve downloaded the CSV file, we will want to parse and load the data into a pandas DataFrame.\nCreate a load_boston_data(filepath: str) -&gt; pd.DataFrame function.\nThis may require iterating through each line in the file until you read the data, at this point you will need to parse the data. Finally, return the data as a dataframe."
  },
  {
    "objectID": "lab-1.html#question-3",
    "href": "lab-1.html#question-3",
    "title": "Linear Models",
    "section": "Question 3",
    "text": "Question 3\nVisualise some scatter plots of the columns of your choice against the target house price column (i.e. the column of your choice will be on the x-axis, will house price will be the y-axis).\nDecide what you think will be the singular best column to use for using a linear model to predict the house price.\nWhat is this column?"
  },
  {
    "objectID": "lab-1.html#question-4",
    "href": "lab-1.html#question-4",
    "title": "Linear Models",
    "section": "Question 4",
    "text": "Question 4\nCreate a function called lm, that takes an x, and y, and returns the random m and b variables in the linear equation:\n\\[\ny = m x + b\n\\]\ndef lm(x, y) -&gt; tuple[float, float]:\n    # create random m, b\n    return m, b"
  },
  {
    "objectID": "lab-1.html#question-5",
    "href": "lab-1.html#question-5",
    "title": "Linear Models",
    "section": "Question 5",
    "text": "Question 5\nUsing these m, b variables, create a housing price prediction for each row of data."
  },
  {
    "objectID": "lab-1.html#question-6",
    "href": "lab-1.html#question-6",
    "title": "Linear Models",
    "section": "Question 6",
    "text": "Question 6\nCreate a function mae that calculate the mean absolute error of the true house price value and the predicted value. What is the error?\ndef mae(y, y_pred) -&gt; float:\n    # calculate the mean absolute error\n    return error"
  },
  {
    "objectID": "lab-1.html#question-7",
    "href": "lab-1.html#question-7",
    "title": "Linear Models",
    "section": "Question 7",
    "text": "Question 7\nVisualise the linear model returned from lm on top of the scatter plot of the input and target data."
  },
  {
    "objectID": "lab-1.html#question-8",
    "href": "lab-1.html#question-8",
    "title": "Linear Models",
    "section": "Question 8",
    "text": "Question 8\nRe-make the lm function. This time, when called with an x, y it returns the optimal m and b.\nYou are free to either implement least-squares regression, or the gradient descent method.\ndef lm(x, y) -&gt; tuple[float, float]:\n    # create the optimal values for m, b\n    return m, b"
  },
  {
    "objectID": "lab-1.html#question-9",
    "href": "lab-1.html#question-9",
    "title": "Linear Models",
    "section": "Question 9",
    "text": "Question 9\nRe-plot this linear model against the scatter plot."
  },
  {
    "objectID": "lab-1.html#question-10",
    "href": "lab-1.html#question-10",
    "title": "Linear Models",
    "section": "Question 10",
    "text": "Question 10\nRe-calculate the mean absolute error for these optimal m, b variables. What is the error now?"
  },
  {
    "objectID": "lab-3.html",
    "href": "lab-3.html",
    "title": "K-Nereast Neighbours",
    "section": "",
    "text": "In this lab, we’re going to create a K-Nearest Neighbour (KNN) classifier. This lab is optional, and will not be marked.\n\nDownload the Data\nIn creating the KNN, we’ll use another toy dataset, the wine quality dataset https://archive.ics.uci.edu/dataset/186/wine+quality. Specifically, the red wine.\nTo get access to the dataset, click on the download button. Inside the now downloaded folder, there will be two CSV files, one for red wine, and another for white wine. For this lab, we’ll be using the red wine dataset.\n\n\nLoad the Data\nThe next task is to load the data in Python. For this section, we’ll want to write some code to load the red wine CSV file as a pandas dataframe.\n\n\nSplit the data\nNow that we’ve loaded the data as a pandas dataframe, we’ll partition the data off into a train and test subset.\nRandomly sample 70% of the data for training, and the other 30% will be used for testing.\n\n\nNormalise the data\nTo ensure all of the columns are within the same range, we’ll normalise them (except from the score column of course!).\nWe can normalise a column \\(x\\) by the following equation:\n\\[\n\\text{normalise}(x) = \\frac{x - \\min_x}{\\max_x - \\min_x}\n\\]\nTherefore, we’ll need to calculate the \\(\\min\\) and \\(\\max\\) values of each column in the training subset, then apply the normalising function, using these values.\n\n\nLooking at the correlations\nUsing the training subset, we’ll want to find out which columns to use in our classifier.\nWe’ll visually inspect the correlations between the input columns and the target score column.\nCreate a series of 2D scatter plots with an input column across the \\(x\\)-axis, and the target score column across the \\(y\\)-axis.\nWhich of these columns show a strong relationship between the input and target columns?\n\n\nCreate a K-Nearest Neighbour\nCreate a KNN classifier and \\(k=3\\), using some of the input colums (the best ones as decided by the correlation plots).\n\n\nCreate Classification performance metrics\nCreate a series of classification metrics for the new KNN classifier:\n\n\\(F_1\\) score (averaged over all classes)\nPlot a confusion matrix.\n\n\n\nPlot performance metrics for different \\(k\\)\nUsing the KNN classifier, modify the \\(k\\) value from 1 to \\(N\\) and plot the \\(F_1\\) score for each value of \\(k\\). What is the optimal value for \\(k\\)?"
  },
  {
    "objectID": "lecture-2-reveal.html#linear-models",
    "href": "lecture-2-reveal.html#linear-models",
    "title": "Linear Models",
    "section": "Linear models",
    "text": "Linear models\nHaving learnt a little about what it means to learn, we’re going to look at our first Machine Learning algorithm, the staple for much of statistics, numeric prediction using a linear model."
  },
  {
    "objectID": "lecture-2-reveal.html#what-is-a-linear-model",
    "href": "lecture-2-reveal.html#what-is-a-linear-model",
    "title": "Linear Models",
    "section": "What is a linear model?",
    "text": "What is a linear model?\nA linear model is a prediction (a response) to an input variable. We have the following terms:\n\nResponse/prediction/dependant – the output of the model.\nfeature/variable/independant variable – the variable upon which the prediction is being made.\n\nFor a linear model based on one independant we have the following:\n\\[\ny = \\beta_0 + \\beta_1 x\n\\]\nwhere \\(y\\) is the response/output/prediction of the model, \\(x\\) is the independant variable, and \\(\\beta_0, \\beta_1\\) are the model parameters."
  },
  {
    "objectID": "lecture-2-reveal.html#slope-intercept",
    "href": "lecture-2-reveal.html#slope-intercept",
    "title": "Linear Models",
    "section": "Slope & intercept",
    "text": "Slope & intercept\nIf we look at our linear model equation, we’ll notice that it’s the same equation for a straight line.\n\nAs we’ve seen, the linear model, or linear regression, has two parameters: \\(\\beta_1, \\beta_0\\). What do these parameters represent?\n\nThe \\(\\beta_1\\) parameter is the slope or strength of relationship between the independant variable and the response.\nMeanwhile, the \\(\\beta_0\\) parameter is called the intercept, as it’s the value of the response when the independant variable is zero.\n\nLet’s look at these two parameters.\n\nHere we see that when \\(\\beta_1\\) is 0 (left figure), any change in \\(x\\) results in 0 change in \\(y\\). While, with \\(\\beta_1 = 2\\), \\(y\\) increases two-fold by every change in \\(x\\). Finally, when the slope is negative, we see that \\(y\\) decreases.\nNotice how the line is at 5 when \\(x\\) is zero, this is because \\(\\beta_0 = 5\\)."
  },
  {
    "objectID": "lecture-2-reveal.html#multiple-variables",
    "href": "lecture-2-reveal.html#multiple-variables",
    "title": "Linear Models",
    "section": "Multiple variables",
    "text": "Multiple variables\nSo we’ve seen how we can take an input variable x, and through the combination multiplication and addition with the learnt \\(\\beta_0, \\beta_1\\) values, we can create a pretty accurate prediction.\nHowever, this was only for a singular variable.\nIn our dataset, we have many variables/features/columns that we may want to use for our prediction. It may be possible to get an even more accurate prediction by adding features to our linear regression model.\n\\[\ny = \\beta_0 + \\sum_{i=1}^m x_i \\beta_i\n\\]\nwhere \\(m\\) is the number of features/variables we’re adding to the model."
  },
  {
    "objectID": "lecture-2-reveal.html#supporting-example",
    "href": "lecture-2-reveal.html#supporting-example",
    "title": "Linear Models",
    "section": "Supporting example",
    "text": "Supporting example\nLet’s have a look at how we would use this linear model with one of the datasets: The Boston housing prices."
  },
  {
    "objectID": "lecture-2-reveal.html#lets-fit-a-linear-model",
    "href": "lecture-2-reveal.html#lets-fit-a-linear-model",
    "title": "Linear Models",
    "section": "Let’s fit a linear model",
    "text": "Let’s fit a linear model\nWe have seen that there seems to be some correlation between the number of rooms and the house price. I.e. we can use the number of rooms of the house to get the estimated price. To get an estimated price we’ll use our linear model:\n\\[\ny = \\beta_0+\\beta_1 x\n\\]\nIn this case, \\(x\\) will be the number of rooms. But what values should we set for \\(\\beta_0\\) and \\(\\beta_1\\)? Or put another way, what is optimal value for our model parameters.\nWe’ll return to the question of optimal later, but for now, let’s just select some random values!\n\\[\\begin{aligned}\n\\beta_0 = 1 \\\\\n\\beta_1 = 1\n\\end{aligned}\n\\]\n\nWell that doesn’t look very good, it could be ‘fit’ better to what we’re seeing in the scatter plot! I wonder how wrong the linear model is – how incorrect our predicted house prices are?"
  },
  {
    "objectID": "lecture-2-reveal.html#evaluating-our-initial-linear-model",
    "href": "lecture-2-reveal.html#evaluating-our-initial-linear-model",
    "title": "Linear Models",
    "section": "Evaluating our initial linear model",
    "text": "Evaluating our initial linear model\nTo evaluate how well, or in this case, how badly our linear model is doing, let’s compare the predicted value from the model against the actual house price. For example, we’ll take a single sample from our dataset.\nIf we have 4 rooms, our model estimates the house price to be \\(2(4) + 5 = 13\\), $13,000, but the actual cost was $24,000. This means we have underestimated the cost by $11,000.\nWhat we’ve done there is the following:\n\\[\n\\delta = | y - \\hat{y} |\n\\]\nwhere \\(\\hat{y}\\) is \\(\\beta_0 + \\beta_1 x\\)\nWe’ve calculated the difference or delta between the real house price \\(y\\) and the predicted house price.\nThat gives us the error for one sample though, what about for the whole dataset? Well we could take the mean over all samples:\n\\[\n\\text{MAE}(X; \\beta_0,\\beta_1) = \\frac{1}{N}\\sum_{i=0}^N | y_i - (\\beta_0+\\beta_1x_i) |\n\\]\nIf we calculate that our linear model we see that the average difference between our estimated value and real value is $15,000!\nAnother common method of calculating how well or how badly our model is performing is to use the sum of squared residuals or perhaps more commonly known in the field of machine learning: mean squared error (MSE).\n\\[\n\\text{MSE}(X; \\beta_0, \\beta_1) = \\frac{1}{N}\\sum_{i=0}^N (y - (\\beta_0 + \\beta_1 x_i))^2\n\\]"
  },
  {
    "objectID": "lecture-2-reveal.html#getting-better-model-parameters",
    "href": "lecture-2-reveal.html#getting-better-model-parameters",
    "title": "Linear Models",
    "section": "Getting better model parameters",
    "text": "Getting better model parameters\nOkay, so we made our initial guess at the model parameters (random values for \\(\\beta_0, \\beta_1\\)), and these weren’t very good. We were incorrectly guessing the house value by $15,000. So how do we get better values?\nWell if we visualise how badly we do vs the value for \\(\\beta_1\\) we get the following:\n\nIn figure 44, we see that as we change the \\(\\beta_1\\) parameter, the mean absolute error (MAE), i.e. the average difference between the predicted house prices and the true house prices, changes. Ideally, we would like the error or loss to be as low as possible. In this case, when \\(\\beta_0 = 1\\) the lowest possible loss we can hope to achieve with the linear model is ~ $5,500.\nBut what value for \\(\\beta_1\\) gets us this lowest value for the loss? Looking at the graph, we see that the lowest point on the loss curve is somewhere between 0 and 5. Maybe even 4? While we could look at the curve and pick these parameter values, we’re going to use a better method – one that give us an optimal value for this loss curve automatically.\nWe’re going to look at the method called Gradient Descent.\nIf we visualise our loss curve again, and visualise where \\(\\beta_1 = 1\\) is on this curve, we will see:\n\nSo we want this rot dot to move down the loss curve and reach the bottom of the curve. Using the Gradient Descent algorithm, we’re going to take very small steps down the loss curve.\n\nTo determine which way is up, and which way is down the curve, we use the Gradient of the curve (hence Gradient Descent). We compute the gradient using finite differences method:\n\\[\n\\Delta = \\frac{f(x+h) - f(x)}{h}\n\\]\nwhere \\(f(x)\\) is the loss when \\(\\beta_1\\) takes on the value of \\(x\\). \\(h\\) is a very small value.\n\nIf we select \\(h = 0.5\\) then we will have the formula:\n\\[\n\\Delta_{\\beta_1} = \\frac{L(\\beta_1 + 0.5) - L(\\beta_1)}{\\beta_1}\n\\]\nwhere \\(L\\) represents our loss function, MAE. If we calculate this we have:\n\\[\\begin{aligned}\n\\Delta_{\\beta_1} &= \\frac{L(\\beta_1 + 0.5) - L(\\beta_1)}{h} \\\\\n&= \\frac{L(1.5)- L(1)}{0.5} \\\\\n&= \\frac{12 - 15}{0.5} \\\\\n&= -6.0\n\\end{aligned}\n\\]\nGiven that the gradient is a negative number, we know that the curve is going down/decreasing. So we will want to move \\(\\beta_1\\) in this direction – we want to move \\(\\beta_1\\) so that the loss decreases.\n\\[\n\\overline{\\beta_1} = \\beta_1 - \\eta \\Delta_{\\beta_1}\n\\]\nIf we plug in the numbers we’ve calculated for when \\(\\beta_1 = 1\\) we get and \\(eta = 0.5\\):\n\\[\\begin{aligned}\n\\overline{\\beta_1} &= \\beta_1 - \\eta \\Delta_{\\beta_1} \\\\\n&= 1.0 - (0.5 * -6.0) \\\\\n&= 1.0 - (-3.0) \\\\\n&= 4.0\n\\end{aligned}\n\\]\nOur new value for the \\(\\beta_1\\) parameter (\\(\\overline{\\beta_1}\\)) is computed by taking its original value and subtracting the gradient modulated/multiplied by \\(\\eta\\). \\(\\eta\\) in this case is what will allow us to take our small steps. It is important to set \\(\\eta\\) to a suitably small value, as high values for \\(\\eta\\) will cause the Gradient Descent to behave erratically, and even, make our loss worse!\n\nIn figure 65, we’ve varied the value of \\(\\eta\\) and computed 10 steps of updating the \\(\\beta_1\\) parameter in our linear model. When \\(\\eta=0.05\\), we see that \\(\\beta_1\\) is slowly being updated in a way that is causing our loss to decrease, but it is more so slowly that we don’t reach the optimal value for \\(\\beta_1\\). When \\(\\eta=3\\), each change in \\(\\beta_1\\) is too large, so we over-shoot the optimal value, and end up bouncing back and forth without ever improving. Finally, when we set \\(\\eta=0.3\\), the changes in \\(\\beta_1\\) are sufficiently large enough such that we reach the global minima in time, but they are also small enough so that we don’t over-shoot this same minimum.\nIf we then apply the Gradient Descent algorithm to both parameters of the linear model \\(\\beta_0, \\beta_1\\), then we can find the optimal trend line for this data. Furthermore, visualising this will look something like figure 68."
  },
  {
    "objectID": "lecture-2-reveal.html#solving-the-linear-model-directly",
    "href": "lecture-2-reveal.html#solving-the-linear-model-directly",
    "title": "Linear Models",
    "section": "Solving the linear model directly",
    "text": "Solving the linear model directly\nThe way we’ve trained our linear regression is not necessarily the best, yes it does help us understand how we can optimise to a solution (especially if not all of our data can fit into memory at the same time). But, when it comes to linear models, we can compute the values for \\(\\beta_0, \\beta_1\\) directly.\nThis is called a closed-form solution.\n\\[\n\\beta_1 = \\frac{N \\sum xy - \\sum x \\sum y}{N \\sum (x^2) - \\sum (x)^2}\n\\]\n\\[\n\\beta_0 = \\frac{\\sum y - \\beta_1 \\sum x}{N}\n\\]\nwhere \\(N\\) is the number of samples in our data."
  },
  {
    "objectID": "lecture-2-reveal.html#moving-from-regression-to-classification",
    "href": "lecture-2-reveal.html#moving-from-regression-to-classification",
    "title": "Linear Models",
    "section": "Moving from regression to classification",
    "text": "Moving from regression to classification\nWe now turn to the problem of classification. We have seen in some of our toy datasets (namely the Iris dataset), that we don’t want to predict a continuous value, but rather predict the class each data point belongs to.\nTo predict the class, we use a model called a logistic regressor.\nA logistic regressor is a model from the class of `Generalised Linear Models’ (GLM). In fact, the linear regressor we investigated in the previous section is also part of this class of models."
  },
  {
    "objectID": "lecture-2-reveal.html#multi-class-vs-binary-classification",
    "href": "lecture-2-reveal.html#multi-class-vs-binary-classification",
    "title": "Linear Models",
    "section": "Multi-class vs binary classification",
    "text": "Multi-class vs binary classification\n\nIn terms of Iris dataset, this means we want to select one class from 3 possible classes.\nWe’ll return to the problem of multiple classes later. But let’s suppose that we only want to decide if the flower is a Setosa, or not Setosa. We’ve changed our classification problem from multi-class to binary classification."
  },
  {
    "objectID": "lecture-2-reveal.html#probability-likelihood-1",
    "href": "lecture-2-reveal.html#probability-likelihood-1",
    "title": "Linear Models",
    "section": "Probability likelihood",
    "text": "Probability likelihood\n\nOur model will eventually look like this, where we have two classes of points, and for each point we give a probability (p) that our point belongs to a class."
  },
  {
    "objectID": "lecture-2-reveal.html#making-it-linear",
    "href": "lecture-2-reveal.html#making-it-linear",
    "title": "Linear Models",
    "section": "Making it linear",
    "text": "Making it linear\nIf we apply the logarithm to each probability, we get back to our linear line.\n\n\\[\n\\log \\left( \\frac{p}{1-p} \\right)\n\\]"
  },
  {
    "objectID": "lecture-2-reveal.html#enter-the-maximum-likelihood",
    "href": "lecture-2-reveal.html#enter-the-maximum-likelihood",
    "title": "Linear Models",
    "section": "Enter the maximum likelihood",
    "text": "Enter the maximum likelihood\nBut there is a problem…we can no longer use the sum of residuals as the value would always be \\(\\infty\\), but instead we can use the maximum likelihood. First we project each sample to its ‘odds’ (i.e. the value of \\(y\\) on the linear line)."
  },
  {
    "objectID": "lecture-2-reveal.html#back-to-the-probability-curve",
    "href": "lecture-2-reveal.html#back-to-the-probability-curve",
    "title": "Linear Models",
    "section": "Back to the probability curve",
    "text": "Back to the probability curve\n\nOur logistic or ‘sigmoid’ function:\n\\[\np = \\frac{1}{1 + e^{-(\\beta_0+\\beta_1x)}} = \\frac{e^{(\\beta_0+\\beta_1x)}}{1 + e^{(\\beta_0+\\beta_1x)}}\n\\]"
  },
  {
    "objectID": "lecture-2-reveal.html#likelihood",
    "href": "lecture-2-reveal.html#likelihood",
    "title": "Linear Models",
    "section": "Likelihood",
    "text": "Likelihood\nProbability of class 1\n\\[\np(1) = p\n\\]\nProbability of class 0 (or not class 1).\n\\[\np(0) = 1 - p\n\\]\nMaximum likelihood loss (which we wish to maximise), using the points on the probability curve:\n\\[ L = (0.9) + (0.89) + (0.6) + (1 - 0.4) + (1 - 0.2) + (1 - 0.05)\n\\]"
  },
  {
    "objectID": "lecture-2-reveal.html#optimising-the-curve",
    "href": "lecture-2-reveal.html#optimising-the-curve",
    "title": "Linear Models",
    "section": "Optimising the curve",
    "text": "Optimising the curve"
  },
  {
    "objectID": "lecture-2-reveal.html#binary-cross-entropy-1",
    "href": "lecture-2-reveal.html#binary-cross-entropy-1",
    "title": "Linear Models",
    "section": "Binary Cross-Entropy",
    "text": "Binary Cross-Entropy\nWe could still use MSE in order to compute our models loss. This may still work. But there is another objective function that we would use for binary classification problems: Binary Cross-entropy (BCE).\n\\[\n\\text{BCE}(X; \\beta_0, \\beta_1) = -(Y \\log(\\beta_0+\\beta_1*X) + (1 - Y) \\log(1- \\beta_0+\\beta_1*X))\n\\]\nIssues when using MSE for binary classification:\n\nMSE is non-convex for binary classification problems.\nMSE assumes the data was generated from a normal distribution, while binary classification problems form a Bernoulli distribution."
  },
  {
    "objectID": "lecture-2.html",
    "href": "lecture-2.html",
    "title": "Linear Models",
    "section": "",
    "text": "Having learnt a little about what it means to learn, we’re going to look at our first Machine Learning algorithm, the staple for much of statistics, numeric prediction using a linear model.\n\n\n\nA linear model is a prediction (a response) to an input variable. We have the following terms:\n\nResponse/prediction/dependant – the output of the model.\nfeature/variable/independant variable – the variable upon which the prediction is being made.\n\nFor a linear model based on one independant we have the following:\n\\[\ny = \\beta_0 + \\beta_1 x\n\\]\nwhere \\(y\\) is the response/output/prediction of the model, \\(x\\) is the independant variable, and \\(\\beta_0, \\beta_1\\) are the model parameters."
  },
  {
    "objectID": "lecture-2.html#linear-models",
    "href": "lecture-2.html#linear-models",
    "title": "Linear Models",
    "section": "",
    "text": "Having learnt a little about what it means to learn, we’re going to look at our first Machine Learning algorithm, the staple for much of statistics, numeric prediction using a linear model."
  },
  {
    "objectID": "lecture-2.html#what-is-a-linear-model",
    "href": "lecture-2.html#what-is-a-linear-model",
    "title": "Linear Models",
    "section": "",
    "text": "A linear model is a prediction (a response) to an input variable. We have the following terms:\n\nResponse/prediction/dependant – the output of the model.\nfeature/variable/independant variable – the variable upon which the prediction is being made.\n\nFor a linear model based on one independant we have the following:\n\\[\ny = \\beta_0 + \\beta_1 x\n\\]\nwhere \\(y\\) is the response/output/prediction of the model, \\(x\\) is the independant variable, and \\(\\beta_0, \\beta_1\\) are the model parameters."
  },
  {
    "objectID": "lecture-2.html#slope-intercept",
    "href": "lecture-2.html#slope-intercept",
    "title": "Linear Models",
    "section": "Slope & intercept",
    "text": "Slope & intercept\nIf we look at our linear model equation, we’ll notice that it’s the same equation for a straight line.\n\nAs we’ve seen, the linear model, or linear regression, has two parameters: \\(\\beta_1, \\beta_0\\). What do these parameters represent?\n\nThe \\(\\beta_1\\) parameter is the slope or strength of relationship between the independant variable and the response.\nMeanwhile, the \\(\\beta_0\\) parameter is called the intercept, as it’s the value of the response when the independant variable is zero.\n\nLet’s look at these two parameters.\n\nHere we see that when \\(\\beta_1\\) is 0 (left figure), any change in \\(x\\) results in 0 change in \\(y\\). While, with \\(\\beta_1 = 2\\), \\(y\\) increases two-fold by every change in \\(x\\). Finally, when the slope is negative, we see that \\(y\\) decreases.\nNotice how the line is at 5 when \\(x\\) is zero, this is because \\(\\beta_0 = 5\\)."
  },
  {
    "objectID": "lecture-2.html#multiple-variables",
    "href": "lecture-2.html#multiple-variables",
    "title": "Linear Models",
    "section": "Multiple variables",
    "text": "Multiple variables\nSo we’ve seen how we can take an input variable x, and through the combination multiplication and addition with the learnt \\(\\beta_0, \\beta_1\\) values, we can create a pretty accurate prediction.\nHowever, this was only for a singular variable.\nIn our dataset, we have many variables/features/columns that we may want to use for our prediction. It may be possible to get an even more accurate prediction by adding features to our linear regression model.\n\\[\ny = \\beta_0 + \\sum_{i=1}^m x_i \\beta_i\n\\]\nwhere \\(m\\) is the number of features/variables we’re adding to the model."
  },
  {
    "objectID": "lecture-2.html#supporting-example",
    "href": "lecture-2.html#supporting-example",
    "title": "Linear Models",
    "section": "Supporting example",
    "text": "Supporting example\nLet’s have a look at how we would use this linear model with one of the datasets: The Boston housing prices."
  },
  {
    "objectID": "lecture-2.html#lets-fit-a-linear-model",
    "href": "lecture-2.html#lets-fit-a-linear-model",
    "title": "Linear Models",
    "section": "Let’s fit a linear model",
    "text": "Let’s fit a linear model\nWe have seen that there seems to be some correlation between the number of rooms and the house price. I.e. we can use the number of rooms of the house to get the estimated price. To get an estimated price we’ll use our linear model:\n\\[\ny = \\beta_0+\\beta_1 x\n\\]\nIn this case, \\(x\\) will be the number of rooms. But what values should we set for \\(\\beta_0\\) and \\(\\beta_1\\)? Or put another way, what is optimal value for our model parameters.\nWe’ll return to the question of optimal later, but for now, let’s just select some random values!\n\\[\\begin{aligned}\n\\beta_0 = 1 \\\\\n\\beta_1 = 1\n\\end{aligned}\n\\]\n\nWell that doesn’t look very good, it could be ‘fit’ better to what we’re seeing in the scatter plot! I wonder how wrong the linear model is – how incorrect our predicted house prices are?"
  },
  {
    "objectID": "lecture-2.html#evaluating-our-initial-linear-model",
    "href": "lecture-2.html#evaluating-our-initial-linear-model",
    "title": "Linear Models",
    "section": "Evaluating our initial linear model",
    "text": "Evaluating our initial linear model\nTo evaluate how well, or in this case, how badly our linear model is doing, let’s compare the predicted value from the model against the actual house price. For example, we’ll take a single sample from our dataset.\nIf we have 4 rooms, our model estimates the house price to be \\(2(4) + 5 = 13\\), $13,000, but the actual cost was $24,000. This means we have underestimated the cost by $11,000.\nWhat we’ve done there is the following:\n\\[\n\\delta = | y - \\hat{y} |\n\\]\nwhere \\(\\hat{y}\\) is \\(\\beta_0 + \\beta_1 x\\)\nWe’ve calculated the difference or delta between the real house price \\(y\\) and the predicted house price.\nThat gives us the error for one sample though, what about for the whole dataset? Well we could take the mean over all samples:\n\\[\n\\text{MAE}(X; \\beta_0,\\beta_1) = \\frac{1}{N}\\sum_{i=0}^N | y_i - (\\beta_0+\\beta_1x_i) |\n\\]\nIf we calculate that our linear model we see that the average difference between our estimated value and real value is $15,000!\nAnother common method of calculating how well or how badly our model is performing is to use the sum of squared residuals or perhaps more commonly known in the field of machine learning: mean squared error (MSE).\n\\[\n\\text{MSE}(X; \\beta_0, \\beta_1) = \\frac{1}{N}\\sum_{i=0}^N (y - (\\beta_0 + \\beta_1 x_i))^2\n\\]"
  },
  {
    "objectID": "lecture-2.html#getting-better-model-parameters",
    "href": "lecture-2.html#getting-better-model-parameters",
    "title": "Linear Models",
    "section": "Getting better model parameters",
    "text": "Getting better model parameters\nOkay, so we made our initial guess at the model parameters (random values for \\(\\beta_0, \\beta_1\\)), and these weren’t very good. We were incorrectly guessing the house value by $15,000. So how do we get better values?\nWell if we visualise how badly we do vs the value for \\(\\beta_1\\) we get the following:\n\nIn figure 44, we see that as we change the \\(\\beta_1\\) parameter, the mean absolute error (MAE), i.e. the average difference between the predicted house prices and the true house prices, changes. Ideally, we would like the error or loss to be as low as possible. In this case, when \\(\\beta_0 = 1\\) the lowest possible loss we can hope to achieve with the linear model is ~ $5,500.\nBut what value for \\(\\beta_1\\) gets us this lowest value for the loss? Looking at the graph, we see that the lowest point on the loss curve is somewhere between 0 and 5. Maybe even 4? While we could look at the curve and pick these parameter values, we’re going to use a better method – one that give us an optimal value for this loss curve automatically.\nWe’re going to look at the method called Gradient Descent.\nIf we visualise our loss curve again, and visualise where \\(\\beta_1 = 1\\) is on this curve, we will see:\n\nSo we want this rot dot to move down the loss curve and reach the bottom of the curve. Using the Gradient Descent algorithm, we’re going to take very small steps down the loss curve.\n\nTo determine which way is up, and which way is down the curve, we use the Gradient of the curve (hence Gradient Descent). We compute the gradient using finite differences method:\n\\[\n\\Delta = \\frac{f(x+h) - f(x)}{h}\n\\]\nwhere \\(f(x)\\) is the loss when \\(\\beta_1\\) takes on the value of \\(x\\). \\(h\\) is a very small value.\n\nIf we select \\(h = 0.5\\) then we will have the formula:\n\\[\n\\Delta_{\\beta_1} = \\frac{L(\\beta_1 + 0.5) - L(\\beta_1)}{\\beta_1}\n\\]\nwhere \\(L\\) represents our loss function, MAE. If we calculate this we have:\n\\[\\begin{aligned}\n\\Delta_{\\beta_1} &= \\frac{L(\\beta_1 + 0.5) - L(\\beta_1)}{h} \\\\\n&= \\frac{L(1.5)- L(1)}{0.5} \\\\\n&= \\frac{12 - 15}{0.5} \\\\\n&= -6.0\n\\end{aligned}\n\\]\nGiven that the gradient is a negative number, we know that the curve is going down/decreasing. So we will want to move \\(\\beta_1\\) in this direction – we want to move \\(\\beta_1\\) so that the loss decreases.\n\\[\n\\overline{\\beta_1} = \\beta_1 - \\eta \\Delta_{\\beta_1}\n\\]\nIf we plug in the numbers we’ve calculated for when \\(\\beta_1 = 1\\) we get and \\(eta = 0.5\\):\n\\[\\begin{aligned}\n\\overline{\\beta_1} &= \\beta_1 - \\eta \\Delta_{\\beta_1} \\\\\n&= 1.0 - (0.5 * -6.0) \\\\\n&= 1.0 - (-3.0) \\\\\n&= 4.0\n\\end{aligned}\n\\]\nOur new value for the \\(\\beta_1\\) parameter (\\(\\overline{\\beta_1}\\)) is computed by taking its original value and subtracting the gradient modulated/multiplied by \\(\\eta\\). \\(\\eta\\) in this case is what will allow us to take our small steps. It is important to set \\(\\eta\\) to a suitably small value, as high values for \\(\\eta\\) will cause the Gradient Descent to behave erratically, and even, make our loss worse!\n\nIn figure 65, we’ve varied the value of \\(\\eta\\) and computed 10 steps of updating the \\(\\beta_1\\) parameter in our linear model. When \\(\\eta=0.05\\), we see that \\(\\beta_1\\) is slowly being updated in a way that is causing our loss to decrease, but it is more so slowly that we don’t reach the optimal value for \\(\\beta_1\\). When \\(\\eta=3\\), each change in \\(\\beta_1\\) is too large, so we over-shoot the optimal value, and end up bouncing back and forth without ever improving. Finally, when we set \\(\\eta=0.3\\), the changes in \\(\\beta_1\\) are sufficiently large enough such that we reach the global minima in time, but they are also small enough so that we don’t over-shoot this same minimum.\nIf we then apply the Gradient Descent algorithm to both parameters of the linear model \\(\\beta_0, \\beta_1\\), then we can find the optimal trend line for this data. Furthermore, visualising this will look something like figure 68."
  },
  {
    "objectID": "lecture-2.html#solving-the-linear-model-directly",
    "href": "lecture-2.html#solving-the-linear-model-directly",
    "title": "Linear Models",
    "section": "Solving the linear model directly",
    "text": "Solving the linear model directly\nThe way we’ve trained our linear regression is not necessarily the best, yes it does help us understand how we can optimise to a solution (especially if not all of our data can fit into memory at the same time). But, when it comes to linear models, we can compute the values for \\(\\beta_0, \\beta_1\\) directly.\nThis is called a closed-form solution.\n\\[\n\\beta_1 = \\frac{N \\sum xy - \\sum x \\sum y}{N \\sum (x^2) - \\sum (x)^2}\n\\]\n\\[\n\\beta_0 = \\frac{\\sum y - \\beta_1 \\sum x}{N}\n\\]\nwhere \\(N\\) is the number of samples in our data."
  },
  {
    "objectID": "lecture-2.html#moving-from-regression-to-classification",
    "href": "lecture-2.html#moving-from-regression-to-classification",
    "title": "Linear Models",
    "section": "Moving from regression to classification",
    "text": "Moving from regression to classification\nWe now turn to the problem of classification. We have seen in some of our toy datasets (namely the Iris dataset), that we don’t want to predict a continuous value, but rather predict the class each data point belongs to.\nTo predict the class, we use a model called a logistic regressor.\nA logistic regressor is a model from the class of `Generalised Linear Models’ (GLM). In fact, the linear regressor we investigated in the previous section is also part of this class of models."
  },
  {
    "objectID": "lecture-2.html#multi-class-vs-binary-classification",
    "href": "lecture-2.html#multi-class-vs-binary-classification",
    "title": "Linear Models",
    "section": "Multi-class vs binary classification",
    "text": "Multi-class vs binary classification\n\nIn terms of Iris dataset, this means we want to select one class from 3 possible classes.\nWe’ll return to the problem of multiple classes later. But let’s suppose that we only want to decide if the flower is a Setosa, or not Setosa. We’ve changed our classification problem from multi-class to binary classification."
  },
  {
    "objectID": "lecture-2.html#probability-likelihood-1",
    "href": "lecture-2.html#probability-likelihood-1",
    "title": "Linear Models",
    "section": "Probability likelihood",
    "text": "Probability likelihood\n\nOur model will eventually look like this, where we have two classes of points, and for each point we give a probability (p) that our point belongs to a class."
  },
  {
    "objectID": "lecture-2.html#making-it-linear",
    "href": "lecture-2.html#making-it-linear",
    "title": "Linear Models",
    "section": "Making it linear",
    "text": "Making it linear\nIf we apply the logarithm to each probability, we get back to our linear line.\n\n\\[\n\\log \\left( \\frac{p}{1-p} \\right)\n\\]"
  },
  {
    "objectID": "lecture-2.html#enter-the-maximum-likelihood",
    "href": "lecture-2.html#enter-the-maximum-likelihood",
    "title": "Linear Models",
    "section": "Enter the maximum likelihood",
    "text": "Enter the maximum likelihood\nBut there is a problem…we can no longer use the sum of residuals as the value would always be \\(\\infty\\), but instead we can use the maximum likelihood. First we project each sample to its ‘odds’ (i.e. the value of \\(y\\) on the linear line)."
  },
  {
    "objectID": "lecture-2.html#back-to-the-probability-curve",
    "href": "lecture-2.html#back-to-the-probability-curve",
    "title": "Linear Models",
    "section": "Back to the probability curve",
    "text": "Back to the probability curve\n\nOur logistic or ‘sigmoid’ function:\n\\[\np = \\frac{1}{1 + e^{-(\\beta_0+\\beta_1x)}} = \\frac{e^{(\\beta_0+\\beta_1x)}}{1 + e^{(\\beta_0+\\beta_1x)}}\n\\]"
  },
  {
    "objectID": "lecture-2.html#likelihood",
    "href": "lecture-2.html#likelihood",
    "title": "Linear Models",
    "section": "Likelihood",
    "text": "Likelihood\nProbability of class 1\n\\[\np(1) = p\n\\]\nProbability of class 0 (or not class 1).\n\\[\np(0) = 1 - p\n\\]\nMaximum likelihood loss (which we wish to maximise), using the points on the probability curve:\n\\[ L = (0.9) + (0.89) + (0.6) + (1 - 0.4) + (1 - 0.2) + (1 - 0.05)\n\\]"
  },
  {
    "objectID": "lecture-2.html#optimising-the-curve",
    "href": "lecture-2.html#optimising-the-curve",
    "title": "Linear Models",
    "section": "Optimising the curve",
    "text": "Optimising the curve"
  },
  {
    "objectID": "lecture-2.html#binary-cross-entropy-1",
    "href": "lecture-2.html#binary-cross-entropy-1",
    "title": "Linear Models",
    "section": "Binary Cross-Entropy",
    "text": "Binary Cross-Entropy\nWe could still use MSE in order to compute our models loss. This may still work. But there is another objective function that we would use for binary classification problems: Binary Cross-entropy (BCE).\n\\[\n\\text{BCE}(X; \\beta_0, \\beta_1) = -(Y \\log(\\beta_0+\\beta_1*X) + (1 - Y) \\log(1- \\beta_0+\\beta_1*X))\n\\]\nIssues when using MSE for binary classification:\n\nMSE is non-convex for binary classification problems.\nMSE assumes the data was generated from a normal distribution, while binary classification problems form a Bernoulli distribution."
  },
  {
    "objectID": "lecture-4-reveal.html#problem-statement",
    "href": "lecture-4-reveal.html#problem-statement",
    "title": "Support Vector Machines",
    "section": "Problem Statement",
    "text": "Problem Statement"
  },
  {
    "objectID": "lecture-4-reveal.html#which-separator-is-best",
    "href": "lecture-4-reveal.html#which-separator-is-best",
    "title": "Support Vector Machines",
    "section": "Which separator is best?",
    "text": "Which separator is best?\n\nTo get to the point of create such a decision boundary, we are going to look at three methods that build off of one another. These are:\n\nMaximal Margin classifier (MMC).\nSupport Vector classifier (SVC).\nSupport Vector Machine (SVM).\n\nFor the maximal margin classifier, we wish to position the decision boundary directly in the centre of these classes (more on this in the next slides), thus `maximising the margin’. The constraint for this model to which we must optimise is:\n\\[\ny_i (\\beta_0 + x \\beta_1) \\geq M\n\\]\nwhere \\(y_i \\in [-1, 1]\\) (the label of the binary classification), and \\(M\\) is the margin between classes that we wish to maximise."
  },
  {
    "objectID": "lecture-4-reveal.html#a-1-dimensional-example",
    "href": "lecture-4-reveal.html#a-1-dimensional-example",
    "title": "Support Vector Machines",
    "section": "A 1-dimensional example",
    "text": "A 1-dimensional example"
  },
  {
    "objectID": "lecture-4-reveal.html#finding-the-best-separator",
    "href": "lecture-4-reveal.html#finding-the-best-separator",
    "title": "Support Vector Machines",
    "section": "Finding the best separator",
    "text": "Finding the best separator"
  },
  {
    "objectID": "lecture-4-reveal.html#widest-margin",
    "href": "lecture-4-reveal.html#widest-margin",
    "title": "Support Vector Machines",
    "section": "Widest margin",
    "text": "Widest margin"
  },
  {
    "objectID": "lecture-4-reveal.html#support-vectors",
    "href": "lecture-4-reveal.html#support-vectors",
    "title": "Support Vector Machines",
    "section": "Support vectors",
    "text": "Support vectors\n\nBias/Variance trade-off: If one of these support vectors changes then the maximal margin classifier will drastically change. This model has low bias, and high variance."
  },
  {
    "objectID": "lecture-4-reveal.html#accounting-for-miss-classifications",
    "href": "lecture-4-reveal.html#accounting-for-miss-classifications",
    "title": "Support Vector Machines",
    "section": "Accounting for miss-classifications",
    "text": "Accounting for miss-classifications\n\n\\[\ny_i (\\beta_0 + x \\beta_1) \\geq M (1 - \\varepsilon_i)\n\\]\nThis type of classifier is called the Support Vector Classifier with a soft-margin as it allows for miss-classifications to reduce the model’s variance.\nwhere \\(\\varepsilon_i\\) is the positive slack variable for each data point. In practice, the sum of all slack variables are bound by a user-defined norm: \\(\\sum_i \\varepsilon_i \\leq D\\), where \\(D\\) is the tolerance for violating the margin of the SVC hyperplane.\nThere are three scenarios given the slack variable:\n\n\\(\\varepsilon_i = 0\\) the data point lies on the correct side of the hyperplane and not within the margin (i.e. the point is correctly classified).\n\\(\\varepsilon_i &gt; 0\\) the point lies with the margin but on the correct side of the separator.\n\\(\\varepsilon_i &gt; 1\\) the point lies on the wrong side of the separator (i.e. that the data point is miss-classified).\n\nSolution of the optimisation problem can be re-framed as unknown parameters (\\(\\alpha\\)) of the function \\(f(x)\\) and the inner product to all other support vectors:\n\\[\nf(x) = \\beta_0 + \\sum_{i=1}^m \\alpha_i \\langle x, x_i \\rangle\n\\]\nAs the constant \\(\\beta_0\\) the number of allowed miss-classifications increases also."
  },
  {
    "objectID": "lecture-4-reveal.html#dimensional",
    "href": "lecture-4-reveal.html#dimensional",
    "title": "Support Vector Machines",
    "section": "1-dimensional",
    "text": "1-dimensional\n\n\n1 dimensional space with a 0-dimensional separator, a point.\nflat affine 0-dimensional subspace"
  },
  {
    "objectID": "lecture-4-reveal.html#dimensional-1",
    "href": "lecture-4-reveal.html#dimensional-1",
    "title": "Support Vector Machines",
    "section": "2-dimensional",
    "text": "2-dimensional\n\n\n2 dimensional space with a 1-dimensional separator, a line\nflat affine 1-dimensional subspace"
  },
  {
    "objectID": "lecture-4-reveal.html#dimensional-2",
    "href": "lecture-4-reveal.html#dimensional-2",
    "title": "Support Vector Machines",
    "section": "3-dimensional",
    "text": "3-dimensional\n\n\n3-dimensional space with a 2-dimensional seperator, a plane\nflat affine 2-dimensional subspace"
  },
  {
    "objectID": "lecture-4-reveal.html#dimensional-3",
    "href": "lecture-4-reveal.html#dimensional-3",
    "title": "Support Vector Machines",
    "section": "4+-dimensional",
    "text": "4+-dimensional\nHere we lose the ability to be able to visualise the space easily… but nevertheless we can still create a SVC model. The separator in this space we refer to as a hyperplane.\n\nSide note :B_block:\nTechnically all of the seperators in 1/2/3 dimensions can also be called hyperplanes, but we generally only this say this for 4+…"
  },
  {
    "objectID": "lecture-4-reveal.html#how-do-we-separate-this-space",
    "href": "lecture-4-reveal.html#how-do-we-separate-this-space",
    "title": "Support Vector Machines",
    "section": "How do we separate this space",
    "text": "How do we separate this space"
  },
  {
    "objectID": "lecture-4-reveal.html#add-dimensionality",
    "href": "lecture-4-reveal.html#add-dimensionality",
    "title": "Support Vector Machines",
    "section": "Add dimensionality",
    "text": "Add dimensionality\nWe’ll take this 1-dimensional space, and add another dimension where the y-axis is \\(x^2\\). Suddenly, we’re able to separate the space:"
  },
  {
    "objectID": "lecture-4-reveal.html#how-do-we-find-an-applicable-transformation",
    "href": "lecture-4-reveal.html#how-do-we-find-an-applicable-transformation",
    "title": "Support Vector Machines",
    "section": "How do we find an applicable transformation?",
    "text": "How do we find an applicable transformation?\nTo make the space linearly separable in the previous example, we transformed the data into a higher dimension with the \\(x^2\\) transformation. But how do we decide which transformation to apply?\nWe’ll look at two types of transformations:\n\nPolynomial Kernel\nRadial Basis Function (RBF) Kernel\n\nInstead of using the inner product, we now choose to use a kernel \\(K\\), and then our solution to the decision boundary looks like:\n\\[\nf(x) = \\beta_0 + \\sum_{i=1}^m \\alpha_i K(x, x_i)\n\\]\nThis then is our Support Vector Machine we have been working towards. The kernel in this case, allows the method to classify non-linear relationships, which just wasn’t possible with the maximal margin classifier or the support vector classifier."
  },
  {
    "objectID": "lecture-4-reveal.html#polynomial-kernel",
    "href": "lecture-4-reveal.html#polynomial-kernel",
    "title": "Support Vector Machines",
    "section": "Polynomial Kernel",
    "text": "Polynomial Kernel\n\\[\n(a \\times b + r)^d\n\\]\nWhere \\(r\\) and \\(d\\) are user-defined parameters to the kernel.\nWe show how, using this kernel, we needn’t explicitly transform the data to the higher dimensions as the kernel is equal to the dot product in these higher dimension feature spaces:\nFor convience, let \\(r = \\frac{1}{2}\\), and \\(d = 2\\). Expanding the brackets:\n\\[\n(a \\times b  + \\frac{1}{2})(a \\times b + \\frac{1}{2})\n\\]\nand simplifying to:\n\\[\nab + a^2 b^2 + \\frac{1}{4}\n\\]\nWhich can be represented as the dot product:\n\\[\n(a, a^2, \\frac{1}{4}) \\cdot (b, b^2, \\frac{1}{4})\n\\]\nwhere \\(a\\) is the coordinate of the first sample on the first dimension, \\(a^2\\) is the coordinate on the second dimension and so on. Since \\(\\frac{1}{4}\\) is present in both sides of the expression, we can drop this.\nTherefore we see that, instead of computing the dot product in the higher dimensions, it is sufficient to apply the kernel."
  },
  {
    "objectID": "lecture-4-reveal.html#radial-basis-function-kernel",
    "href": "lecture-4-reveal.html#radial-basis-function-kernel",
    "title": "Support Vector Machines",
    "section": "Radial Basis Function Kernel",
    "text": "Radial Basis Function Kernel\n\\[\ne^{-\\gamma(a - b)^2}\n\\]\nwhere \\(\\gamma\\) is the scale of the kernel. This kernel generalises to infinite dimensions, and we return to how this can be true at the end of the lecture."
  },
  {
    "objectID": "lecture-4-reveal.html#kernel-trick",
    "href": "lecture-4-reveal.html#kernel-trick",
    "title": "Support Vector Machines",
    "section": "Kernel Trick",
    "text": "Kernel Trick\nLet \\(\\phi(x)\\) be a function transformation into a higher dimension. So we would have the following equation to compute the relationship in the higher dimension space:\n\\[\n\\phi(x_i) \\cdot \\phi(x_j)\n\\]\nThe kernel trick is that we have a kernel function \\(K(x_i, x_j) = \\langle \\phi(x_i), \\phi(x_j) \\rangle\\) to which computes the relationship as if \\(x_i, x_j\\) was in a higher dimension, without needing to explicitly transformation \\(x_i, x_j\\) to these higher dimensional feature spaces!"
  },
  {
    "objectID": "lecture-4-reveal.html#how-the-rbf-works-in-infinite-dimensions",
    "href": "lecture-4-reveal.html#how-the-rbf-works-in-infinite-dimensions",
    "title": "Support Vector Machines",
    "section": "How the RBF works in infinite dimensions",
    "text": "How the RBF works in infinite dimensions\nWe are going to take a look at an interesting aspect of the RBF kernel: how does it work in infinite dimensions? But first, we’ll revisit the polynomial kernel. Let’s take our polynomial kernel with \\(r = 0\\), we have:\n\\[\n(a \\times b + r)^d = a^d b^d\n\\]\nAll this does is scale the space on the one dimension.\nBut we can also add multiple polynomial kernels with different values for \\(d\\).\n\\[\na^1b^1 + a^2b^2 + ... + a^\\infty b^\\infty\n\\]\nAnd it continues to scale the space to infinity. We shall show how the RBF kernel works in very much this way.\nLet’s first take our RBF kernel and expand the brackets and simplify:\n\\[\\begin{align}e^{-\\gamma(a-b)^2} &= e^{-\\gamma(a^2-ab+b^2-ab)} \\\\\n&= e^{-\\gamma(a^2 - ab + b^2 - ab)} \\\\\n&= e^{-\\gamma(a^2 + b^2)} e^{\\gamma 2ab}\\end{align}\\]\nSetting \\(\\gamma = \\frac{1}{2}\\) to remove the 2 from the second term we have:\n\\[\ne^{-\\gamma(a^2+b^2)}e^{ab}\n\\]\nWe can use taylor series expansion (a function is equal to an infinite sum) on the second term. For example, we have the taylor series expansion for some function \\(f\\):\n\\[\nf(x) = f(a) + \\frac{f'(a)}{1 !} (x - a) + \\frac{f''(a)}{2 !} (x - a)^2 +\n... \\frac{f^\\infty(a)}{\\infty !}(x - a)^\\infty\n\\]\nThe same can be done for an exponential where the \\(\\frac{d}{dx} e^x = e^x\\):\n\\[\ne^x = e^a + \\frac{e^a}{1!} (x - a) + \\frac{e^a}{2!} (x - a)^2 + ... + \\frac{e^a}{\\infty!}(x-a)^\\infty\n\\]\nBut what is \\(a\\)? A can be anything so long as \\(f(a)\\) exists. So let’s choose something that makes our life simpler. We know that \\(e^0 = 1\\), so let \\(a = 0\\) :\n\\[\ne^x = 1 + \\frac{1}{1!} x + \\frac{1}{2!} x^2 + ... + \\frac{1}{\\infty!}x^\\infty\n\\]\nthus, going back our RBF kernel we have:\n\\[\ne^{ab} = 1 + \\frac{1}{1!} ab + \\frac{1}{2!} (ab)^2 + ... + \\frac{1}{\\infty!}(ab)^\\infty\n\\]\nThis looks very much like what the polynomial kernel was doing! Then if we take this term and position it in terms of a dot product instead we have:\n\\[\ne^{ab} = \\left( 1, \\sqrt{\\frac{1}{1!}}a, \\sqrt{\\frac{1}{2!}}a^2, ...,\n\\sqrt{\\frac{1}{\\infty!}}a^\\infty \\right) \\cdot \\left( 1, \\sqrt{\\frac{1}{1!}}b, \\sqrt{\\frac{1}{2!}}b^2, ...,\n\\sqrt{\\frac{1}{\\infty!}}b^\\infty \\right)\n\\]\nAnd we can add the left term in terms of a dot product \\(\\sqrt{e^{-\\frac{1}{2}(a^2 + b^2)}}\\), which conciseness, we’ll refer to as \\(s\\)\n\\[\ne^{-\\frac{1}{2}(a^2+b^2)}e^{ab} =\n\\]\n\\[\n\\left( s, s\\sqrt{\\frac{1}{1!}}a, s\\sqrt{\\frac{1}{2!}}a^2, ...,\ns\\sqrt{\\frac{1}{\\infty!}}a^\\infty \\right) \\cdot \\left( s, s\\sqrt{\\frac{1}{1!}}b, s\\sqrt{\\frac{1}{2!}}b^2, ...,\ns\\sqrt{\\frac{1}{\\infty!}}b^\\infty \\right)\n\\]"
  },
  {
    "objectID": "lecture-4.html",
    "href": "lecture-4.html",
    "title": "Support Vector Machines",
    "section": "",
    "text": "To get to the point of create such a decision boundary, we are going to look at three methods that build off of one another. These are:\n\nMaximal Margin classifier (MMC).\nSupport Vector classifier (SVC).\nSupport Vector Machine (SVM).\n\nFor the maximal margin classifier, we wish to position the decision boundary directly in the centre of these classes (more on this in the next slides), thus `maximising the margin’. The constraint for this model to which we must optimise is:\n\\[\ny_i (\\beta_0 + x \\beta_1) \\geq M\n\\]\nwhere \\(y_i \\in [-1, 1]\\) (the label of the binary classification), and \\(M\\) is the margin between classes that we wish to maximise."
  },
  {
    "objectID": "lecture-4.html#which-separator-is-best",
    "href": "lecture-4.html#which-separator-is-best",
    "title": "Support Vector Machines",
    "section": "",
    "text": "To get to the point of create such a decision boundary, we are going to look at three methods that build off of one another. These are:\n\nMaximal Margin classifier (MMC).\nSupport Vector classifier (SVC).\nSupport Vector Machine (SVM).\n\nFor the maximal margin classifier, we wish to position the decision boundary directly in the centre of these classes (more on this in the next slides), thus `maximising the margin’. The constraint for this model to which we must optimise is:\n\\[\ny_i (\\beta_0 + x \\beta_1) \\geq M\n\\]\nwhere \\(y_i \\in [-1, 1]\\) (the label of the binary classification), and \\(M\\) is the margin between classes that we wish to maximise."
  },
  {
    "objectID": "lecture-4.html#finding-the-best-separator",
    "href": "lecture-4.html#finding-the-best-separator",
    "title": "Support Vector Machines",
    "section": "Finding the best separator",
    "text": "Finding the best separator"
  },
  {
    "objectID": "lecture-4.html#widest-margin",
    "href": "lecture-4.html#widest-margin",
    "title": "Support Vector Machines",
    "section": "Widest margin",
    "text": "Widest margin"
  },
  {
    "objectID": "lecture-4.html#support-vectors",
    "href": "lecture-4.html#support-vectors",
    "title": "Support Vector Machines",
    "section": "Support vectors",
    "text": "Support vectors\n\nBias/Variance trade-off: If one of these support vectors changes then the maximal margin classifier will drastically change. This model has low bias, and high variance."
  },
  {
    "objectID": "lecture-4.html#accounting-for-miss-classifications",
    "href": "lecture-4.html#accounting-for-miss-classifications",
    "title": "Support Vector Machines",
    "section": "Accounting for miss-classifications",
    "text": "Accounting for miss-classifications\n\n\\[\ny_i (\\beta_0 + x \\beta_1) \\geq M (1 - \\varepsilon_i)\n\\]\nThis type of classifier is called the Support Vector Classifier with a soft-margin as it allows for miss-classifications to reduce the model’s variance.\nwhere \\(\\varepsilon_i\\) is the positive slack variable for each data point. In practice, the sum of all slack variables are bound by a user-defined norm: \\(\\sum_i \\varepsilon_i \\leq D\\), where \\(D\\) is the tolerance for violating the margin of the SVC hyperplane.\nThere are three scenarios given the slack variable:\n\n\\(\\varepsilon_i = 0\\) the data point lies on the correct side of the hyperplane and not within the margin (i.e. the point is correctly classified).\n\\(\\varepsilon_i &gt; 0\\) the point lies with the margin but on the correct side of the separator.\n\\(\\varepsilon_i &gt; 1\\) the point lies on the wrong side of the separator (i.e. that the data point is miss-classified).\n\nSolution of the optimisation problem can be re-framed as unknown parameters (\\(\\alpha\\)) of the function \\(f(x)\\) and the inner product to all other support vectors:\n\\[\nf(x) = \\beta_0 + \\sum_{i=1}^m \\alpha_i \\langle x, x_i \\rangle\n\\]\nAs the constant \\(\\beta_0\\) the number of allowed miss-classifications increases also."
  },
  {
    "objectID": "lecture-4.html#dimensional",
    "href": "lecture-4.html#dimensional",
    "title": "Support Vector Machines",
    "section": "1-dimensional",
    "text": "1-dimensional\n\n\n1 dimensional space with a 0-dimensional separator, a point.\nflat affine 0-dimensional subspace"
  },
  {
    "objectID": "lecture-4.html#dimensional-1",
    "href": "lecture-4.html#dimensional-1",
    "title": "Support Vector Machines",
    "section": "2-dimensional",
    "text": "2-dimensional\n\n\n2 dimensional space with a 1-dimensional separator, a line\nflat affine 1-dimensional subspace"
  },
  {
    "objectID": "lecture-4.html#dimensional-2",
    "href": "lecture-4.html#dimensional-2",
    "title": "Support Vector Machines",
    "section": "3-dimensional",
    "text": "3-dimensional\n\n\n3-dimensional space with a 2-dimensional seperator, a plane\nflat affine 2-dimensional subspace"
  },
  {
    "objectID": "lecture-4.html#dimensional-3",
    "href": "lecture-4.html#dimensional-3",
    "title": "Support Vector Machines",
    "section": "4+-dimensional",
    "text": "4+-dimensional\nHere we lose the ability to be able to visualise the space easily… but nevertheless we can still create a SVC model. The separator in this space we refer to as a hyperplane.\n\nSide note :B_block:\nTechnically all of the seperators in 1/2/3 dimensions can also be called hyperplanes, but we generally only this say this for 4+…"
  },
  {
    "objectID": "lecture-4.html#how-do-we-separate-this-space",
    "href": "lecture-4.html#how-do-we-separate-this-space",
    "title": "Support Vector Machines",
    "section": "How do we separate this space",
    "text": "How do we separate this space"
  },
  {
    "objectID": "lecture-4.html#add-dimensionality",
    "href": "lecture-4.html#add-dimensionality",
    "title": "Support Vector Machines",
    "section": "Add dimensionality",
    "text": "Add dimensionality\nWe’ll take this 1-dimensional space, and add another dimension where the y-axis is \\(x^2\\). Suddenly, we’re able to separate the space:"
  },
  {
    "objectID": "lecture-4.html#how-do-we-find-an-applicable-transformation",
    "href": "lecture-4.html#how-do-we-find-an-applicable-transformation",
    "title": "Support Vector Machines",
    "section": "How do we find an applicable transformation?",
    "text": "How do we find an applicable transformation?\nTo make the space linearly separable in the previous example, we transformed the data into a higher dimension with the \\(x^2\\) transformation. But how do we decide which transformation to apply?\nWe’ll look at two types of transformations:\n\nPolynomial Kernel\nRadial Basis Function (RBF) Kernel\n\nInstead of using the inner product, we now choose to use a kernel \\(K\\), and then our solution to the decision boundary looks like:\n\\[\nf(x) = \\beta_0 + \\sum_{i=1}^m \\alpha_i K(x, x_i)\n\\]\nThis then is our Support Vector Machine we have been working towards. The kernel in this case, allows the method to classify non-linear relationships, which just wasn’t possible with the maximal margin classifier or the support vector classifier."
  },
  {
    "objectID": "lecture-4.html#polynomial-kernel",
    "href": "lecture-4.html#polynomial-kernel",
    "title": "Support Vector Machines",
    "section": "Polynomial Kernel",
    "text": "Polynomial Kernel\n\\[\n(a \\times b + r)^d\n\\]\nWhere \\(r\\) and \\(d\\) are user-defined parameters to the kernel.\nWe show how, using this kernel, we needn’t explicitly transform the data to the higher dimensions as the kernel is equal to the dot product in these higher dimension feature spaces:\nFor convience, let \\(r = \\frac{1}{2}\\), and \\(d = 2\\). Expanding the brackets:\n\\[\n(a \\times b  + \\frac{1}{2})(a \\times b + \\frac{1}{2})\n\\]\nand simplifying to:\n\\[\nab + a^2 b^2 + \\frac{1}{4}\n\\]\nWhich can be represented as the dot product:\n\\[\n(a, a^2, \\frac{1}{4}) \\cdot (b, b^2, \\frac{1}{4})\n\\]\nwhere \\(a\\) is the coordinate of the first sample on the first dimension, \\(a^2\\) is the coordinate on the second dimension and so on. Since \\(\\frac{1}{4}\\) is present in both sides of the expression, we can drop this.\nTherefore we see that, instead of computing the dot product in the higher dimensions, it is sufficient to apply the kernel."
  },
  {
    "objectID": "lecture-4.html#radial-basis-function-kernel",
    "href": "lecture-4.html#radial-basis-function-kernel",
    "title": "Support Vector Machines",
    "section": "Radial Basis Function Kernel",
    "text": "Radial Basis Function Kernel\n\\[\ne^{-\\gamma(a - b)^2}\n\\]\nwhere \\(\\gamma\\) is the scale of the kernel. This kernel generalises to infinite dimensions, and we return to how this can be true at the end of the lecture."
  },
  {
    "objectID": "lecture-4.html#kernel-trick",
    "href": "lecture-4.html#kernel-trick",
    "title": "Support Vector Machines",
    "section": "Kernel Trick",
    "text": "Kernel Trick\nLet \\(\\phi(x)\\) be a function transformation into a higher dimension. So we would have the following equation to compute the relationship in the higher dimension space:\n\\[\n\\phi(x_i) \\cdot \\phi(x_j)\n\\]\nThe kernel trick is that we have a kernel function \\(K(x_i, x_j) = \\langle \\phi(x_i), \\phi(x_j) \\rangle\\) to which computes the relationship as if \\(x_i, x_j\\) was in a higher dimension, without needing to explicitly transformation \\(x_i, x_j\\) to these higher dimensional feature spaces!"
  },
  {
    "objectID": "lecture-4.html#how-the-rbf-works-in-infinite-dimensions",
    "href": "lecture-4.html#how-the-rbf-works-in-infinite-dimensions",
    "title": "Support Vector Machines",
    "section": "How the RBF works in infinite dimensions",
    "text": "How the RBF works in infinite dimensions\nWe are going to take a look at an interesting aspect of the RBF kernel: how does it work in infinite dimensions? But first, we’ll revisit the polynomial kernel. Let’s take our polynomial kernel with \\(r = 0\\), we have:\n\\[\n(a \\times b + r)^d = a^d b^d\n\\]\nAll this does is scale the space on the one dimension.\nBut we can also add multiple polynomial kernels with different values for \\(d\\).\n\\[\na^1b^1 + a^2b^2 + ... + a^\\infty b^\\infty\n\\]\nAnd it continues to scale the space to infinity. We shall show how the RBF kernel works in very much this way.\nLet’s first take our RBF kernel and expand the brackets and simplify:\n\\[\\begin{align}e^{-\\gamma(a-b)^2} &= e^{-\\gamma(a^2-ab+b^2-ab)} \\\\\n&= e^{-\\gamma(a^2 - ab + b^2 - ab)} \\\\\n&= e^{-\\gamma(a^2 + b^2)} e^{\\gamma 2ab}\\end{align}\\]\nSetting \\(\\gamma = \\frac{1}{2}\\) to remove the 2 from the second term we have:\n\\[\ne^{-\\gamma(a^2+b^2)}e^{ab}\n\\]\nWe can use taylor series expansion (a function is equal to an infinite sum) on the second term. For example, we have the taylor series expansion for some function \\(f\\):\n\\[\nf(x) = f(a) + \\frac{f'(a)}{1 !} (x - a) + \\frac{f''(a)}{2 !} (x - a)^2 +\n... \\frac{f^\\infty(a)}{\\infty !}(x - a)^\\infty\n\\]\nThe same can be done for an exponential where the \\(\\frac{d}{dx} e^x = e^x\\):\n\\[\ne^x = e^a + \\frac{e^a}{1!} (x - a) + \\frac{e^a}{2!} (x - a)^2 + ... + \\frac{e^a}{\\infty!}(x-a)^\\infty\n\\]\nBut what is \\(a\\)? A can be anything so long as \\(f(a)\\) exists. So let’s choose something that makes our life simpler. We know that \\(e^0 = 1\\), so let \\(a = 0\\) :\n\\[\ne^x = 1 + \\frac{1}{1!} x + \\frac{1}{2!} x^2 + ... + \\frac{1}{\\infty!}x^\\infty\n\\]\nthus, going back our RBF kernel we have:\n\\[\ne^{ab} = 1 + \\frac{1}{1!} ab + \\frac{1}{2!} (ab)^2 + ... + \\frac{1}{\\infty!}(ab)^\\infty\n\\]\nThis looks very much like what the polynomial kernel was doing! Then if we take this term and position it in terms of a dot product instead we have:\n\\[\ne^{ab} = \\left( 1, \\sqrt{\\frac{1}{1!}}a, \\sqrt{\\frac{1}{2!}}a^2, ...,\n\\sqrt{\\frac{1}{\\infty!}}a^\\infty \\right) \\cdot \\left( 1, \\sqrt{\\frac{1}{1!}}b, \\sqrt{\\frac{1}{2!}}b^2, ...,\n\\sqrt{\\frac{1}{\\infty!}}b^\\infty \\right)\n\\]\nAnd we can add the left term in terms of a dot product \\(\\sqrt{e^{-\\frac{1}{2}(a^2 + b^2)}}\\), which conciseness, we’ll refer to as \\(s\\)\n\\[\ne^{-\\frac{1}{2}(a^2+b^2)}e^{ab} =\n\\]\n\\[\n\\left( s, s\\sqrt{\\frac{1}{1!}}a, s\\sqrt{\\frac{1}{2!}}a^2, ...,\ns\\sqrt{\\frac{1}{\\infty!}}a^\\infty \\right) \\cdot \\left( s, s\\sqrt{\\frac{1}{1!}}b, s\\sqrt{\\frac{1}{2!}}b^2, ...,\ns\\sqrt{\\frac{1}{\\infty!}}b^\\infty \\right)\n\\]"
  }
]